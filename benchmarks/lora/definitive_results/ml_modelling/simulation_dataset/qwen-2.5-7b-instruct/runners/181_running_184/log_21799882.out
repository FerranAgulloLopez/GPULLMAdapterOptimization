INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 17.044406339991838,
    "estimated_duration": 3600.1944658425205,
    "input_throughput": 4623.044437713447,
    "output_throughput": 4078.1602603136234,
    "total_throughput": 8701.204698027072,
    "itl": 210.07982405379073,
    "ttft": 2220168.226910057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0183084295806535,
    "arrivals": 1577546,
    "finished_requests": 67486,
    "scheduler_time": 103.89640455581207
}
#Debug simulation 
Total elapsed time: 17.04457182297483. Arrivals time: 0.7284156689420342 Scheduler time: 16.207110946998 Scheduler overhead time: 0.035881801042705774 Adapter cache time: 0.02345628058537841 Engine time: 0.035584105644375086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.299598705023527,
    "estimated_duration": 3600.021215629264,
    "input_throughput": 4429.4952848528355,
    "output_throughput": 3915.7874789179364,
    "total_throughput": 8345.282763770772,
    "itl": 179.2441577329065,
    "ttft": 2238906.2369072153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.941071478836183,
    "arrivals": 1577546,
    "finished_requests": 64663,
    "scheduler_time": 109.04557218833526
}
#Debug simulation 
Total elapsed time: 10.299748419318348. Arrivals time: 0.2764306631870568 Scheduler time: 9.902347103692591 Scheduler overhead time: 0.035411789547652006 Adapter cache time: 0.03518658457323909 Engine time: 0.034907442051917315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 16.69314280198887,
    "estimated_duration": 3600.0633529628462,
    "input_throughput": 4623.212807158555,
    "output_throughput": 4078.3087852930694,
    "total_throughput": 8701.521592451625,
    "itl": 210.07279243434488,
    "ttft": 2220118.884301054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8875579276797065,
    "arrivals": 1577546,
    "finished_requests": 67486,
    "scheduler_time": 103.89604217799997
}
#Debug simulation 
Total elapsed time: 16.693241181783378. Arrivals time: 0.4699081680737436 Scheduler time: 16.11369439167902 Scheduler overhead time: 0.03565787384286523 Adapter cache time: 0.023718551732599735 Engine time: 0.03613105323165655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.544237763155252,
    "estimated_duration": 3600.086591961134,
    "input_throughput": 4429.414846744929,
    "output_throughput": 3915.7163695667537,
    "total_throughput": 8345.131216311682,
    "itl": 179.24722758001965,
    "ttft": 2238928.3374196356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.006337693985505,
    "arrivals": 1577546,
    "finished_requests": 64663,
    "scheduler_time": 109.04568230512821
}
#Debug simulation 
Total elapsed time: 10.544367517344654. Arrivals time: 0.27825738582760096 Scheduler time: 10.144659000448883 Scheduler overhead time: 0.03536876570433378 Adapter cache time: 0.03540917159989476 Engine time: 0.035302740056067705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 16.78901655273512,
    "estimated_duration": 3600.2074232820255,
    "input_throughput": 4618.669994530873,
    "output_throughput": 4078.781379383229,
    "total_throughput": 8697.451373914102,
    "itl": 210.15814626146405,
    "ttft": 2220210.9258615714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8704482831060236,
    "arrivals": 1577546,
    "finished_requests": 67467,
    "scheduler_time": 103.89119363111531
}
#Debug simulation 
Total elapsed time: 16.78911220189184. Arrivals time: 0.4809612361714244 Scheduler time: 16.197672518901527 Scheduler overhead time: 0.03576454380527139 Adapter cache time: 0.025243204087018967 Engine time: 0.03532885201275349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.537168248090893,
    "estimated_duration": 3600.147946091091,
    "input_throughput": 4429.339360154319,
    "output_throughput": 3915.6496374839035,
    "total_throughput": 8344.988997638224,
    "itl": 179.25006576395833,
    "ttft": 2238949.035647558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.067579787969546,
    "arrivals": 1577546,
    "finished_requests": 64663,
    "scheduler_time": 109.0457943411681
}
#Debug simulation 
Total elapsed time: 10.537310769315809. Arrivals time: 0.44663727609440684 Scheduler time: 9.96874090936035 Scheduler overhead time: 0.03560397867113352 Adapter cache time: 0.03558465978130698 Engine time: 0.03534963261336088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.141181621234864,
    "estimated_duration": 3600.0276871571145,
    "input_throughput": 4652.133387681105,
    "output_throughput": 4072.2553474517736,
    "total_throughput": 8724.388735132878,
    "itl": 209.29851346777787,
    "ttft": 2217594.6916364627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.512660437768842,
    "arrivals": 1558275,
    "finished_requests": 67607,
    "scheduler_time": 103.9829964705082
}
#Debug simulation 
Total elapsed time: 15.14130631601438. Arrivals time: 0.3043048856779933 Scheduler time: 14.730390242766589 Scheduler overhead time: 0.034753196872770786 Adapter cache time: 0.02270402666181326 Engine time: 0.03494734223932028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 15.559276276268065,
    "estimated_duration": 3600.201019499258,
    "input_throughput": 4650.7175319695925,
    "output_throughput": 4076.544593068666,
    "total_throughput": 8727.262125038258,
    "itl": 209.432079152677,
    "ttft": 2216896.8138869503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.72890402018326,
    "arrivals": 1558275,
    "finished_requests": 67599,
    "scheduler_time": 103.9695099059068
}
#Debug simulation 
Total elapsed time: 15.559446409344673. Arrivals time: 0.30113305849954486 Scheduler time: 15.152300947345793 Scheduler overhead time: 0.03521360084414482 Adapter cache time: 0.02242535911500454 Engine time: 0.03438546322286129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.690084364265203,
    "estimated_duration": 3600.0579388054716,
    "input_throughput": 4465.697850778036,
    "output_throughput": 3912.7823050186603,
    "total_throughput": 8378.480155796697,
    "itl": 178.34717102653178,
    "ttft": 2238217.959096547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.169844882488189,
    "arrivals": 1558275,
    "finished_requests": 64880,
    "scheduler_time": 109.20137503904643
}
#Debug simulation 
Total elapsed time: 9.690179293975234. Arrivals time: 0.37717629689723253 Scheduler time: 9.197529223747551 Scheduler overhead time: 0.034672499634325504 Adapter cache time: 0.03134157136082649 Engine time: 0.03407936030998826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 15.182979362085462,
    "estimated_duration": 3600.0832512314487,
    "input_throughput": 4652.061586151161,
    "output_throughput": 4072.19249582223,
    "total_throughput": 8724.25408197339,
    "itl": 209.3012489011676,
    "ttft": 2217615.81477073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5680121953226394,
    "arrivals": 1558275,
    "finished_requests": 67607,
    "scheduler_time": 103.98320878720048
}
#Debug simulation 
Total elapsed time: 15.183156546205282. Arrivals time: 0.30833788216114044 Scheduler time: 14.768133400473744 Scheduler overhead time: 0.03500940790399909 Adapter cache time: 0.0225574835203588 Engine time: 0.03494185581803322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.612314393743873,
    "estimated_duration": 3600.1111079036746,
    "input_throughput": 4465.631898055895,
    "output_throughput": 3912.7245181614253,
    "total_throughput": 8378.35641621732,
    "itl": 178.34965804933586,
    "ttft": 2238238.308705635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.222912980355307,
    "arrivals": 1558275,
    "finished_requests": 64880,
    "scheduler_time": 109.20147603941642
}
#Debug simulation 
Total elapsed time: 9.612407637760043. Arrivals time: 0.26824830938130617 Scheduler time: 9.227836524136364 Scheduler overhead time: 0.03474542452022433 Adapter cache time: 0.03141655446961522 Engine time: 0.03475314658135176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.228807976003736,
    "estimated_duration": 3600.211763793944,
    "input_throughput": 4652.438828306284,
    "output_throughput": 4072.3223970997296,
    "total_throughput": 8724.761225406015,
    "itl": 209.296406307158,
    "ttft": 2217619.207295018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.454831292114636,
    "arrivals": 1558275,
    "finished_requests": 67613,
    "scheduler_time": 103.98975228611718
}
#Debug simulation 
Total elapsed time: 15.228959894739091. Arrivals time: 0.30492824828252196 Scheduler time: 14.816890918649733 Scheduler overhead time: 0.03632726799696684 Adapter cache time: 0.022316550370305777 Engine time: 0.03451764862984419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.645964332856238,
    "estimated_duration": 3600.1660711417053,
    "input_throughput": 4465.563721870653,
    "output_throughput": 3912.664783136765,
    "total_throughput": 8378.228505007419,
    "itl": 178.3521958117951,
    "ttft": 2238259.263088107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.277741631232235,
    "arrivals": 1558275,
    "finished_requests": 64880,
    "scheduler_time": 109.20161062660782
}
#Debug simulation 
Total elapsed time: 9.646080303937197. Arrivals time: 0.27334207808598876 Scheduler time: 9.256633277516812 Scheduler overhead time: 0.034570842515677214 Adapter cache time: 0.03163647651672363 Engine time: 0.034402632620185614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.299324289895594,
    "estimated_duration": 3600.148510575182,
    "input_throughput": 4642.730973709077,
    "output_throughput": 4082.083546506824,
    "total_throughput": 8724.814520215901,
    "itl": 209.86595150459272,
    "ttft": 2221955.9703685874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.120918006545436,
    "arrivals": 1548789,
    "finished_requests": 67614,
    "scheduler_time": 103.94658264226314
}
#Debug simulation 
Total elapsed time: 14.299464977812022. Arrivals time: 0.4285423387773335 Scheduler time: 13.770767713431269 Scheduler overhead time: 0.033572022803127766 Adapter cache time: 0.018843181896954775 Engine time: 0.03392742108553648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.320906409993768,
    "estimated_duration": 3600.062754328038,
    "input_throughput": 4642.219077961433,
    "output_throughput": 4081.844679605549,
    "total_throughput": 8724.06375756698,
    "itl": 209.8733486873048,
    "ttft": 2221984.781281114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.261154603739276,
    "arrivals": 1548789,
    "finished_requests": 67607,
    "scheduler_time": 103.94041946572729
}
#Debug simulation 
Total elapsed time: 14.321003193035722. Arrivals time: 0.308633373118937 Scheduler time: 13.909210766665637 Scheduler overhead time: 0.0343540096655488 Adapter cache time: 0.019556002225726843 Engine time: 0.03492806712165475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.595757680945098,
    "estimated_duration": 3600.0157918867862,
    "input_throughput": 4442.511623433165,
    "output_throughput": 3916.619485885693,
    "total_throughput": 8359.131109318858,
    "itl": 179.19898867838234,
    "ttft": 2241859.420062867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.508176673296793,
    "arrivals": 1548789,
    "finished_requests": 64701,
    "scheduler_time": 109.08496453489225
}
#Debug simulation 
Total elapsed time: 9.595897002145648. Arrivals time: 0.7072166940197349 Scheduler time: 8.777242808137089 Scheduler overhead time: 0.034196887630969286 Adapter cache time: 0.027369447983801365 Engine time: 0.03457641368731856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.146568873897195,
    "estimated_duration": 3600.19423576167,
    "input_throughput": 4642.672007518455,
    "output_throughput": 4082.031700962056,
    "total_throughput": 8724.70370848051,
    "itl": 209.86824138529346,
    "ttft": 2221974.9279870293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1664903729269116,
    "arrivals": 1548789,
    "finished_requests": 67614,
    "scheduler_time": 103.94673546230042
}
#Debug simulation 
Total elapsed time: 14.146676043979824. Arrivals time: 0.30284065566956997 Scheduler time: 13.741986305452883 Scheduler overhead time: 0.0341796949505806 Adapter cache time: 0.019578364212065935 Engine time: 0.03411487443372607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.240675668232143,
    "estimated_duration": 3600.062296873971,
    "input_throughput": 4442.454235830097,
    "output_throughput": 3916.5688916670438,
    "total_throughput": 8359.023127497141,
    "itl": 179.2011420521974,
    "ttft": 2241877.3348690504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.554579820483925,
    "arrivals": 1548789,
    "finished_requests": 64701,
    "scheduler_time": 109.0850663749328
}
#Debug simulation 
Total elapsed time: 9.24082237901166. Arrivals time: 0.37952230172231793 Scheduler time: 8.749225750565529 Scheduler overhead time: 0.03495306055992842 Adapter cache time: 0.0275524421595037 Engine time: 0.03421409334987402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.08963014325127,
    "estimated_duration": 3600.0995148547327,
    "input_throughput": 4642.794159170471,
    "output_throughput": 4082.1391018111904,
    "total_throughput": 8724.933260981661,
    "itl": 209.86349424338582,
    "ttft": 2221936.1262133587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.072104854367171,
    "arrivals": 1548789,
    "finished_requests": 67614,
    "scheduler_time": 103.94640007389836
}
#Debug simulation 
Total elapsed time: 14.089747834950686. Arrivals time: 0.3002280294895172 Scheduler time: 13.688818279653788 Scheduler overhead time: 0.034155687782913446 Adapter cache time: 0.018432716839015484 Engine time: 0.03425174858421087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.602601347025484,
    "estimated_duration": 3600.106422495314,
    "input_throughput": 4442.399785758227,
    "output_throughput": 3916.520887242842,
    "total_throughput": 8358.920673001068,
    "itl": 179.20315189121268,
    "ttft": 2241894.7765896795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.598593645729174,
    "arrivals": 1548789,
    "finished_requests": 64701,
    "scheduler_time": 109.08517817106681
}
#Debug simulation 
Total elapsed time: 9.602736238855869. Arrivals time: 0.7206761208362877 Scheduler time: 8.770476683508605 Scheduler overhead time: 0.03408176591619849 Adapter cache time: 0.027728309854865074 Engine time: 0.03434374136850238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.952879949007183,
    "estimated_duration": 3600.1351160713853,
    "input_throughput": 4627.191608902294,
    "output_throughput": 4078.5597002878853,
    "total_throughput": 8705.75130919018,
    "itl": 209.9202774323843,
    "ttft": 2216670.3134604115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.925046790933733,
    "arrivals": 1544103,
    "finished_requests": 67447,
    "scheduler_time": 103.92721863095164
}
#Debug simulation 
Total elapsed time: 14.952945051714778. Arrivals time: 0.30767338909208775 Scheduler time: 14.543662312440574 Scheduler overhead time: 0.035439316648989916 Adapter cache time: 0.01762214070186019 Engine time: 0.034455031622201204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.938669305294752,
    "estimated_duration": 3600.022210069046,
    "input_throughput": 4627.143675227635,
    "output_throughput": 4078.419838337164,
    "total_throughput": 8705.563513564799,
    "itl": 209.9255005061042,
    "ttft": 2216646.976058958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.051534478601539,
    "arrivals": 1544103,
    "finished_requests": 67440,
    "scheduler_time": 103.92086836656094
}
#Debug simulation 
Total elapsed time: 14.938835508190095. Arrivals time: 0.3033888968639076 Scheduler time: 14.532567876856774 Scheduler overhead time: 0.03548115352168679 Adapter cache time: 0.017816432286053896 Engine time: 0.035620009526610374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.68230699095875,
    "estimated_duration": 3600.1280566573255,
    "input_throughput": 4347.1184229293785,
    "output_throughput": 3839.233433499948,
    "total_throughput": 8186.351856429326,
    "itl": 167.2891808896229,
    "ttft": 2247062.9612325504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.777535855863227,
    "arrivals": 1544103,
    "finished_requests": 63353,
    "scheduler_time": 111.59974440765004
}
#Debug simulation 
Total elapsed time: 9.682413786649704. Arrivals time: 0.2847397136501968 Scheduler time: 9.285791548900306 Scheduler overhead time: 0.03643794963136315 Adapter cache time: 0.023181953467428684 Engine time: 0.035972675774246454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.86489100009203,
    "estimated_duration": 3600.1751571626996,
    "input_throughput": 4627.140145350202,
    "output_throughput": 4078.5143386112277,
    "total_throughput": 8705.654483961429,
    "itl": 209.92226024025842,
    "ttft": 2216687.2773041516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9649122710921663,
    "arrivals": 1544103,
    "finished_requests": 67447,
    "scheduler_time": 103.92739424204629
}
#Debug simulation 
Total elapsed time: 14.865047478117049. Arrivals time: 0.307029246352613 Scheduler time: 14.457709973677993 Scheduler overhead time: 0.03435547975823283 Adapter cache time: 0.017594342585653067 Engine time: 0.03441826859489083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.470821485854685,
    "estimated_duration": 3600.1635136641166,
    "input_throughput": 4347.075609371922,
    "output_throughput": 3839.1956219601648,
    "total_throughput": 8186.271231332087,
    "itl": 167.29065948060207,
    "ttft": 2247077.0268109865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.812872669845823,
    "arrivals": 1544103,
    "finished_requests": 63353,
    "scheduler_time": 111.5998646004894
}
#Debug simulation 
Total elapsed time: 9.470942182932049. Arrivals time: 0.263783463742584 Scheduler time: 9.096208225935698 Scheduler overhead time: 0.03600588673725724 Adapter cache time: 0.023117744363844395 Engine time: 0.035668369848281145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.975992015562952,
    "estimated_duration": 3600.090619231238,
    "input_throughput": 4627.248800630817,
    "output_throughput": 4078.6101109686733,
    "total_throughput": 8705.85891159949,
    "itl": 209.9180820759534,
    "ttft": 2216652.738779659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8807416354934385,
    "arrivals": 1544103,
    "finished_requests": 67447,
    "scheduler_time": 103.92702694616392
}
#Debug simulation 
Total elapsed time: 14.97613922180608. Arrivals time: 0.32553412998095155 Scheduler time: 14.54854381782934 Scheduler overhead time: 0.03511599963530898 Adapter cache time: 0.017355347517877817 Engine time: 0.03548073722049594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.487010987009853,
    "estimated_duration": 3600.0131751896647,
    "input_throughput": 4347.071590696474,
    "output_throughput": 3839.324560047427,
    "total_throughput": 8186.396150743901,
    "itl": 167.2918543527743,
    "ttft": 2247095.065276459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.848586745187663,
    "arrivals": 1544103,
    "finished_requests": 63351,
    "scheduler_time": 111.59419194887904
}
#Debug simulation 
Total elapsed time: 9.487129522953182. Arrivals time: 0.2627494935877621 Scheduler time: 9.113010884728283 Scheduler overhead time: 0.036058430559933186 Adapter cache time: 0.023425799794495106 Engine time: 0.0357816512696445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.692798558156937,
    "estimated_duration": 3600.067622258833,
    "input_throughput": 4634.486557097355,
    "output_throughput": 4082.9983051199433,
    "total_throughput": 8717.484862217298,
    "itl": 209.78414964077945,
    "ttft": 2214219.61829921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.15764385947263,
    "arrivals": 1541713,
    "finished_requests": 67700,
    "scheduler_time": 103.95875979845464
}
#Debug simulation 
Total elapsed time: 12.692952175159007. Arrivals time: 0.3119821948930621 Scheduler time: 12.282891647424549 Scheduler overhead time: 0.03276222851127386 Adapter cache time: 0.01829641778022051 Engine time: 0.03321484476327896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.999944217968732,
    "estimated_duration": 3600.1604225201704,
    "input_throughput": 4631.654716188297,
    "output_throughput": 4084.2338324765637,
    "total_throughput": 8715.888548664861,
    "itl": 209.83943689901588,
    "ttft": 2213971.1195726623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3826697090617426,
    "arrivals": 1541713,
    "finished_requests": 67716,
    "scheduler_time": 103.95418374749795
}
#Debug simulation 
Total elapsed time: 13.000036644283682. Arrivals time: 0.2975441445596516 Scheduler time: 12.604311982169747 Scheduler overhead time: 0.03263110667467117 Adapter cache time: 0.019054594915360212 Engine time: 0.03277882840484381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.241305814124644,
    "estimated_duration": 3600.1389982018836,
    "input_throughput": 4432.662463302235,
    "output_throughput": 3920.2911351614866,
    "total_throughput": 8352.95359846372,
    "itl": 179.26710957786437,
    "ttft": 2233671.1127363946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9747638856618974,
    "arrivals": 1541713,
    "finished_requests": 64907,
    "scheduler_time": 109.0099499659395
}
#Debug simulation 
Total elapsed time: 8.241409257054329. Arrivals time: 0.2625691508874297 Scheduler time: 7.8670681533403695 Scheduler overhead time: 0.03354168031364679 Adapter cache time: 0.029649971518665552 Engine time: 0.03335673548281193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.759600571356714,
    "estimated_duration": 3600.112141821697,
    "input_throughput": 4634.4292462949425,
    "output_throughput": 4082.9478141095087,
    "total_throughput": 8717.377060404451,
    "itl": 209.786296374529,
    "ttft": 2214237.2234010804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2019623811472964,
    "arrivals": 1541713,
    "finished_requests": 67700,
    "scheduler_time": 103.95896083957119
}
#Debug simulation 
Total elapsed time: 12.759694474283606. Arrivals time: 0.41096755117177963 Scheduler time: 12.251036236993968 Scheduler overhead time: 0.03274174872785807 Adapter cache time: 0.018225273583084345 Engine time: 0.03299110848456621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.229286493267864,
    "estimated_duration": 3600.1920485035484,
    "input_throughput": 4432.597146208677,
    "output_throughput": 3920.233368068917,
    "total_throughput": 8352.830514277593,
    "itl": 179.2695687729125,
    "ttft": 2233690.5042845933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.02770622974262,
    "arrivals": 1541713,
    "finished_requests": 64907,
    "scheduler_time": 109.01005792357964
}
#Debug simulation 
Total elapsed time: 8.229404878336936. Arrivals time: 0.26381108025088906 Scheduler time: 7.854333695024252 Scheduler overhead time: 0.033560892567038536 Adapter cache time: 0.029633599799126387 Engine time: 0.032972031738609076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.639166118111461,
    "estimated_duration": 3600.0177787699863,
    "input_throughput": 4634.550723163528,
    "output_throughput": 4083.054835640899,
    "total_throughput": 8717.605558804427,
    "itl": 209.78167934781112,
    "ttft": 2214200.413236038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.107985457905996,
    "arrivals": 1541713,
    "finished_requests": 67700,
    "scheduler_time": 103.95857471107826
}
#Debug simulation 
Total elapsed time: 12.639271220192313. Arrivals time: 0.2997242040000856 Scheduler time: 12.242507350165397 Scheduler overhead time: 0.03269271505996585 Adapter cache time: 0.018170960247516632 Engine time: 0.03246183646842837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.184616946149617,
    "estimated_duration": 3600.043828666765,
    "input_throughput": 4432.7788103374105,
    "output_throughput": 3920.22893933116,
    "total_throughput": 8353.00774966857,
    "itl": 179.27109182812103,
    "ttft": 2233655.227418436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.076875960230882,
    "arrivals": 1541713,
    "finished_requests": 64904,
    "scheduler_time": 109.00415547122023
}
#Debug simulation 
Total elapsed time: 8.184708623215556. Arrivals time: 0.26509885024279356 Scheduler time: 7.808075563516468 Scheduler overhead time: 0.03349084686487913 Adapter cache time: 0.029816440772265196 Engine time: 0.03307315520942211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.725048813968897,
    "estimated_duration": 3600.1774268986487,
    "input_throughput": 4633.498859074317,
    "output_throughput": 4081.8132712584493,
    "total_throughput": 8715.312130332766,
    "itl": 210.0047986352946,
    "ttft": 2216679.205744266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7995667934324857,
    "arrivals": 1540502,
    "finished_requests": 67348,
    "scheduler_time": 103.93453382033434
}
#Debug simulation 
Total elapsed time: 12.725113885942847. Arrivals time: 0.7338165454566479 Scheduler time: 11.896402010228485 Scheduler overhead time: 0.03299156157299876 Adapter cache time: 0.015942913480103016 Engine time: 0.03243012260645628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.24648295296356,
    "estimated_duration": 3600.0693988522416,
    "input_throughput": 4633.466789645249,
    "output_throughput": 4081.8365903404424,
    "total_throughput": 8715.303379985691,
    "itl": 210.01013784800327,
    "ttft": 2216722.2525919103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9207705101417443,
    "arrivals": 1540502,
    "finished_requests": 67346,
    "scheduler_time": 103.92838728855044
}
#Debug simulation 
Total elapsed time: 12.246601373888552. Arrivals time: 0.2936477046459913 Scheduler time: 11.858024330344051 Scheduler overhead time: 0.03228916693478823 Adapter cache time: 0.016359852626919746 Engine time: 0.03274381719529629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.535203442443162,
    "estimated_duration": 3600.1418737532813,
    "input_throughput": 4448.864950786553,
    "output_throughput": 3915.9009545650274,
    "total_throughput": 8364.76590535158,
    "itl": 178.65582949461555,
    "ttft": 2238527.906934571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0885829422436353,
    "arrivals": 1540502,
    "finished_requests": 64627,
    "scheduler_time": 109.18637794817299
}
#Debug simulation 
Total elapsed time: 8.535294731147587. Arrivals time: 0.3744295206852257 Scheduler time: 8.054273671936244 Scheduler overhead time: 0.0335660120472312 Adapter cache time: 0.024505867157131433 Engine time: 0.03327978774905205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.351856002118438,
    "estimated_duration": 3600.21714294093,
    "input_throughput": 4633.447744313932,
    "output_throughput": 4081.768242455455,
    "total_throughput": 8715.215986769386,
    "itl": 210.00660430676757,
    "ttft": 2216697.91420756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.839051446453657,
    "arrivals": 1540502,
    "finished_requests": 67348,
    "scheduler_time": 103.93476520954306
}
#Debug simulation 
Total elapsed time: 12.352003986015916. Arrivals time: 0.293193397577852 Scheduler time: 11.962277537211776 Scheduler overhead time: 0.033420479856431484 Adapter cache time: 0.015919286757707596 Engine time: 0.03352508693933487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.894767719786614,
    "estimated_duration": 3600.181962418495,
    "input_throughput": 4448.8154118856155,
    "output_throughput": 3915.857350312793,
    "total_throughput": 8364.672762198408,
    "itl": 178.65765837155186,
    "ttft": 2238543.243814884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.128572646323593,
    "arrivals": 1540502,
    "finished_requests": 64627,
    "scheduler_time": 109.18647690934313
}
#Debug simulation 
Total elapsed time: 8.89483699761331. Arrivals time: 0.7116373712196946 Scheduler time: 8.076376528479159 Scheduler overhead time: 0.03375779138877988 Adapter cache time: 0.024051534477621317 Engine time: 0.033824147656559944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.310070592910051,
    "estimated_duration": 3600.135821712441,
    "input_throughput": 4633.552406382633,
    "output_throughput": 4081.8604429790803,
    "total_throughput": 8715.412849361714,
    "itl": 210.0027976028736,
    "ttft": 2216660.954370236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7581495734024537,
    "arrivals": 1540502,
    "finished_requests": 67348,
    "scheduler_time": 103.93434585408754
}
#Debug simulation 
Total elapsed time: 12.31014028005302. Arrivals time: 0.29168273229151964 Scheduler time: 11.92328448779881 Scheduler overhead time: 0.03270260477438569 Adapter cache time: 0.01628434658050537 Engine time: 0.03253459744155407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.44015996903181,
    "estimated_duration": 3600.0282739780696,
    "input_throughput": 4448.800059645744,
    "output_throughput": 3915.750912817935,
    "total_throughput": 8364.550972463678,
    "itl": 178.6583447183668,
    "ttft": 2238567.7614195463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.168939611762797,
    "arrivals": 1540502,
    "finished_requests": 64623,
    "scheduler_time": 109.18065305486095
}
#Debug simulation 
Total elapsed time: 8.440280850045383. Arrivals time: 0.37195797078311443 Scheduler time: 7.961785587482154 Scheduler overhead time: 0.033455017022788525 Adapter cache time: 0.024501959327608347 Engine time: 0.033399641048163176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.786055621225387,
    "estimated_duration": 3600.150167928183,
    "input_throughput": 4618.4712371508185,
    "output_throughput": 4082.458873780287,
    "total_throughput": 8700.930110931105,
    "itl": 210.3784674711776,
    "ttft": 2216878.317555955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1668253227044287,
    "arrivals": 1423678,
    "finished_requests": 67283,
    "scheduler_time": 103.86267982183237
}
#Debug simulation 
Total elapsed time: 12.786155562847853. Arrivals time: 0.30313138058409095 Scheduler time: 12.383093549404293 Scheduler overhead time: 0.033471552189439535 Adapter cache time: 0.019069138914346695 Engine time: 0.03359785536304116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.711012707091868,
    "estimated_duration": 3600.061294284152,
    "input_throughput": 4618.353033710232,
    "output_throughput": 4082.422991890307,
    "total_throughput": 8700.77602560054,
    "itl": 210.38792075466995,
    "ttft": 2216844.9119232916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3081782178208288,
    "arrivals": 1423678,
    "finished_requests": 67279,
    "scheduler_time": 103.85649603269171
}
#Debug simulation 
Total elapsed time: 12.711137993261218. Arrivals time: 0.2938429801724851 Scheduler time: 12.31986825261265 Scheduler overhead time: 0.03286085370928049 Adapter cache time: 0.01843886962160468 Engine time: 0.032332245260477066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.781716625671834,
    "estimated_duration": 3600.1202044727793,
    "input_throughput": 4422.9878714096685,
    "output_throughput": 3915.0492759905205,
    "total_throughput": 8338.03714740019,
    "itl": 178.97712577460572,
    "ttft": 2237472.409816795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9950484837218476,
    "arrivals": 1423678,
    "finished_requests": 64418,
    "scheduler_time": 109.11606525899423
}
#Debug simulation 
Total elapsed time: 8.781806335784495. Arrivals time: 0.28924449905753136 Scheduler time: 8.380119212903082 Scheduler overhead time: 0.03394014947116375 Adapter cache time: 0.029230698477476835 Engine time: 0.033964039757847786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.70979367615655,
    "estimated_duration": 3600.194873138574,
    "input_throughput": 4618.413887552916,
    "output_throughput": 4082.408180084724,
    "total_throughput": 8700.82206763764,
    "itl": 210.38066944738225,
    "ttft": 2216897.6906195753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.211341127350443,
    "arrivals": 1423678,
    "finished_requests": 67283,
    "scheduler_time": 103.86286922751437
}
#Debug simulation 
Total elapsed time: 12.709887612145394. Arrivals time: 0.29203325882554054 Scheduler time: 12.318549907300621 Scheduler overhead time: 0.033488568384200335 Adapter cache time: 0.018693875055760145 Engine time: 0.03325792541727424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.172744143754244,
    "estimated_duration": 3600.1712427138746,
    "input_throughput": 4422.925168414138,
    "output_throughput": 3914.9937738448234,
    "total_throughput": 8337.91894225896,
    "itl": 178.97952782745486,
    "ttft": 2237492.2333360664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.045978767219927,
    "arrivals": 1423678,
    "finished_requests": 64418,
    "scheduler_time": 109.11617321663438
}
#Debug simulation 
Total elapsed time: 9.17280749976635. Arrivals time: 0.6964281634427607 Scheduler time: 8.36355948029086 Scheduler overhead time: 0.0341821345500648 Adapter cache time: 0.029730327893048525 Engine time: 0.03369553154334426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.708287212997675,
    "estimated_duration": 3600.1001080889555,
    "input_throughput": 4618.535457567103,
    "output_throughput": 4082.5156408780726,
    "total_throughput": 8701.051098445176,
    "itl": 210.3759336195369,
    "ttft": 2216856.6887901044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.116955608790702,
    "arrivals": 1423678,
    "finished_requests": 67283,
    "scheduler_time": 103.86248969643277
}
#Debug simulation 
Total elapsed time: 12.708353728055954. Arrivals time: 0.2907135346904397 Scheduler time: 12.31881319032982 Scheduler overhead time: 0.03292563045397401 Adapter cache time: 0.018681148067116737 Engine time: 0.03348103864118457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.725666375365108,
    "estimated_duration": 3600.0293070550924,
    "input_throughput": 4422.834827704455,
    "output_throughput": 3914.9881286742298,
    "total_throughput": 8337.822956378684,
    "itl": 178.98266448359766,
    "ttft": 2237443.713105539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0979150810093214,
    "arrivals": 1423678,
    "finished_requests": 64415,
    "scheduler_time": 109.11034129171397
}
#Debug simulation 
Total elapsed time: 8.725782576948404. Arrivals time: 0.26581065403297544 Scheduler time: 8.34772050846368 Scheduler overhead time: 0.03367297677323222 Adapter cache time: 0.029597104992717505 Engine time: 0.03375240555033088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.947130167856812,
    "estimated_duration": 3600.1654396821496,
    "input_throughput": 4609.354008316097,
    "output_throughput": 4082.5129417657063,
    "total_throughput": 8691.866950081803,
    "itl": 210.7498046952742,
    "ttft": 2214359.5637988225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3871804402675947,
    "arrivals": 1404624,
    "finished_requests": 67255,
    "scheduler_time": 103.81276144301307
}
#Debug simulation 
Total elapsed time: 10.947227903176099. Arrivals time: 0.2928953403607011 Scheduler time: 10.558541485574096 Scheduler overhead time: 0.031296859961003065 Adapter cache time: 0.019677027128636837 Engine time: 0.03139343950897455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.360981752164662,
    "estimated_duration": 3600.093057705415,
    "input_throughput": 4609.017526501324,
    "output_throughput": 4082.0944804595447,
    "total_throughput": 8691.112006960868,
    "itl": 210.75756877416052,
    "ttft": 2214356.84673538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5483861534786483,
    "arrivals": 1404624,
    "finished_requests": 67246,
    "scheduler_time": 103.80647206658513
}
#Debug simulation 
Total elapsed time: 11.361076822970062. Arrivals time: 0.7004724540747702 Scheduler time: 10.56347252195701 Scheduler overhead time: 0.031845287419855595 Adapter cache time: 0.020040713716298342 Engine time: 0.03169859340414405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.061031599994749,
    "estimated_duration": 3600.011331565924,
    "input_throughput": 4411.565558348347,
    "output_throughput": 3916.2882284227117,
    "total_throughput": 8327.853786771058,
    "itl": 178.85949094030914,
    "ttft": 2237009.762189328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7438268662429794,
    "arrivals": 1404624,
    "finished_requests": 64465,
    "scheduler_time": 109.12368607548875
}
#Debug simulation 
Total elapsed time: 8.061126821208745. Arrivals time: 0.2601857017725706 Scheduler time: 7.690718221012503 Scheduler overhead time: 0.03351222490891814 Adapter cache time: 0.0279172295704484 Engine time: 0.03355049109086394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.876397289801389,
    "estimated_duration": 3600.2152694465735,
    "input_throughput": 4609.290211290866,
    "output_throughput": 4082.456436628396,
    "total_throughput": 8691.746647919263,
    "itl": 210.7523093930806,
    "ttft": 2214379.305729467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4368396315444047,
    "arrivals": 1404624,
    "finished_requests": 67255,
    "scheduler_time": 103.81293201608452
}
#Debug simulation 
Total elapsed time: 10.876489496789873. Arrivals time: 0.2813724516890943 Scheduler time: 10.498700208961964 Scheduler overhead time: 0.032000135630369186 Adapter cache time: 0.01973873283714056 Engine time: 0.03119914047420025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.983702906873077,
    "estimated_duration": 3600.0616172035457,
    "input_throughput": 4411.5039376288705,
    "output_throughput": 3916.233525733809,
    "total_throughput": 8327.737463362679,
    "itl": 178.8618104797622,
    "ttft": 2237028.7471967274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7940026270225653,
    "arrivals": 1404624,
    "finished_requests": 64465,
    "scheduler_time": 109.12379595237583
}
#Debug simulation 
Total elapsed time: 7.983794351108372. Arrivals time: 0.25531725585460663 Scheduler time: 7.619250059593469 Scheduler overhead time: 0.033673911821097136 Adapter cache time: 0.027150527108460665 Engine time: 0.0332068856805563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.96838017506525,
    "estimated_duration": 3600.1103133846314,
    "input_throughput": 4609.424588547899,
    "output_throughput": 4082.5754548009913,
    "total_throughput": 8692.00004334889,
    "itl": 210.74695116097692,
    "ttft": 2214337.5404592403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.332239230023651,
    "arrivals": 1404624,
    "finished_requests": 67255,
    "scheduler_time": 103.8125763556367
}
#Debug simulation 
Total elapsed time: 10.968480884097517. Arrivals time: 0.2898519583977759 Scheduler time: 10.58413868304342 Scheduler overhead time: 0.030913358088582754 Adapter cache time: 0.019540136214345694 Engine time: 0.030673528090119362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.958633454050869,
    "estimated_duration": 3600.1092628513234,
    "input_throughput": 4411.445553577877,
    "output_throughput": 3916.1816963393217,
    "total_throughput": 8327.6272499172,
    "itl": 178.86399135018698,
    "ttft": 2237046.6233436107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8415375582874396,
    "arrivals": 1404624,
    "finished_requests": 64465,
    "scheduler_time": 109.12390666893346
}
#Debug simulation 
Total elapsed time: 7.958729379344732. Arrivals time: 0.2560900463722646 Scheduler time: 7.5932151335291564 Scheduler overhead time: 0.03358301427215338 Adapter cache time: 0.027536851819604635 Engine time: 0.033152878284454346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.12293432885781,
    "estimated_duration": 3600.1188181289504,
    "input_throughput": 4677.959214899661,
    "output_throughput": 4074.9566170220032,
    "total_throughput": 8752.915831921664,
    "itl": 208.6674693524695,
    "ttft": 2210447.4911725083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1698858104483616,
    "arrivals": 1395198,
    "finished_requests": 67939,
    "scheduler_time": 104.02623445449399
}
#Debug simulation 
Total elapsed time: 10.123041231185198. Arrivals time: 0.2943089581094682 Scheduler time: 9.736041732132435 Scheduler overhead time: 0.03076422493904829 Adapter cache time: 0.01775870705023408 Engine time: 0.03069991199299693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.146776020061225,
    "estimated_duration": 3600.0288891828304,
    "input_throughput": 4677.839128069494,
    "output_throughput": 4074.9506327794847,
    "total_throughput": 8752.789760848978,
    "itl": 208.67706485457322,
    "ttft": 2210426.5270178514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3123940540710524,
    "arrivals": 1395198,
    "finished_requests": 67936,
    "scheduler_time": 104.01994655585693
}
#Debug simulation 
Total elapsed time: 10.146868626121432. Arrivals time: 0.27972088335081935 Scheduler time: 9.772776247002184 Scheduler overhead time: 0.031743867322802544 Adapter cache time: 0.01809992454946041 Engine time: 0.031008470803499222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.484643976204097,
    "estimated_duration": 3600.1193549340287,
    "input_throughput": 4481.748911431762,
    "output_throughput": 3916.0665550374088,
    "total_throughput": 8397.81546646917,
    "itl": 178.6061272629097,
    "ttft": 2228877.0310877454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7641197557001758,
    "arrivals": 1395198,
    "finished_requests": 65102,
    "scheduler_time": 109.11215267587481
}
#Debug simulation 
Total elapsed time: 7.484758642036468. Arrivals time: 0.2542566773481667 Scheduler time: 7.121072186157107 Scheduler overhead time: 0.03357294388115406 Adapter cache time: 0.027729656547307968 Engine time: 0.03292227862402797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.108434258960187,
    "estimated_duration": 3600.1593218464077,
    "input_throughput": 4677.906585357083,
    "output_throughput": 4074.91077158109,
    "total_throughput": 8752.817356938172,
    "itl": 208.66952133045126,
    "ttft": 2210464.9860001537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.210245224460941,
    "arrivals": 1395198,
    "finished_requests": 67939,
    "scheduler_time": 104.02637875787299
}
#Debug simulation 
Total elapsed time: 10.108523400966078. Arrivals time: 0.2851841268129647 Scheduler time: 9.728984410408884 Scheduler overhead time: 0.031067603267729282 Adapter cache time: 0.018258824478834867 Engine time: 0.031562477350234985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.437453179154545,
    "estimated_duration": 3600.171015106737,
    "input_throughput": 4481.68460117488,
    "output_throughput": 3916.0103619638794,
    "total_throughput": 8397.69496313876,
    "itl": 178.6085230298206,
    "ttft": 2228896.722590991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8156788081303263,
    "arrivals": 1395198,
    "finished_requests": 65102,
    "scheduler_time": 109.11225379619775
}
#Debug simulation 
Total elapsed time: 7.437577642034739. Arrivals time: 0.25726439291611314 Scheduler time: 7.071519592776895 Scheduler overhead time: 0.03330882405862212 Adapter cache time: 0.02753782505169511 Engine time: 0.032895680982619524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.130110589321703,
    "estimated_duration": 3600.0687048855916,
    "input_throughput": 4678.024332464845,
    "output_throughput": 4075.0133407429557,
    "total_throughput": 8753.0376732078,
    "itl": 208.6649519028503,
    "ttft": 2210426.0828652154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1199456590856043,
    "arrivals": 1395198,
    "finished_requests": 67939,
    "scheduler_time": 104.02606136241094
}
#Debug simulation 
Total elapsed time: 10.130205477122217. Arrivals time: 0.28888593474403024 Scheduler time: 9.747405563946813 Scheduler overhead time: 0.031156342942267656 Adapter cache time: 0.018259155564010143 Engine time: 0.030994586180895567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.436340500134975,
    "estimated_duration": 3600.025637678915,
    "input_throughput": 4481.66836122932,
    "output_throughput": 3916.039889396305,
    "total_throughput": 8397.708250625625,
    "itl": 178.61009654908315,
    "ttft": 2228858.734980793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8614531863853903,
    "arrivals": 1395198,
    "finished_requests": 65100,
    "scheduler_time": 109.10646098546162
}
#Debug simulation 
Total elapsed time: 7.436463113874197. Arrivals time: 0.2562847239896655 Scheduler time: 7.071475871838629 Scheduler overhead time: 0.03316102176904678 Adapter cache time: 0.027408371679484844 Engine time: 0.03309183521196246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.133585097733885,
    "estimated_duration": 3600.0010955244697,
    "input_throughput": 4635.458589372691,
    "output_throughput": 4079.822369570767,
    "total_throughput": 8715.280958943458,
    "itl": 209.84918800668598,
    "ttft": 2215411.173997471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.15764385947263,
    "arrivals": 1390337,
    "finished_requests": 67497,
    "scheduler_time": 103.89371445229669
}
#Debug simulation 
Total elapsed time: 9.133676007855684. Arrivals time: 0.2799095818772912 Scheduler time: 8.762179487384856 Scheduler overhead time: 0.030353225767612457 Adapter cache time: 0.017707444727420807 Engine time: 0.030208612326532602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.823182750027627,
    "estimated_duration": 3600.165965283545,
    "input_throughput": 4634.7693858846405,
    "output_throughput": 4079.28166135067,
    "total_throughput": 8714.05104723531,
    "itl": 209.8271295617586,
    "ttft": 2215700.9665623293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.282902146440472,
    "arrivals": 1390337,
    "finished_requests": 67490,
    "scheduler_time": 103.89502517702627
}
#Debug simulation 
Total elapsed time: 8.82330469833687. Arrivals time: 0.2722850413993001 Scheduler time: 8.460669231135398 Scheduler overhead time: 0.029581038281321526 Adapter cache time: 0.017528797034174204 Engine time: 0.02987512620165944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.065881907939911,
    "estimated_duration": 3600.165977622181,
    "input_throughput": 4445.40282294717,
    "output_throughput": 3918.5051710636676,
    "total_throughput": 8363.907994010837,
    "itl": 178.96538830464291,
    "ttft": 2236869.230298322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.288064739294312,
    "arrivals": 1390337,
    "finished_requests": 64763,
    "scheduler_time": 109.0776557118464
}
#Debug simulation 
Total elapsed time: 7.065971927251667. Arrivals time: 0.25961413607001305 Scheduler time: 6.700074048247188 Scheduler overhead time: 0.03316446486860514 Adapter cache time: 0.02503905026242137 Engine time: 0.03294652793556452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.829125929623842,
    "estimated_duration": 3600.237417151105,
    "input_throughput": 4634.477415437546,
    "output_throughput": 4079.143205955859,
    "total_throughput": 8713.620621393406,
    "itl": 209.84489289451287,
    "ttft": 2215512.746816664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.230915810393618,
    "arrivals": 1390337,
    "finished_requests": 67479,
    "scheduler_time": 103.89724151550325
}
#Debug simulation 
Total elapsed time: 8.82924769865349. Arrivals time: 0.2747563486918807 Scheduler time: 8.463819024153054 Scheduler overhead time: 0.029749104287475348 Adapter cache time: 0.017907049506902695 Engine time: 0.029770299326628447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.0328657948412,
    "estimated_duration": 3600.015577752588,
    "input_throughput": 4445.11465419547,
    "output_throughput": 3918.506377354761,
    "total_throughput": 8363.62103155023,
    "itl": 178.96931129132366,
    "ttft": 2236762.272452785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3323300721123807,
    "arrivals": 1390337,
    "finished_requests": 64758,
    "scheduler_time": 109.07179657202396
}
#Debug simulation 
Total elapsed time: 7.032951781060547. Arrivals time: 0.2552919122390449 Scheduler time: 6.67270515114069 Scheduler overhead time: 0.03287261864170432 Adapter cache time: 0.024442994967103004 Engine time: 0.03255602531135082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.9763212390244,
    "estimated_duration": 3600.190228882852,
    "input_throughput": 4635.3600612872015,
    "output_throughput": 4079.6616473673353,
    "total_throughput": 8715.021708654536,
    "itl": 209.84737898751348,
    "ttft": 2215415.1437333757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.107985457905996,
    "arrivals": 1390337,
    "finished_requests": 67499,
    "scheduler_time": 103.90042030518785
}
#Debug simulation 
Total elapsed time: 8.976446205750108. Arrivals time: 0.2768672560341656 Scheduler time: 8.60878953943029 Scheduler overhead time: 0.029863731004297733 Adapter cache time: 0.017428058199584484 Engine time: 0.030195354018360376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.041245128959417,
    "estimated_duration": 3600.056933911756,
    "input_throughput": 4445.063590317166,
    "output_throughput": 3918.4613629629284,
    "total_throughput": 8363.524953280095,
    "itl": 178.9711705832054,
    "ttft": 2236778.316845279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.373577314056498,
    "arrivals": 1390337,
    "finished_requests": 64758,
    "scheduler_time": 109.07190548928757
}
#Debug simulation 
Total elapsed time: 7.0413328763097525. Arrivals time: 0.25473759695887566 Scheduler time: 6.681014163419604 Scheduler overhead time: 0.0328387669287622 Adapter cache time: 0.024988743010908365 Engine time: 0.03279932402074337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.859407652635127,
    "estimated_duration": 3600.0747119386047,
    "input_throughput": 4641.527561799381,
    "output_throughput": 4079.6578335706695,
    "total_throughput": 8721.18539537005,
    "itl": 209.66556440980344,
    "ttft": 2211270.593120637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9984984967881216,
    "arrivals": 1387991,
    "finished_requests": 67521,
    "scheduler_time": 103.90929194296888
}
#Debug simulation 
Total elapsed time: 8.859528208617121. Arrivals time: 0.270394382532686 Scheduler time: 8.50036132754758 Scheduler overhead time: 0.0295320232398808 Adapter cache time: 0.01628589816391468 Engine time: 0.029661737382411957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.981888711918145,
    "estimated_duration": 3600.2123442006014,
    "input_throughput": 4641.350121171891,
    "output_throughput": 4079.501872621113,
    "total_throughput": 8720.851993793005,
    "itl": 209.67240284959536,
    "ttft": 2211328.9387590806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1355535452324035,
    "arrivals": 1387991,
    "finished_requests": 67521,
    "scheduler_time": 103.90986915648487
}
#Debug simulation 
Total elapsed time: 8.981976417824626. Arrivals time: 0.37262923875823617 Scheduler time: 8.519001217093319 Scheduler overhead time: 0.030435084830969572 Adapter cache time: 0.016334792133420706 Engine time: 0.030259259045124054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.872280582319945,
    "estimated_duration": 3600.1656051818536,
    "input_throughput": 4450.092789326211,
    "output_throughput": 3916.4442823701106,
    "total_throughput": 8366.53707169632,
    "itl": 179.01821404792997,
    "ttft": 2231759.4388462664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2762279113940527,
    "arrivals": 1387991,
    "finished_requests": 64757,
    "scheduler_time": 109.04621647997632
}
#Debug simulation 
Total elapsed time: 6.872399676125497. Arrivals time: 0.25076024839654565 Scheduler time: 6.516399137675762 Scheduler overhead time: 0.033091436605900526 Adapter cache time: 0.024493814911693335 Engine time: 0.03266069386154413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.91894429223612,
    "estimated_duration": 3600.115528977216,
    "input_throughput": 4641.474937541026,
    "output_throughput": 4079.611579624102,
    "total_throughput": 8721.086517165128,
    "itl": 209.66754446362336,
    "ttft": 2211288.898025533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.039125050080459,
    "arrivals": 1387991,
    "finished_requests": 67521,
    "scheduler_time": 103.90948242822726
}
#Debug simulation 
Total elapsed time: 8.919034338090569. Arrivals time: 0.2770239836536348 Scheduler time: 8.551679173950106 Scheduler overhead time: 0.03011681092903018 Adapter cache time: 0.016333160921931267 Engine time: 0.030497591476887465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.022531952243298,
    "estimated_duration": 3600.01094136799,
    "input_throughput": 4450.250641158357,
    "output_throughput": 3916.547541003362,
    "total_throughput": 8366.79818216172,
    "itl": 179.0195854285219,
    "ttft": 2231781.2846546206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3214992745034446,
    "arrivals": 1387991,
    "finished_requests": 64755,
    "scheduler_time": 109.0402579664773
}
#Debug simulation 
Total elapsed time: 7.022651560138911. Arrivals time: 0.3500584391877055 Scheduler time: 6.567244206089526 Scheduler overhead time: 0.03312939032912254 Adapter cache time: 0.024434908293187618 Engine time: 0.032691982574760914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.808070802595466,
    "estimated_duration": 3600.0285132041517,
    "input_throughput": 4641.587125966303,
    "output_throughput": 4079.710187330708,
    "total_throughput": 8721.297313297011,
    "itl": 209.66328057229327,
    "ttft": 2211250.961555094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525028425710882,
    "arrivals": 1387991,
    "finished_requests": 67521,
    "scheduler_time": 103.90908886265245
}
#Debug simulation 
Total elapsed time: 8.808227248024195. Arrivals time: 0.2716080788522959 Scheduler time: 8.447596387472004 Scheduler overhead time: 0.029813827015459538 Adapter cache time: 0.016204610466957092 Engine time: 0.029798004776239395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.900595706887543,
    "estimated_duration": 3600.0514362032236,
    "input_throughput": 4450.2005829384525,
    "output_throughput": 3916.5034860918786,
    "total_throughput": 8366.704069030331,
    "itl": 179.02142658988456,
    "ttft": 2231798.0777406073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.361866239942651,
    "arrivals": 1387991,
    "finished_requests": 64755,
    "scheduler_time": 109.04038583630441
}
#Debug simulation 
Total elapsed time: 6.900714018847793. Arrivals time: 0.2533944738097489 Scheduler time: 6.5426345760934055 Scheduler overhead time: 0.032742402981966734 Adapter cache time: 0.024526795372366905 Engine time: 0.032358030788600445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.462429522071034,
    "estimated_duration": 3600.1646508833824,
    "input_throughput": 4595.755084684861,
    "output_throughput": 4085.98617743511,
    "total_throughput": 8681.741262119971,
    "itl": 211.0415899929646,
    "ttft": 2213093.760691867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9831960580684573,
    "arrivals": 1386791,
    "finished_requests": 67220,
    "scheduler_time": 103.74873738385344
}
#Debug simulation 
Total elapsed time: 8.46252192882821. Arrivals time: 0.2680225782096386 Scheduler time: 8.105469565372914 Scheduler overhead time: 0.029755935072898865 Adapter cache time: 0.016216241754591465 Engine time: 0.029804858844727278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.449234183877707,
    "estimated_duration": 3600.066971995816,
    "input_throughput": 4595.763114603311,
    "output_throughput": 4086.016764250656,
    "total_throughput": 8681.779878853966,
    "itl": 211.04807327231214,
    "ttft": 2213111.036121486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.116925935891929,
    "arrivals": 1386791,
    "finished_requests": 67219,
    "scheduler_time": 103.74252039089338
}
#Debug simulation 
Total elapsed time: 8.44933742377907. Arrivals time: 0.2707430478185415 Scheduler time: 8.090561622288078 Scheduler overhead time: 0.029370388481765985 Adapter cache time: 0.01630206359550357 Engine time: 0.02928221318870783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.740985904820263,
    "estimated_duration": 3600.0542505655844,
    "input_throughput": 4400.155080305065,
    "output_throughput": 3916.610144912351,
    "total_throughput": 8316.765225217416,
    "itl": 178.92814239024582,
    "ttft": 2234495.096914009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.14673046506938,
    "arrivals": 1386791,
    "finished_requests": 64362,
    "scheduler_time": 109.09851115556218
}
#Debug simulation 
Total elapsed time: 6.741081524640322. Arrivals time: 0.24823166150599718 Scheduler time: 6.388723687268794 Scheduler overhead time: 0.0329290684312582 Adapter cache time: 0.02381128165870905 Engine time: 0.032391034066677094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.573199877981097,
    "estimated_duration": 3600.204977310168,
    "input_throughput": 4595.703606954533,
    "output_throughput": 4085.940409701476,
    "total_throughput": 8681.644016656008,
    "itl": 211.04360199290343,
    "ttft": 2213111.342107615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0233576079690683,
    "arrivals": 1386791,
    "finished_requests": 67220,
    "scheduler_time": 103.74890226068294
}
#Debug simulation 
Total elapsed time: 8.57331840088591. Arrivals time: 0.3634986933320761 Scheduler time: 8.120861231349409 Scheduler overhead time: 0.029842941090464592 Adapter cache time: 0.01616380224004388 Engine time: 0.029664053115993738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.9385500978678465,
    "estimated_duration": 3600.0981307969514,
    "input_throughput": 4400.101448482831,
    "output_throughput": 3916.56240683603,
    "total_throughput": 8316.66385531886,
    "itl": 178.9301808570309,
    "ttft": 2234512.4572454756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1904927827417886,
    "arrivals": 1386791,
    "finished_requests": 64362,
    "scheduler_time": 109.09862906929581
}
#Debug simulation 
Total elapsed time: 6.9386404869146645. Arrivals time: 0.2578099053353071 Scheduler time: 6.575775851961225 Scheduler overhead time: 0.03322736918926239 Adapter cache time: 0.023859642446041107 Engine time: 0.032854161225259304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.926531333941966,
    "estimated_duration": 3600.1188229288737,
    "input_throughput": 4595.813586658077,
    "output_throughput": 4086.038190270762,
    "total_throughput": 8681.85177692884,
    "itl": 211.03930006004157,
    "ttft": 2213073.5739982584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9375525910965778,
    "arrivals": 1386791,
    "finished_requests": 67220,
    "scheduler_time": 103.74855289624172
}
#Debug simulation 
Total elapsed time: 8.926627424079925. Arrivals time: 0.6837094500660896 Scheduler time: 8.142609102185816 Scheduler overhead time: 0.029902870766818523 Adapter cache time: 0.016495660413056612 Engine time: 0.04069104650989175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.9428923623636365,
    "estimated_duration": 3600.1372395816165,
    "input_throughput": 4400.053649577234,
    "output_throughput": 3916.5198606813688,
    "total_throughput": 8316.573510258602,
    "itl": 178.93195108686822,
    "ttft": 2234528.287312765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2294764565304286,
    "arrivals": 1386791,
    "finished_requests": 64362,
    "scheduler_time": 109.09875418020545
}
#Debug simulation 
Total elapsed time: 6.942985717207193. Arrivals time: 0.35180449951440096 Scheduler time: 6.485052362084389 Scheduler overhead time: 0.033312694169580936 Adapter cache time: 0.024457330349832773 Engine time: 0.03329859487712383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.27175110206008,
    "estimated_duration": 3600.1476029716237,
    "input_throughput": 4609.175742212143,
    "output_throughput": 4082.948429077467,
    "total_throughput": 8692.12417128961,
    "itl": 210.6526394845384,
    "ttft": 2209788.472085809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.19514920466587,
    "arrivals": 1289387,
    "finished_requests": 67096,
    "scheduler_time": 103.74205468198055
}
#Debug simulation 
Total elapsed time: 6.271849725861102. Arrivals time: 0.25349407084286213 Scheduler time: 5.924739132169634 Scheduler overhead time: 0.02863318845629692 Adapter cache time: 0.02315658237785101 Engine time: 0.028701314702630043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.285279293078929,
    "estimated_duration": 3600.118717782507,
    "input_throughput": 4608.8291250073125,
    "output_throughput": 4082.517036841761,
    "total_throughput": 8691.346161849075,
    "itl": 210.66333119690594,
    "ttft": 2209799.243023013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.401500301009514,
    "arrivals": 1289387,
    "finished_requests": 67090,
    "scheduler_time": 103.73572761638965
}
#Debug simulation 
Total elapsed time: 6.285375325940549. Arrivals time: 0.25602202489972115 Scheduler time: 5.935047756880522 Scheduler overhead time: 0.02885029325261712 Adapter cache time: 0.023237823974341154 Engine time: 0.029105389956384897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.498054276686162,
    "estimated_duration": 3600.048462300042,
    "input_throughput": 4414.463906923783,
    "output_throughput": 3915.009797116818,
    "total_throughput": 8329.4737040406,
    "itl": 178.86618781851666,
    "ttft": 2230791.970838648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.055351330917277,
    "arrivals": 1289387,
    "finished_requests": 64220,
    "scheduler_time": 109.0413335522918
}
#Debug simulation 
Total elapsed time: 5.498171193990856. Arrivals time: 0.23848350066691637 Scheduler time: 5.146665250416845 Scheduler overhead time: 0.03282952168956399 Adapter cache time: 0.03283531963825226 Engine time: 0.03232115088030696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.313670402858406,
    "estimated_duration": 3600.2103121639198,
    "input_throughput": 4609.09545865566,
    "output_throughput": 4082.8773114548912,
    "total_throughput": 8691.972770110551,
    "itl": 210.65599969209188,
    "ttft": 2209815.5349966553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2576747489184688,
    "arrivals": 1289387,
    "finished_requests": 67096,
    "scheduler_time": 103.74223832992173
}
#Debug simulation 
Total elapsed time: 6.313761860132217. Arrivals time: 0.2536798482760787 Scheduler time: 5.965584730263799 Scheduler overhead time: 0.0291526997461915 Adapter cache time: 0.023261576890945435 Engine time: 0.02897528139874339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.476380510721356,
    "estimated_duration": 3600.114457204856,
    "input_throughput": 4414.382983906249,
    "output_throughput": 3914.93802975998,
    "total_throughput": 8329.32101366623,
    "itl": 178.86931109995317,
    "ttft": 2230816.221037395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.121246314998663,
    "arrivals": 1289387,
    "finished_requests": 64220,
    "scheduler_time": 109.0414334730854
}
#Debug simulation 
Total elapsed time: 5.476496162824333. Arrivals time: 0.23941035056486726 Scheduler time: 5.124679200351238 Scheduler overhead time: 0.03247067518532276 Adapter cache time: 0.032511772122234106 Engine time: 0.032428635749965906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.314445471391082,
    "estimated_duration": 3600.0738985807693,
    "input_throughput": 4609.270105966885,
    "output_throughput": 4083.032019369037,
    "total_throughput": 8692.302125335922,
    "itl": 210.6487017457189,
    "ttft": 2209758.850982481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1216125078777974,
    "arrivals": 1289387,
    "finished_requests": 67096,
    "scheduler_time": 103.74188698777951
}
#Debug simulation 
Total elapsed time: 6.314539728220552. Arrivals time: 0.2545722792856395 Scheduler time: 5.965138770174235 Scheduler overhead time: 0.02905369782820344 Adapter cache time: 0.023819460533559322 Engine time: 0.028918203432112932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.484796382021159,
    "estimated_duration": 3600.178078381616,
    "input_throughput": 4414.304974365057,
    "output_throughput": 3914.8688462476725,
    "total_throughput": 8329.17382061273,
    "itl": 178.87228827425898,
    "ttft": 2230840.475742004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.184751977138166,
    "arrivals": 1289387,
    "finished_requests": 64220,
    "scheduler_time": 109.04154898776036
}
#Debug simulation 
Total elapsed time: 5.484911106992513. Arrivals time: 0.24070686334744096 Scheduler time: 5.131359922233969 Scheduler overhead time: 0.03280738927423954 Adapter cache time: 0.03292738366872072 Engine time: 0.03216028865426779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.777435096912086,
    "estimated_duration": 3600.1753005501514,
    "input_throughput": 4600.083778550799,
    "output_throughput": 4084.5636038203115,
    "total_throughput": 8684.647382371111,
    "itl": 210.80862403693962,
    "ttft": 2207824.3656082614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.455290662900163,
    "arrivals": 1279697,
    "finished_requests": 67766,
    "scheduler_time": 103.70764240967786
}
#Debug simulation 
Total elapsed time: 5.777526799123734. Arrivals time: 0.34390876442193985 Scheduler time: 5.339041267521679 Scheduler overhead time: 0.028810706455260515 Adapter cache time: 0.02415992273017764 Engine time: 0.02858759043738246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.711826305836439,
    "estimated_duration": 3600.017761289606,
    "input_throughput": 4599.229808818723,
    "output_throughput": 4084.040128383477,
    "total_throughput": 8683.2699372022,
    "itl": 210.8224546357966,
    "ttft": 2207847.755262293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6879336062329893,
    "arrivals": 1279697,
    "finished_requests": 67756,
    "scheduler_time": 103.69669620965432
}
#Debug simulation 
Total elapsed time: 5.711920803878456. Arrivals time: 0.2690457059070468 Scheduler time: 5.348701356910169 Scheduler overhead time: 0.02857946790754795 Adapter cache time: 0.024163850117474794 Engine time: 0.0285040233284235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.068332883063704,
    "estimated_duration": 3600.098487932121,
    "input_throughput": 4408.152458383305,
    "output_throughput": 3921.678544997128,
    "total_throughput": 8329.831003380434,
    "itl": 179.79925578580267,
    "ttft": 2229859.391979345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.164884843882123,
    "arrivals": 1279697,
    "finished_requests": 64971,
    "scheduler_time": 108.84366452665239
}
#Debug simulation 
Total elapsed time: 5.0684270220808685. Arrivals time: 0.24003841355443 Scheduler time: 4.716232776641846 Scheduler overhead time: 0.032256098464131355 Adapter cache time: 0.03301124880090356 Engine time: 0.03209659131243825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.822320843115449,
    "estimated_duration": 3600.017614558936,
    "input_throughput": 4599.588605632062,
    "output_throughput": 4084.4111263609707,
    "total_throughput": 8683.999731993033,
    "itl": 210.81260841449816,
    "ttft": 2207826.7656496875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.528172836722766,
    "arrivals": 1279697,
    "finished_requests": 67759,
    "scheduler_time": 103.70111699458259
}
#Debug simulation 
Total elapsed time: 5.82241765409708. Arrivals time: 0.35472772317007184 Scheduler time: 5.373294852208346 Scheduler overhead time: 0.028552209958434105 Adapter cache time: 0.024077958427369595 Engine time: 0.0287253325805068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.083346301689744,
    "estimated_duration": 3600.168133175382,
    "input_throughput": 4408.067182685355,
    "output_throughput": 3921.6026801357784,
    "total_throughput": 8329.669862821132,
    "itl": 179.80261401108174,
    "ttft": 2229885.956950168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.234426687769537,
    "arrivals": 1279697,
    "finished_requests": 64971,
    "scheduler_time": 108.84376792608107
}
#Debug simulation 
Total elapsed time: 5.083433751016855. Arrivals time: 0.2354652350768447 Scheduler time: 4.735399967525154 Scheduler overhead time: 0.03233175678178668 Adapter cache time: 0.03304665349423885 Engine time: 0.03235133085399866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.6882027462124825,
    "estimated_duration": 3600.095610655476,
    "input_throughput": 4600.185603677533,
    "output_throughput": 4084.6540176533276,
    "total_throughput": 8684.839621330862,
    "itl": 210.8042940244774,
    "ttft": 2207792.1600013897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3757667829444733,
    "arrivals": 1279697,
    "finished_requests": 67766,
    "scheduler_time": 103.70747639481789
}
#Debug simulation 
Total elapsed time: 5.688306272029877. Arrivals time: 0.24828676972538233 Scheduler time: 5.3457041014917195 Scheduler overhead time: 0.028388726990669966 Adapter cache time: 0.0240579922683537 Engine time: 0.02876412682235241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.128533469047397,
    "estimated_duration": 3600.0312005829237,
    "input_throughput": 4408.094851353071,
    "output_throughput": 3921.615178700117,
    "total_throughput": 8329.710030053187,
    "itl": 179.80629889280632,
    "ttft": 2229768.1897927877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.298812626413936,
    "arrivals": 1279697,
    "finished_requests": 64968,
    "scheduler_time": 108.83776658462081
}
#Debug simulation 
Total elapsed time: 5.128626222722232. Arrivals time: 0.323851166293025 Scheduler time: 4.69280027365312 Scheduler overhead time: 0.032245217356830835 Adapter cache time: 0.032939383294433355 Engine time: 0.031983377411961555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.284807689953595,
    "estimated_duration": 3600.0522910814384,
    "input_throughput": 4646.178068423402,
    "output_throughput": 4076.0174612886076,
    "total_throughput": 8722.19552971201,
    "itl": 209.65174887818512,
    "ttft": 2206510.2002480556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.868456508331099,
    "arrivals": 1274994,
    "finished_requests": 67383,
    "scheduler_time": 103.83640254181171
}
#Debug simulation 
Total elapsed time: 5.2849001721479. Arrivals time: 0.24412368843331933 Scheduler time: 4.945174332242459 Scheduler overhead time: 0.02827119454741478 Adapter cache time: 0.025924396235495806 Engine time: 0.02842723485082388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.459248344879597,
    "estimated_duration": 3600.080969195815,
    "input_throughput": 4646.059670079112,
    "output_throughput": 4075.709442523351,
    "total_throughput": 8721.769112602464,
    "itl": 209.66481131670255,
    "ttft": 2206574.8995525734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.128363974704403,
    "arrivals": 1274994,
    "finished_requests": 67380,
    "scheduler_time": 103.83017345846774
}
#Debug simulation 
Total elapsed time: 5.459343943744898. Arrivals time: 0.34442049032077193 Scheduler time: 5.019478710833937 Scheduler overhead time: 0.02849989477545023 Adapter cache time: 0.025593101978302002 Engine time: 0.02823352813720703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.81504113599658,
    "estimated_duration": 3600.069428218592,
    "input_throughput": 4455.689624835209,
    "output_throughput": 3917.545281058301,
    "total_throughput": 8373.234905893509,
    "itl": 178.71682725969535,
    "ttft": 2226589.289855537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.694012087900151,
    "arrivals": 1274994,
    "finished_requests": 64600,
    "scheduler_time": 109.07409365521968
}
#Debug simulation 
Total elapsed time: 4.815165353938937. Arrivals time: 0.23588325828313828 Scheduler time: 4.465660836081952 Scheduler overhead time: 0.03186263656243682 Adapter cache time: 0.03521061409264803 Engine time: 0.03175169276073575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.389684671070427,
    "estimated_duration": 3600.123192247489,
    "input_throughput": 4646.086566153857,
    "output_throughput": 4075.9371878158913,
    "total_throughput": 8722.023753969748,
    "itl": 209.65558178036426,
    "ttft": 2206538.8317985106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9391843422664747,
    "arrivals": 1274994,
    "finished_requests": 67383,
    "scheduler_time": 103.83657587380061
}
#Debug simulation 
Total elapsed time: 5.389776939991862. Arrivals time: 0.33549695275723934 Scheduler time: 4.958559284452349 Scheduler overhead time: 0.028546273708343506 Adapter cache time: 0.02584691345691681 Engine time: 0.02837930480018258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9016175819560885,
    "estimated_duration": 3600.1502734657156,
    "input_throughput": 4455.589567531633,
    "output_throughput": 3917.457308364855,
    "total_throughput": 8373.046875896489,
    "itl": 178.72074463713824,
    "ttft": 2226618.5494282455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.77474601877845,
    "arrivals": 1274994,
    "finished_requests": 64600,
    "scheduler_time": 109.07420497154197
}
#Debug simulation 
Total elapsed time: 4.9017067407257855. Arrivals time: 0.2482942626811564 Scheduler time: 4.538863921537995 Scheduler overhead time: 0.03217221982777119 Adapter cache time: 0.03558854991570115 Engine time: 0.03184661781415343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.367104504723102,
    "estimated_duration": 3600.1952083458036,
    "input_throughput": 4645.993628685869,
    "output_throughput": 4075.8556552666114,
    "total_throughput": 8721.84928395248,
    "itl": 209.6469047689038,
    "ttft": 2206490.0483537605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7794235727562526,
    "arrivals": 1274994,
    "finished_requests": 67383,
    "scheduler_time": 103.84296946538595
}
#Debug simulation 
Total elapsed time: 5.367198194842786. Arrivals time: 0.33491058461368084 Scheduler time: 4.936697112862021 Scheduler overhead time: 0.028424134477972984 Adapter cache time: 0.025968897622078657 Engine time: 0.02822614973410964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.831586677115411,
    "estimated_duration": 3600.024364178105,
    "input_throughput": 4455.47984608208,
    "output_throughput": 3917.215711182983,
    "total_throughput": 8372.695557265062,
    "itl": 178.72251818129388,
    "ttft": 2226614.065883544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.842527309656024,
    "arrivals": 1274994,
    "finished_requests": 64594,
    "scheduler_time": 109.06836293698345
}
#Debug simulation 
Total elapsed time: 4.831677344162017. Arrivals time: 0.24057993944734335 Scheduler time: 4.4752421961165965 Scheduler overhead time: 0.03389732679352164 Adapter cache time: 0.035454024095088243 Engine time: 0.031765375752002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.187836578115821,
    "estimated_duration": 3600.175553842652,
    "input_throughput": 4641.383107600067,
    "output_throughput": 4077.4119985154407,
    "total_throughput": 8718.795106115507,
    "itl": 210.0727331680714,
    "ttft": 2208095.0735871536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6389199275361346,
    "arrivals": 1272675,
    "finished_requests": 67478,
    "scheduler_time": 103.82753389582048
}
#Debug simulation 
Total elapsed time: 5.187951919157058. Arrivals time: 0.2454868028871715 Scheduler time: 4.848043113015592 Scheduler overhead time: 0.028220168314874172 Adapter cache time: 0.025214387569576502 Engine time: 0.027971169911324978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.248426701873541,
    "estimated_duration": 3600.1989678479536,
    "input_throughput": 4641.048772364866,
    "output_throughput": 4077.127717408954,
    "total_throughput": 8718.17648977382,
    "itl": 210.0871860631085,
    "ttft": 2208114.7832422764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8959382962179485,
    "arrivals": 1272675,
    "finished_requests": 67474,
    "scheduler_time": 103.82122784593479
}
#Debug simulation 
Total elapsed time: 5.248520718887448. Arrivals time: 0.25990678649395704 Scheduler time: 4.893881478346884 Scheduler overhead time: 0.02822663728147745 Adapter cache time: 0.02519989851862192 Engine time: 0.028184168972074986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.824542423244566,
    "estimated_duration": 3600.00041938202,
    "input_throughput": 4451.366981437979,
    "output_throughput": 3919.36426563586,
    "total_throughput": 8370.73124707384,
    "itl": 178.79818122242574,
    "ttft": 2228332.300158591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.263584980033296,
    "arrivals": 1272675,
    "finished_requests": 64715,
    "scheduler_time": 109.156598357699
}
#Debug simulation 
Total elapsed time: 4.824638043995947. Arrivals time: 0.23319957172498107 Scheduler time: 4.478836904279888 Scheduler overhead time: 0.03195639979094267 Adapter cache time: 0.033818989992141724 Engine time: 0.03203328372910619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.233954570256174,
    "estimated_duration": 3600.020513809416,
    "input_throughput": 4641.278830469618,
    "output_throughput": 4077.3298217869747,
    "total_throughput": 8718.608652256593,
    "itl": 210.0773913653936,
    "ttft": 2208047.167803164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7177907373779027,
    "arrivals": 1272675,
    "finished_requests": 67474,
    "scheduler_time": 103.8209213661897
}
#Debug simulation 
Total elapsed time: 5.234045724850148. Arrivals time: 0.2581318924203515 Scheduler time: 4.8814587271772325 Scheduler overhead time: 0.02821661764755845 Adapter cache time: 0.025145350955426693 Engine time: 0.028103983495384455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.786910155788064,
    "estimated_duration": 3600.0738371189045,
    "input_throughput": 4451.276202941591,
    "output_throughput": 3919.2843364823407,
    "total_throughput": 8370.560539423932,
    "itl": 178.8017342442649,
    "ttft": 2228358.970044617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.33689943751315,
    "arrivals": 1272675,
    "finished_requests": 64715,
    "scheduler_time": 109.15670163717473
}
#Debug simulation 
Total elapsed time: 4.787007879000157. Arrivals time: 0.23429064312949777 Scheduler time: 4.440066179726273 Scheduler overhead time: 0.031844296492636204 Adapter cache time: 0.03401541896164417 Engine time: 0.031976000871509314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.223879707045853,
    "estimated_duration": 3600.0916335027023,
    "input_throughput": 4641.491301081755,
    "output_throughput": 4077.5070454853135,
    "total_throughput": 8718.998346567068,
    "itl": 210.06820026989553,
    "ttft": 2208062.635849605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5551698006385974,
    "arrivals": 1272675,
    "finished_requests": 67478,
    "scheduler_time": 103.82736368260785
}
#Debug simulation 
Total elapsed time: 5.223981868941337. Arrivals time: 0.25493701035156846 Scheduler time: 4.874541727825999 Scheduler overhead time: 0.02832297096028924 Adapter cache time: 0.02509707771241665 Engine time: 0.028060530312359333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.87709776731208,
    "estimated_duration": 3600.140725135182,
    "input_throughput": 4451.193501442441,
    "output_throughput": 3919.211519008106,
    "total_throughput": 8370.405020450547,
    "itl": 178.80488677934255,
    "ttft": 2228383.816685186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.403674698099422,
    "arrivals": 1272675,
    "finished_requests": 64715,
    "scheduler_time": 109.15681439293223
}
#Debug simulation 
Total elapsed time: 4.8771882662549615. Arrivals time: 0.2407757700420916 Scheduler time: 4.522744393907487 Scheduler overhead time: 0.03232245659455657 Adapter cache time: 0.03417777270078659 Engine time: 0.032274078112095594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.127789199817926,
    "estimated_duration": 3600.0998633638887,
    "input_throughput": 4622.675101142843,
    "output_throughput": 4078.511862801589,
    "total_throughput": 8701.186963944432,
    "itl": 209.9161450736931,
    "ttft": 2203593.935265857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9510896774172863,
    "arrivals": 1271499,
    "finished_requests": 67581,
    "scheduler_time": 103.76180254051899
}
#Debug simulation 
Total elapsed time: 5.127906517125666. Arrivals time: 0.24526139441877604 Scheduler time: 4.787786943838 Scheduler overhead time: 0.028091553132981062 Adapter cache time: 0.025888812728226185 Engine time: 0.02792749973013997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1380350068211555,
    "estimated_duration": 3600.1345119527427,
    "input_throughput": 4622.4258967961705,
    "output_throughput": 4078.2367856683923,
    "total_throughput": 8700.662682464563,
    "itl": 209.9300373133468,
    "ttft": 2203678.714389914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.222449095109466,
    "arrivals": 1271499,
    "finished_requests": 67578,
    "scheduler_time": 103.75545408495026
}
#Debug simulation 
Total elapsed time: 5.13813036493957. Arrivals time: 0.2508165007457137 Scheduler time: 4.791477739810944 Scheduler overhead time: 0.028298365883529186 Adapter cache time: 0.026244772132486105 Engine time: 0.02837350545451045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.78336148802191,
    "estimated_duration": 3600.0622740839867,
    "input_throughput": 4444.822278545589,
    "output_throughput": 3927.320119371401,
    "total_throughput": 8372.14239791699,
    "itl": 178.86612998654044,
    "ttft": 2223637.705072108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.456971447989295,
    "arrivals": 1271499,
    "finished_requests": 64974,
    "scheduler_time": 109.10037767143068
}
#Debug simulation 
Total elapsed time: 4.783453451935202. Arrivals time: 0.2353059402666986 Scheduler time: 4.435115811880678 Scheduler overhead time: 0.031713430769741535 Adapter cache time: 0.03462106268852949 Engine time: 0.03187254723161459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.145636396948248,
    "estimated_duration": 3600.182765155644,
    "input_throughput": 4622.568654311228,
    "output_throughput": 4078.4179464747863,
    "total_throughput": 8700.986600786015,
    "itl": 209.92058967809726,
    "ttft": 2203626.3911789847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.033807941055806,
    "arrivals": 1271499,
    "finished_requests": 67581,
    "scheduler_time": 103.76198606850724
}
#Debug simulation 
Total elapsed time: 5.1457250257954. Arrivals time: 0.2482035532593727 Scheduler time: 4.801616610959172 Scheduler overhead time: 0.028361524920910597 Adapter cache time: 0.026405239012092352 Engine time: 0.028166477102786303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.86696894839406,
    "estimated_duration": 3600.1408521643725,
    "input_throughput": 4444.725264118474,
    "output_throughput": 3927.234400148539,
    "total_throughput": 8371.959664267013,
    "itl": 178.86986361965938,
    "ttft": 2223666.3291035225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5354418107121495,
    "arrivals": 1271499,
    "finished_requests": 64974,
    "scheduler_time": 109.10048538916496
}
#Debug simulation 
Total elapsed time: 4.867054200265557. Arrivals time: 0.2422105479054153 Scheduler time: 4.511128465179354 Scheduler overhead time: 0.03216765820980072 Adapter cache time: 0.034531325567513704 Engine time: 0.032195779494941235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.12625929992646,
    "estimated_duration": 3600.008755645233,
    "input_throughput": 4622.792090131243,
    "output_throughput": 4078.6150803036985,
    "total_throughput": 8701.40717043494,
    "itl": 209.91119868271616,
    "ttft": 2203558.9248823943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8601549307186085,
    "arrivals": 1271499,
    "finished_requests": 67581,
    "scheduler_time": 103.76162956838888
}
#Debug simulation 
Total elapsed time: 5.126349770929664. Arrivals time: 0.2455658558756113 Scheduler time: 4.785505732987076 Scheduler overhead time: 0.028180892579257488 Adapter cache time: 0.026036647614091635 Engine time: 0.028051793109625578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.831532116048038,
    "estimated_duration": 3600.0131215418064,
    "input_throughput": 4444.87546566132,
    "output_throughput": 3927.2431856984317,
    "total_throughput": 8372.118651359751,
    "itl": 178.87250393037652,
    "ttft": 2223636.4317136905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.603348855376152,
    "arrivals": 1271499,
    "finished_requests": 64972,
    "scheduler_time": 109.09461130323137
}
#Debug simulation 
Total elapsed time: 4.83166766166687. Arrivals time: 0.24795675836503506 Scheduler time: 4.46754012722522 Scheduler overhead time: 0.03173345373943448 Adapter cache time: 0.03780727880075574 Engine time: 0.031840558629482985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.925897873938084,
    "estimated_duration": 3600.211265836391,
    "input_throughput": 4596.661634009802,
    "output_throughput": 4093.032022823979,
    "total_throughput": 8689.69365683378,
    "itl": 210.5959632058762,
    "ttft": 2203377.459176022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.416283814495081,
    "arrivals": 1260602,
    "finished_requests": 67366,
    "scheduler_time": 103.87238137456723
}
#Debug simulation 
Total elapsed time: 4.9259910001419485. Arrivals time: 0.24170364905148745 Scheduler time: 4.587736860383302 Scheduler overhead time: 0.027628339361399412 Adapter cache time: 0.028358257841318846 Engine time: 0.027835626155138016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.981110127642751,
    "estimated_duration": 3600.0533179977488,
    "input_throughput": 4596.198038867587,
    "output_throughput": 4092.5052210599547,
    "total_throughput": 8688.70325992754,
    "itl": 210.6146659200141,
    "ttft": 2203388.8104424356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.723237893984129,
    "arrivals": 1260602,
    "finished_requests": 67355,
    "scheduler_time": 103.85939503117126
}
#Debug simulation 
Total elapsed time: 4.981241616886109. Arrivals time: 0.2419787524268031 Scheduler time: 4.64191746013239 Scheduler overhead time: 0.027742948848754168 Adapter cache time: 0.028734967578202486 Engine time: 0.02784631261602044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.835236180108041,
    "estimated_duration": 3600.123074854978,
    "input_throughput": 4461.426641823073,
    "output_throughput": 3978.983413109298,
    "total_throughput": 8440.41005493237,
    "itl": 176.56529938206248,
    "ttft": 2219812.940616078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.910265877265424,
    "arrivals": 1260602,
    "finished_requests": 65383,
    "scheduler_time": 110.62819021709328
}
#Debug simulation 
Total elapsed time: 4.835330672096461. Arrivals time: 0.23554563149809837 Scheduler time: 4.488465233705938 Scheduler overhead time: 0.03159787133336067 Adapter cache time: 0.03289554035291076 Engine time: 0.0319451610557735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.9900440610945225,
    "estimated_duration": 3600.071768794602,
    "input_throughput": 4596.450866183857,
    "output_throughput": 4092.566467066064,
    "total_throughput": 8689.017333249922,
    "itl": 210.60044914789486,
    "ttft": 2203388.5529872463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.509133947121363,
    "arrivals": 1260602,
    "finished_requests": 67359,
    "scheduler_time": 103.86580048368315
}
#Debug simulation 
Total elapsed time: 4.990144749172032. Arrivals time: 0.24447678495198488 Scheduler time: 4.648716135881841 Scheduler overhead time: 0.027645351365208626 Adapter cache time: 0.02870074100792408 Engine time: 0.02778592612594366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.820966004859656,
    "estimated_duration": 3600.1923632288754,
    "input_throughput": 4461.3407783563225,
    "output_throughput": 3978.906834620527,
    "total_throughput": 8440.24761297685,
    "itl": 176.56862727945133,
    "ttft": 2219838.88817184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.979430459793617,
    "arrivals": 1260602,
    "finished_requests": 65383,
    "scheduler_time": 110.62831400852065
}
#Debug simulation 
Total elapsed time: 4.821053134743124. Arrivals time: 0.23727585701271892 Scheduler time: 4.472155487164855 Scheduler overhead time: 0.03173639299347997 Adapter cache time: 0.03291803412139416 Engine time: 0.03205440333113074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.987641931977123,
    "estimated_duration": 3600.1094529449842,
    "input_throughput": 4596.791629894064,
    "output_throughput": 4093.1477758115784,
    "total_throughput": 8689.939405705642,
    "itl": 210.590306690169,
    "ttft": 2203338.5063803843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.314642575543723,
    "arrivals": 1260602,
    "finished_requests": 67366,
    "scheduler_time": 103.87220972191938
}
#Debug simulation 
Total elapsed time: 4.987733197864145. Arrivals time: 0.24297898774966598 Scheduler time: 4.6477260296233 Scheduler overhead time: 0.027690235059708357 Adapter cache time: 0.028858513571321964 Engine time: 0.02771906927227974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8179986560717225,
    "estimated_duration": 3600.0546867883795,
    "input_throughput": 4461.125565380631,
    "output_throughput": 3978.82261415825,
    "total_throughput": 8439.94817953888,
    "itl": 176.57444558115262,
    "ttft": 2219786.63096795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.037669048793578,
    "arrivals": 1260602,
    "finished_requests": 65377,
    "scheduler_time": 110.6223816159334
}
#Debug simulation 
Total elapsed time: 4.818087176885456. Arrivals time: 0.23403391148895025 Scheduler time: 4.4723698063753545 Scheduler overhead time: 0.0318797966465354 Adapter cache time: 0.033101754263043404 Engine time: 0.03193533746525645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.9543187553063035,
    "estimated_duration": 3600.096888867797,
    "input_throughput": 4690.3548768962255,
    "output_throughput": 4135.8367454056515,
    "total_throughput": 8826.191622301876,
    "itl": 207.36704500033076,
    "ttft": 2199472.8493704027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.850093581867502,
    "arrivals": 1256018,
    "finished_requests": 68428,
    "scheduler_time": 105.20958442195203
}
#Debug simulation 
Total elapsed time: 4.954417596105486. Arrivals time: 0.24687025602906942 Scheduler time: 4.613224227912724 Scheduler overhead time: 0.02750433050096035 Adapter cache time: 0.025945778004825115 Engine time: 0.02803349820896983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9510097787715495,
    "estimated_duration": 3600.1333754784137,
    "input_throughput": 4690.0581836794345,
    "output_throughput": 4135.433176283796,
    "total_throughput": 8825.491359963231,
    "itl": 207.3797953691501,
    "ttft": 2199528.3040677686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.112466649527195,
    "arrivals": 1256018,
    "finished_requests": 68423,
    "scheduler_time": 105.20335435015689
}
#Debug simulation 
Total elapsed time: 4.95110081275925. Arrivals time: 0.24242255464196205 Scheduler time: 4.614250258542597 Scheduler overhead time: 0.027605554088950157 Adapter cache time: 0.025882395450025797 Engine time: 0.028031437192112207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.875802665948868,
    "estimated_duration": 3600.0990852333744,
    "input_throughput": 4556.295982874782,
    "output_throughput": 4027.163602098514,
    "total_throughput": 8583.459584973296,
    "itl": 174.98631422581624,
    "ttft": 2214946.433026885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.055885695107214,
    "arrivals": 1256018,
    "finished_requests": 66500,
    "scheduler_time": 111.77714886804952
}
#Debug simulation 
Total elapsed time: 4.875894472002983. Arrivals time: 0.23569118231534958 Scheduler time: 4.533110436052084 Scheduler overhead time: 0.03188995597884059 Adapter cache time: 0.027944988571107388 Engine time: 0.03223546501249075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.924551652744412,
    "estimated_duration": 3600.1776063924162,
    "input_throughput": 4690.249717130058,
    "output_throughput": 4135.744018173604,
    "total_throughput": 8825.993735303662,
    "itl": 207.37130808325784,
    "ttft": 2199504.8405840504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9306417328211944,
    "arrivals": 1256018,
    "finished_requests": 68428,
    "scheduler_time": 105.20975379549414
}
#Debug simulation 
Total elapsed time: 4.9246689598076046. Arrivals time: 0.24413737375289202 Scheduler time: 4.586526179686189 Scheduler overhead time: 0.027496851980686188 Adapter cache time: 0.02569060167297721 Engine time: 0.027919381856918335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.810185044072568,
    "estimated_duration": 3600.154643053735,
    "input_throughput": 4556.225669819142,
    "output_throughput": 4027.1014546481533,
    "total_throughput": 8583.327124467296,
    "itl": 174.9889346722457,
    "ttft": 2214967.469200204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1113431149162345,
    "arrivals": 1256018,
    "finished_requests": 66500,
    "scheduler_time": 111.77724926865487
}
#Debug simulation 
Total elapsed time: 4.810272148810327. Arrivals time: 0.24108248529955745 Scheduler time: 4.462652518413961 Scheduler overhead time: 0.03166341222822666 Adapter cache time: 0.027957050129771233 Engine time: 0.032081520184874535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.9380300818011165,
    "estimated_duration": 3600.0081174602947,
    "input_throughput": 4690.470534803242,
    "output_throughput": 4135.938729633773,
    "total_throughput": 8826.409264437014,
    "itl": 207.362230919621,
    "ttft": 2199438.2000398864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.76148327098684,
    "arrivals": 1256018,
    "finished_requests": 68428,
    "scheduler_time": 105.20942332516235
}
#Debug simulation 
Total elapsed time: 4.938147082924843. Arrivals time: 0.245849690400064 Scheduler time: 4.597734012175351 Scheduler overhead time: 0.02759089693427086 Adapter cache time: 0.026133104227483273 Engine time: 0.027972958516329527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.861436713952571,
    "estimated_duration": 3600.010384664614,
    "input_throughput": 4556.285745694624,
    "output_throughput": 4027.187549724433,
    "total_throughput": 8583.473295419057,
    "itl": 174.99109119038184,
    "ttft": 2214888.028615403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.159772908575882,
    "arrivals": 1256018,
    "finished_requests": 66498,
    "scheduler_time": 111.77127711411313
}
#Debug simulation 
Total elapsed time: 4.861526251770556. Arrivals time: 0.24015416391193867 Scheduler time: 4.5143297258764505 Scheduler overhead time: 0.03185267187654972 Adapter cache time: 0.028196710161864758 Engine time: 0.032055245246738195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.095880303066224,
    "estimated_duration": 3600.121751412618,
    "input_throughput": 4734.015729693765,
    "output_throughput": 4154.929203194495,
    "total_throughput": 8888.94493288826,
    "itl": 205.78807014883196,
    "ttft": 2195940.4804142886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5348633442424173,
    "arrivals": 1253655,
    "finished_requests": 68917,
    "scheduler_time": 105.75805092281678
}
#Debug simulation 
Total elapsed time: 5.09603624092415. Arrivals time: 0.3861891711130738 Scheduler time: 4.615793398115784 Scheduler overhead time: 0.027659436222165823 Adapter cache time: 0.024879373610019684 Engine time: 0.028329237829893827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9405814642086625,
    "estimated_duration": 3600.13502312924,
    "input_throughput": 4733.5585722525375,
    "output_throughput": 4154.468902946776,
    "total_throughput": 8888.027475199313,
    "itl": 205.79894194535444,
    "ttft": 2195995.607034206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7767069874983363,
    "arrivals": 1253655,
    "finished_requests": 68910,
    "scheduler_time": 105.75177070116744
}
#Debug simulation 
Total elapsed time: 4.940672036260366. Arrivals time: 0.24528646003454924 Scheduler time: 4.6020891815423965 Scheduler overhead time: 0.027663241140544415 Adapter cache time: 0.024797003716230392 Engine time: 0.028063866309821606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.981284947134554,
    "estimated_duration": 3600.133986049067,
    "input_throughput": 4597.041405717959,
    "output_throughput": 4038.6516325067228,
    "total_throughput": 8635.693038224681,
    "itl": 173.79515827258635,
    "ttft": 2210570.847056706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6741714716143377,
    "arrivals": 1253655,
    "finished_requests": 66909,
    "scheduler_time": 112.3021881552609
}
#Debug simulation 
Total elapsed time: 4.981404727790505. Arrivals time: 0.23781000450253487 Scheduler time: 4.637137280777097 Scheduler overhead time: 0.03187616402283311 Adapter cache time: 0.027131660375744104 Engine time: 0.03250935487449169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.096230003982782,
    "estimated_duration": 3600.1978778490193,
    "input_throughput": 4733.915628599437,
    "output_throughput": 4154.841346925348,
    "total_throughput": 8888.756975524786,
    "itl": 205.79206257981213,
    "ttft": 2195971.629599827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.610817288211505,
    "arrivals": 1253655,
    "finished_requests": 68917,
    "scheduler_time": 105.75822341513515
}
#Debug simulation 
Total elapsed time: 5.096319487784058. Arrivals time: 0.38912637904286385 Scheduler time: 4.614258652552962 Scheduler overhead time: 0.027547935489565134 Adapter cache time: 0.024731210432946682 Engine time: 0.027864973060786724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.050101733300835,
    "estimated_duration": 3600.1835043290102,
    "input_throughput": 4596.978176278969,
    "output_throughput": 4038.5960833709937,
    "total_throughput": 8635.574259649962,
    "itl": 173.79747596785322,
    "ttft": 2210590.230826453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.723592709675433,
    "arrivals": 1253655,
    "finished_requests": 66909,
    "scheduler_time": 112.30228519718409
}
#Debug simulation 
Total elapsed time: 5.050196315161884. Arrivals time: 0.32606192398816347 Scheduler time: 4.618229653686285 Scheduler overhead time: 0.031738430727273226 Adapter cache time: 0.027224735356867313 Engine time: 0.0321130258962512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.084163375664502,
    "estimated_duration": 3600.04023374287,
    "input_throughput": 4734.122924587649,
    "output_throughput": 4155.023285517086,
    "total_throughput": 8889.146210104736,
    "itl": 205.78372653030365,
    "ttft": 2195908.301764686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.453508090611927,
    "arrivals": 1253655,
    "finished_requests": 68917,
    "scheduler_time": 105.75788850654482
}
#Debug simulation 
Total elapsed time: 5.0842833230271935. Arrivals time: 0.3825758844614029 Scheduler time: 4.6084875031374395 Scheduler overhead time: 0.02756544668227434 Adapter cache time: 0.024733284022659063 Engine time: 0.027996329590678215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.888875229749829,
    "estimated_duration": 3600.045436918841,
    "input_throughput": 4596.846703735944,
    "output_throughput": 4038.5662499980735,
    "total_throughput": 8635.412953734018,
    "itl": 173.79883407334847,
    "ttft": 2210603.807375649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7708761333674743,
    "arrivals": 1253655,
    "finished_requests": 66905,
    "scheduler_time": 112.29646839109729
}
#Debug simulation 
Total elapsed time: 4.888965172693133. Arrivals time: 0.24290747102349997 Scheduler time: 4.539576316718012 Scheduler overhead time: 0.031897086184471846 Adapter cache time: 0.027320992667227983 Engine time: 0.03235215973109007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.072343778796494,
    "estimated_duration": 3600.181324215833,
    "input_throughput": 4800.669034014426,
    "output_throughput": 4212.743924308728,
    "total_throughput": 9013.412958323153,
    "itl": 202.83279494201346,
    "ttft": 2185843.670724454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9870360380784353,
    "arrivals": 1252442,
    "finished_requests": 69547,
    "scheduler_time": 107.26689651264165
}
#Debug simulation 
Total elapsed time: 5.072464590892196. Arrivals time: 0.33047038596123457 Scheduler time: 4.651870680041611 Scheduler overhead time: 0.027757601346820593 Adapter cache time: 0.021473875734955072 Engine time: 0.027939482126384974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.011756215710193,
    "estimated_duration": 3600.1537268059865,
    "input_throughput": 4800.434179051752,
    "output_throughput": 4212.60289167016,
    "total_throughput": 9013.037070721912,
    "itl": 202.84252005763352,
    "ttft": 2185896.8280899622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1887791886320414,
    "arrivals": 1252442,
    "finished_requests": 69545,
    "scheduler_time": 107.26064118354707
}
#Debug simulation 
Total elapsed time: 5.011849970091134. Arrivals time: 0.2460324470885098 Scheduler time: 4.67548345727846 Scheduler overhead time: 0.02778055891394615 Adapter cache time: 0.021419153548777103 Engine time: 0.028136441949754953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.888372597284615,
    "estimated_duration": 3600.1675816804786,
    "input_throughput": 4650.445464037267,
    "output_throughput": 4087.8266542054953,
    "total_throughput": 8738.272118242763,
    "itl": 170.99299089026934,
    "ttft": 2202293.5973907174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.072353605516225,
    "arrivals": 1252442,
    "finished_requests": 67380,
    "scheduler_time": 113.8899271923948
}
#Debug simulation 
Total elapsed time: 4.888465960044414. Arrivals time: 0.23596345307305455 Scheduler time: 4.548444259911776 Scheduler overhead time: 0.032235711347311735 Adapter cache time: 0.024049182422459126 Engine time: 0.03260873118415475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.017134683206677,
    "estimated_duration": 3600.0164119013825,
    "input_throughput": 4800.61728131739,
    "output_throughput": 4212.76357237214,
    "total_throughput": 9013.38085368953,
    "itl": 202.83533046716028,
    "ttft": 2185846.9195413943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.049856780362283,
    "arrivals": 1252442,
    "finished_requests": 69545,
    "scheduler_time": 107.26038952229258
}
#Debug simulation 
Total elapsed time: 5.017228024080396. Arrivals time: 0.24713354278355837 Scheduler time: 4.6792772258631885 Scheduler overhead time: 0.02787467325106263 Adapter cache time: 0.021369352005422115 Engine time: 0.028495535254478455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.898442040197551,
    "estimated_duration": 3600.017566252947,
    "input_throughput": 4650.639251581817,
    "output_throughput": 4087.9969970029733,
    "total_throughput": 8738.636248584791,
    "itl": 170.99481505282137,
    "ttft": 2202263.9250771394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.112846324741843,
    "arrivals": 1252442,
    "finished_requests": 67380,
    "scheduler_time": 113.88400356113569
}
#Debug simulation 
Total elapsed time: 4.898586030118167. Arrivals time: 0.23870964627712965 Scheduler time: 4.555403566453606 Scheduler overhead time: 0.03247441491112113 Adapter cache time: 0.02393602440133691 Engine time: 0.032694653142243624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.962398686911911,
    "estimated_duration": 3600.1124238459074,
    "input_throughput": 4800.760911109747,
    "output_throughput": 4212.824549461671,
    "total_throughput": 9013.58546057142,
    "itl": 202.82925358166693,
    "ttft": 2185816.9999962454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9182890878244567,
    "arrivals": 1252442,
    "finished_requests": 69547,
    "scheduler_time": 107.2667430928397
}
#Debug simulation 
Total elapsed time: 4.962493535596877. Arrivals time: 0.24672335665673018 Scheduler time: 4.625758609734476 Scheduler overhead time: 0.02769760647788644 Adapter cache time: 0.021288393530994654 Engine time: 0.028136457782238722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.99405563576147,
    "estimated_duration": 3600.057160659577,
    "input_throughput": 4650.5881025879535,
    "output_throughput": 4087.952036101471,
    "total_throughput": 8738.540138689425,
    "itl": 170.99656015667193,
    "ttft": 2202279.587438481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1523330136761416,
    "arrivals": 1252442,
    "finished_requests": 67380,
    "scheduler_time": 113.88411127886997
}
#Debug simulation 
Total elapsed time: 4.994148355908692. Arrivals time: 0.23352858051657677 Scheduler time: 4.657133100554347 Scheduler overhead time: 0.032191835809499025 Adapter cache time: 0.02370703313499689 Engine time: 0.032475628424435854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.057939855847508,
    "estimated_duration": 3600.209419184744,
    "input_throughput": 4851.711377377426,
    "output_throughput": 4261.128510539232,
    "total_throughput": 9112.839887916658,
    "itl": 200.99150310847392,
    "ttft": 2183394.1523440075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5861121436232306,
    "arrivals": 1246365,
    "finished_requests": 70555,
    "scheduler_time": 108.41651901228127
}
#Debug simulation 
Total elapsed time: 5.05802928796038. Arrivals time: 0.2489996636286378 Scheduler time: 4.719600958283991 Scheduler overhead time: 0.028147246688604355 Adapter cache time: 0.019470644649118185 Engine time: 0.028516180347651243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0295439548790455,
    "estimated_duration": 3600.1612220153015,
    "input_throughput": 4851.539951375479,
    "output_throughput": 4261.004175644332,
    "total_throughput": 9112.54412701981,
    "itl": 200.9993389074662,
    "ttft": 2183401.1421464127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.761534807295545,
    "arrivals": 1246365,
    "finished_requests": 70552,
    "scheduler_time": 108.41022347501215
}
#Debug simulation 
Total elapsed time: 5.0296343131922185. Arrivals time: 0.24613849399611354 Scheduler time: 4.694775820244104 Scheduler overhead time: 0.02800361020490527 Adapter cache time: 0.019338724203407764 Engine time: 0.02825131732970476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9357554777525365,
    "estimated_duration": 3600.1636861574493,
    "input_throughput": 4697.896949805609,
    "output_throughput": 4129.327523956876,
    "total_throughput": 8827.224473762486,
    "itl": 170.3353497079825,
    "ttft": 2200929.3176346878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.680826039090739,
    "arrivals": 1246365,
    "finished_requests": 68331,
    "scheduler_time": 114.74398958743524
}
#Debug simulation 
Total elapsed time: 4.935846239794046. Arrivals time: 0.24037702288478613 Scheduler time: 4.593605333939195 Scheduler overhead time: 0.03259205864742398 Adapter cache time: 0.021268023177981377 Engine time: 0.03270251676440239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.127662615850568,
    "estimated_duration": 3600.038341738174,
    "input_throughput": 4851.705549215593,
    "output_throughput": 4261.149616699187,
    "total_throughput": 9112.855165914782,
    "itl": 200.99302615303554,
    "ttft": 2183351.3326286785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6389562117634084,
    "arrivals": 1246365,
    "finished_requests": 70552,
    "scheduler_time": 108.4099217933844
}
#Debug simulation 
Total elapsed time: 5.127783625852317. Arrivals time: 0.3325584130361676 Scheduler time: 4.706095860339701 Scheduler overhead time: 0.028087293729186058 Adapter cache time: 0.019450682681053877 Engine time: 0.028401911724358797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.976079354993999,
    "estimated_duration": 3600.0111374629496,
    "input_throughput": 4697.762688567253,
    "output_throughput": 4129.3747247894435,
    "total_throughput": 8827.137413356697,
    "itl": 170.3364830439531,
    "ttft": 2200963.975605962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7172946371510647,
    "arrivals": 1246365,
    "finished_requests": 68329,
    "scheduler_time": 114.7380144868397
}
#Debug simulation 
Total elapsed time: 4.976172448135912. Arrivals time: 0.25386816868558526 Scheduler time: 4.619919701945037 Scheduler overhead time: 0.032632135320454836 Adapter cache time: 0.021635198034346104 Engine time: 0.03283913154155016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.052194194868207,
    "estimated_duration": 3600.149747320151,
    "input_throughput": 4851.79179366138,
    "output_throughput": 4261.199138013459,
    "total_throughput": 9112.990931674838,
    "itl": 200.98847298415504,
    "ttft": 2183369.7071181466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5265924991922857,
    "arrivals": 1246365,
    "finished_requests": 70555,
    "scheduler_time": 108.41636679200866
}
#Debug simulation 
Total elapsed time: 5.052284206263721. Arrivals time: 0.24510131170973182 Scheduler time: 4.718139212578535 Scheduler overhead time: 0.02802641736343503 Adapter cache time: 0.019529385957866907 Engine time: 0.028350549284368753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.966824731323868,
    "estimated_duration": 3600.0449357998828,
    "input_throughput": 4697.71858451605,
    "output_throughput": 4129.335956940497,
    "total_throughput": 8827.054541456548,
    "itl": 170.3379587752604,
    "ttft": 2200977.8978815326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.750996651910266,
    "arrivals": 1246365,
    "finished_requests": 68329,
    "scheduler_time": 114.73811080904531
}
#Debug simulation 
Total elapsed time: 4.966915616299957. Arrivals time: 0.24339549150317907 Scheduler time: 4.621576512698084 Scheduler overhead time: 0.03240211494266987 Adapter cache time: 0.021374134812504053 Engine time: 0.03284787805750966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.059092852752656,
    "estimated_duration": 3600.1216910113512,
    "input_throughput": 4869.620947472779,
    "output_throughput": 4284.15184923019,
    "total_throughput": 9153.77279670297,
    "itl": 200.0951529036212,
    "ttft": 2186541.9007295882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2402770285588174,
    "arrivals": 1243986,
    "finished_requests": 70537,
    "scheduler_time": 109.01798618390815
}
#Debug simulation 
Total elapsed time: 5.059180743061006. Arrivals time: 0.24946185946464539 Scheduler time: 4.722234832588583 Scheduler overhead time: 0.027902815025299788 Adapter cache time: 0.018093150574713945 Engine time: 0.028326458297669888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.020816480740905,
    "estimated_duration": 3600.220745567764,
    "input_throughput": 4869.486967315189,
    "output_throughput": 4284.033977357597,
    "total_throughput": 9153.520944672786,
    "itl": 200.09967793346843,
    "ttft": 2186601.751258866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3852511640382033,
    "arrivals": 1243986,
    "finished_requests": 70537,
    "scheduler_time": 109.01841153701034
}
#Debug simulation 
Total elapsed time: 5.020906573161483. Arrivals time: 0.24494141386821866 Scheduler time: 4.6883978601545095 Scheduler overhead time: 0.027910503558814526 Adapter cache time: 0.01811748743057251 Engine time: 0.028448161203414202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9200748689472675,
    "estimated_duration": 3600.1658824963897,
    "input_throughput": 4708.182220827709,
    "output_throughput": 4148.494121510796,
    "total_throughput": 8856.676342338505,
    "itl": 169.25560351546994,
    "ttft": 2203776.7793549807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.33968930311501,
    "arrivals": 1243986,
    "finished_requests": 68222,
    "scheduler_time": 115.37828946781298
}
#Debug simulation 
Total elapsed time: 4.920172210782766. Arrivals time: 0.24144666688516736 Scheduler time: 4.578720387537032 Scheduler overhead time: 0.032289593014866114 Adapter cache time: 0.01987798884510994 Engine time: 0.03259805403649807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.180540910921991,
    "estimated_duration": 3600.1183240851606,
    "input_throughput": 4869.625501671511,
    "output_throughput": 4284.1558558826855,
    "total_throughput": 9153.781357554197,
    "itl": 200.0945574672733,
    "ttft": 2186558.8263486885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2831023344280927,
    "arrivals": 1243986,
    "finished_requests": 70537,
    "scheduler_time": 109.01813888399249
}
#Debug simulation 
Total elapsed time: 5.180680157151073. Arrivals time: 0.33928145421668887 Scheduler time: 4.753245481289923 Scheduler overhead time: 0.02826050017029047 Adapter cache time: 0.01825206493958831 Engine time: 0.02841358259320259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3525445237755775,
    "estimated_duration": 3600.014393230433,
    "input_throughput": 4708.083120965206,
    "output_throughput": 4148.475636120617,
    "total_throughput": 8856.558757085824,
    "itl": 169.25740741477352,
    "ttft": 2203784.5527369655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3708762421458998,
    "arrivals": 1243986,
    "finished_requests": 68218,
    "scheduler_time": 115.37242695489452
}
#Debug simulation 
Total elapsed time: 5.3526065540499985. Arrivals time: 0.6325587183237076 Scheduler time: 4.61957952240482 Scheduler overhead time: 0.03262798814103007 Adapter cache time: 0.01969508733600378 Engine time: 0.03287674719467759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.19123376486823,
    "estimated_duration": 3600.069974500081,
    "input_throughput": 4869.690901614892,
    "output_throughput": 4284.213392863776,
    "total_throughput": 9153.904294478667,
    "itl": 200.09260519644366,
    "ttft": 2186520.318140363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.188716815868352,
    "arrivals": 1243986,
    "finished_requests": 70537,
    "scheduler_time": 109.0178298852358
}
#Debug simulation 
Total elapsed time: 5.191326975822449. Arrivals time: 0.33317448291927576 Scheduler time: 4.770369662437588 Scheduler overhead time: 0.028068877290934324 Adapter cache time: 0.0180638050660491 Engine time: 0.0285445642657578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.051715616136789,
    "estimated_duration": 3600.0431617757804,
    "input_throughput": 4708.045497887738,
    "output_throughput": 4148.442484959896,
    "total_throughput": 8856.487982847633,
    "itl": 169.25861709357864,
    "ttft": 2203796.9021259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3995481054484933,
    "arrivals": 1243986,
    "finished_requests": 68218,
    "scheduler_time": 115.37252363695892
}
#Debug simulation 
Total elapsed time: 5.051804861053824. Arrivals time: 0.2625139690935612 Scheduler time: 4.688462767750025 Scheduler overhead time: 0.032520275097340345 Adapter cache time: 0.019935936201363802 Engine time: 0.03300198120996356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.4806461269035935,
    "estimated_duration": 3600.0238170293073,
    "input_throughput": 4906.549205714936,
    "output_throughput": 4314.339790345214,
    "total_throughput": 9220.88899606015,
    "itl": 198.68704085544235,
    "ttft": 2182366.035628015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.00767996001992,
    "arrivals": 1242821,
    "finished_requests": 71355,
    "scheduler_time": 109.78238497367751
}
#Debug simulation 
Total elapsed time: 5.480715557001531. Arrivals time: 0.24986417964100838 Scheduler time: 5.144328960683197 Scheduler overhead time: 0.028252817690372467 Adapter cache time: 0.016605594661086798 Engine time: 0.028497880324721336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.106169168371707,
    "estimated_duration": 3600.160280562298,
    "input_throughput": 4906.363223706574,
    "output_throughput": 4314.176255945513,
    "total_throughput": 9220.539479652087,
    "itl": 198.69376598631507,
    "ttft": 2182422.7176004266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1432979101617886,
    "arrivals": 1242821,
    "finished_requests": 71355,
    "scheduler_time": 109.78284115468361
}
#Debug simulation 
Total elapsed time: 5.106285290326923. Arrivals time: 0.2499155541881919 Scheduler time: 4.769146848469973 Scheduler overhead time: 0.02838499378412962 Adapter cache time: 0.016567593906074762 Engine time: 0.028912979178130627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.022349376231432,
    "estimated_duration": 3600.112200036796,
    "input_throughput": 4737.932056624697,
    "output_throughput": 4172.034693764957,
    "total_throughput": 8909.966750389654,
    "itl": 168.44758005573544,
    "ttft": 2199966.8332369966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.094554723333576,
    "arrivals": 1242821,
    "finished_requests": 68924,
    "scheduler_time": 115.9821270778025
}
#Debug simulation 
Total elapsed time: 5.022437860257924. Arrivals time: 0.24558231281116605 Scheduler time: 4.676977000199258 Scheduler overhead time: 0.032787635922431946 Adapter cache time: 0.018409996293485165 Engine time: 0.033241665456444025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.125638247933239,
    "estimated_duration": 3600.066436702511,
    "input_throughput": 4906.491119141429,
    "output_throughput": 4314.288714690032,
    "total_throughput": 9220.77983383146,
    "itl": 198.68907861489635,
    "ttft": 2182384.7939886134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.049729582238927,
    "arrivals": 1242821,
    "finished_requests": 71355,
    "scheduler_time": 109.78256562279536
}
#Debug simulation 
Total elapsed time: 5.125727167818695. Arrivals time: 0.25025041960179806 Scheduler time: 4.785846933256835 Scheduler overhead time: 0.030660930555313826 Adapter cache time: 0.016694090329110622 Engine time: 0.02897488232702017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.967681915033609,
    "estimated_duration": 3600.1402090213965,
    "input_throughput": 4737.895195653094,
    "output_throughput": 4172.00223545814,
    "total_throughput": 8909.897431111234,
    "itl": 168.44878559950254,
    "ttft": 2199978.1315615242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1224720639176677,
    "arrivals": 1242821,
    "finished_requests": 68924,
    "scheduler_time": 115.9822187218437
}
#Debug simulation 
Total elapsed time: 4.96777460211888. Arrivals time: 0.2437754152342677 Scheduler time: 4.624315865337849 Scheduler overhead time: 0.03268430847674608 Adapter cache time: 0.01835891278460622 Engine time: 0.03315451415255666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.1445939890109,
    "estimated_duration": 3600.2019525968926,
    "input_throughput": 4906.67863430769,
    "output_throughput": 4314.41741449974,
    "total_throughput": 9221.09604880743,
    "itl": 198.685197371609,
    "ttft": 2182401.9570059264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9614729934557944,
    "arrivals": 1242821,
    "finished_requests": 71362,
    "scheduler_time": 109.78912878446519
}
#Debug simulation 
Total elapsed time: 5.144692858681083. Arrivals time: 0.2605158928781748 Scheduler time: 4.796744989231229 Scheduler overhead time: 0.02844626037403941 Adapter cache time: 0.0168173024430871 Engine time: 0.02884829230606556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.959904137998819,
    "estimated_duration": 3600.1671058942015,
    "input_throughput": 4737.859798806033,
    "output_throughput": 4171.971066401213,
    "total_throughput": 8909.830865207246,
    "itl": 168.4499211951132,
    "ttft": 2199989.5026050666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149257620424032,
    "arrivals": 1242821,
    "finished_requests": 68924,
    "scheduler_time": 115.98233003816598
}
#Debug simulation 
Total elapsed time: 4.959993346594274. Arrivals time: 0.2428091918118298 Scheduler time: 4.617436529137194 Scheduler overhead time: 0.032803595531731844 Adapter cache time: 0.018471453338861465 Engine time: 0.033060985151678324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.158279817085713,
    "estimated_duration": 3600.2015329956016,
    "input_throughput": 4924.534595497507,
    "output_throughput": 4359.83093061451,
    "total_throughput": 9284.365526112017,
    "itl": 197.36266677552877,
    "ttft": 2174174.3056118367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 1239193,
    "finished_requests": 72040,
    "scheduler_time": 110.74457619866959
}
#Debug simulation 
Total elapsed time: 5.1584367589093745. Arrivals time: 0.25142982974648476 Scheduler time: 4.82240962004289 Scheduler overhead time: 0.028408823534846306 Adapter cache time: 0.013920933939516544 Engine time: 0.028852888848632574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.178052233997732,
    "estimated_duration": 3600.0891223402373,
    "input_throughput": 4924.105597829318,
    "output_throughput": 4359.1412508695275,
    "total_throughput": 9283.246848698845,
    "itl": 197.36601409904364,
    "ttft": 2174183.6133211753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6595023393537913,
    "arrivals": 1239193,
    "finished_requests": 72033,
    "scheduler_time": 110.73821125189353
}
#Debug simulation 
Total elapsed time: 5.178146589081734. Arrivals time: 0.25405430514365435 Scheduler time: 4.839384553954005 Scheduler overhead time: 0.028550831601023674 Adapter cache time: 0.013834663201123476 Engine time: 0.028924457728862762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.044540553819388,
    "estimated_duration": 3600.0687265951065,
    "input_throughput": 4744.920249385335,
    "output_throughput": 4208.201884614708,
    "total_throughput": 8953.122134000045,
    "itl": 167.53055131151376,
    "ttft": 2192018.341683096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6185079983249404,
    "arrivals": 1239193,
    "finished_requests": 69461,
    "scheduler_time": 116.8239824223568
}
#Debug simulation 
Total elapsed time: 5.044665502849966. Arrivals time: 0.24680721294134855 Scheduler time: 4.700361756142229 Scheduler overhead time: 0.03289348445832729 Adapter cache time: 0.0156609327532351 Engine time: 0.03332911804318428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.158275246154517,
    "estimated_duration": 3600.0144940958444,
    "input_throughput": 4924.207674461669,
    "output_throughput": 4359.231615799765,
    "total_throughput": 9283.439290261435,
    "itl": 197.36235280198855,
    "ttft": 2174150.8539339546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5851379913976344,
    "arrivals": 1239193,
    "finished_requests": 72033,
    "scheduler_time": 110.73794735543984
}
#Debug simulation 
Total elapsed time: 5.158369661774486. Arrivals time: 0.26500701578333974 Scheduler time: 4.808578658849001 Scheduler overhead time: 0.028602023608982563 Adapter cache time: 0.013890089467167854 Engine time: 0.02891159988939762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.049687677063048,
    "estimated_duration": 3600.091068982336,
    "input_throughput": 4744.890802117599,
    "output_throughput": 4208.175768254248,
    "total_throughput": 8953.066570371848,
    "itl": 167.53151974035742,
    "ttft": 2192028.1137313396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6407664185203645,
    "arrivals": 1239193,
    "finished_requests": 69461,
    "scheduler_time": 116.82406638941026
}
#Debug simulation 
Total elapsed time: 5.049803120084107. Arrivals time: 0.24295068020001054 Scheduler time: 4.709292662329972 Scheduler overhead time: 0.033023128286004066 Adapter cache time: 0.015653664711862803 Engine time: 0.03333255182951689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.166939354036003,
    "estimated_duration": 3600.165595912313,
    "input_throughput": 4924.583752516872,
    "output_throughput": 4359.874450725767,
    "total_throughput": 9284.458203242639,
    "itl": 197.3609562059913,
    "ttft": 2174158.0995266074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5189455498102882,
    "arrivals": 1239193,
    "finished_requests": 72040,
    "scheduler_time": 110.74442133943244
}
#Debug simulation 
Total elapsed time: 5.167028157971799. Arrivals time: 0.25643592327833176 Scheduler time: 4.825632893014699 Scheduler overhead time: 0.02850322611629963 Adapter cache time: 0.014046662952750921 Engine time: 0.02901627914980054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0347734349779785,
    "estimated_duration": 3600.11066277921,
    "input_throughput": 4744.8649777929395,
    "output_throughput": 4208.152865030171,
    "total_throughput": 8953.01784282311,
    "itl": 167.53232879066317,
    "ttft": 2192036.9309647786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6602582554146632,
    "arrivals": 1239193,
    "finished_requests": 69461,
    "scheduler_time": 116.82416834940373
}
#Debug simulation 
Total elapsed time: 5.034886995796114. Arrivals time: 0.2428139359690249 Scheduler time: 4.694621993228793 Scheduler overhead time: 0.03298204578459263 Adapter cache time: 0.015617684461176395 Engine time: 0.03326151520013809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.646214150823653,
    "estimated_duration": 3600.1470490257348,
    "input_throughput": 4972.556330676712,
    "output_throughput": 4380.322188302724,
    "total_throughput": 9352.878518979436,
    "itl": 195.91963591276567,
    "ttft": 2174136.8020323184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3251911931228924,
    "arrivals": 1238058,
    "finished_requests": 72071,
    "scheduler_time": 111.37140566624863
}
#Debug simulation 
Total elapsed time: 5.646286650095135. Arrivals time: 0.6576152686029673 Scheduler time: 4.904676162172109 Scheduler overhead time: 0.02886739606037736 Adapter cache time: 0.01224259426817298 Engine time: 0.02943395357578993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1577256000600755,
    "estimated_duration": 3600.017156173689,
    "input_throughput": 4972.735468579609,
    "output_throughput": 4380.399124753275,
    "total_throughput": 9353.134593332883,
    "itl": 195.92328410871076,
    "ttft": 2174105.3184408923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4127758247219089,
    "arrivals": 1238058,
    "finished_requests": 72070,
    "scheduler_time": 111.36507376406283
}
#Debug simulation 
Total elapsed time: 5.157818565145135. Arrivals time: 0.25110529782250524 Scheduler time: 4.8230655821971595 Scheduler overhead time: 0.028522993437945843 Adapter cache time: 0.012402951251715422 Engine time: 0.029258384369313717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.050851151812822,
    "estimated_duration": 3600.119153894394,
    "input_throughput": 4792.794977725936,
    "output_throughput": 4220.069211755224,
    "total_throughput": 9012.86418948116,
    "itl": 165.83641153805019,
    "ttft": 2194204.0067466456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3632394109107633,
    "arrivals": 1238058,
    "finished_requests": 69405,
    "scheduler_time": 117.53005075458907
}
#Debug simulation 
Total elapsed time: 5.050941945053637. Arrivals time: 0.24742649355903268 Scheduler time: 4.706905764061958 Scheduler overhead time: 0.033499413169920444 Adapter cache time: 0.013839943800121546 Engine time: 0.03369620628654957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.5693958210758865,
    "estimated_duration": 3600.17022565818,
    "input_throughput": 4972.524319104157,
    "output_throughput": 4380.293989325735,
    "total_throughput": 9352.818308429893,
    "itl": 195.92063724405097,
    "ttft": 2174147.589021297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3482177644083244,
    "arrivals": 1238058,
    "finished_requests": 72071,
    "scheduler_time": 111.37155572736845
}
#Debug simulation 
Total elapsed time: 5.569457380101085. Arrivals time: 0.6448901807889342 Scheduler time: 4.841203066986054 Scheduler overhead time: 0.028537311125546694 Adapter cache time: 0.012282738462090492 Engine time: 0.029181034304201603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.086796745657921,
    "estimated_duration": 3600.138479030422,
    "input_throughput": 4792.769250544764,
    "output_throughput": 4220.046558901164,
    "total_throughput": 9012.815809445927,
    "itl": 165.83718249903498,
    "ttft": 2194212.1253517815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3824797402322335,
    "arrivals": 1238058,
    "finished_requests": 69405,
    "scheduler_time": 117.53013556131306
}
#Debug simulation 
Total elapsed time: 5.086934833787382. Arrivals time: 0.25761437183246017 Scheduler time: 4.732097632717341 Scheduler overhead time: 0.03342704754322767 Adapter cache time: 0.013971753418445587 Engine time: 0.03405531542375684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.163091703783721,
    "estimated_duration": 3600.1164051870246,
    "input_throughput": 4972.598656589828,
    "output_throughput": 4380.359473176747,
    "total_throughput": 9352.958129766575,
    "itl": 195.91825893928083,
    "ttft": 2174123.2975013535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.294691777692633,
    "arrivals": 1238058,
    "finished_requests": 72071,
    "scheduler_time": 111.3712612429167
}
#Debug simulation 
Total elapsed time: 5.163182085845619. Arrivals time: 0.25229357462376356 Scheduler time: 4.826956518460065 Scheduler overhead time: 0.028685682453215122 Adapter cache time: 0.012184650637209415 Engine time: 0.029653273057192564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.410916060209274,
    "estimated_duration": 3600.154423568433,
    "input_throughput": 4792.748024096533,
    "output_throughput": 4220.027868954886,
    "total_throughput": 9012.77589305142,
    "itl": 165.83780080745407,
    "ttft": 2194219.384906114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3983247173205027,
    "arrivals": 1238058,
    "finished_requests": 69405,
    "scheduler_time": 117.53023512224786
}
#Debug simulation 
Total elapsed time: 5.411003564018756. Arrivals time: 0.6358160693198442 Scheduler time: 4.67880044085905 Scheduler overhead time: 0.03323952341452241 Adapter cache time: 0.013988565187901258 Engine time: 0.03353685047477484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.311703972052783,
    "estimated_duration": 3600.00553989012,
    "input_throughput": 5020.293941145333,
    "output_throughput": 4421.026252222318,
    "total_throughput": 9441.32019336765,
    "itl": 194.03742136990405,
    "ttft": 2168658.912436281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9609931515948834,
    "arrivals": 1235689,
    "finished_requests": 73074,
    "scheduler_time": 112.36141909608051
}
#Debug simulation 
Total elapsed time: 5.31179897300899. Arrivals time: 0.3348733582533896 Scheduler time: 4.894724043551832 Scheduler overhead time: 0.028962157666683197 Adapter cache time: 0.010199037846177816 Engine time: 0.029467813670635223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1577230002731085,
    "estimated_duration": 3600.065952032473,
    "input_throughput": 5020.209696379746,
    "output_throughput": 4420.952063673871,
    "total_throughput": 9441.161760053616,
    "itl": 194.03999478041374,
    "ttft": 2168687.4959095633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0210034516057986,
    "arrivals": 1235689,
    "finished_requests": 73074,
    "scheduler_time": 112.36182093840773
}
#Debug simulation 
Total elapsed time: 5.157840934116393. Arrivals time: 0.25242633651942015 Scheduler time: 4.823511675465852 Scheduler overhead time: 0.02883414225652814 Adapter cache time: 0.010053636506199837 Engine time: 0.029541507828980684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.104095888789743,
    "estimated_duration": 3600.1787558579804,
    "input_throughput": 4826.327851562222,
    "output_throughput": 4253.794891456807,
    "total_throughput": 9080.122743019028,
    "itl": 164.8427725933472,
    "ttft": 2188580.8339940053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9811879399232617,
    "arrivals": 1235689,
    "finished_requests": 70255,
    "scheduler_time": 118.35749881619725
}
#Debug simulation 
Total elapsed time: 5.104187214747071. Arrivals time: 0.24950588075444102 Scheduler time: 4.760177467018366 Scheduler overhead time: 0.03345298580825329 Adapter cache time: 0.011674629524350166 Engine time: 0.03370771696791053 
