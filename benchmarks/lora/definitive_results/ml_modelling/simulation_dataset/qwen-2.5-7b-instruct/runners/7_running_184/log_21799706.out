INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.407445157878101,
    "estimated_duration": 3599.9976004606897,
    "input_throughput": 3515.6698433299975,
    "output_throughput": 3146.1079303360148,
    "total_throughput": 6661.777773666013,
    "itl": 29.868378443536653,
    "ttft": 37922.84367315115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7842643547128214,
    "arrivals": 51326,
    "finished_requests": 51020,
    "scheduler_time": 26.20344710563518
}
#Debug simulation 
Total elapsed time: 6.407598178833723. Arrivals time: 0.1487817713059485 Scheduler time: 5.920881518162787 Scheduler overhead time: 0.1300980127416551 Adapter cache time: 0.023258415516465902 Engine time: 0.12554865796118975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.537862023804337,
    "estimated_duration": 3600.0319757480297,
    "input_throughput": 3511.7085306924637,
    "output_throughput": 3142.0609806249417,
    "total_throughput": 6653.769511317405,
    "itl": 29.92665884366692,
    "ttft": 42298.47570680454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8315885335579567,
    "arrivals": 51326,
    "finished_requests": 50975,
    "scheduler_time": 26.36084284049535
}
#Debug simulation 
Total elapsed time: 6.537967787589878. Arrivals time: 0.15000536013394594 Scheduler time: 6.047585554886609 Scheduler overhead time: 0.13138185627758503 Adapter cache time: 0.022945408709347248 Engine time: 0.12712535029277205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.546615936793387,
    "estimated_duration": 3600.000314888719,
    "input_throughput": 3511.7391372758225,
    "output_throughput": 3144.3411138562374,
    "total_throughput": 6656.08025113206,
    "itl": 29.934930101720322,
    "ttft": 41805.9852699122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8152918154187612,
    "arrivals": 51326,
    "finished_requests": 50983,
    "scheduler_time": 26.377739063834085
}
#Debug simulation 
Total elapsed time: 6.546740707941353. Arrivals time: 0.1481830906122923 Scheduler time: 6.060674971435219 Scheduler overhead time: 0.13124449830502272 Adapter cache time: 0.02294839872047305 Engine time: 0.12496567983180285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.42308539012447,
    "estimated_duration": 3600.0011724701244,
    "input_throughput": 3514.5505220262535,
    "output_throughput": 3145.160086776045,
    "total_throughput": 6659.710608802298,
    "itl": 29.877266903497855,
    "ttft": 39238.842662792646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.806680425473011,
    "arrivals": 51326,
    "finished_requests": 51001,
    "scheduler_time": 26.193864035409206
}
#Debug simulation 
Total elapsed time: 6.423206202220172. Arrivals time: 0.15751828299835324 Scheduler time: 5.926932447589934 Scheduler overhead time: 0.13082599500194192 Adapter cache time: 0.02335037337616086 Engine time: 0.12585455318912864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.681633705738932,
    "estimated_duration": 3600.0168611670933,
    "input_throughput": 3515.2407580383906,
    "output_throughput": 3145.8141549727466,
    "total_throughput": 6661.054913011138,
    "itl": 29.893691381995957,
    "ttft": 40094.76559399875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8286457586661011,
    "arrivals": 51326,
    "finished_requests": 51018,
    "scheduler_time": 26.517219421214307
}
#Debug simulation 
Total elapsed time: 6.68173534469679. Arrivals time: 0.15617397287860513 Scheduler time: 6.183529443107545 Scheduler overhead time: 0.13255384331569076 Adapter cache time: 0.023458756506443024 Engine time: 0.12678615376353264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.1377062657848,
    "estimated_duration": 3600.014653458715,
    "input_throughput": 3515.7729116018854,
    "output_throughput": 3146.801080133413,
    "total_throughput": 6662.5739917352985,
    "itl": 29.752822833059877,
    "ttft": 35352.74445509158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.946522741981284,
    "arrivals": 51326,
    "finished_requests": 51027,
    "scheduler_time": 25.913410486785853
}
#Debug simulation 
Total elapsed time: 6.1378168277442455. Arrivals time: 0.1579450573772192 Scheduler time: 5.642980882897973 Scheduler overhead time: 0.1286269621923566 Adapter cache time: 0.023685201071202755 Engine time: 0.12541211396455765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.547138956841081,
    "estimated_duration": 3600.018047294201,
    "input_throughput": 3513.7412740215227,
    "output_throughput": 3144.9511783724543,
    "total_throughput": 6658.692452393977,
    "itl": 29.90632847260237,
    "ttft": 40997.43809661982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9088942254334647,
    "arrivals": 51326,
    "finished_requests": 50996,
    "scheduler_time": 26.388727896200336
}
#Debug simulation 
Total elapsed time: 6.5472875838167965. Arrivals time: 0.14997928403317928 Scheduler time: 6.059197096154094 Scheduler overhead time: 0.13083187025040388 Adapter cache time: 0.023068088572472334 Engine time: 0.12521967105567455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.44405083078891,
    "estimated_duration": 3599.98047831489,
    "input_throughput": 3410.0526583261676,
    "output_throughput": 3008.414647034283,
    "total_throughput": 6418.467305360451,
    "itl": 29.081003194627552,
    "ttft": 32391.446992544283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1913092246558916,
    "arrivals": 49599,
    "finished_requests": 49304,
    "scheduler_time": 22.903339914468532
}
#Debug simulation 
Total elapsed time: 5.444155245088041. Arrivals time: 0.14784651435911655 Scheduler time: 4.958469623699784 Scheduler overhead time: 0.12814617482945323 Adapter cache time: 0.024036190938204527 Engine time: 0.1257928228005767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.399460474029183,
    "estimated_duration": 3599.9560941457266,
    "input_throughput": 3409.8921428409753,
    "output_throughput": 3008.4383577933686,
    "total_throughput": 6418.330500634344,
    "itl": 29.028824152657815,
    "ttft": 32514.735713811155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4001824693917317,
    "arrivals": 49599,
    "finished_requests": 49299,
    "scheduler_time": 22.84521628856129
}
#Debug simulation 
Total elapsed time: 5.3995854603126645. Arrivals time: 0.14349535340443254 Scheduler time: 4.9185857232660055 Scheduler overhead time: 0.12858809577301145 Adapter cache time: 0.024158802814781666 Engine time: 0.12506938399747014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.359759295824915,
    "estimated_duration": 3599.964712415629,
    "input_throughput": 3409.883979602396,
    "output_throughput": 3008.4311556300636,
    "total_throughput": 6418.315135232459,
    "itl": 29.02893530871024,
    "ttft": 32514.857622329677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4070005480758825,
    "arrivals": 49599,
    "finished_requests": 49299,
    "scheduler_time": 22.845315823882228
}
#Debug simulation 
Total elapsed time: 5.359858554787934. Arrivals time: 0.13015242526307702 Scheduler time: 4.8944823099300265 Scheduler overhead time: 0.12713551241904497 Adapter cache time: 0.023785121738910675 Engine time: 0.1251319982111454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.415094763971865,
    "estimated_duration": 3599.978666638824,
    "input_throughput": 3409.6696499205923,
    "output_throughput": 3008.0122697256033,
    "total_throughput": 6417.681919646196,
    "itl": 29.08341592835531,
    "ttft": 32605.433376975718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2221864795195656,
    "arrivals": 49599,
    "finished_requests": 49301,
    "scheduler_time": 22.899188027380355
}
#Debug simulation 
Total elapsed time: 5.415193004067987. Arrivals time: 0.1433256920427084 Scheduler time: 4.936042480636388 Scheduler overhead time: 0.1271728784777224 Adapter cache time: 0.023849384393543005 Engine time: 0.1253745025023818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.4699900397099555,
    "estimated_duration": 3599.972123740941,
    "input_throughput": 3410.0605721477546,
    "output_throughput": 3008.421628761301,
    "total_throughput": 6418.482200909056,
    "itl": 29.08687827594406,
    "ttft": 32389.821453307937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3587810583971485,
    "arrivals": 49599,
    "finished_requests": 49304,
    "scheduler_time": 22.90454840017081
}
#Debug simulation 
Total elapsed time: 5.470086564775556. Arrivals time: 0.14665170991793275 Scheduler time: 4.986009835731238 Scheduler overhead time: 0.128237537574023 Adapter cache time: 0.02382168173789978 Engine time: 0.12551089469343424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.482415535952896,
    "estimated_duration": 3599.967680204303,
    "input_throughput": 3410.0647812769566,
    "output_throughput": 3008.4253421367853,
    "total_throughput": 6418.4901234137415,
    "itl": 29.08419785262895,
    "ttft": 32389.311709973426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1408760111499188,
    "arrivals": 49599,
    "finished_requests": 49304,
    "scheduler_time": 22.902655489061477
}
#Debug simulation 
Total elapsed time: 5.482513713184744. Arrivals time: 0.14497870998457074 Scheduler time: 5.001720241736621 Scheduler overhead time: 0.12760257627815008 Adapter cache time: 0.023877269588410854 Engine time: 0.12488298211246729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.445709933061153,
    "estimated_duration": 3599.975334714249,
    "input_throughput": 3410.057530567616,
    "output_throughput": 3008.4189454202633,
    "total_throughput": 6418.476475987879,
    "itl": 29.087169857977823,
    "ttft": 32386.32649222216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3838060618937096,
    "arrivals": 49599,
    "finished_requests": 49304,
    "scheduler_time": 22.904236431916477
}
#Debug simulation 
Total elapsed time: 5.445871198084205. Arrivals time: 0.1451900997199118 Scheduler time: 4.963595267385244 Scheduler overhead time: 0.12776814820244908 Adapter cache time: 0.023785369470715523 Engine time: 0.1257975809276104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.194389868993312,
    "estimated_duration": 3600.029277187082,
    "input_throughput": 3364.1806961812167,
    "output_throughput": 2971.269447107924,
    "total_throughput": 6335.450143289141,
    "itl": 28.77612429634956,
    "ttft": 23366.673070493474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.15764385947263,
    "arrivals": 48729,
    "finished_requests": 48540,
    "scheduler_time": 21.975333684174437
}
#Debug simulation 
Total elapsed time: 5.194491672329605. Arrivals time: 0.14280607644468546 Scheduler time: 4.714087737724185 Scheduler overhead time: 0.1284246565774083 Adapter cache time: 0.023644241970032454 Engine time: 0.12589388294145465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.285617634188384,
    "estimated_duration": 3600.0044832804597,
    "input_throughput": 3363.133033925385,
    "output_throughput": 2971.0612999719247,
    "total_throughput": 6334.19433389731,
    "itl": 28.837225956739477,
    "ttft": 25531.711595708035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1744052529451467,
    "arrivals": 48729,
    "finished_requests": 48520,
    "scheduler_time": 22.066250093084804
}
#Debug simulation 
Total elapsed time: 5.285724477376789. Arrivals time: 0.1434314576908946 Scheduler time: 4.807050331495702 Scheduler overhead time: 0.12700363481417298 Adapter cache time: 0.02355360286310315 Engine time: 0.12540120258927345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.431931119877845,
    "estimated_duration": 3599.999829265197,
    "input_throughput": 3362.868492821858,
    "output_throughput": 2970.904863121349,
    "total_throughput": 6333.773355943207,
    "itl": 28.852566596537713,
    "ttft": 27468.225511895573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9951800921931986,
    "arrivals": 48729,
    "finished_requests": 48511,
    "scheduler_time": 22.243008877335818
}
#Debug simulation 
Total elapsed time: 5.43202969012782. Arrivals time: 0.14725375967100263 Scheduler time: 4.948021613527089 Scheduler overhead time: 0.12815072247758508 Adapter cache time: 0.023406841792166233 Engine time: 0.12568516423925757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.196110063698143,
    "estimated_duration": 3600.00970654425,
    "input_throughput": 3363.8350968849395,
    "output_throughput": 2970.9569895206987,
    "total_throughput": 6334.792086405639,
    "itl": 28.801537148338785,
    "ttft": 24549.87859773192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.14403657653367,
    "arrivals": 48729,
    "finished_requests": 48526,
    "scheduler_time": 21.980659616186998
}
#Debug simulation 
Total elapsed time: 5.196250387933105. Arrivals time: 0.1457643462345004 Scheduler time: 4.712306606583297 Scheduler overhead time: 0.12792815500870347 Adapter cache time: 0.02369417017325759 Engine time: 0.12656787456944585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.207609958015382,
    "estimated_duration": 3600.0209954888965,
    "input_throughput": 3363.824548571956,
    "output_throughput": 2970.9476731947543,
    "total_throughput": 6334.77222176671,
    "itl": 28.80309878855171,
    "ttft": 24550.936381437186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.280701324678962,
    "arrivals": 48729,
    "finished_requests": 48526,
    "scheduler_time": 21.982011765906144
}
#Debug simulation 
Total elapsed time: 5.207716230303049. Arrivals time: 0.14902012655511498 Scheduler time: 4.721622419077903 Scheduler overhead time: 0.12804607022553682 Adapter cache time: 0.023738714400678873 Engine time: 0.1256820443086326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.195041672792286,
    "estimated_duration": 3600.010307585682,
    "input_throughput": 3363.4939806937787,
    "output_throughput": 2970.7203830680874,
    "total_throughput": 6334.2143637618665,
    "itl": 28.75341267744836,
    "ttft": 24672.639077116084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0930352064314857,
    "arrivals": 48729,
    "finished_requests": 48522,
    "scheduler_time": 21.953425020751773
}
#Debug simulation 
Total elapsed time: 5.195157438982278. Arrivals time: 0.14637514343485236 Scheduler time: 4.70995053416118 Scheduler overhead time: 0.12840891256928444 Adapter cache time: 0.02401633094996214 Engine time: 0.1264806124381721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.489101914688945,
    "estimated_duration": 3600.007670901587,
    "input_throughput": 3362.4511686022206,
    "output_throughput": 2970.6183924107386,
    "total_throughput": 6333.06956101296,
    "itl": 28.836450289030818,
    "ttft": 27376.133988920006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.97916067011654,
    "arrivals": 48729,
    "finished_requests": 48514,
    "scheduler_time": 22.26030687255948
}
#Debug simulation 
Total elapsed time: 5.4892845009453595. Arrivals time: 0.14394809398800135 Scheduler time: 5.007591136265546 Scheduler overhead time: 0.12809040769934654 Adapter cache time: 0.023246412631124258 Engine time: 0.12666586693376303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.783628889825195,
    "estimated_duration": 3599.9862960557757,
    "input_throughput": 3333.6690790042003,
    "output_throughput": 2926.2272502375067,
    "total_throughput": 6259.8963292417075,
    "itl": 28.46948197090467,
    "ttft": 19212.14324911924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.203551175631623,
    "arrivals": 48221,
    "finished_requests": 48057,
    "scheduler_time": 20.782725238064373
}
#Debug simulation 
Total elapsed time: 4.78372747823596. Arrivals time: 0.14247747603803873 Scheduler time: 4.302007149439305 Scheduler overhead time: 0.12823164789006114 Adapter cache time: 0.024176479782909155 Engine time: 0.1266564284451306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.813373825047165,
    "estimated_duration": 3599.974186024082,
    "input_throughput": 3333.602792650614,
    "output_throughput": 2926.036814623297,
    "total_throughput": 6259.639607273911,
    "itl": 28.477149840169243,
    "ttft": 19088.708175589953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.348832082115119,
    "arrivals": 48221,
    "finished_requests": 48059,
    "scheduler_time": 20.786474639979023
}
#Debug simulation 
Total elapsed time: 4.81347398320213. Arrivals time: 0.1426438521593809 Scheduler time: 4.3352306936867535 Scheduler overhead time: 0.1275112060829997 Adapter cache time: 0.024073288775980473 Engine time: 0.1242254264652729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.785185109823942,
    "estimated_duration": 3599.978834784447,
    "input_throughput": 3333.598487869601,
    "output_throughput": 2926.033036144424,
    "total_throughput": 6259.631524014025,
    "itl": 28.477148111107812,
    "ttft": 19088.76962690929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.352529582101851,
    "arrivals": 48221,
    "finished_requests": 48059,
    "scheduler_time": 20.786525553108618
}
#Debug simulation 
Total elapsed time: 4.785287234932184. Arrivals time: 0.14153424464166164 Scheduler time: 4.304837725125253 Scheduler overhead time: 0.12853949284181 Adapter cache time: 0.02413001609966159 Engine time: 0.12575481925159693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.797551082447171,
    "estimated_duration": 3599.9673629826325,
    "input_throughput": 3333.609110849569,
    "output_throughput": 2926.0423603598147,
    "total_throughput": 6259.651471209383,
    "itl": 28.476129147655524,
    "ttft": 19088.607306375437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2364683695439975,
    "arrivals": 48221,
    "finished_requests": 48059,
    "scheduler_time": 20.785487352956697
}
#Debug simulation 
Total elapsed time: 4.797649398446083. Arrivals time: 0.14142102468758821 Scheduler time: 4.317756806500256 Scheduler overhead time: 0.12790456926450133 Adapter cache time: 0.02421407960355282 Engine time: 0.12619492318481207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.799558803904802,
    "estimated_duration": 3599.9782901890767,
    "input_throughput": 3333.676492635093,
    "output_throughput": 2926.233757772666,
    "total_throughput": 6259.910250407759,
    "itl": 28.470496705768834,
    "ttft": 19213.008569293524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3906183934956826,
    "arrivals": 48221,
    "finished_requests": 48057,
    "scheduler_time": 20.7843941308743
}
#Debug simulation 
Total elapsed time: 4.79965561022982. Arrivals time: 0.13984796218574047 Scheduler time: 4.321119143161923 Scheduler overhead time: 0.1285748821683228 Adapter cache time: 0.023923376575112343 Engine time: 0.12623154371976852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.801516614854336,
    "estimated_duration": 3599.9664353664452,
    "input_throughput": 3333.6099698325143,
    "output_throughput": 2926.043114323583,
    "total_throughput": 6259.653084156097,
    "itl": 28.475148632244984,
    "ttft": 19088.252212032025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149846162034625,
    "arrivals": 48221,
    "finished_requests": 48059,
    "scheduler_time": 20.78468003693438
}
#Debug simulation 
Total elapsed time: 4.801612875889987. Arrivals time: 0.1418627742677927 Scheduler time: 4.3196948897093534 Scheduler overhead time: 0.1304112276993692 Adapter cache time: 0.02398904785513878 Engine time: 0.12549036741256714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.803708190098405,
    "estimated_duration": 3599.9847461015033,
    "input_throughput": 3333.6705142976793,
    "output_throughput": 2926.228510109075,
    "total_throughput": 6259.8990244067545,
    "itl": 28.471923490656955,
    "ttft": 19212.470944882756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4172781962156393,
    "arrivals": 48221,
    "finished_requests": 48057,
    "scheduler_time": 20.784589428194938
}
#Debug simulation 
Total elapsed time: 4.803865987807512. Arrivals time: 0.13988468889147043 Scheduler time: 4.324683199636638 Scheduler overhead time: 0.12875949824228883 Adapter cache time: 0.024055996909737587 Engine time: 0.12639667419716716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.822341676801443,
    "estimated_duration": 3599.9895365973566,
    "input_throughput": 3295.1917996996076,
    "output_throughput": 2948.2360690502996,
    "total_throughput": 6243.427868749907,
    "itl": 28.598670129301603,
    "ttft": 23595.153598991856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7903853302006871,
    "arrivals": 48032,
    "finished_requests": 47810,
    "scheduler_time": 21.18700763025957
}
#Debug simulation 
Total elapsed time: 4.822468895930797. Arrivals time: 0.1404640474356711 Scheduler time: 4.347540459595621 Scheduler overhead time: 0.1274460507556796 Adapter cache time: 0.023377610836178064 Engine time: 0.1240504034794867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.795074755791575,
    "estimated_duration": 3599.9765443858323,
    "input_throughput": 3295.5842499868404,
    "output_throughput": 2948.320598519556,
    "total_throughput": 6243.904848506396,
    "itl": 28.572137246352295,
    "ttft": 23006.787483783963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.944301263303503,
    "arrivals": 48032,
    "finished_requests": 47817,
    "scheduler_time": 21.18728287281308
}
#Debug simulation 
Total elapsed time: 4.795166814699769. Arrivals time: 0.1401893557049334 Scheduler time: 4.322981043718755 Scheduler overhead time: 0.12631238577887416 Adapter cache time: 0.022796135861426592 Engine time: 0.12369789322838187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.798988783266395,
    "estimated_duration": 3599.9788787796692,
    "input_throughput": 3295.5821129766464,
    "output_throughput": 2948.3186866912743,
    "total_throughput": 6243.90079966792,
    "itl": 28.572263136440192,
    "ttft": 23006.76456176457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.94611337753014,
    "arrivals": 48032,
    "finished_requests": 47817,
    "scheduler_time": 21.18730495948588
}
#Debug simulation 
Total elapsed time: 4.799117524176836. Arrivals time: 0.13899028580635786 Scheduler time: 4.326533081475645 Scheduler overhead time: 0.12794693186879158 Adapter cache time: 0.022761305328458548 Engine time: 0.12337664235383272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.784948675893247,
    "estimated_duration": 3599.9919935985245,
    "input_throughput": 3295.570107127047,
    "output_throughput": 2948.307945926969,
    "total_throughput": 6243.878053054016,
    "itl": 28.566736328067655,
    "ttft": 22970.663958347206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8539827518071845,
    "arrivals": 48032,
    "finished_requests": 47817,
    "scheduler_time": 21.18109088393334
}
#Debug simulation 
Total elapsed time: 4.785046117845923. Arrivals time: 0.1388071202673018 Scheduler time: 4.313071118667722 Scheduler overhead time: 0.12666780082508922 Adapter cache time: 0.02286479575559497 Engine time: 0.12457959447056055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.797456871252507,
    "estimated_duration": 3599.9664912524368,
    "input_throughput": 3295.5934531136363,
    "output_throughput": 2948.3288318907116,
    "total_throughput": 6243.922285004348,
    "itl": 28.568281157111436,
    "ttft": 22971.060063281366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9867281067371385,
    "arrivals": 48032,
    "finished_requests": 47817,
    "scheduler_time": 21.182103778867962
}
#Debug simulation 
Total elapsed time: 4.797558123245835. Arrivals time: 0.14330842392519116 Scheduler time: 4.320807376876473 Scheduler overhead time: 0.1273286333307624 Adapter cache time: 0.022950395476073027 Engine time: 0.1238263132981956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.788040100131184,
    "estimated_duration": 3599.989059040223,
    "input_throughput": 3295.1922368238115,
    "output_throughput": 2948.2364601490344,
    "total_throughput": 6243.4286969728455,
    "itl": 28.595689005293575,
    "ttft": 23605.833898923316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 48032,
    "finished_requests": 47810,
    "scheduler_time": 21.188026922862328
}
#Debug simulation 
Total elapsed time: 4.788163830991834. Arrivals time: 0.14075094973668456 Scheduler time: 4.317440936807543 Scheduler overhead time: 0.1257417411543429 Adapter cache time: 0.022959069348871708 Engine time: 0.12257581949234009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.778151802718639,
    "estimated_duration": 3599.982912607349,
    "input_throughput": 3293.6986890896596,
    "output_throughput": 2946.359818224196,
    "total_throughput": 6240.058507313855,
    "itl": 28.6012890336098,
    "ttft": 25225.085985767673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9892106562107745,
    "arrivals": 48032,
    "finished_requests": 47789,
    "scheduler_time": 21.197643426027263
}
#Debug simulation 
Total elapsed time: 4.7783019435592. Arrivals time: 0.13969339663162827 Scheduler time: 4.309100463055074 Scheduler overhead time: 0.12632323801517487 Adapter cache time: 0.022758393082767725 Engine time: 0.12151348311454058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.757255224045366,
    "estimated_duration": 3599.971982845499,
    "input_throughput": 3277.794954024347,
    "output_throughput": 2944.4262484569776,
    "total_throughput": 6222.221202481324,
    "itl": 28.554719638869173,
    "ttft": 18477.14605693314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.615937528796514,
    "arrivals": 47900,
    "finished_requests": 47738,
    "scheduler_time": 21.017294269378663
}
#Debug simulation 
Total elapsed time: 4.75735001405701. Arrivals time: 0.1346075446344912 Scheduler time: 4.291410114616156 Scheduler overhead time: 0.12681680358946323 Adapter cache time: 0.022538029123097658 Engine time: 0.12253450136631727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.656439223326743,
    "estimated_duration": 3599.9871778344036,
    "input_throughput": 3276.842504504785,
    "output_throughput": 2942.743536762482,
    "total_throughput": 6219.586041267267,
    "itl": 28.51077330957854,
    "ttft": 19518.703744835737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8467255064612353,
    "arrivals": 47900,
    "finished_requests": 47720,
    "scheduler_time": 20.957586656837123
}
#Debug simulation 
Total elapsed time: 4.656570797320455. Arrivals time: 0.13907371321693063 Scheduler time: 4.185802198480815 Scheduler overhead time: 0.1261311280541122 Adapter cache time: 0.022671240381896496 Engine time: 0.12365416018292308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.650015316903591,
    "estimated_duration": 3599.9845909167398,
    "input_throughput": 3276.844859215352,
    "output_throughput": 2942.745651392432,
    "total_throughput": 6219.590510607784,
    "itl": 28.510741941668847,
    "ttft": 19518.70233911461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.846006211619836,
    "arrivals": 47900,
    "finished_requests": 47720,
    "scheduler_time": 20.95750184914801
}
#Debug simulation 
Total elapsed time: 4.650109082926065. Arrivals time: 0.13660145038738847 Scheduler time: 4.1816477864049375 Scheduler overhead time: 0.1279883082024753 Adapter cache time: 0.022510639391839504 Engine time: 0.12217091489583254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.634611196815968,
    "estimated_duration": 3599.991575649244,
    "input_throughput": 3276.838501454696,
    "output_throughput": 2942.739941853737,
    "total_throughput": 6219.578443308434,
    "itl": 28.509760735429154,
    "ttft": 19517.63029403444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7437594862142478,
    "arrivals": 47900,
    "finished_requests": 47720,
    "scheduler_time": 20.95654296569279
}
#Debug simulation 
Total elapsed time: 4.634725116658956. Arrivals time: 0.13804685836657882 Scheduler time: 4.166322291828692 Scheduler overhead time: 0.126853012945503 Adapter cache time: 0.022607622668147087 Engine time: 0.12203100975602865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.639644784852862,
    "estimated_duration": 3599.9693366947427,
    "input_throughput": 3276.8587442555445,
    "output_throughput": 2942.7581207473763,
    "total_throughput": 6219.616865002921,
    "itl": 28.511235535680935,
    "ttft": 19518.76426484842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.877696165796371,
    "arrivals": 47900,
    "finished_requests": 47720,
    "scheduler_time": 20.957718569298695
}
#Debug simulation 
Total elapsed time: 4.639763604849577. Arrivals time: 0.13640451524406672 Scheduler time: 4.1727110161446035 Scheduler overhead time: 0.1267319922335446 Adapter cache time: 0.022773356642574072 Engine time: 0.12222676631063223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.67037593619898,
    "estimated_duration": 3599.9629960454436,
    "input_throughput": 3277.8031365773086,
    "output_throughput": 2944.433598801968,
    "total_throughput": 6222.236735379276,
    "itl": 28.547348782733028,
    "ttft": 18410.231044731405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.596686857477742,
    "arrivals": 47900,
    "finished_requests": 47738,
    "scheduler_time": 21.007244561465683
}
#Debug simulation 
Total elapsed time: 4.6704773642122746. Arrivals time: 0.13650501798838377 Scheduler time: 4.204893070273101 Scheduler overhead time: 0.12638026708737016 Adapter cache time: 0.022411512210965157 Engine time: 0.12121521541848779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.629283216316253,
    "estimated_duration": 3599.9703098467903,
    "input_throughput": 3276.85785844774,
    "output_throughput": 2942.7573252544016,
    "total_throughput": 6219.615183702142,
    "itl": 28.512006172501764,
    "ttft": 19519.211778534358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8999545859917946,
    "arrivals": 47900,
    "finished_requests": 47720,
    "scheduler_time": 20.957975846053113
}
#Debug simulation 
Total elapsed time: 4.62940906221047. Arrivals time: 0.1374661847949028 Scheduler time: 4.164247051812708 Scheduler overhead time: 0.1263595470227301 Adapter cache time: 0.022294867783784866 Engine time: 0.1199066056869924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.2432090272195637,
    "estimated_duration": 3599.965176363147,
    "input_throughput": 2596.916231685497,
    "output_throughput": 2313.1787648048007,
    "total_throughput": 4910.0949964902975,
    "itl": 25.86848236341068,
    "ttft": 12938.975056820249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.661902326275755,
    "arrivals": 37706,
    "finished_requests": 37591,
    "scheduler_time": 9.037006262165452
}
#Debug simulation 
Total elapsed time: 3.24330250127241. Arrivals time: 0.1103127570822835 Scheduler time: 2.7829085513949394 Scheduler overhead time: 0.1338745728135109 Adapter cache time: 0.028970658313483 Engine time: 0.124855428468436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.3195752552710474,
    "estimated_duration": 3599.9839300904655,
    "input_throughput": 2595.8363096818507,
    "output_throughput": 2312.0378206218384,
    "total_throughput": 4907.8741303036895,
    "itl": 25.887453491233735,
    "ttft": 14862.785302790193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.024675549263975,
    "arrivals": 37706,
    "finished_requests": 37577,
    "scheduler_time": 9.116892815958323
}
#Debug simulation 
Total elapsed time: 3.319667681120336. Arrivals time: 0.10845512570813298 Scheduler time: 2.860206739511341 Scheduler overhead time: 0.13373051211237907 Adapter cache time: 0.028036731760948896 Engine time: 0.12661348097026348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.3600867171771824,
    "estimated_duration": 3599.9784411083037,
    "input_throughput": 2595.8402676219976,
    "output_throughput": 2312.0413458469366,
    "total_throughput": 4907.881613468934,
    "itl": 25.88548057623829,
    "ttft": 14865.092828954432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.020902338083776,
    "arrivals": 37706,
    "finished_requests": 37577,
    "scheduler_time": 9.117613560156316
}
#Debug simulation 
Total elapsed time: 3.360174488276243. Arrivals time: 0.108662701677531 Scheduler time: 2.8983404571190476 Scheduler overhead time: 0.13463915511965752 Adapter cache time: 0.0277904630638659 Engine time: 0.12788624223321676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.28143294993788,
    "estimated_duration": 3599.982896743135,
    "input_throughput": 2596.9965047495275,
    "output_throughput": 2313.29015688771,
    "total_throughput": 4910.286661637238,
    "itl": 25.868033755982506,
    "ttft": 12838.579853908994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.742279400697284,
    "arrivals": 37706,
    "finished_requests": 37592,
    "scheduler_time": 9.034710068545133
}
#Debug simulation 
Total elapsed time: 3.2815240351483226. Arrivals time: 0.10850308556109667 Scheduler time: 2.822796728461981 Scheduler overhead time: 0.13240726059302688 Adapter cache time: 0.02925336640328169 Engine time: 0.12630447512492537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.247904409188777,
    "estimated_duration": 3599.9814331593993,
    "input_throughput": 2596.9975605665963,
    "output_throughput": 2313.291097363074,
    "total_throughput": 4910.288657929671,
    "itl": 25.870836644597464,
    "ttft": 12833.593366873853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1279902807435755,
    "arrivals": 37706,
    "finished_requests": 37592,
    "scheduler_time": 9.03926050446178
}
#Debug simulation 
Total elapsed time: 3.2479982748627663. Arrivals time: 0.1085960241034627 Scheduler time: 2.788920126389712 Scheduler overhead time: 0.1326559237204492 Adapter cache time: 0.02909389277920127 Engine time: 0.12650471506640315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.2497431938536465,
    "estimated_duration": 3599.980450290702,
    "input_throughput": 2596.9982696003385,
    "output_throughput": 2313.2917289391175,
    "total_throughput": 4910.289998539456,
    "itl": 25.867246246506824,
    "ttft": 12837.395375690243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5465432970433755,
    "arrivals": 37706,
    "finished_requests": 37592,
    "scheduler_time": 9.034118438206304
}
#Debug simulation 
Total elapsed time: 3.249827029183507. Arrivals time: 0.10864437744021416 Scheduler time: 2.787490652408451 Scheduler overhead time: 0.13393497047945857 Adapter cache time: 0.02921311603859067 Engine time: 0.1280997828580439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.323046271223575,
    "estimated_duration": 3599.9885002508395,
    "input_throughput": 2595.833014285702,
    "output_throughput": 2312.0348855058983,
    "total_throughput": 4907.8678997916,
    "itl": 25.886741239872695,
    "ttft": 14873.605497664561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.133747242167539,
    "arrivals": 37706,
    "finished_requests": 37577,
    "scheduler_time": 9.120230415127315
}
#Debug simulation 
Total elapsed time: 3.3231616681441665. Arrivals time: 0.10788903897628188 Scheduler time: 2.870555338449776 Scheduler overhead time: 0.13167751347646117 Adapter cache time: 0.027478078845888376 Engine time: 0.12341649224981666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.0441297851502895,
    "estimated_duration": 3600.0186236509912,
    "input_throughput": 2525.5136015878084,
    "output_throughput": 2236.556763096506,
    "total_throughput": 4762.070364684315,
    "itl": 25.56043815983019,
    "ttft": 8093.648141859079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.433145237746836,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.541309231814007
}
#Debug simulation 
Total elapsed time: 3.044222861994058. Arrivals time: 0.10453510703518987 Scheduler time: 2.586581756360829 Scheduler overhead time: 0.13244042824953794 Adapter cache time: 0.030372210312634706 Engine time: 0.12825308507308364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.028632893692702,
    "estimated_duration": 3600.003648942715,
    "input_throughput": 2525.5241068075584,
    "output_throughput": 2236.5660663607073,
    "total_throughput": 4762.090173168265,
    "itl": 25.566452587593183,
    "ttft": 8017.180256470635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.728825715272441,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.5586757531990285
}
#Debug simulation 
Total elapsed time: 3.028720729984343. Arrivals time: 0.10396462213248014 Scheduler time: 2.574826022144407 Scheduler overhead time: 0.13453469099476933 Adapter cache time: 0.029805876314640045 Engine time: 0.12303035892546177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.047671572305262,
    "estimated_duration": 3600.012380309527,
    "input_throughput": 2525.517981473798,
    "output_throughput": 2236.560641857494,
    "total_throughput": 4762.078623331292,
    "itl": 25.565737243283216,
    "ttft": 8107.474163015238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.76139713248235,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.557906673474503
}
#Debug simulation 
Total elapsed time: 3.0477564460597932. Arrivals time: 0.10445806244388223 Scheduler time: 2.5931263202801347 Scheduler overhead time: 0.13254912057891488 Adapter cache time: 0.030059752985835075 Engine time: 0.12504867650568485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.08444318594411,
    "estimated_duration": 3600.00631098979,
    "input_throughput": 2525.522239293037,
    "output_throughput": 2236.564412518008,
    "total_throughput": 4762.086651811044,
    "itl": 25.560267676793412,
    "ttft": 7988.968550843458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.524782342621849,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.540819431405988
}
#Debug simulation 
Total elapsed time: 3.084535356145352. Arrivals time: 0.10776401963084936 Scheduler time: 2.6229037400335073 Scheduler overhead time: 0.1323316809721291 Adapter cache time: 0.030262242536991835 Engine time: 0.12827204959467053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.038817647844553,
    "estimated_duration": 3600.0204338389176,
    "input_throughput": 2525.512331691064,
    "output_throughput": 2236.555638495098,
    "total_throughput": 4762.067970186162,
    "itl": 25.564865381733618,
    "ttft": 8091.2485760703985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9896867812795875,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.545439102401416
}
#Debug simulation 
Total elapsed time: 3.038933876901865. Arrivals time: 0.10759388701990247 Scheduler time: 2.5805178452283144 Scheduler overhead time: 0.13205784745514393 Adapter cache time: 0.030157105531543493 Engine time: 0.12611130392178893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.01782307960093,
    "estimated_duration": 3600.0005880464105,
    "input_throughput": 2525.5262541314864,
    "output_throughput": 2236.5679679983987,
    "total_throughput": 4762.094222129885,
    "itl": 25.558945806230938,
    "ttft": 7999.898321255477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2850857198841865,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.539437882126494
}
#Debug simulation 
Total elapsed time: 3.0179133769124746. Arrivals time: 0.10587344830855727 Scheduler time: 2.5644025136716664 Scheduler overhead time: 0.13314311252906919 Adapter cache time: 0.03004569187760353 Engine time: 0.12198213627561927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.0555339427664876,
    "estimated_duration": 3600.0022037154213,
    "input_throughput": 2525.525120683707,
    "output_throughput": 2236.5669642341363,
    "total_throughput": 4762.092084917843,
    "itl": 25.565306750540255,
    "ttft": 7991.975153971712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.075181026346747,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 7.5440298163864306
}
#Debug simulation 
Total elapsed time: 3.055655475705862. Arrivals time: 0.10718826903030276 Scheduler time: 2.593620929867029 Scheduler overhead time: 0.1335402480326593 Adapter cache time: 0.03027238743379712 Engine time: 0.12826232379302382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.008281038608402,
    "estimated_duration": 3599.915824054567,
    "input_throughput": 2491.9693788551263,
    "output_throughput": 2225.3698118355137,
    "total_throughput": 4717.33919069064,
    "itl": 25.475846609166215,
    "ttft": 7312.49833346495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.368874995124246,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.2752259345906785
}
#Debug simulation 
Total elapsed time: 3.0083724786527455. Arrivals time: 0.10176152177155018 Scheduler time: 2.5538824750110507 Scheduler overhead time: 0.13285873271524906 Adapter cache time: 0.029969547409564257 Engine time: 0.12760242354124784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9646091358736157,
    "estimated_duration": 3599.912887339033,
    "input_throughput": 2491.9714117390918,
    "output_throughput": 2225.371627234469,
    "total_throughput": 4717.34303897356,
    "itl": 25.480201760206693,
    "ttft": 7313.191085416267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.834519279901611,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.279220587619974
}
#Debug simulation 
Total elapsed time: 2.9646974839270115. Arrivals time: 0.10306519083678722 Scheduler time: 2.5136571279726923 Scheduler overhead time: 0.1331987022422254 Adapter cache time: 0.02964322129264474 Engine time: 0.12255950039252639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.97580655105412,
    "estimated_duration": 3599.913240066226,
    "input_throughput": 2491.971167570407,
    "output_throughput": 2225.371409187801,
    "total_throughput": 4717.3425767582075,
    "itl": 25.48014715326479,
    "ttft": 7313.178553940522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.834687626976512,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.279229390059247
}
#Debug simulation 
Total elapsed time: 2.975886148866266. Arrivals time: 0.10207806061953306 Scheduler time: 2.5248591313138604 Scheduler overhead time: 0.13158603943884373 Adapter cache time: 0.02988265920430422 Engine time: 0.12534218607470393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9842983363196254,
    "estimated_duration": 3599.9030569275365,
    "input_throughput": 2491.978216673566,
    "output_throughput": 2225.377704153342,
    "total_throughput": 4717.355920826908,
    "itl": 25.476656110430334,
    "ttft": 7314.14656520494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.454117038433702,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.27460866754008
}
#Debug simulation 
Total elapsed time: 2.984382930211723. Arrivals time: 0.10204406036064029 Scheduler time: 2.530439460184425 Scheduler overhead time: 0.13193598296493292 Adapter cache time: 0.030099449213594198 Engine time: 0.12736649252474308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9919932410120964,
    "estimated_duration": 3599.9263104646366,
    "input_throughput": 2491.9621198696545,
    "output_throughput": 2225.3633294416004,
    "total_throughput": 4717.325449311255,
    "itl": 25.481324927601385,
    "ttft": 7313.1553412385565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.95142715463401,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.280374017272613
}
#Debug simulation 
Total elapsed time: 2.9920843737199903. Arrivals time: 0.10371858486905694 Scheduler time: 2.537391694728285 Scheduler overhead time: 0.13156176544725895 Adapter cache time: 0.029800718650221825 Engine time: 0.1271410039626062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9879018678329885,
    "estimated_duration": 3599.9132359967566,
    "input_throughput": 2491.9711703874195,
    "output_throughput": 2225.3714117034397,
    "total_throughput": 4717.342582090859,
    "itl": 25.474824607017705,
    "ttft": 7312.406992762214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.219304613396341,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.273849220987422
}
#Debug simulation 
Total elapsed time: 2.9879900850355625. Arrivals time: 0.10437339451164007 Scheduler time: 2.530833686236292 Scheduler overhead time: 0.1332681830972433 Adapter cache time: 0.029960359912365675 Engine time: 0.1272855824790895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.988656889181584,
    "estimated_duration": 3599.9192592001677,
    "input_throughput": 2491.9670009468923,
    "output_throughput": 2225.367688324188,
    "total_throughput": 4717.33468927108,
    "itl": 25.48124418635567,
    "ttft": 7314.857358468223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.017940065562502,
    "arrivals": 36327,
    "finished_requests": 36259,
    "scheduler_time": 7.279567111338882
}
#Debug simulation 
Total elapsed time: 2.98876876803115. Arrivals time: 0.10296745924279094 Scheduler time: 2.5320430295541883 Scheduler overhead time: 0.13188480027019978 Adapter cache time: 0.030081097036600113 Engine time: 0.12995242374017835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9293839330784976,
    "estimated_duration": 3600.0084320674164,
    "input_throughput": 2475.875867568825,
    "output_throughput": 2228.732835326244,
    "total_throughput": 4704.60870289507,
    "itl": 25.452901229358975,
    "ttft": 7675.827618207281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9648906129251085,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.323252107203745
}
#Debug simulation 
Total elapsed time: 2.9294769898988307. Arrivals time: 0.09986537788063288 Scheduler time: 2.485955810174346 Scheduler overhead time: 0.13092164089903235 Adapter cache time: 0.029398501850664616 Engine time: 0.12146490812301636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9498191280290484,
    "estimated_duration": 3599.9920994415947,
    "input_throughput": 2475.8871002474,
    "output_throughput": 2228.742946753839,
    "total_throughput": 4704.630047001239,
    "itl": 25.455512948981788,
    "ttft": 7679.779796219245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1926,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.366418106502177,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.326871569177111
}
#Debug simulation 
Total elapsed time: 2.9499112591147423. Arrivals time: 0.1017084289342165 Scheduler time: 2.5020697191357613 Scheduler overhead time: 0.13064045971259475 Adapter cache time: 0.029415791388601065 Engine time: 0.12394687160849571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9447650867514312,
    "estimated_duration": 3599.989848711376,
    "input_throughput": 2475.888648183408,
    "output_throughput": 2228.7443401741853,
    "total_throughput": 4704.632988357593,
    "itl": 25.45732414137094,
    "ttft": 7676.366119737206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.453573275897644,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.327469514989988
}
#Debug simulation 
Total elapsed time: 2.9448523367755115. Arrivals time: 0.10368298972025514 Scheduler time: 2.492147974204272 Scheduler overhead time: 0.13070796057581902 Adapter cache time: 0.029512241017073393 Engine time: 0.12663442874327302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.930061900988221,
    "estimated_duration": 3599.992252814736,
    "input_throughput": 2475.8869947653448,
    "output_throughput": 2228.7428518010497,
    "total_throughput": 4704.629846566395,
    "itl": 25.454558870160742,
    "ttft": 7675.584405162457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1952,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.068251721204545,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.325820349340708
}
#Debug simulation 
Total elapsed time: 2.9301738808862865. Arrivals time: 0.10268477769568563 Scheduler time: 2.4831586820073426 Scheduler overhead time: 0.13099257461726665 Adapter cache time: 0.029518337920308113 Engine time: 0.1221440457738936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9505970398895442,
    "estimated_duration": 3599.985632216406,
    "input_throughput": 2475.8915480761016,
    "output_throughput": 2228.7469505982976,
    "total_throughput": 4704.638498674399,
    "itl": 25.458520864949396,
    "ttft": 7675.5829750923085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.555215250905491,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.329935671585623
}
#Debug simulation 
Total elapsed time: 2.9506843369454145. Arrivals time: 0.10524303466081619 Scheduler time: 2.497719082981348 Scheduler overhead time: 0.13105676509439945 Adapter cache time: 0.02967328205704689 Engine time: 0.12525018630549312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9517075992189348,
    "estimated_duration": 3600.001192504088,
    "input_throughput": 2475.8808465283246,
    "output_throughput": 2228.7373172837883,
    "total_throughput": 4704.618163812113,
    "itl": 25.45338039776015,
    "ttft": 7681.797384054342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.746876666801814,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.323831247420832
}
#Debug simulation 
Total elapsed time: 2.951798787806183. Arrivals time: 0.10264152102172375 Scheduler time: 2.4995618206448853 Scheduler overhead time: 0.13084910530596972 Adapter cache time: 0.03008773224428296 Engine time: 0.12677054852247238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9373912918381393,
    "estimated_duration": 3599.990208884603,
    "input_throughput": 2475.8884004747333,
    "output_throughput": 2228.7441171919004,
    "total_throughput": 4704.632517666634,
    "itl": 25.45900236657095,
    "ttft": 7676.498957591962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.64358724717033,
    "arrivals": 36084,
    "finished_requests": 36011,
    "scheduler_time": 7.329212974729963
}
#Debug simulation 
Total elapsed time: 2.9375698580406606. Arrivals time: 0.10205277381464839 Scheduler time: 2.4902426176704466 Scheduler overhead time: 0.13067605951800942 Adapter cache time: 0.029714158736169338 Engine time: 0.12283680401742458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.8860178752802312,
    "estimated_duration": 3599.652433892895,
    "input_throughput": 2491.7625144991653,
    "output_throughput": 2195.1997158387644,
    "total_throughput": 4686.96223033793,
    "itl": 25.295057162825994,
    "ttft": 7987.839790756518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9648906129251085,
    "arrivals": 35993,
    "finished_requests": 35916,
    "scheduler_time": 6.668794598381866
}
#Debug simulation 
Total elapsed time: 2.88609816506505. Arrivals time: 0.1002841186709702 Scheduler time: 2.43935671960935 Scheduler overhead time: 0.1304593221284449 Adapter cache time: 0.029434487223625183 Engine time: 0.12473705084994435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9123172420077026,
    "estimated_duration": 3599.652672020994,
    "input_throughput": 2491.7623496614087,
    "output_throughput": 2195.1995706195494,
    "total_throughput": 4686.961920280958,
    "itl": 25.29975613755092,
    "ttft": 7987.823757544953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.450994597638268,
    "arrivals": 35993,
    "finished_requests": 35916,
    "scheduler_time": 6.672774479398668
}
#Debug simulation 
Total elapsed time: 2.9124041069298983. Arrivals time: 0.10156928841024637 Scheduler time: 2.4594475673511624 Scheduler overhead time: 0.13320194091647863 Adapter cache time: 0.02967214910313487 Engine time: 0.1260388484224677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8948707687668502,
    "estimated_duration": 3599.6509908449725,
    "input_throughput": 2491.763513410651,
    "output_throughput": 2195.200595862522,
    "total_throughput": 4686.964109273173,
    "itl": 25.299681063451978,
    "ttft": 7987.834856297666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.449493140373384,
    "arrivals": 35993,
    "finished_requests": 35916,
    "scheduler_time": 6.672920121638952
}
#Debug simulation 
Total elapsed time: 2.894953961018473. Arrivals time: 0.1001489907503128 Scheduler time: 2.446400375571102 Scheduler overhead time: 0.13368020299822092 Adapter cache time: 0.029550338629633188 Engine time: 0.12253955472260714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.913921648170799,
    "estimated_duration": 3599.628359113576,
    "input_throughput": 2491.5358212725487,
    "output_throughput": 2195.153558003926,
    "total_throughput": 4686.689379276474,
    "itl": 25.296601050978296,
    "ttft": 8187.852356920825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.056291520024933,
    "arrivals": 35993,
    "finished_requests": 35914,
    "scheduler_time": 6.669541087737341
}
#Debug simulation 
Total elapsed time: 2.9140138658694923. Arrivals time: 0.10149001562967896 Scheduler time: 2.4632204393856227 Scheduler overhead time: 0.1312051177956164 Adapter cache time: 0.02951233321800828 Engine time: 0.12656883196905255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.897892908193171,
    "estimated_duration": 3599.6444064794227,
    "input_throughput": 2491.7680712724796,
    "output_throughput": 2195.204611260029,
    "total_throughput": 4686.972682532509,
    "itl": 25.301078067156165,
    "ttft": 7987.881777611136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.566916036717489,
    "arrivals": 35993,
    "finished_requests": 35916,
    "scheduler_time": 6.67379288033585
}
#Debug simulation 
Total elapsed time: 2.8979832883924246. Arrivals time: 0.10216487804427743 Scheduler time: 2.449571589473635 Scheduler overhead time: 0.13135423976927996 Adapter cache time: 0.029812291264533997 Engine time: 0.1231592888943851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9004281871020794,
    "estimated_duration": 3599.6282285416464,
    "input_throughput": 2491.5359116498375,
    "output_throughput": 2195.1536376303256,
    "total_throughput": 4686.689549280163,
    "itl": 25.29446405226932,
    "ttft": 8187.634564915973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.82760802476417,
    "arrivals": 35993,
    "finished_requests": 35914,
    "scheduler_time": 6.667390184537826
}
#Debug simulation 
Total elapsed time: 2.9005150352604687. Arrivals time: 0.10067775892093778 Scheduler time: 2.453046801034361 Scheduler overhead time: 0.13167294394224882 Adapter cache time: 0.029514639172703028 Engine time: 0.12336390232667327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8868331983685493,
    "estimated_duration": 3599.630314041939,
    "input_throughput": 2491.5344681408046,
    "output_throughput": 2195.1523658348483,
    "total_throughput": 4686.686833975653,
    "itl": 25.301591825336512,
    "ttft": 8187.846579225053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.639018682390277,
    "arrivals": 35993,
    "finished_requests": 35914,
    "scheduler_time": 6.674595944020411
}
#Debug simulation 
Total elapsed time: 2.8869476499967277. Arrivals time: 0.10056660044938326 Scheduler time: 2.4425564939156175 Scheduler overhead time: 0.13081047544255853 Adapter cache time: 0.029432762414216995 Engine time: 0.12161061773076653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7974300920031965,
    "estimated_duration": 3599.954550613173,
    "input_throughput": 2413.3579682332916,
    "output_throughput": 2122.537630009389,
    "total_throughput": 4535.8955982426805,
    "itl": 24.924282745258832,
    "ttft": 4704.881714131918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2342135343912,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.299881545354217
}
#Debug simulation 
Total elapsed time: 2.797520542051643. Arrivals time: 0.09817553544417024 Scheduler time: 2.343782326672226 Scheduler overhead time: 0.1345945722423494 Adapter cache time: 0.030199857894331217 Engine time: 0.12760649248957634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7631557560525835,
    "estimated_duration": 3599.946880939269,
    "input_throughput": 2413.3631098837777,
    "output_throughput": 2122.542152068189,
    "total_throughput": 4535.905261951967,
    "itl": 24.92887371426964,
    "ttft": 4705.165764051813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.630524758617164,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.3039137626682855
}
#Debug simulation 
Total elapsed time: 2.7632450670935214. Arrivals time: 0.098301044665277 Scheduler time: 2.3163146367296576 Scheduler overhead time: 0.1311022713780403 Adapter cache time: 0.029865989927202463 Engine time: 0.12566788541153073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7890546186827123,
    "estimated_duration": 3599.9455637586802,
    "input_throughput": 2413.363992906864,
    "output_throughput": 2122.542928683077,
    "total_throughput": 4535.906921589941,
    "itl": 24.928857181310757,
    "ttft": 4705.029068333747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.641729611884752,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.3038652004208915
}
#Debug simulation 
Total elapsed time: 2.7891392009332776. Arrivals time: 0.09801817080006003 Scheduler time: 2.340649706777185 Scheduler overhead time: 0.13133913418278098 Adapter cache time: 0.030124534852802753 Engine time: 0.12648608814924955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7771562580019236,
    "estimated_duration": 3599.948612419938,
    "input_throughput": 2413.3619491195495,
    "output_throughput": 2122.541131181198,
    "total_throughput": 4535.903080300748,
    "itl": 24.924901778183244,
    "ttft": 4704.8918937355575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.311503805739147,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.300438085844149
}
#Debug simulation 
Total elapsed time: 2.777248755097389. Arrivals time: 0.09823526162654161 Scheduler time: 2.328966534230858 Scheduler overhead time: 0.1314841960556805 Adapter cache time: 0.030208231881260872 Engine time: 0.1259215958416462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7618814827874303,
    "estimated_duration": 3599.9487036632354,
    "input_throughput": 2413.3618879511496,
    "output_throughput": 2122.5410773838616,
    "total_throughput": 4535.902965335012,
    "itl": 24.928916146205342,
    "ttft": 4704.719346667898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.767858884241278,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.304294811534001
}
#Debug simulation 
Total elapsed time: 2.761968940962106. Arrivals time: 0.09776961896568537 Scheduler time: 2.3179613878019154 Scheduler overhead time: 0.13003698363900185 Adapter cache time: 0.029979601502418518 Engine time: 0.12422437081113458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7917188336141407,
    "estimated_duration": 3599.948102177648,
    "input_throughput": 2413.3622911798498,
    "output_throughput": 2122.541432021715,
    "total_throughput": 4535.903723201564,
    "itl": 24.922985483926038,
    "ttft": 4704.716468234769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.096712551305356,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.29865284307087
}
#Debug simulation 
Total elapsed time: 2.7918091686442494. Arrivals time: 0.0982533385977149 Scheduler time: 2.3418034804053605 Scheduler overhead time: 0.13279237365350127 Adapter cache time: 0.030015266966074705 Engine time: 0.12639137264341116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7804791647940874,
    "estimated_duration": 3599.969426338705,
    "input_throughput": 2413.3479958011694,
    "output_throughput": 2122.528859299565,
    "total_throughput": 4535.876855100734,
    "itl": 24.93081433193341,
    "ttft": 4705.4949294091875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.814309532902919,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.305224437903001
}
#Debug simulation 
Total elapsed time: 2.7805910306051373. Arrivals time: 0.09578296123072505 Scheduler time: 2.335987484548241 Scheduler overhead time: 0.13261722913011909 Adapter cache time: 0.030065537430346012 Engine time: 0.12316394690424204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.710166876204312,
    "estimated_duration": 3599.657887600493,
    "input_throughput": 2367.6388885059205,
    "output_throughput": 2083.9133146067848,
    "total_throughput": 4451.552203112705,
    "itl": 24.655918679788055,
    "ttft": 6401.993476005055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.159982336270766,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.601021561507795
}
#Debug simulation 
Total elapsed time: 2.710257278289646. Arrivals time: 0.09353984706103802 Scheduler time: 2.2673456659540534 Scheduler overhead time: 0.13211663393303752 Adapter cache time: 0.028760148212313652 Engine time: 0.1257280637510121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.705736021976918,
    "estimated_duration": 3599.6427176393313,
    "input_throughput": 2367.648866437843,
    "output_throughput": 2083.9220968350573,
    "total_throughput": 4451.5709632729,
    "itl": 24.659685790751112,
    "ttft": 6401.969741255813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.542013828426004,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.604363660498283
}
#Debug simulation 
Total elapsed time: 2.7058222447521985. Arrivals time: 0.09284362196922302 Scheduler time: 2.269313446711749 Scheduler overhead time: 0.1303983018733561 Adapter cache time: 0.028775790706276894 Engine time: 0.12237064726650715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7220655330456793,
    "estimated_duration": 3599.6443537387986,
    "input_throughput": 2367.6477903012396,
    "output_throughput": 2083.9211496570874,
    "total_throughput": 4451.568939958327,
    "itl": 24.659599600935046,
    "ttft": 6401.960455367253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.542823013756375,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.604349979025524
}
#Debug simulation 
Total elapsed time: 2.7221487700007856. Arrivals time: 0.09366026427596807 Scheduler time: 2.27603108715266 Scheduler overhead time: 0.1326504461467266 Adapter cache time: 0.02899766620248556 Engine time: 0.12813477963209152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7314198818057775,
    "estimated_duration": 3599.658320990365,
    "input_throughput": 2367.638603448111,
    "output_throughput": 2083.913063708826,
    "total_throughput": 4451.551667156937,
    "itl": 24.656654644833143,
    "ttft": 6401.846198453048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.225909881139976,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.601871367555557
}
#Debug simulation 
Total elapsed time: 2.7315089027397335. Arrivals time: 0.09457501024007797 Scheduler time: 2.283731241710484 Scheduler overhead time: 0.1338115599937737 Adapter cache time: 0.02902079839259386 Engine time: 0.12733312882483006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.720202136784792,
    "estimated_duration": 3599.6609393240483,
    "input_throughput": 2367.6368812670476,
    "output_throughput": 2083.9115479050156,
    "total_throughput": 4451.548429172063,
    "itl": 24.66027993892566,
    "ttft": 6402.013418401992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6380186300723985,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.6049647660152155
}
#Debug simulation 
Total elapsed time: 2.720287799835205. Arrivals time: 0.0942197903059423 Scheduler time: 2.27673835773021 Scheduler overhead time: 0.1318245311267674 Adapter cache time: 0.02877018880099058 Engine time: 0.1262554251588881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.706479476764798,
    "estimated_duration": 3599.6562577885693,
    "input_throughput": 2367.639960498859,
    "output_throughput": 2083.9142581376454,
    "total_throughput": 4451.554218636505,
    "itl": 24.656290223051585,
    "ttft": 6401.867483513887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.035244696615122,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.6015446731401575
}
#Debug simulation 
Total elapsed time: 2.7065684869885445. Arrivals time: 0.09423299320042133 Scheduler time: 2.263519453816116 Scheduler overhead time: 0.13144714385271072 Adapter cache time: 0.02875461522489786 Engine time: 0.1260107266716659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7095086541958153,
    "estimated_duration": 3599.6523623258563,
    "input_throughput": 2367.6425227054992,
    "output_throughput": 2083.9165133027204,
    "total_throughput": 4451.55903600822,
    "itl": 24.66058876720128,
    "ttft": 6402.078203234503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.691141327693961,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.6053842003838845
}
#Debug simulation 
Total elapsed time: 2.7096229288727045. Arrivals time: 0.09412750648334622 Scheduler time: 2.2661295062862337 Scheduler overhead time: 0.1327292718924582 Adapter cache time: 0.02882816130295396 Engine time: 0.12537826597690582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.695047270040959,
    "estimated_duration": 3599.8017337468427,
    "input_throughput": 2350.207490787039,
    "output_throughput": 2066.98717050045,
    "total_throughput": 4417.194661287489,
    "itl": 24.508707456464858,
    "ttft": 7459.978800888973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.46831210614194,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.225656115885065
}
#Debug simulation 
Total elapsed time: 2.695134143345058. Arrivals time: 0.09315241780132055 Scheduler time: 2.2528425585478544 Scheduler overhead time: 0.13171051908284426 Adapter cache time: 0.02827551495283842 Engine time: 0.12649075873196125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6978128771297634,
    "estimated_duration": 3599.8039167400702,
    "input_throughput": 2350.2060655741234,
    "output_throughput": 2066.9859170380114,
    "total_throughput": 4417.191982612135,
    "itl": 24.511096236401762,
    "ttft": 7460.374755394194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.831531859710751,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.228576175735219
}
#Debug simulation 
Total elapsed time: 2.6979041462764144. Arrivals time: 0.09423300810158253 Scheduler time: 2.2553862081840634 Scheduler overhead time: 0.13289142400026321 Adapter cache time: 0.028292317409068346 Engine time: 0.12398231728002429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6980500700883567,
    "estimated_duration": 3599.7920020811293,
    "input_throughput": 2350.213844330145,
    "output_throughput": 2066.9927583866847,
    "total_throughput": 4417.206602716829,
    "itl": 24.511434634552806,
    "ttft": 7460.353873352585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8226037030666555,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.228432105495735
}
#Debug simulation 
Total elapsed time: 2.698132119141519. Arrivals time: 0.09352286485955119 Scheduler time: 2.2561549502424896 Scheduler overhead time: 0.1327030877582729 Adapter cache time: 0.02821442484855652 Engine time: 0.12443794216960669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.674426826648414,
    "estimated_duration": 3599.787747243309,
    "input_throughput": 2350.216622210246,
    "output_throughput": 2066.995201508219,
    "total_throughput": 4417.211823718465,
    "itl": 24.50894727979313,
    "ttft": 7460.2925631253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.53557896609409,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.226188739495258
}
#Debug simulation 
Total elapsed time: 2.674513847567141. Arrivals time: 0.09418154135346413 Scheduler time: 2.236298147123307 Scheduler overhead time: 0.1313530527986586 Adapter cache time: 0.028117967303842306 Engine time: 0.12240142142400146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6932484968565404,
    "estimated_duration": 3599.8019199036085,
    "input_throughput": 2350.2073692506224,
    "output_throughput": 2066.9870636102223,
    "total_throughput": 4417.194432860845,
    "itl": 24.51218861061321,
    "ttft": 7460.305480821264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.916024180483049,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.22931510511348
}
#Debug simulation 
Total elapsed time: 2.6933354986831546. Arrivals time: 0.09503746964037418 Scheduler time: 2.2494945083744824 Scheduler overhead time: 0.1311140893958509 Adapter cache time: 0.02833089791238308 Engine time: 0.126912085339427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7103199060074985,
    "estimated_duration": 3599.7814930410864,
    "input_throughput": 2350.220705438645,
    "output_throughput": 2066.9987926722956,
    "total_throughput": 4417.219498110941,
    "itl": 24.507630185270138,
    "ttft": 7460.318748451461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.365473430557058,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.224898616557994
}
#Debug simulation 
Total elapsed time: 2.710402929689735. Arrivals time: 0.09432618133723736 Scheduler time: 2.2663526530377567 Scheduler overhead time: 0.13158303033560514 Adapter cache time: 0.028328037355095148 Engine time: 0.12706039752811193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6897427211515605,
    "estimated_duration": 3599.806496507774,
    "input_throughput": 2350.204381320897,
    "output_throughput": 2066.9844357518596,
    "total_throughput": 4417.188817072757,
    "itl": 24.512796192197083,
    "ttft": 7460.290862644269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.956937918737509,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.229353683884015
}
#Debug simulation 
Total elapsed time: 2.689860795158893. Arrivals time: 0.09351130435243249 Scheduler time: 2.2487984620966017 Scheduler overhead time: 0.13097833283245564 Adapter cache time: 0.028115882072597742 Engine time: 0.12586307618767023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6858349931426346,
    "estimated_duration": 3599.8697620579405,
    "input_throughput": 2326.728063409642,
    "output_throughput": 2068.3662165998544,
    "total_throughput": 4395.094280009496,
    "itl": 24.47922653026359,
    "ttft": 6312.2240603159335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.975573579368749,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.19218731959475
}
#Debug simulation 
Total elapsed time: 2.685923478100449. Arrivals time: 0.09220602223649621 Scheduler time: 2.2447935780510306 Scheduler overhead time: 0.13186271535232663 Adapter cache time: 0.027717940974980593 Engine time: 0.12669253256171942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6987060219980776,
    "estimated_duration": 3599.887456222871,
    "input_throughput": 2326.716627077089,
    "output_throughput": 2068.3560501673146,
    "total_throughput": 4395.072677244403,
    "itl": 24.482430640628593,
    "ttft": 6312.1973227466615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.297722624526355,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.19481985178447
}
#Debug simulation 
Total elapsed time: 2.6987919700331986. Arrivals time: 0.09290334722027183 Scheduler time: 2.2562708011828363 Scheduler overhead time: 0.13246651832014322 Adapter cache time: 0.027668965049088 Engine time: 0.12643845938146114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.686794323846698,
    "estimated_duration": 3599.8922216064348,
    "input_throughput": 2326.7135470689973,
    "output_throughput": 2068.3533121659198,
    "total_throughput": 4395.066859234917,
    "itl": 24.481542174200456,
    "ttft": 6312.309992843096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.283992072213368,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.194410379660146
}
#Debug simulation 
Total elapsed time: 2.68686869321391. Arrivals time: 0.0863439510576427 Scheduler time: 2.2494966951198876 Scheduler overhead time: 0.13416608562693 Adapter cache time: 0.02780679054558277 Engine time: 0.126065568998456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.678277629893273,
    "estimated_duration": 3599.8913549303215,
    "input_throughput": 2326.7141072267505,
    "output_throughput": 2068.3538101232834,
    "total_throughput": 4395.067917350034,
    "itl": 24.47976736389465,
    "ttft": 6312.164940822438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.028328426608295,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.192855149428787
}
#Debug simulation 
Total elapsed time: 2.678359983023256. Arrivals time: 0.09219888970255852 Scheduler time: 2.2418859424069524 Scheduler overhead time: 0.1307892561890185 Adapter cache time: 0.027494977694004774 Engine time: 0.12329240189865232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.687489630188793,
    "estimated_duration": 3599.8764241483973,
    "input_throughput": 2326.7237574638257,
    "output_throughput": 2068.362388789894,
    "total_throughput": 4395.08614625372,
    "itl": 24.48202630390745,
    "ttft": 6312.649993564269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.375451344996688,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.195121038804894
}
#Debug simulation 
Total elapsed time: 2.6875786460004747. Arrivals time: 0.09354091668501496 Scheduler time: 2.2497634678147733 Scheduler overhead time: 0.13037077942863107 Adapter cache time: 0.027671405114233494 Engine time: 0.12356591923162341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.678743148688227,
    "estimated_duration": 3599.876942646403,
    "input_throughput": 2326.723422340807,
    "output_throughput": 2068.3620908792177,
    "total_throughput": 4395.085513220025,
    "itl": 24.47848958627451,
    "ttft": 6312.294234217279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.878095232488021,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.191438867437013
}
#Debug simulation 
Total elapsed time: 2.67883398802951. Arrivals time: 0.09356269100680947 Scheduler time: 2.240626821760088 Scheduler overhead time: 0.13208370748907328 Adapter cache time: 0.027502933517098427 Engine time: 0.12227525794878602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.697052369825542,
    "estimated_duration": 3599.8861705171466,
    "input_throughput": 2326.717458068055,
    "output_throughput": 2068.356788884343,
    "total_throughput": 4395.074246952398,
    "itl": 24.483203782661874,
    "ttft": 6312.295028426275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.419439742267162,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.195757849771273
}
#Debug simulation 
Total elapsed time: 2.6971694617532194. Arrivals time: 0.09462401131168008 Scheduler time: 2.2509336713701487 Scheduler overhead time: 0.13398391334339976 Adapter cache time: 0.027852425817400217 Engine time: 0.12621649960055947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.628211251925677,
    "estimated_duration": 3599.943628953021,
    "input_throughput": 2300.1107387918096,
    "output_throughput": 2001.8607908301904,
    "total_throughput": 4301.971529622,
    "itl": 24.03946490866597,
    "ttft": 7721.87277817919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4705931016198273,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.22562433266781
}
#Debug simulation 
Total elapsed time: 2.6283048102632165. Arrivals time: 0.09296147851273417 Scheduler time: 2.180275703780353 Scheduler overhead time: 0.1344491201452911 Adapter cache time: 0.02697946224361658 Engine time: 0.1294934474863112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6366214738227427,
    "estimated_duration": 3599.955878019968,
    "input_throughput": 2300.102912526327,
    "output_throughput": 2001.8539793781401,
    "total_throughput": 4301.956891904468,
    "itl": 24.04169478369405,
    "ttft": 7721.942422009108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7023453793232406,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.226817966793608
}
#Debug simulation 
Total elapsed time: 2.636714354157448. Arrivals time: 0.09246909338980913 Scheduler time: 2.1867803684435785 Scheduler overhead time: 0.13514222437515855 Adapter cache time: 0.027310387697070837 Engine time: 0.12876446545124054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.622315459884703,
    "estimated_duration": 3599.936080669675,
    "input_throughput": 2300.1155616239917,
    "output_throughput": 2001.8649882970703,
    "total_throughput": 4301.9805499210615,
    "itl": 24.0413345108707,
    "ttft": 7721.90976867582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7110309452935493,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2270400295585016
}
#Debug simulation 
Total elapsed time: 2.622406248934567. Arrivals time: 0.09184543276205659 Scheduler time: 2.177908689249307 Scheduler overhead time: 0.13405271712690592 Adapter cache time: 0.02689512725919485 Engine time: 0.1279036235064268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6104700989089906,
    "estimated_duration": 3599.943696318759,
    "input_throughput": 2300.1106957498423,
    "output_throughput": 2001.860753369374,
    "total_throughput": 4301.971449119216,
    "itl": 24.040059819178097,
    "ttft": 7721.883879562115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5108440580404796,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.225692168645995
}
#Debug simulation 
Total elapsed time: 2.610552702564746. Arrivals time: 0.09062218200415373 Scheduler time: 2.169943565968424 Scheduler overhead time: 0.1331641087308526 Adapter cache time: 0.02679398050531745 Engine time: 0.12643856089562178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.636948237195611,
    "estimated_duration": 3599.9330268686917,
    "input_throughput": 2300.117512797836,
    "output_throughput": 2001.8666864667928,
    "total_throughput": 4301.984199264629,
    "itl": 24.042306710709447,
    "ttft": 7721.907800660043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.767846228778374,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2272670572109465
}
#Debug simulation 
Total elapsed time: 2.6370579972863197. Arrivals time: 0.09226489579305053 Scheduler time: 2.192455243319273 Scheduler overhead time: 0.13265511253848672 Adapter cache time: 0.02700855117291212 Engine time: 0.12901187408715487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.615570994094014,
    "estimated_duration": 3599.946505868725,
    "input_throughput": 2300.1089006465218,
    "output_throughput": 2001.8591910328776,
    "total_throughput": 4301.968091679399,
    "itl": 24.038789437959146,
    "ttft": 7721.844745935358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3907170344189836,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.225239697698372
}
#Debug simulation 
Total elapsed time: 2.615668277721852. Arrivals time: 0.0905580255202949 Scheduler time: 2.1761164693161845 Scheduler overhead time: 0.13395925657823682 Adapter cache time: 0.026728020049631596 Engine time: 0.12488840846344829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6196347577497363,
    "estimated_duration": 3599.951961362692,
    "input_throughput": 2300.1054149805,
    "output_throughput": 2001.856157344968,
    "total_throughput": 4301.961572325468,
    "itl": 24.042640452632615,
    "ttft": 7721.898566183678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.80481784198439,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2275758219270716
}
#Debug simulation 
Total elapsed time: 2.61975041590631. Arrivals time: 0.09166846051812172 Scheduler time: 2.1700908434577286 Scheduler overhead time: 0.13858196465298533 Adapter cache time: 0.0279782647266984 Engine time: 0.12710331473499537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6262382799759507,
    "estimated_duration": 3599.9594974398083,
    "input_throughput": 2273.7072474901806,
    "output_throughput": 2008.5239862121246,
    "total_throughput": 4282.231233702305,
    "itl": 23.945200111558698,
    "ttft": 5922.263618933332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6595638494776193,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.149701370304874
}
#Debug simulation 
Total elapsed time: 2.6263338490389287. Arrivals time: 0.09025706211104989 Scheduler time: 2.188327880576253 Scheduler overhead time: 0.13362099323421717 Adapter cache time: 0.025911716744303703 Engine time: 0.12455012323334813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6324815349653363,
    "estimated_duration": 3599.949906141031,
    "input_throughput": 2273.7133052982363,
    "output_throughput": 2008.5293374959354,
    "total_throughput": 4282.242642794172,
    "itl": 23.946838295960468,
    "ttft": 5922.323313454593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.85495156625054,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.150911194538811
}
#Debug simulation 
Total elapsed time: 2.6325778639875352. Arrivals time: 0.09204296953976154 Scheduler time: 2.184235272463411 Scheduler overhead time: 0.13560470659285784 Adapter cache time: 0.02587093412876129 Engine time: 0.1305544748902321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5983167719095945,
    "estimated_duration": 3599.950799199995,
    "input_throughput": 2273.71274124607,
    "output_throughput": 2008.5288392293676,
    "total_throughput": 4282.241580475437,
    "itl": 23.946871158954103,
    "ttft": 5922.341013956924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.856609306149162,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.1509208270049114
}
#Debug simulation 
Total elapsed time: 2.5984060228802264. Arrivals time: 0.09011486498638988 Scheduler time: 2.1602414124645293 Scheduler overhead time: 0.13329421263188124 Adapter cache time: 0.025853085331618786 Engine time: 0.1251332312822342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6430646423250437,
    "estimated_duration": 3599.9547477125575,
    "input_throughput": 2273.710247386021,
    "output_throughput": 2008.5266362290774,
    "total_throughput": 4282.236883615098,
    "itl": 23.945485054249378,
    "ttft": 5922.234221946536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.694782201421881,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.149894748246077
}
#Debug simulation 
Total elapsed time: 2.6431772504001856. Arrivals time: 0.09194056643173099 Scheduler time: 2.1986435251310468 Scheduler overhead time: 0.13368355948477983 Adapter cache time: 0.025842171162366867 Engine time: 0.129166126716882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6154388822615147,
    "estimated_duration": 3599.9622709902283,
    "input_throughput": 2273.7054957380187,
    "output_throughput": 2008.522438767422,
    "total_throughput": 4282.22793450544,
    "itl": 23.94745667434234,
    "ttft": 5922.252169539263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.905904790423816,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.1513308442034957
}
#Debug simulation 
Total elapsed time: 2.6155289099551737. Arrivals time: 0.0910564293153584 Scheduler time: 2.1749171228148043 Scheduler overhead time: 0.13345768675208092 Adapter cache time: 0.02606667159125209 Engine time: 0.12643324118107557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6255819080397487,
    "estimated_duration": 3599.961188712106,
    "input_throughput": 2273.7061792958643,
    "output_throughput": 2008.5230426016801,
    "total_throughput": 4282.229221897544,
    "itl": 23.944558467142546,
    "ttft": 5922.257459754436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5983537062699353,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.149461885606301
}
#Debug simulation 
Total elapsed time: 2.625672854948789. Arrivals time: 0.09154733782634139 Scheduler time: 2.181622357107699 Scheduler overhead time: 0.13465978670865297 Adapter cache time: 0.025815897155553102 Engine time: 0.12807376123964787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6077529592439532,
    "estimated_duration": 3599.9468827937408,
    "input_throughput": 2273.715214833345,
    "output_throughput": 2008.5310243213048,
    "total_throughput": 4282.24623915465,
    "itl": 23.947736551765182,
    "ttft": 5922.349839459928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9355826840177452,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.15174044416805
}
#Debug simulation 
Total elapsed time: 2.607873841188848. Arrivals time: 0.09003528580069542 Scheduler time: 2.169941511005163 Scheduler overhead time: 0.13243694650009274 Adapter cache time: 0.025670872535556555 Engine time: 0.12608444364741445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.622973696794361,
    "estimated_duration": 3600.014805353138,
    "input_throughput": 2249.0468616852745,
    "output_throughput": 2015.8792094990056,
    "total_throughput": 4264.92607118428,
    "itl": 23.926546371516316,
    "ttft": 5500.187602202256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1239784942893687,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.127740181184839
}
#Debug simulation 
Total elapsed time: 2.6230661547742784. Arrivals time: 0.09045860497280955 Scheduler time: 2.182900947984308 Scheduler overhead time: 0.1327909380197525 Adapter cache time: 0.02491466887295246 Engine time: 0.12841177731752396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.611235859338194,
    "estimated_duration": 3600.0182208580345,
    "input_throughput": 2249.0447279098053,
    "output_throughput": 2015.8772969405438,
    "total_throughput": 4264.922024850349,
    "itl": 23.9267838024543,
    "ttft": 5500.244589495897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2921889018197654,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.127468281079314
}
#Debug simulation 
Total elapsed time: 2.6113252183422446. Arrivals time: 0.09022537991404533 Scheduler time: 2.1752416216768324 Scheduler overhead time: 0.13265396701171994 Adapter cache time: 0.025019187480211258 Engine time: 0.12454116996377707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.634880308061838,
    "estimated_duration": 3600.0178567662247,
    "input_throughput": 2249.0449553694452,
    "output_throughput": 2015.8775008185362,
    "total_throughput": 4264.922456187982,
    "itl": 23.926622477993003,
    "ttft": 5500.237061700315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2919632870331403,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1274714919013435
}
#Debug simulation 
Total elapsed time: 2.6349706100299954. Arrivals time: 0.08943145349621773 Scheduler time: 2.1929782456718385 Scheduler overhead time: 0.13679742300882936 Adapter cache time: 0.025035484693944454 Engine time: 0.12591564375907183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6172593031078577,
    "estimated_duration": 3600.0039250027485,
    "input_throughput": 2249.0536590161687,
    "output_throughput": 2015.8853021235134,
    "total_throughput": 4264.938961139682,
    "itl": 23.92538144794561,
    "ttft": 5500.166326890997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1607510923477617,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.126587952767075
}
#Debug simulation 
Total elapsed time: 2.617356600239873. Arrivals time: 0.08936630934476852 Scheduler time: 2.175920458044857 Scheduler overhead time: 0.1340115345083177 Adapter cache time: 0.025060515850782394 Engine time: 0.1292453627102077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.630317049100995,
    "estimated_duration": 3600.0200645900204,
    "input_throughput": 2249.0435760729742,
    "output_throughput": 2015.876264519228,
    "total_throughput": 4264.9198405922025,
    "itl": 23.92663024005569,
    "ttft": 5500.2599841857445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.333462036550049,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1276335245893545
}
#Debug simulation 
Total elapsed time: 2.6303996643982828. Arrivals time: 0.09050312405452132 Scheduler time: 2.1877001910470426 Scheduler overhead time: 0.13445193273946643 Adapter cache time: 0.02522190660238266 Engine time: 0.12838339619338512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.631292436737567,
    "estimated_duration": 3600.007302263544,
    "input_throughput": 2249.05154912024,
    "output_throughput": 2015.8834109689053,
    "total_throughput": 4264.9349600891455,
    "itl": 23.926199988515172,
    "ttft": 5500.189137002373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0750949046620732,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1273796927811697
}
#Debug simulation 
Total elapsed time: 2.6313822818920016. Arrivals time: 0.09110044222325087 Scheduler time: 2.188551391940564 Scheduler overhead time: 0.13370300270617008 Adapter cache time: 0.02510378835722804 Engine time: 0.1290831882506609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6075630951672792,
    "estimated_duration": 3600.022692738351,
    "input_throughput": 2249.0419341888464,
    "output_throughput": 2015.8747928557714,
    "total_throughput": 4264.916727044618,
    "itl": 23.926958345871363,
    "ttft": 5500.242597928727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.361364791244275,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.128007346891551
}
#Debug simulation 
Total elapsed time: 2.6076780762523413. Arrivals time: 0.08888666750863194 Scheduler time: 2.1700308709405363 Scheduler overhead time: 0.13337814435362816 Adapter cache time: 0.024991669226437807 Engine time: 0.12685920484364033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6038358598016202,
    "estimated_duration": 3599.975033474771,
    "input_throughput": 2237.7616303145,
    "output_throughput": 1990.609082942192,
    "total_throughput": 4228.3707132566915,
    "itl": 23.715140931040576,
    "ttft": 5676.532710998982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5883931391011183,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.818243367712006
}
#Debug simulation 
Total elapsed time: 2.6039175228215754. Arrivals time: 0.0882229832932353 Scheduler time: 2.1637428044341505 Scheduler overhead time: 0.1347222519107163 Adapter cache time: 0.023903474677354097 Engine time: 0.12897101789712906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5894509172067046,
    "estimated_duration": 3599.978733986955,
    "input_throughput": 2237.7593300608623,
    "output_throughput": 1990.6070367431141,
    "total_throughput": 4228.366366803976,
    "itl": 23.71595723332332,
    "ttft": 5676.506665688362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6944358691899168,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8189408259210986
}
#Debug simulation 
Total elapsed time: 2.589539684355259. Arrivals time: 0.08734904835000634 Scheduler time: 2.1529559660702944 Scheduler overhead time: 0.13422304298728704 Adapter cache time: 0.02390777226537466 Engine time: 0.1268707737326622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6030156682245433,
    "estimated_duration": 3599.9799903243597,
    "input_throughput": 2237.7585491174245,
    "output_throughput": 1990.6063420520088,
    "total_throughput": 4228.364891169434,
    "itl": 23.715793489045367,
    "ttft": 5676.48551812712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6972856581024929,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8190086285497697
}
#Debug simulation 
Total elapsed time: 2.6031011161394417. Arrivals time: 0.08826716104522347 Scheduler time: 2.160042793955654 Scheduler overhead time: 0.13540767692029476 Adapter cache time: 0.024005824234336615 Engine time: 0.13067519199103117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.585524156689644,
    "estimated_duration": 3599.986814713606,
    "input_throughput": 2237.754307064283,
    "output_throughput": 1990.6025685180452,
    "total_throughput": 4228.356875582328,
    "itl": 23.71525150741454,
    "ttft": 5676.481668305055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6012761365855006,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8183867192098306
}
#Debug simulation 
Total elapsed time: 2.5856325356289744. Arrivals time: 0.08709137560799718 Scheduler time: 2.1516603087075055 Scheduler overhead time: 0.1333879274316132 Adapter cache time: 0.023929288610816002 Engine time: 0.12555157206952572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.580092174001038,
    "estimated_duration": 3599.9937534507753,
    "input_throughput": 2237.749993948747,
    "output_throughput": 1990.598731770268,
    "total_throughput": 4228.348725719015,
    "itl": 23.716307094243167,
    "ttft": 5676.484937164992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7259575214050726,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8192131625338757
}
#Debug simulation 
Total elapsed time: 2.5801787497475743. Arrivals time: 0.08709724806249142 Scheduler time: 2.142272174358368 Scheduler overhead time: 0.13509904174134135 Adapter cache time: 0.024154111742973328 Engine time: 0.12748234439641237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6103322277776897,
    "estimated_duration": 3599.9829091178412,
    "input_throughput": 2237.7567347879594,
    "output_throughput": 1990.6047281085646,
    "total_throughput": 4228.361462896524,
    "itl": 23.714948376006152,
    "ttft": 5676.59212424515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551836103054211,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.818058442035716
}
#Debug simulation 
Total elapsed time: 2.610413255635649. Arrivals time: 0.08450798131525517 Scheduler time: 2.171241900883615 Scheduler overhead time: 0.13577535515651107 Adapter cache time: 0.023955378215759993 Engine time: 0.1302775302901864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.600270755123347,
    "estimated_duration": 3599.9846167386922,
    "input_throughput": 2237.7556733278516,
    "output_throughput": 1990.6037838828242,
    "total_throughput": 4228.359457210676,
    "itl": 23.716294002989894,
    "ttft": 5676.483110054501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7411737295612664,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8190423214881446
}
#Debug simulation 
Total elapsed time: 2.6003813669085503. Arrivals time: 0.08849868504330516 Scheduler time: 2.158889043610543 Scheduler overhead time: 0.1348279337398708 Adapter cache time: 0.023875385522842407 Engine time: 0.12969008414074779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.5590494158677757,
    "estimated_duration": 3599.956471752412,
    "input_throughput": 2220.6260166552925,
    "output_throughput": 1964.4373634766466,
    "total_throughput": 4185.063380131939,
    "itl": 23.57094313363376,
    "ttft": 5809.297244252984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.309888754403228,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.509015498382757
}
#Debug simulation 
Total elapsed time: 2.5591371301561594. Arrivals time: 0.08807293884456158 Scheduler time: 2.119458897970617 Scheduler overhead time: 0.13377423025667667 Adapter cache time: 0.023620376363396645 Engine time: 0.13013645820319653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5678020250052214,
    "estimated_duration": 3599.9497954625685,
    "input_throughput": 2220.6301349190917,
    "output_throughput": 1964.4410066255691,
    "total_throughput": 4185.071141544661,
    "itl": 23.571898136533132,
    "ttft": 5809.290726043407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4046418105950653,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5096346973887047
}
#Debug simulation 
Total elapsed time: 2.5678921779617667. Arrivals time: 0.08846585499122739 Scheduler time: 2.1285635316744447 Scheduler overhead time: 0.13502178713679314 Adapter cache time: 0.02367575978860259 Engine time: 0.12788879545405507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5625737393274903,
    "estimated_duration": 3599.950050191259,
    "input_throughput": 2220.629977789632,
    "output_throughput": 1964.4408676237836,
    "total_throughput": 4185.070845413416,
    "itl": 23.571900267175366,
    "ttft": 5809.3043585444675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4051410142146135,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5096032980323852
}
#Debug simulation 
Total elapsed time: 2.562662836164236. Arrivals time: 0.088284180033952 Scheduler time: 2.121803146786988 Scheduler overhead time: 0.13534193858504295 Adapter cache time: 0.023603464011102915 Engine time: 0.12892436236143112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5747985378839076,
    "estimated_duration": 3599.9557939511683,
    "input_throughput": 2220.6264347557253,
    "output_throughput": 1964.4377333417685,
    "total_throughput": 4185.064168097494,
    "itl": 23.571350747105217,
    "ttft": 5809.324876643496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.325782914136067,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.509262565171273
}
#Debug simulation 
Total elapsed time: 2.5748857888393104. Arrivals time: 0.08800855185836554 Scheduler time: 2.133394935633987 Scheduler overhead time: 0.1373606459237635 Adapter cache time: 0.023934194818139076 Engine time: 0.12714512180536985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5768521609716117,
    "estimated_duration": 3599.958987873373,
    "input_throughput": 2220.624464592148,
    "output_throughput": 1964.4359904715532,
    "total_throughput": 4185.060455063701,
    "itl": 23.57213113155727,
    "ttft": 5809.251245883627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4327922613360022,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5095608386043287
}
#Debug simulation 
Total elapsed time: 2.576940534170717. Arrivals time: 0.09024602733552456 Scheduler time: 2.1336716641671956 Scheduler overhead time: 0.13455107621848583 Adapter cache time: 0.02379088243469596 Engine time: 0.1302473028190434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.5556160677224398,
    "estimated_duration": 3599.970775149443,
    "input_throughput": 2220.6171936682304,
    "output_throughput": 1964.4295583778537,
    "total_throughput": 4185.046752046084,
    "itl": 23.57084231765532,
    "ttft": 5809.236174547107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2797415262181226,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5088191890143805
}
#Debug simulation 
Total elapsed time: 2.5557047207839787. Arrivals time: 0.0871278727427125 Scheduler time: 2.1206667185761034 Scheduler overhead time: 0.13417809177190065 Adapter cache time: 0.023489585146307945 Engine time: 0.12587231025099754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.562107121106237,
    "estimated_duration": 3599.950145247055,
    "input_throughput": 2220.629919154445,
    "output_throughput": 1964.4408157532068,
    "total_throughput": 4185.070734907652,
    "itl": 23.571876758250397,
    "ttft": 5809.263668288582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4445019493624571,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5096475307991915
}
#Debug simulation 
Total elapsed time: 2.562224430963397. Arrivals time: 0.08807488717138767 Scheduler time: 2.124029421247542 Scheduler overhead time: 0.13421400031074882 Adapter cache time: 0.02353243064135313 Engine time: 0.12783438432961702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.566503739915788,
    "estimated_duration": 3599.937753755805,
    "input_throughput": 2201.6611236488716,
    "output_throughput": 1966.0606610811144,
    "total_throughput": 4167.721784729986,
    "itl": 23.476359124467788,
    "ttft": 7532.249725907792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7375775462877927,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4422550493213584
}
#Debug simulation 
Total elapsed time: 2.5665895543061197. Arrivals time: 0.08787616016343236 Scheduler time: 2.1252298266626894 Scheduler overhead time: 0.1358115072362125 Adapter cache time: 0.022921754512935877 Engine time: 0.13008380588144064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5763237811625004,
    "estimated_duration": 3599.944060124035,
    "input_throughput": 2201.6572667873393,
    "output_throughput": 1966.0572169435711,
    "total_throughput": 4167.714483730911,
    "itl": 23.476614302859456,
    "ttft": 7532.23548323198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7851601813850023,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4425529055203787
}
#Debug simulation 
Total elapsed time: 2.576411558780819. Arrivals time: 0.08665775926783681 Scheduler time: 2.1340104611590505 Scheduler overhead time: 0.13730859151110053 Adapter cache time: 0.02303587691858411 Engine time: 0.13020423986017704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5639095208607614,
    "estimated_duration": 3599.945741056851,
    "input_throughput": 2201.6562387613035,
    "output_throughput": 1966.0562989269308,
    "total_throughput": 4167.712537688234,
    "itl": 23.476677699401368,
    "ttft": 7532.2378232538995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7867731466889418,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4425134165479836
}
#Debug simulation 
Total elapsed time: 2.5640015569515526. Arrivals time: 0.086991460993886 Scheduler time: 2.1268293214961886 Scheduler overhead time: 0.1351865124888718 Adapter cache time: 0.02295366209000349 Engine time: 0.12760346243157983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5671240631490946,
    "estimated_duration": 3599.943893755522,
    "input_throughput": 2201.65736853516,
    "output_throughput": 1966.0573078033249,
    "total_throughput": 4167.714676338484,
    "itl": 23.476337943705367,
    "ttft": 7532.16539283298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7434834589040854,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4423369045901917
}
#Debug simulation 
Total elapsed time: 2.5672151162289083. Arrivals time: 0.08587407739832997 Scheduler time: 2.1257800585590303 Scheduler overhead time: 0.13662909530103207 Adapter cache time: 0.02293834602460265 Engine time: 0.13091468531638384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5666140150278807,
    "estimated_duration": 3599.9408323796333,
    "input_throughput": 2201.659240816149,
    "output_throughput": 1966.0589797309253,
    "total_throughput": 4167.718220547074,
    "itl": 23.476798889365206,
    "ttft": 7532.242788877291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7996000329032571,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.442706149605962
}
#Debug simulation 
Total elapsed time: 2.5667029498144984. Arrivals time: 0.08636405691504478 Scheduler time: 2.1285125012509525 Scheduler overhead time: 0.13488957565277815 Adapter cache time: 0.02298135496675968 Engine time: 0.12945156963542104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.559361029881984,
    "estimated_duration": 3599.940971532391,
    "input_throughput": 2201.659155712822,
    "output_throughput": 1966.0589037345324,
    "total_throughput": 4167.718059447355,
    "itl": 23.476195347461967,
    "ttft": 7532.135338497865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206021210714253,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4421064337858405
}
#Debug simulation 
Total elapsed time: 2.5594553970731795. Arrivals time: 0.08697081403806806 Scheduler time: 2.1231189714744687 Scheduler overhead time: 0.1346642686985433 Adapter cache time: 0.02324999449774623 Engine time: 0.12670258013531566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5909596029669046,
    "estimated_duration": 3599.9223880495797,
    "input_throughput": 2201.6705210953683,
    "output_throughput": 1966.069052903849,
    "total_throughput": 4167.739573999217,
    "itl": 23.47702451187634,
    "ttft": 7532.302059022586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8066422449424893,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4427084431879917
}
#Debug simulation 
Total elapsed time: 2.5910824108868837. Arrivals time: 0.08830488193780184 Scheduler time: 2.1442604516632855 Scheduler overhead time: 0.13869537180289626 Adapter cache time: 0.023060079663991928 Engine time: 0.13135929591953754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9783653980121017,
    "estimated_duration": 3599.897439387273,
    "input_throughput": 1480.3966195512166,
    "output_throughput": 1301.5981924189275,
    "total_throughput": 2781.994811970144,
    "itl": 22.695699263970216,
    "ttft": 5927.866683221795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.652835825682812,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.011688746866968787
}
#Debug simulation 
Total elapsed time: 1.9784512617625296. Arrivals time: 0.06818504584953189 Scheduler time: 1.5316189052537084 Scheduler overhead time: 0.13717379886657 Adapter cache time: 0.0413762372918427 Engine time: 0.13354355422779918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9801526609808207,
    "estimated_duration": 3599.89908299442,
    "input_throughput": 1480.3959436460293,
    "output_throughput": 1301.5975981477986,
    "total_throughput": 2781.993541793828,
    "itl": 22.702608383026767,
    "ttft": 5928.805048400958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.63506836484966,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.01171189417654204
}
#Debug simulation 
Total elapsed time: 1.980238395743072. Arrivals time: 0.06764254532754421 Scheduler time: 1.537352209445089 Scheduler overhead time: 0.13708052225410938 Adapter cache time: 0.04120863461866975 Engine time: 0.1305958447046578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9834072208032012,
    "estimated_duration": 3599.9024560201588,
    "input_throughput": 1480.3945565491058,
    "output_throughput": 1301.5963785808094,
    "total_throughput": 2781.990935129915,
    "itl": 22.702594038934386,
    "ttft": 5929.38857308422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.635749178304096,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.011727607750582403
}
#Debug simulation 
Total elapsed time: 1.9834940377622843. Arrivals time: 0.06809490313753486 Scheduler time: 1.536364832893014 Scheduler overhead time: 0.13750759419053793 Adapter cache time: 0.04143726360052824 Engine time: 0.13351860828697681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.9873889898881316,
    "estimated_duration": 3599.9201326589045,
    "input_throughput": 1480.3872873878986,
    "output_throughput": 1301.5899873698577,
    "total_throughput": 2781.9772747577563,
    "itl": 22.697598757251782,
    "ttft": 5928.003801315286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.955314584151909,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.011717481595157264
}
#Debug simulation 
Total elapsed time: 1.9874812136404216. Arrivals time: 0.06866990262642503 Scheduler time: 1.5381653741933405 Scheduler overhead time: 0.1385776442475617 Adapter cache time: 0.041602073702961206 Engine time: 0.13363934680819511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.972339394968003,
    "estimated_duration": 3599.919156764698,
    "input_throughput": 1480.387688702849,
    "output_throughput": 1301.590340215039,
    "total_throughput": 2781.978028917888,
    "itl": 22.703277593562905,
    "ttft": 5929.630728213557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.852544962278406,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.011746252751780206
}
#Debug simulation 
Total elapsed time: 1.9724498903378844. Arrivals time: 0.06791628012433648 Scheduler time: 1.5280067650601268 Scheduler overhead time: 0.13738673133775592 Adapter cache time: 0.04150748020038009 Engine time: 0.13122920086607337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9788182470947504,
    "estimated_duration": 3599.916034070324,
    "input_throughput": 1480.3889728434408,
    "output_throughput": 1301.591469260493,
    "total_throughput": 2781.980442103934,
    "itl": 22.693463280800188,
    "ttft": 5927.251977003803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.347584516444462,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.01170990642203962
}
#Debug simulation 
Total elapsed time: 1.978908868972212. Arrivals time: 0.0681854672729969 Scheduler time: 1.5303372922353446 Scheduler overhead time: 0.13812649762257934 Adapter cache time: 0.041355947498232126 Engine time: 0.13384061120450497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9942340697161853,
    "estimated_duration": 3599.900425420087,
    "input_throughput": 1480.3953915970067,
    "output_throughput": 1301.5971127738112,
    "total_throughput": 2781.992504370818,
    "itl": 22.704970700151286,
    "ttft": 5929.895062182288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.031159096657229,
    "arrivals": 21639,
    "finished_requests": 21608,
    "scheduler_time": 0.011756245387970831
}
#Debug simulation 
Total elapsed time: 1.9943647510372102. Arrivals time: 0.06807764107361436 Scheduler time: 1.5428932211361825 Scheduler overhead time: 0.1416515251621604 Adapter cache time: 0.0412416635081172 Engine time: 0.1327434298582375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9054117812775075,
    "estimated_duration": 3600.014809467392,
    "input_throughput": 1422.1160942272431,
    "output_throughput": 1263.4617468901274,
    "total_throughput": 2685.5778411173706,
    "itl": 22.539796770426726,
    "ttft": 7970.925807369213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.027716833654935,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013289512704264181
}
#Debug simulation 
Total elapsed time: 1.9055015901103616. Arrivals time: 0.0649077701382339 Scheduler time: 1.4633529037237167 Scheduler overhead time: 0.13921744422987103 Adapter cache time: 0.039937988854944706 Engine time: 0.1311831958591938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9106667172163725,
    "estimated_duration": 3600.012976761796,
    "input_throughput": 1422.1168182024455,
    "output_throughput": 1263.4623900970905,
    "total_throughput": 2685.5792082995363,
    "itl": 22.54561098935329,
    "ttft": 7970.896996607066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.945072945580382,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013269469609029293
}
#Debug simulation 
Total elapsed time: 1.9107558373361826. Arrivals time: 0.06586753763258457 Scheduler time: 1.4657425531186163 Scheduler overhead time: 0.13758206367492676 Adapter cache time: 0.04023920465260744 Engine time: 0.13454335881397128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9014090802520514,
    "estimated_duration": 3600.020648730648,
    "input_throughput": 1422.1137875431805,
    "output_throughput": 1263.459697544728,
    "total_throughput": 2685.5734850879085,
    "itl": 22.545319623040804,
    "ttft": 7969.1889556838805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.957636879011105,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.001343405587942707
}
#Debug simulation 
Total elapsed time: 1.9014936638996005. Arrivals time: 0.06528407242149115 Scheduler time: 1.4590382343158126 Scheduler overhead time: 0.13901616586372256 Adapter cache time: 0.040060393046587706 Engine time: 0.1312311072833836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.9135953281074762,
    "estimated_duration": 3600.0221288360904,
    "input_throughput": 1422.1132028583422,
    "output_throughput": 1263.4591780885949,
    "total_throughput": 2685.572380946937,
    "itl": 22.542057935816405,
    "ttft": 7971.289802850554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.313254700205924,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013189504764453577
}
#Debug simulation 
Total elapsed time: 1.913709171116352. Arrivals time: 0.06645551603287458 Scheduler time: 1.468588907737285 Scheduler overhead time: 0.13773997267708182 Adapter cache time: 0.040171186439692974 Engine time: 0.13399247964844108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9110680227167904,
    "estimated_duration": 3600.0119990902595,
    "input_throughput": 1422.1172044131401,
    "output_throughput": 1263.4627332212847,
    "total_throughput": 2685.579937634425,
    "itl": 22.54783791333673,
    "ttft": 7971.5196969434155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.141492658554666,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013378748725179428
}
#Debug simulation 
Total elapsed time: 1.911157626658678. Arrivals time: 0.06519489688798785 Scheduler time: 1.4690821170806885 Scheduler overhead time: 0.13780290121212602 Adapter cache time: 0.03992218244820833 Engine time: 0.13280663592740893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9006218016147614,
    "estimated_duration": 3600.00046516751,
    "input_throughput": 1422.121760687545,
    "output_throughput": 1263.4667811878621,
    "total_throughput": 2685.588541875407,
    "itl": 22.53822359535242,
    "ttft": 7799.019832133606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.756877759556088,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013195620102102585
}
#Debug simulation 
Total elapsed time: 1.9007097035646439. Arrivals time: 0.06544559961184859 Scheduler time: 1.460432215128094 Scheduler overhead time: 0.13665982708334923 Adapter cache time: 0.0399164124391973 Engine time: 0.13180923694744706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9104135730303824,
    "estimated_duration": 3600.0226201533806,
    "input_throughput": 1422.1130087737824,
    "output_throughput": 1263.4590056565282,
    "total_throughput": 2685.572014430311,
    "itl": 22.549012662445858,
    "ttft": 7971.54872890778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.310480319521503,
    "arrivals": 20840,
    "finished_requests": 20796,
    "scheduler_time": 0.0013187642131955036
}
#Debug simulation 
Total elapsed time: 1.9105353290215135. Arrivals time: 0.06547913979738951 Scheduler time: 1.4702744516544044 Scheduler overhead time: 0.13693246897310019 Adapter cache time: 0.03997051855549216 Engine time: 0.13133791647851467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8696648781187832,
    "estimated_duration": 3600.00297313647,
    "input_throughput": 1394.7127370357491,
    "output_throughput": 1250.2123008189483,
    "total_throughput": 2644.925037854697,
    "itl": 22.40396977455968,
    "ttft": 4815.308757531551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.338327599004487,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008423196420835456
}
#Debug simulation 
Total elapsed time: 1.8697504391893744. Arrivals time: 0.06308848224580288 Scheduler time: 1.4315353259444237 Scheduler overhead time: 0.13675788044929504 Adapter cache time: 0.03853108175098896 Engine time: 0.13349424209445715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8844366720877588,
    "estimated_duration": 3600.0017693659574,
    "input_throughput": 1394.7132034005383,
    "output_throughput": 1250.2127188656043,
    "total_throughput": 2644.9259222661426,
    "itl": 22.40993864935709,
    "ttft": 4815.938247831448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.171986587261946,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008419347591780862
}
#Debug simulation 
Total elapsed time: 1.8845305810682476. Arrivals time: 0.0634389091283083 Scheduler time: 1.4453892670571804 Scheduler overhead time: 0.1364659951068461 Adapter cache time: 0.03848942508921027 Engine time: 0.13415444269776344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8714549229480326,
    "estimated_duration": 3600.02692581001,
    "input_throughput": 1394.7034573554686,
    "output_throughput": 1250.2039825680808,
    "total_throughput": 2644.9074399235496,
    "itl": 22.40996799593548,
    "ttft": 4992.468466196021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.14736231902562,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008326344319715374
}
#Debug simulation 
Total elapsed time: 1.8715425543487072. Arrivals time: 0.06246327655389905 Scheduler time: 1.4329330706968904 Scheduler overhead time: 0.13934098789468408 Adapter cache time: 0.03845071652904153 Engine time: 0.1309225712902844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.875233223196119,
    "estimated_duration": 3600.024855410051,
    "input_throughput": 1394.70425945937,
    "output_throughput": 1250.2047015693042,
    "total_throughput": 2644.908961028674,
    "itl": 22.406085805324274,
    "ttft": 4991.809722175902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.595439646821728,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008323592357120729
}
#Debug simulation 
Total elapsed time: 1.875327412970364. Arrivals time: 0.06332777813076973 Scheduler time: 1.4341656463220716 Scheduler overhead time: 0.13799700886011124 Adapter cache time: 0.03847981337457895 Engine time: 0.13410894898697734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8686351622454822,
    "estimated_duration": 3600.012618755701,
    "input_throughput": 1394.7090001410702,
    "output_throughput": 1250.2089510885196,
    "total_throughput": 2644.91795122959,
    "itl": 22.4098740872514,
    "ttft": 4815.8119749057005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.351735874506977,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008330473460808326
}
#Debug simulation 
Total elapsed time: 1.8687241380102932. Arrivals time: 0.06341655179858208 Scheduler time: 1.4313982701860368 Scheduler overhead time: 0.1371294315904379 Adapter cache time: 0.03848665859550238 Engine time: 0.13161253556609154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8814831469208002,
    "estimated_duration": 3600.0109492610936,
    "input_throughput": 1394.7096469333128,
    "output_throughput": 1250.2095308692847,
    "total_throughput": 2644.9191778025975,
    "itl": 22.401221840273795,
    "ttft": 4815.374312969637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.106369996769656,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0008165121424371956
}
#Debug simulation 
Total elapsed time: 1.8815712709911168. Arrivals time: 0.06320581305772066 Scheduler time: 1.4409616109915078 Scheduler overhead time: 0.13928497303277254 Adapter cache time: 0.03844233648851514 Engine time: 0.1321209049783647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9015777022577822,
    "estimated_duration": 3600.014239637096,
    "input_throughput": 1394.7083721830347,
    "output_throughput": 1250.2083881906271,
    "total_throughput": 2644.916760373662,
    "itl": 22.41110876588192,
    "ttft": 4815.858671807983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.502077091112103,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.000840821378294279
}
#Debug simulation 
Total elapsed time: 1.901693762280047. Arrivals time: 0.06356347817927599 Scheduler time: 1.4578730524517596 Scheduler overhead time: 0.1399585260078311 Adapter cache time: 0.038678329437971115 Engine time: 0.13420778978616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8464339468628168,
    "estimated_duration": 3599.9217139442167,
    "input_throughput": 1397.8501200479097,
    "output_throughput": 1224.2057884007336,
    "total_throughput": 2622.055908448643,
    "itl": 22.254627762018217,
    "ttft": 4989.175751655408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.392636886129507,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017381052915267457
}
#Debug simulation 
Total elapsed time: 1.8465325231663883. Arrivals time: 0.062473464757204056 Scheduler time: 1.4067592709325254 Scheduler overhead time: 0.1383991613984108 Adapter cache time: 0.0379280811175704 Engine time: 0.13416860019788146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8347358671016991,
    "estimated_duration": 3599.9091672476034,
    "input_throughput": 1397.8549919489917,
    "output_throughput": 1224.2100551024491,
    "total_throughput": 2622.0650470514406,
    "itl": 22.261069124131968,
    "ttft": 4989.3301970502425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.155626513345613,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017411298503091151
}
#Debug simulation 
Total elapsed time: 1.8348240409977734. Arrivals time: 0.0613814084790647 Scheduler time: 1.3986011273227632 Scheduler overhead time: 0.13837403012439609 Adapter cache time: 0.03773414762690663 Engine time: 0.13146352861076593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8560784831643105,
    "estimated_duration": 3599.9224892910074,
    "input_throughput": 1397.849818980704,
    "output_throughput": 1224.2055247328262,
    "total_throughput": 2622.0553437135304,
    "itl": 22.26105895644897,
    "ttft": 4989.398581967565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.149245673194185,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017446200672161184
}
#Debug simulation 
Total elapsed time: 1.8561677262187004. Arrivals time: 0.06118813622742891 Scheduler time: 1.416394344996661 Scheduler overhead time: 0.13889514794573188 Adapter cache time: 0.03775552939623594 Engine time: 0.1343869986012578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.8302526529878378,
    "estimated_duration": 3599.907529132759,
    "input_throughput": 1397.855628033945,
    "output_throughput": 1224.210612171387,
    "total_throughput": 2622.066240205332,
    "itl": 22.256186366648173,
    "ttft": 4989.134205774571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.618155894288833,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017206668028376753
}
#Debug simulation 
Total elapsed time: 1.8303151996806264. Arrivals time: 0.05752864293754101 Scheduler time: 1.3971880804747343 Scheduler overhead time: 0.13837952632457018 Adapter cache time: 0.037715138867497444 Engine time: 0.1321316035464406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8475314350798726,
    "estimated_duration": 3599.913226619165,
    "input_throughput": 1397.8534156852197,
    "output_throughput": 1224.2086746459852,
    "total_throughput": 2622.0620903312047,
    "itl": 22.26154437841975,
    "ttft": 4989.235412395473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.326655094045687,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017388503445261614
}
#Debug simulation 
Total elapsed time: 1.8476257850416005. Arrivals time: 0.06237313523888588 Scheduler time: 1.4081455091945827 Scheduler overhead time: 0.13945690402761102 Adapter cache time: 0.03785333316773176 Engine time: 0.1319896476343274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8427551183849573,
    "estimated_duration": 3599.9206994694387,
    "input_throughput": 1397.8505139687231,
    "output_throughput": 1224.2061333877484,
    "total_throughput": 2622.0566473564713,
    "itl": 22.253493314120842,
    "ttft": 4988.890011902697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.182444455644642,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0017394618782910624
}
#Debug simulation 
Total elapsed time: 1.8428218383342028. Arrivals time: 0.058199713472276926 Scheduler time: 1.4070789865218103 Scheduler overhead time: 0.13811221392825246 Adapter cache time: 0.037826139479875565 Engine time: 0.13452743832021952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8554470059461892,
    "estimated_duration": 3599.924060124108,
    "input_throughput": 1397.8492090265136,
    "output_throughput": 1224.2049905486247,
    "total_throughput": 2622.0541995751382,
    "itl": 22.262558534717,
    "ttft": 4989.318572678853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.479876030235959,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.001752523420048763
}
#Debug simulation 
Total elapsed time: 1.8555624280124903. Arrivals time: 0.06461059721186757 Scheduler time: 1.412649229168892 Scheduler overhead time: 0.13988506887108088 Adapter cache time: 0.03747831378132105 Engine time: 0.13044949946925044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.825978067703545,
    "estimated_duration": 3599.1516048120047,
    "input_throughput": 1393.3858727415152,
    "output_throughput": 1220.2456251434844,
    "total_throughput": 2613.6314978849996,
    "itl": 22.1935541887727,
    "ttft": 5509.465116158887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.844809579965684,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0017366042657633424
}
#Debug simulation 
Total elapsed time: 1.8260640478692949. Arrivals time: 0.0597213888540864 Scheduler time: 1.3910411824472249 Scheduler overhead time: 0.1393422707915306 Adapter cache time: 0.037131212186068296 Engine time: 0.13165625790134072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8415830358862877,
    "estimated_duration": 3599.1672519222134,
    "input_throughput": 1393.3798151007366,
    "output_throughput": 1220.2403202169717,
    "total_throughput": 2613.6201353177084,
    "itl": 22.198425847532494,
    "ttft": 5509.627337164797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.594628113254325,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0017469775862441108
}
#Debug simulation 
Total elapsed time: 1.8416673988103867. Arrivals time: 0.060790808871388435 Scheduler time: 1.4012324344366789 Scheduler overhead time: 0.13913479028269649 Adapter cache time: 0.037271021399647 Engine time: 0.1357888109050691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8350794780999422,
    "estimated_duration": 3599.1663784319453,
    "input_throughput": 1393.3801532634054,
    "output_throughput": 1220.240616360004,
    "total_throughput": 2613.620769623409,
    "itl": 22.19824648085836,
    "ttft": 5509.715932206873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.569727598726534,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0017402807459201998
}
#Debug simulation 
Total elapsed time: 1.835162182804197. Arrivals time: 0.061512130312621593 Scheduler time: 1.3988534156233072 Scheduler overhead time: 0.13655271381139755 Adapter cache time: 0.03744565835222602 Engine time: 0.13416311470791698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.8520350558683276,
    "estimated_duration": 3599.1570591328846,
    "input_throughput": 1393.3837611432896,
    "output_throughput": 1220.243775929604,
    "total_throughput": 2613.6275370728936,
    "itl": 22.195122884678007,
    "ttft": 5509.564836208998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.07517358045086,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0017205181652232724
}
#Debug simulation 
Total elapsed time: 1.8521183151751757. Arrivals time: 0.06433181604370475 Scheduler time: 1.4095877083018422 Scheduler overhead time: 0.13856036076322198 Adapter cache time: 0.03739315690472722 Engine time: 0.13518373016268015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8406959064304829,
    "estimated_duration": 3599.1463688096546,
    "input_throughput": 1393.1561782129847,
    "output_throughput": 1220.2468446573666,
    "total_throughput": 2613.4030228703514,
    "itl": 22.201168141705566,
    "ttft": 5689.173244985784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.735779164936034,
    "arrivals": 20063,
    "finished_requests": 20032,
    "scheduler_time": 0.001745527867854867
}
#Debug simulation 
Total elapsed time: 1.8407889530062675. Arrivals time: 0.06137566547840834 Scheduler time: 1.4030210715718567 Scheduler overhead time: 0.13803992746397853 Adapter cache time: 0.03727980377152562 Engine time: 0.13421575212851167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.832592214923352,
    "estimated_duration": 3599.157685991885,
    "input_throughput": 1393.3835184600764,
    "output_throughput": 1220.2435634018793,
    "total_throughput": 2613.627081861956,
    "itl": 22.192798884725047,
    "ttft": 5509.3520975742385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.632275201382498,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0017308914857040397
}
#Debug simulation 
Total elapsed time: 1.8326761880889535. Arrivals time: 0.06122180446982384 Scheduler time: 1.3959326264448464 Scheduler overhead time: 0.13783560786396265 Adapter cache time: 0.03724086517468095 Engine time: 0.13326880894601345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8326315870508552,
    "estimated_duration": 3599.1504593980917,
    "input_throughput": 1393.386316180483,
    "output_throughput": 1220.2460134813248,
    "total_throughput": 2613.632329661808,
    "itl": 22.20184804599555,
    "ttft": 5509.649683808694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.869203932322096,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.001729352834305186
}
#Debug simulation 
Total elapsed time: 1.8327481751330197. Arrivals time: 0.06075679091736674 Scheduler time: 1.3982158163562417 Scheduler overhead time: 0.1379718966782093 Adapter cache time: 0.03709849854931235 Engine time: 0.13163234945386648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.77801817888394,
    "estimated_duration": 3599.9610451910066,
    "input_throughput": 1284.42417624957,
    "output_throughput": 1164.5331567129683,
    "total_throughput": 2448.9573329625387,
    "itl": 21.977158601480244,
    "ttft": 6365.978290443501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.486732513925643,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0002621810264587033
}
#Debug simulation 
Total elapsed time: 1.778081363067031. Arrivals time: 0.055919861886650324 Scheduler time: 1.342228861991316 Scheduler overhead time: 0.1399265741929412 Adapter cache time: 0.03703071642667055 Engine time: 0.1357614486478269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7650955291464925,
    "estimated_duration": 3599.97185117101,
    "input_throughput": 1284.4203208133229,
    "output_throughput": 1164.529661151746,
    "total_throughput": 2448.9499819650687,
    "itl": 21.98126229922782,
    "ttft": 6366.096806368365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.09429926849885,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.00026900718740181253
}
#Debug simulation 
Total elapsed time: 1.765188792720437. Arrivals time: 0.06021680682897568 Scheduler time: 1.3268319061025977 Scheduler overhead time: 0.14149948442354798 Adapter cache time: 0.03718493366613984 Engine time: 0.1312302560545504 
