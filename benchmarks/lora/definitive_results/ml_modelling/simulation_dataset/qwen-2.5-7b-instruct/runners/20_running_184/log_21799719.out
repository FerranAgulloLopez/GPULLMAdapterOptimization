INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106426455 . Total output tokens: 95403918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 104.90364718809724,
    "estimated_duration": 3600.040986191668,
    "input_throughput": 7700.942602136246,
    "output_throughput": 6863.600190879735,
    "total_throughput": 14564.54279301598,
    "itl": 125.38863228101918,
    "ttft": 947040.4922034449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1196020117960871,
    "arrivals": 158690,
    "finished_requests": 112223,
    "scheduler_time": 138.74335888919256
}
#Debug simulation 
Total elapsed time: 104.90389253292233. Arrivals time: 0.4911141819320619 Scheduler time: 104.22171793226153 Scheduler overhead time: 0.07620549155399203 Adapter cache time: 0.014099718071520329 Engine time: 0.07291793311014771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106426455 . Total output tokens: 95403918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 104.95782320108265,
    "estimated_duration": 3600.12327493889,
    "input_throughput": 7700.995738950247,
    "output_throughput": 6863.600247249709,
    "total_throughput": 14564.595986199956,
    "itl": 125.38836004879536,
    "ttft": 947037.3858754352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13331578597426408,
    "arrivals": 158690,
    "finished_requests": 112226,
    "scheduler_time": 138.74705350377977
}
#Debug simulation 
Total elapsed time: 104.9580478221178. Arrivals time: 0.4963788134045899 Scheduler time: 104.26919560832903 Scheduler overhead time: 0.07773685501888394 Adapter cache time: 0.01347928773611784 Engine time: 0.07340674614533782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 85.46702813683078,
    "estimated_duration": 3600.1048122614516,
    "input_throughput": 7757.650528640151,
    "output_throughput": 6861.0638545504,
    "total_throughput": 14618.71438319055,
    "itl": 124.84688539152147,
    "ttft": 955109.6904972275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13466146073304108,
    "arrivals": 157801,
    "finished_requests": 112440,
    "scheduler_time": 138.3298679382583
}
#Debug simulation 
Total elapsed time: 85.46721138199791. Arrivals time: 0.49167695781216025 Scheduler time: 84.78822086984292 Scheduler overhead time: 0.07603441178798676 Adapter cache time: 0.01284862169995904 Engine time: 0.07191707519814372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 89.14067990519106,
    "estimated_duration": 3600.0252216384674,
    "input_throughput": 7757.601205718615,
    "output_throughput": 6860.9633209065505,
    "total_throughput": 14618.564526625165,
    "itl": 124.84652862580785,
    "ttft": 955097.9348724193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14463726316578684,
    "arrivals": 157801,
    "finished_requests": 112437,
    "scheduler_time": 138.3265355772261
}
#Debug simulation 
Total elapsed time: 89.1408643820323. Arrivals time: 0.4873768542893231 Scheduler time: 88.46617490891367 Scheduler overhead time: 0.07523196609690785 Adapter cache time: 0.013175043277442455 Engine time: 0.07212881743907928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 85.33963030483574,
    "estimated_duration": 3600.0251704356315,
    "input_throughput": 7757.601316054283,
    "output_throughput": 6860.9634184894185,
    "total_throughput": 14618.564734543701,
    "itl": 124.84651562178907,
    "ttft": 955097.8950937497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14470674917101858,
    "arrivals": 157801,
    "finished_requests": 112437,
    "scheduler_time": 138.3265279934163
}
#Debug simulation 
Total elapsed time: 85.33981573581696. Arrivals time: 0.4716922505758703 Scheduler time: 84.68335577659309 Scheduler overhead time: 0.07403289992362261 Adapter cache time: 0.01330420607700944 Engine time: 0.07106345891952515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 88.87074687285349,
    "estimated_duration": 3600.110995244042,
    "input_throughput": 7757.637205323668,
    "output_throughput": 6861.052071069718,
    "total_throughput": 14618.689276393387,
    "itl": 124.8467319103815,
    "ttft": 955111.3795505407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1368739521154203,
    "arrivals": 157801,
    "finished_requests": 112440,
    "scheduler_time": 138.3302207017523
}
#Debug simulation 
Total elapsed time: 88.87093143165112. Arrivals time: 0.46760893566533923 Scheduler time: 88.21655847504735 Scheduler overhead time: 0.07503127073869109 Adapter cache time: 0.01290540723130107 Engine time: 0.0719716502353549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 85.3561394191347,
    "estimated_duration": 3600.044869800096,
    "input_throughput": 7757.558866634561,
    "output_throughput": 6860.925875452082,
    "total_throughput": 14618.484742086643,
    "itl": 124.84687849167754,
    "ttft": 955136.7943512911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14709607111290088,
    "arrivals": 157801,
    "finished_requests": 112437,
    "scheduler_time": 138.3274115386752
}
#Debug simulation 
Total elapsed time: 85.35631898418069. Arrivals time: 0.4770997678861022 Scheduler time: 84.6916303052567 Scheduler overhead time: 0.07504212995991111 Adapter cache time: 0.01307363249361515 Engine time: 0.07216151338070631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 85.49455262394622,
    "estimated_duration": 3600.093783229428,
    "input_throughput": 7757.568186167498,
    "output_throughput": 6860.894045333241,
    "total_throughput": 14618.462231500738,
    "itl": 124.84692681519823,
    "ttft": 955110.0302828539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1315622129756958,
    "arrivals": 157801,
    "finished_requests": 112439,
    "scheduler_time": 138.32935306618455
}
#Debug simulation 
Total elapsed time: 85.49473743373528. Arrivals time: 0.47272913018241525 Scheduler time: 84.83757527451962 Scheduler overhead time: 0.07421747827902436 Adapter cache time: 0.012823534198105335 Engine time: 0.07090683421120048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105816986 . Total output tokens: 94813786
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 85.69945594388992,
    "estimated_duration": 3600.0458625400556,
    "input_throughput": 7757.556727428849,
    "output_throughput": 6860.923983499719,
    "total_throughput": 14618.480710928567,
    "itl": 124.84672237412678,
    "ttft": 955137.1578100264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14873087033629406,
    "arrivals": 157801,
    "finished_requests": 112437,
    "scheduler_time": 138.3274889422486
}
#Debug simulation 
Total elapsed time: 85.69963986286893. Arrivals time: 0.4778694794513285 Scheduler time: 85.03639446338639 Scheduler overhead time: 0.07498650113120675 Adapter cache time: 0.013098862022161484 Engine time: 0.07095096539705992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 127.72011750331149,
    "estimated_duration": 3600.100493805956,
    "input_throughput": 7777.776494899487,
    "output_throughput": 6861.68595640638,
    "total_throughput": 14639.462451305866,
    "itl": 124.80682369383739,
    "ttft": 881721.0823614908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12547999750124283,
    "arrivals": 157261,
    "finished_requests": 112375,
    "scheduler_time": 138.1788239869615
}
#Debug simulation 
Total elapsed time: 127.72042665397748. Arrivals time: 0.4899100591428578 Scheduler time: 127.03652153117582 Scheduler overhead time: 0.0779691063798964 Adapter cache time: 0.013594221789389849 Engine time: 0.07449506875127554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 128.1695429859683,
    "estimated_duration": 3600.087641050714,
    "input_throughput": 7777.739819641674,
    "output_throughput": 6861.646010592779,
    "total_throughput": 14639.385830234452,
    "itl": 124.80704770729709,
    "ttft": 881742.0514245379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13403273100731894,
    "arrivals": 157261,
    "finished_requests": 112374,
    "scheduler_time": 138.17830105514102
}
#Debug simulation 
Total elapsed time: 128.16973009798676. Arrivals time: 0.49173373356461525 Scheduler time: 127.48289575660601 Scheduler overhead time: 0.07898078858852386 Adapter cache time: 0.013714693021029234 Engine time: 0.07479780958965421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 127.65436872979626,
    "estimated_duration": 3600.087849864622,
    "input_throughput": 7777.739368513725,
    "output_throughput": 6861.645612600513,
    "total_throughput": 14639.384981114239,
    "itl": 124.80704311679509,
    "ttft": 881742.2172015817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1342272026464343,
    "arrivals": 157261,
    "finished_requests": 112374,
    "scheduler_time": 138.17831539741118
}
#Debug simulation 
Total elapsed time: 127.6545556508936. Arrivals time: 0.4838096876628697 Scheduler time: 126.97560851229355 Scheduler overhead time: 0.07937366841360927 Adapter cache time: 0.01383203361183405 Engine time: 0.07434543175622821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 127.53715471504256,
    "estimated_duration": 3600.1030259506106,
    "input_throughput": 7777.77102437405,
    "output_throughput": 6861.681130216326,
    "total_throughput": 14639.452154590377,
    "itl": 124.80659739928612,
    "ttft": 881722.4056060722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1274952059122734,
    "arrivals": 157261,
    "finished_requests": 112375,
    "scheduler_time": 138.17902617571963
}
#Debug simulation 
Total elapsed time: 127.53733669919893. Arrivals time: 0.4954007538035512 Scheduler time: 126.8465716955252 Scheduler overhead time: 0.07880581682547927 Adapter cache time: 0.014072493650019169 Engine time: 0.07464534742757678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 127.95767966425046,
    "estimated_duration": 3600.0950143869745,
    "input_throughput": 7777.7238900923685,
    "output_throughput": 6861.631957290537,
    "total_throughput": 14639.355847382905,
    "itl": 124.80700870465054,
    "ttft": 881746.2950136384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13623926322907204,
    "arrivals": 157261,
    "finished_requests": 112374,
    "scheduler_time": 138.1787490264682
}
#Debug simulation 
Total elapsed time: 127.95786412898451. Arrivals time: 0.49641014030203223 Scheduler time: 127.26911375951022 Scheduler overhead time: 0.07706791535019875 Adapter cache time: 0.013811588753014803 Engine time: 0.07482438534498215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 127.8687581596896,
    "estimated_duration": 3600.0905755011645,
    "input_throughput": 7777.733479970036,
    "output_throughput": 6861.640417633434,
    "total_throughput": 14639.37389760347,
    "itl": 124.80695347084465,
    "ttft": 881743.2006075525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12259206209098927,
    "arrivals": 157261,
    "finished_requests": 112374,
    "scheduler_time": 138.1784588507109
}
#Debug simulation 
Total elapsed time: 127.86894138809294. Arrivals time: 0.4950011600740254 Scheduler time: 127.17807637993246 Scheduler overhead time: 0.07841888768598437 Adapter cache time: 0.013449883554130793 Engine time: 0.07549245655536652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105490336 . Total output tokens: 94521237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 127.97882128693163,
    "estimated_duration": 3600.1014402738706,
    "input_throughput": 7777.774450119355,
    "output_throughput": 6861.684152466767,
    "total_throughput": 14639.45860258612,
    "itl": 124.80694694973563,
    "ttft": 881721.8128599843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13774830866605034,
    "arrivals": 157261,
    "finished_requests": 112375,
    "scheduler_time": 138.1788866029249
}
#Debug simulation 
Total elapsed time: 127.97900418704376. Arrivals time: 0.49934755079448223 Scheduler time: 127.28354119835421 Scheduler overhead time: 0.0791462897323072 Adapter cache time: 0.013553023338317871 Engine time: 0.07458280073478818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 105.20424433378503,
    "estimated_duration": 3600.1281242956347,
    "input_throughput": 7763.959235608778,
    "output_throughput": 6864.669852502884,
    "total_throughput": 14628.629088111662,
    "itl": 125.13309254067038,
    "ttft": 914875.9514231855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 157020,
    "finished_requests": 112516,
    "scheduler_time": 137.88992343574674
}
#Debug simulation 
Total elapsed time: 105.20442877709866. Arrivals time: 0.5077755437232554 Scheduler time: 104.50581441819668 Scheduler overhead time: 0.07713065203279257 Adapter cache time: 0.013445971067994833 Engine time: 0.07370064593851566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 105.17889830004424,
    "estimated_duration": 3600.020067458898,
    "input_throughput": 7764.153109215723,
    "output_throughput": 6864.814233506257,
    "total_throughput": 14628.96734272198,
    "itl": 125.13293132391398,
    "ttft": 914885.5322823201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10684356610057875,
    "arrivals": 157020,
    "finished_requests": 112514,
    "scheduler_time": 137.88546129613155
}
#Debug simulation 
Total elapsed time: 105.17908476479352. Arrivals time: 0.4892342006787658 Scheduler time: 104.49702571937814 Scheduler overhead time: 0.07699990225955844 Adapter cache time: 0.013588751200586557 Engine time: 0.07419302500784397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 104.82472160318866,
    "estimated_duration": 3600.020421262732,
    "input_throughput": 7764.152346168069,
    "output_throughput": 6864.813558844086,
    "total_throughput": 14628.965905012155,
    "itl": 125.13289242411962,
    "ttft": 914885.7808435464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1071810718998313,
    "arrivals": 157020,
    "finished_requests": 112514,
    "scheduler_time": 137.8854775941659
}
#Debug simulation 
Total elapsed time: 104.82490539597347. Arrivals time: 0.49999353755265474 Scheduler time: 104.12718170275912 Scheduler overhead time: 0.08193806791678071 Adapter cache time: 0.013498748186975718 Engine time: 0.07444008672609925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 105.0930521399714,
    "estimated_duration": 3600.1377777742528,
    "input_throughput": 7763.938417179291,
    "output_throughput": 6864.651445445229,
    "total_throughput": 14628.58986262452,
    "itl": 125.13319004075376,
    "ttft": 914880.6195309992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10234901759773496,
    "arrivals": 157020,
    "finished_requests": 112516,
    "scheduler_time": 137.89054591663847
}
#Debug simulation 
Total elapsed time: 105.09323927899823. Arrivals time: 0.49544429453089833 Scheduler time: 104.40466616908088 Scheduler overhead time: 0.07816531462594867 Adapter cache time: 0.013247380964457989 Engine time: 0.07431692164391279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 104.64481373596936,
    "estimated_duration": 3600.0512497649975,
    "input_throughput": 7764.085859006752,
    "output_throughput": 6864.754773036421,
    "total_throughput": 14628.840632043173,
    "itl": 125.13350472930368,
    "ttft": 914900.8028452627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10856436355039474,
    "arrivals": 157020,
    "finished_requests": 112514,
    "scheduler_time": 137.88669561420232
}
#Debug simulation 
Total elapsed time: 104.64499216387048. Arrivals time: 0.48525890661403537 Scheduler time: 103.96319466317073 Scheduler overhead time: 0.07849123189225793 Adapter cache time: 0.013727891258895397 Engine time: 0.0754517917521298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 105.25436263438314,
    "estimated_duration": 3600.119067062137,
    "input_throughput": 7763.978768293768,
    "output_throughput": 6864.687122742168,
    "total_throughput": 14628.665891035935,
    "itl": 125.13319884016391,
    "ttft": 914877.570488381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 157020,
    "finished_requests": 112516,
    "scheduler_time": 137.8896002617109
}
#Debug simulation 
Total elapsed time: 105.25455377623439. Arrivals time: 0.48095352994278073 Scheduler time: 104.58324080286548 Scheduler overhead time: 0.07646662788465619 Adapter cache time: 0.013374855276197195 Engine time: 0.07364859012886882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105322266 . Total output tokens: 94392224
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 105.2453414448537,
    "estimated_duration": 3600.0527430928864,
    "input_throughput": 7764.08263840784,
    "output_throughput": 6864.751925486542,
    "total_throughput": 14628.834563894383,
    "itl": 125.13322446533887,
    "ttft": 914899.2392166834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10969614762812849,
    "arrivals": 157020,
    "finished_requests": 112514,
    "scheduler_time": 137.88672274281765
}
#Debug simulation 
Total elapsed time: 105.24565348122269. Arrivals time: 0.4727646694518626 Scheduler time: 104.58009344851598 Scheduler overhead time: 0.07710468908771873 Adapter cache time: 0.01376678142696619 Engine time: 0.07308319443836808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 12.903250067960471,
    "estimated_duration": 3600.0344081733765,
    "input_throughput": 7807.788707847903,
    "output_throughput": 6884.212535228202,
    "total_throughput": 14692.001243076105,
    "itl": 124.00979387421494,
    "ttft": 900233.991266197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7161541320802635,
    "arrivals": 137849,
    "finished_requests": 112742,
    "scheduler_time": 124.05995053548455
}
#Debug simulation 
Total elapsed time: 12.903345905710012. Arrivals time: 0.31113701686263084 Scheduler time: 12.46367239812389 Scheduler overhead time: 0.04801411321386695 Adapter cache time: 0.009816562756896019 Engine time: 0.048680595587939024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 12.957255295943469,
    "estimated_duration": 3600.107847574723,
    "input_throughput": 7807.646934503839,
    "output_throughput": 6884.090713197891,
    "total_throughput": 14691.73764770173,
    "itl": 124.01060218381234,
    "ttft": 900420.7494838092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7654556152760082,
    "arrivals": 137849,
    "finished_requests": 112743,
    "scheduler_time": 124.06448120039924
}
#Debug simulation 
Total elapsed time: 12.95740824798122. Arrivals time: 0.3291568490676582 Scheduler time: 12.499459328129888 Scheduler overhead time: 0.04795109620317817 Adapter cache time: 0.00978079717606306 Engine time: 0.04889801703393459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 12.898166046943516,
    "estimated_duration": 3600.1057376928898,
    "input_throughput": 7807.651510261782,
    "output_throughput": 6884.094747695484,
    "total_throughput": 14691.746257957268,
    "itl": 124.01048761138024,
    "ttft": 900418.6335970805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7664802572317457,
    "arrivals": 137849,
    "finished_requests": 112743,
    "scheduler_time": 124.06417593567683
}
#Debug simulation 
Total elapsed time: 12.898259033914655. Arrivals time: 0.30995880300179124 Scheduler time: 12.459175951313227 Scheduler overhead time: 0.048114493023604155 Adapter cache time: 0.009716538712382317 Engine time: 0.0491736950352788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 12.912682814057916,
    "estimated_duration": 3600.0541513412695,
    "input_throughput": 7807.745888913284,
    "output_throughput": 6884.174781306127,
    "total_throughput": 14691.920670219411,
    "itl": 124.00968663902337,
    "ttft": 900327.0783695427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.730316417890137,
    "arrivals": 137849,
    "finished_requests": 112742,
    "scheduler_time": 124.06172919714002
}
#Debug simulation 
Total elapsed time: 12.912820260040462. Arrivals time: 0.32838887022808194 Scheduler time: 12.455605097580701 Scheduler overhead time: 0.047939661890268326 Adapter cache time: 0.009869147557765245 Engine time: 0.04904145281761885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 12.90537453116849,
    "estimated_duration": 3600.004975745327,
    "input_throughput": 7807.761430713207,
    "output_throughput": 6884.163818376125,
    "total_throughput": 14691.925249089332,
    "itl": 124.01090036116702,
    "ttft": 900260.5172354734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7772950828634235,
    "arrivals": 137849,
    "finished_requests": 112741,
    "scheduler_time": 124.05953818369875
}
#Debug simulation 
Total elapsed time: 12.905467642936856. Arrivals time: 0.31085976492613554 Scheduler time: 12.465354227926582 Scheduler overhead time: 0.04798750299960375 Adapter cache time: 0.009735038969665766 Engine time: 0.049494851380586624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 12.93632092513144,
    "estimated_duration": 3600.0127943554653,
    "input_throughput": 7807.835584382256,
    "output_throughput": 6884.253866780255,
    "total_throughput": 14692.08945116251,
    "itl": 124.00925302398578,
    "ttft": 900206.5015014422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.69967176900711,
    "arrivals": 137849,
    "finished_requests": 112742,
    "scheduler_time": 124.05885486101928
}
#Debug simulation 
Total elapsed time: 12.936417237855494. Arrivals time: 0.3265554220415652 Scheduler time: 12.481447747442871 Scheduler overhead time: 0.04790614265948534 Adapter cache time: 0.009686168748885393 Engine time: 0.04877003422006965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92449691 . Total output tokens: 82868236
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 12.822924165055156,
    "estimated_duration": 3600.023231300944,
    "input_throughput": 7807.721837906749,
    "output_throughput": 6884.128909091549,
    "total_throughput": 14691.850746998298,
    "itl": 124.01133376697527,
    "ttft": 900269.218721632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7867266168445379,
    "arrivals": 137849,
    "finished_requests": 112741,
    "scheduler_time": 124.06077811278578
}
#Debug simulation 
Total elapsed time: 12.82306868582964. Arrivals time: 0.31038521556183696 Scheduler time: 12.384220600593835 Scheduler overhead time: 0.048031429294496775 Adapter cache time: 0.009695908986032009 Engine time: 0.04884443199262023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 11.771234987769276,
    "estimated_duration": 3600.0309800052055,
    "input_throughput": 7798.367335149823,
    "output_throughput": 6887.262675712904,
    "total_throughput": 14685.630010862727,
    "itl": 124.04290244248475,
    "ttft": 829577.9420643107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7283960830559945,
    "arrivals": 135943,
    "finished_requests": 113134,
    "scheduler_time": 121.1053625940706
}
#Debug simulation 
Total elapsed time: 11.771340626757592. Arrivals time: 0.315919307526201 Scheduler time: 11.327797915786505 Scheduler overhead time: 0.04770292202010751 Adapter cache time: 0.00971456291154027 Engine time: 0.04832744924351573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 11.8123698271811,
    "estimated_duration": 3600.048093195411,
    "input_throughput": 7796.420012569119,
    "output_throughput": 6885.629680018408,
    "total_throughput": 14682.049692587527,
    "itl": 124.05757807442735,
    "ttft": 830110.978546128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7714357158658125,
    "arrivals": 135943,
    "finished_requests": 113109,
    "scheduler_time": 121.10618076986499
}
#Debug simulation 
Total elapsed time: 11.812510862015188. Arrivals time: 0.30496995896101 Scheduler time: 11.379328051116318 Scheduler overhead time: 0.04788627801463008 Adapter cache time: 0.009785348549485207 Engine time: 0.04837966710329056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 11.808661835733801,
    "estimated_duration": 3600.048398578922,
    "input_throughput": 7796.419351217422,
    "output_throughput": 6885.629095926882,
    "total_throughput": 14682.048447144305,
    "itl": 124.05753560014001,
    "ttft": 830110.9097996091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7725672949291802,
    "arrivals": 135943,
    "finished_requests": 113109,
    "scheduler_time": 121.10614630952142
}
#Debug simulation 
Total elapsed time: 11.808785473927855. Arrivals time: 0.31987162167206407 Scheduler time: 11.359936277847737 Scheduler overhead time: 0.04806668357923627 Adapter cache time: 0.010014225263148546 Engine time: 0.048653874546289444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 11.784293020144105,
    "estimated_duration": 3600.0614259575564,
    "input_throughput": 7798.301383852829,
    "output_throughput": 6887.20442968695,
    "total_throughput": 14685.50581353978,
    "itl": 124.04345265464914,
    "ttft": 829666.6384346841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7435024050250669,
    "arrivals": 135943,
    "finished_requests": 113134,
    "scheduler_time": 121.10674238939868
}
#Debug simulation 
Total elapsed time: 11.784387195017189. Arrivals time: 0.30505365366116166 Scheduler time: 11.351092335768044 Scheduler overhead time: 0.047768221236765385 Adapter cache time: 0.00970953656360507 Engine time: 0.048720961436629295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 11.74123282218352,
    "estimated_duration": 3600.1235540149073,
    "input_throughput": 7796.8760179622905,
    "output_throughput": 6887.367788349335,
    "total_throughput": 14684.243806311626,
    "itl": 124.05138389213104,
    "ttft": 829868.6014038831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7872258881852064,
    "arrivals": 135943,
    "finished_requests": 113126,
    "scheduler_time": 121.11136912563181
}
#Debug simulation 
Total elapsed time: 11.741366881877184. Arrivals time: 0.3144808718934655 Scheduler time: 11.299069984816015 Scheduler overhead time: 0.04776342073455453 Adapter cache time: 0.009855806361883879 Engine time: 0.04832167597487569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 11.753092681989074,
    "estimated_duration": 3600.011791001544,
    "input_throughput": 7798.408902485719,
    "output_throughput": 6887.29938662286,
    "total_throughput": 14685.70828910858,
    "itl": 124.04241194698271,
    "ttft": 829570.5129033817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7116319701867188,
    "arrivals": 135943,
    "finished_requests": 113134,
    "scheduler_time": 121.10444434027669
}
#Debug simulation 
Total elapsed time: 11.753281470853835. Arrivals time: 0.29755470296368003 Scheduler time: 11.32761276094243 Scheduler overhead time: 0.047859395388513803 Adapter cache time: 0.009713808074593544 Engine time: 0.04854746628552675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91162926 . Total output tokens: 81773250
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 11.757291346322745,
    "estimated_duration": 3600.100412649533,
    "input_throughput": 7797.109742097804,
    "output_throughput": 6887.148178667681,
    "total_throughput": 14684.257920765485,
    "itl": 124.04998810168725,
    "ttft": 829897.2734650923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7967831759527357,
    "arrivals": 135943,
    "finished_requests": 113125,
    "scheduler_time": 121.11055656352285
}
#Debug simulation 
Total elapsed time: 11.757415113039315. Arrivals time: 0.3049952583387494 Scheduler time: 11.323720370419323 Scheduler overhead time: 0.04815060505643487 Adapter cache time: 0.009788803290575743 Engine time: 0.04880198976024985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 11.011283743195236,
    "estimated_duration": 3600.090990133293,
    "input_throughput": 7742.280146915956,
    "output_throughput": 6898.789799499051,
    "total_throughput": 14641.069946415008,
    "itl": 124.82001696157207,
    "ttft": 818568.5642544476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.771242911471053,
    "arrivals": 135044,
    "finished_requests": 112819,
    "scheduler_time": 120.92436015262103
}
#Debug simulation 
Total elapsed time: 11.011403309181333. Arrivals time: 0.30604191636666656 Scheduler time: 10.577943342272192 Scheduler overhead time: 0.04738044319674373 Adapter cache time: 0.009794872719794512 Engine time: 0.04838248295709491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 10.95757413096726,
    "estimated_duration": 3600.032132786527,
    "input_throughput": 7742.00700770598,
    "output_throughput": 6898.653701953686,
    "total_throughput": 14640.660709659667,
    "itl": 124.82127922666427,
    "ttft": 818557.012925385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8237710690870919,
    "arrivals": 135044,
    "finished_requests": 112815,
    "scheduler_time": 120.92226825300828
}
#Debug simulation 
Total elapsed time: 10.957671395968646. Arrivals time: 0.2929291012696922 Scheduler time: 10.538006956223398 Scheduler overhead time: 0.04724868107587099 Adapter cache time: 0.00978586869314313 Engine time: 0.04802946746349335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 11.10340301785618,
    "estimated_duration": 3600.036346912034,
    "input_throughput": 7741.997945078257,
    "output_throughput": 6898.645626537294,
    "total_throughput": 14640.64357161555,
    "itl": 124.82141423866618,
    "ttft": 818558.96534798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8249733189493458,
    "arrivals": 135044,
    "finished_requests": 112815,
    "scheduler_time": 120.92257949099016
}
#Debug simulation 
Total elapsed time: 11.103507551830262. Arrivals time: 0.31317385751754045 Scheduler time: 10.663413833361119 Scheduler overhead time: 0.047390407882630825 Adapter cache time: 0.009770960081368685 Engine time: 0.04789659706875682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 11.021653871051967,
    "estimated_duration": 3600.1185667994987,
    "input_throughput": 7742.220841570501,
    "output_throughput": 6898.736955232954,
    "total_throughput": 14640.957796803455,
    "itl": 124.81997505398124,
    "ttft": 818574.8305138695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7857717044721378,
    "arrivals": 135044,
    "finished_requests": 112819,
    "scheduler_time": 120.9256129822319
}
#Debug simulation 
Total elapsed time: 11.021772223059088. Arrivals time: 0.29690812109038234 Scheduler time: 10.598304227460176 Scheduler overhead time: 0.04711381625384092 Adapter cache time: 0.00977243296802044 Engine time: 0.047872784081846476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 11.029064760077745,
    "estimated_duration": 3600.0490032738458,
    "input_throughput": 7742.071559207569,
    "output_throughput": 6898.729983234845,
    "total_throughput": 14640.801542442416,
    "itl": 124.82166354368933,
    "ttft": 818540.566875183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8366684210859276,
    "arrivals": 135044,
    "finished_requests": 112816,
    "scheduler_time": 120.92311283013579
}
#Debug simulation 
Total elapsed time: 11.02916124695912. Arrivals time: 0.3100225077942014 Scheduler time: 10.59244817495346 Scheduler overhead time: 0.0474569839425385 Adapter cache time: 0.009819613303989172 Engine time: 0.04778703721240163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 10.865929532330483,
    "estimated_duration": 3600.0037622681457,
    "input_throughput": 7742.1688533013175,
    "output_throughput": 6898.816679111602,
    "total_throughput": 14640.98553241292,
    "itl": 124.81796610555969,
    "ttft": 818474.5958650137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7534926743153493,
    "arrivals": 135044,
    "finished_requests": 112816,
    "scheduler_time": 120.92119365031333
}
#Debug simulation 
Total elapsed time: 10.866020767018199. Arrivals time: 0.3021072088740766 Scheduler time: 10.438140734564513 Scheduler overhead time: 0.04712398676201701 Adapter cache time: 0.00965422298759222 Engine time: 0.047318334225565195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90534155 . Total output tokens: 81185589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 10.919623270630836,
    "estimated_duration": 3600.0656486450403,
    "input_throughput": 7742.035762733979,
    "output_throughput": 6898.698086060585,
    "total_throughput": 14640.733848794564,
    "itl": 124.82205869044256,
    "ttft": 818586.1220032217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8466029702127016,
    "arrivals": 135044,
    "finished_requests": 112816,
    "scheduler_time": 120.92388706794318
}
#Debug simulation 
Total elapsed time: 10.919738167896867. Arrivals time: 0.30930165527388453 Scheduler time: 10.484574268106371 Scheduler overhead time: 0.046908149030059576 Adapter cache time: 0.009704263880848885 Engine time: 0.04755769297480583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 10.30935813812539,
    "estimated_duration": 3600.0030754400827,
    "input_throughput": 7739.631165896691,
    "output_throughput": 6900.381882858048,
    "total_throughput": 14640.013048754738,
    "itl": 124.81932108941983,
    "ttft": 802608.7830730353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7620614482392547,
    "arrivals": 134574,
    "finished_requests": 112967,
    "scheduler_time": 120.53059403333336
}
#Debug simulation 
Total elapsed time: 10.309480176772922. Arrivals time: 0.28857126692309976 Scheduler time: 9.895342741627246 Scheduler overhead time: 0.046944194938987494 Adapter cache time: 0.009673419408500195 Engine time: 0.04733504494652152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 10.223662179894745,
    "estimated_duration": 3600.0702445922516,
    "input_throughput": 7739.486761918937,
    "output_throughput": 6900.253137369981,
    "total_throughput": 14639.739899288918,
    "itl": 124.82067724933323,
    "ttft": 802693.9140677261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8135751322470641,
    "arrivals": 134574,
    "finished_requests": 112967,
    "scheduler_time": 120.53370559839219
}
#Debug simulation 
Total elapsed time: 10.223805802874267. Arrivals time: 0.2885465766303241 Scheduler time: 9.811323496047407 Scheduler overhead time: 0.04603469278663397 Adapter cache time: 0.009649084880948067 Engine time: 0.04689117940142751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 10.23509824136272,
    "estimated_duration": 3600.0704611040396,
    "input_throughput": 7739.48629645857,
    "output_throughput": 6900.2527223819525,
    "total_throughput": 14639.739018840522,
    "itl": 124.82062584212787,
    "ttft": 802693.9518595287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8148310199193696,
    "arrivals": 134574,
    "finished_requests": 112967,
    "scheduler_time": 120.5336833511266
}
#Debug simulation 
Total elapsed time: 10.235219261143357. Arrivals time: 0.27842164877802134 Scheduler time: 9.832628102507442 Scheduler overhead time: 0.046294504310935736 Adapter cache time: 0.009627028834074736 Engine time: 0.046812459360808134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 10.241964400280267,
    "estimated_duration": 3600.01833804462,
    "input_throughput": 7739.5983530277945,
    "output_throughput": 6900.35262806267,
    "total_throughput": 14639.950981090464,
    "itl": 124.81952272422231,
    "ttft": 802613.1379024889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7743499816767893,
    "arrivals": 134574,
    "finished_requests": 112967,
    "scheduler_time": 120.53117459349765
}
#Debug simulation 
Total elapsed time: 10.242057960946113. Arrivals time: 0.2900657714344561 Scheduler time: 9.828106315340847 Scheduler overhead time: 0.046215448528528214 Adapter cache time: 0.009641292504966259 Engine time: 0.04663760820403695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 10.169831350911409,
    "estimated_duration": 3600.0871206583906,
    "input_throughput": 7739.450481660682,
    "output_throughput": 6900.2207911726755,
    "total_throughput": 14639.671272833359,
    "itl": 124.82108827436535,
    "ttft": 802698.6054608596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8269033834151961,
    "arrivals": 134574,
    "finished_requests": 112967,
    "scheduler_time": 120.53438624938154
}
#Debug simulation 
Total elapsed time: 10.16996504087001. Arrivals time: 0.280323073733598 Scheduler time: 9.76541764428839 Scheduler overhead time: 0.046231475193053484 Adapter cache time: 0.009567576460540295 Engine time: 0.047025046311318874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 10.232360689900815,
    "estimated_duration": 3600.1167332913556,
    "input_throughput": 7739.689866813271,
    "output_throughput": 6900.29291836009,
    "total_throughput": 14639.98278517336,
    "itl": 124.81901467246583,
    "ttft": 802569.6146376854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7445225234306427,
    "arrivals": 134574,
    "finished_requests": 112971,
    "scheduler_time": 120.53476843071637
}
#Debug simulation 
Total elapsed time: 10.232454860117286. Arrivals time: 0.289401485119015 Scheduler time: 9.819332795683295 Scheduler overhead time: 0.04623686010017991 Adapter cache time: 0.009503809735178947 Engine time: 0.04660065704956651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90200478 . Total output tokens: 80895868
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 10.275014674756676,
    "estimated_duration": 3600.1345511570184,
    "input_throughput": 7740.7829079731955,
    "output_throughput": 6899.164641504173,
    "total_throughput": 14639.947549477369,
    "itl": 124.80092660880186,
    "ttft": 802669.2079412412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8697596072778147,
    "arrivals": 134574,
    "finished_requests": 112970,
    "scheduler_time": 120.53472008319477
}
#Debug simulation 
Total elapsed time: 10.27511876495555. Arrivals time: 0.2850170317105949 Scheduler time: 9.866276560816914 Scheduler overhead time: 0.04607973946258426 Adapter cache time: 0.009693599306046963 Engine time: 0.04668426373973489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 9.788236725144088,
    "estimated_duration": 3600.093647342799,
    "input_throughput": 7758.1387419227085,
    "output_throughput": 6899.412746758164,
    "total_throughput": 14657.551488680872,
    "itl": 124.73733844112692,
    "ttft": 794263.8456920738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7681824237271202,
    "arrivals": 134344,
    "finished_requests": 112994,
    "scheduler_time": 120.25075036557617
}
#Debug simulation 
Total elapsed time: 9.788369757123291. Arrivals time: 0.3015292165800929 Scheduler time: 9.362448237836361 Scheduler overhead time: 0.0464477245695889 Adapter cache time: 0.009623694233596325 Engine time: 0.046815584879368544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.743710439186543,
    "estimated_duration": 3600.03197306742,
    "input_throughput": 7758.012209042387,
    "output_throughput": 6899.3748349509015,
    "total_throughput": 14657.387043993289,
    "itl": 124.73874422257332,
    "ttft": 794249.3407787322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.819963828155309,
    "arrivals": 134344,
    "finished_requests": 112991,
    "scheduler_time": 120.24855408779797
}
#Debug simulation 
Total elapsed time: 9.743831248022616. Arrivals time: 0.2849830277264118 Scheduler time: 9.33470532251522 Scheduler overhead time: 0.046153119299560785 Adapter cache time: 0.009490835946053267 Engine time: 0.04713336518034339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.809367436915636,
    "estimated_duration": 3600.0333387132077,
    "input_throughput": 7758.009266098337,
    "output_throughput": 6899.372217724534,
    "total_throughput": 14657.38148382287,
    "itl": 124.73875313219169,
    "ttft": 794250.0531815656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8212553051114122,
    "arrivals": 134344,
    "finished_requests": 112991,
    "scheduler_time": 120.24863315654751
}
#Debug simulation 
Total elapsed time: 9.809459839947522. Arrivals time: 0.2929918454028666 Scheduler time: 9.391665612347424 Scheduler overhead time: 0.04637275217100978 Adapter cache time: 0.009638195857405663 Engine time: 0.04730814276263118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 9.753434955142438,
    "estimated_duration": 3600.109623158278,
    "input_throughput": 7758.104314472999,
    "output_throughput": 6899.382129983541,
    "total_throughput": 14657.48644445654,
    "itl": 124.73747942706231,
    "ttft": 794309.8600540919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7799214869481532,
    "arrivals": 134344,
    "finished_requests": 112994,
    "scheduler_time": 120.2513705468293
}
#Debug simulation 
Total elapsed time: 9.75352676725015. Arrivals time: 0.28386734845116735 Scheduler time: 9.34506549546495 Scheduler overhead time: 0.046177313663065434 Adapter cache time: 0.009626731276512146 Engine time: 0.04728394607082009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 9.701011699158698,
    "estimated_duration": 3600.0495111060286,
    "input_throughput": 7757.974415029492,
    "output_throughput": 6899.34122388476,
    "total_throughput": 14657.315638914251,
    "itl": 124.73912733909272,
    "ttft": 794275.7245578927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8335791761800686,
    "arrivals": 134344,
    "finished_requests": 112991,
    "scheduler_time": 120.24934087033445
}
#Debug simulation 
Total elapsed time: 9.701099478174001. Arrivals time: 0.2891765274107456 Scheduler time: 9.28822611644864 Scheduler overhead time: 0.045985713601112366 Adapter cache time: 0.009586058091372252 Engine time: 0.04674306930974126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 9.73318717489019,
    "estimated_duration": 3600.044070514058,
    "input_throughput": 7758.107248951505,
    "output_throughput": 6899.4269274190565,
    "total_throughput": 14657.534176370562,
    "itl": 124.73621887356215,
    "ttft": 794178.6410494773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7505026240204471,
    "arrivals": 134344,
    "finished_requests": 112993,
    "scheduler_time": 120.24881616590005
}
#Debug simulation 
Total elapsed time: 9.73327807476744. Arrivals time: 0.28674921998754144 Scheduler time: 9.32177113275975 Scheduler overhead time: 0.04635446332395077 Adapter cache time: 0.009694516193121672 Engine time: 0.047090794425457716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90053908 . Total output tokens: 80753743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.74301808187738,
    "estimated_duration": 3600.061251192257,
    "input_throughput": 7757.949115657555,
    "output_throughput": 6899.318724583989,
    "total_throughput": 14657.267840241544,
    "itl": 124.73916215056555,
    "ttft": 794341.3743388234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8426334488019385,
    "arrivals": 134344,
    "finished_requests": 112991,
    "scheduler_time": 120.2497549223449
}
#Debug simulation 
Total elapsed time: 9.743113350123167. Arrivals time: 0.28689679224044085 Scheduler time: 9.3320790999569 Scheduler overhead time: 0.04609036399051547 Adapter cache time: 0.009597240015864372 Engine time: 0.0470177554525435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 9.36452226806432,
    "estimated_duration": 3600.039528115789,
    "input_throughput": 7789.411972006012,
    "output_throughput": 6900.380344712985,
    "total_throughput": 14689.792316718997,
    "itl": 124.27162163776865,
    "ttft": 712882.5071356294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.221134609829175,
    "arrivals": 132130,
    "finished_requests": 113342,
    "scheduler_time": 117.20994901878687
}
#Debug simulation 
Total elapsed time: 9.364612895064056. Arrivals time: 0.27608108380809426 Scheduler time: 8.962429827079177 Scheduler overhead time: 0.046583210583776236 Adapter cache time: 0.010800845921039581 Engine time: 0.04721778351813555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.373563883360475,
    "estimated_duration": 3600.0167304547545,
    "input_throughput": 7789.163523264472,
    "output_throughput": 6900.29182082775,
    "total_throughput": 14689.455344092221,
    "itl": 124.27347440616839,
    "ttft": 712994.4881236245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.306619566192391,
    "arrivals": 132130,
    "finished_requests": 113338,
    "scheduler_time": 117.209913822588
}
#Debug simulation 
Total elapsed time: 9.373668877407908. Arrivals time: 0.2801043838262558 Scheduler time: 8.96731419954449 Scheduler overhead time: 0.046701138373464346 Adapter cache time: 0.01085935765877366 Engine time: 0.04715632926672697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.357322616968304,
    "estimated_duration": 3600.0183038454848,
    "input_throughput": 7789.160119004646,
    "output_throughput": 6900.288805049976,
    "total_throughput": 14689.44892405462,
    "itl": 124.27352158059789,
    "ttft": 712995.1982270947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.308118824139245,
    "arrivals": 132130,
    "finished_requests": 113338,
    "scheduler_time": 117.20998795536151
}
#Debug simulation 
Total elapsed time: 9.357426853850484. Arrivals time: 0.2796357348561287 Scheduler time: 8.952057492919266 Scheduler overhead time: 0.046543706208467484 Adapter cache time: 0.01077167084440589 Engine time: 0.046989344991743565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 9.336018112953752,
    "estimated_duration": 3600.076013851767,
    "input_throughput": 7789.477747720317,
    "output_throughput": 6900.329855374786,
    "total_throughput": 14689.807603095103,
    "itl": 124.27217987085841,
    "ttft": 712891.6921929447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2453302684263317,
    "arrivals": 132130,
    "finished_requests": 113343,
    "scheduler_time": 117.21159749137166
}
#Debug simulation 
Total elapsed time: 9.33615682227537. Arrivals time: 0.2650546026416123 Scheduler time: 8.945834387559444 Scheduler overhead time: 0.04619843792170286 Adapter cache time: 0.010712528601288795 Engine time: 0.046972193755209446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 9.351359293796122,
    "estimated_duration": 3600.0423809175722,
    "input_throughput": 7789.10802512634,
    "output_throughput": 6900.242655940214,
    "total_throughput": 14689.350681066555,
    "itl": 124.27405664669328,
    "ttft": 713027.3252573564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.326981892101471,
    "arrivals": 132130,
    "finished_requests": 113338,
    "scheduler_time": 117.21120129521768
}
#Debug simulation 
Total elapsed time: 9.351447517052293. Arrivals time: 0.27727603260427713 Scheduler time: 8.949106156360358 Scheduler overhead time: 0.046000643633306026 Adapter cache time: 0.01058643078431487 Engine time: 0.04720297455787659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 9.286972947884351,
    "estimated_duration": 3600.0052511309686,
    "input_throughput": 7789.486137885587,
    "output_throughput": 6900.446045792798,
    "total_throughput": 14689.932183678384,
    "itl": 124.27086497761113,
    "ttft": 712848.3796043369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1930300676659626,
    "arrivals": 132130,
    "finished_requests": 113342,
    "scheduler_time": 117.20841217817292
}
#Debug simulation 
Total elapsed time: 9.287056814879179. Arrivals time: 0.26752990717068315 Scheduler time: 8.894366021733731 Scheduler overhead time: 0.04632006539031863 Adapter cache time: 0.010654866229742765 Engine time: 0.04688937356695533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88631775 . Total output tokens: 79453170
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 9.331061098724604,
    "estimated_duration": 3600.0787510246205,
    "input_throughput": 7789.101277859304,
    "output_throughput": 6900.277943344943,
    "total_throughput": 14689.379221204248,
    "itl": 124.27474812500651,
    "ttft": 713005.9579919195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3430783767625707,
    "arrivals": 132130,
    "finished_requests": 113340,
    "scheduler_time": 117.2126329266602
}
#Debug simulation 
Total elapsed time: 9.331148148979992. Arrivals time: 0.2761440072208643 Scheduler time: 8.929503208491951 Scheduler overhead time: 0.046305857598781586 Adapter cache time: 0.010614815168082714 Engine time: 0.047278127167373896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.787041460629553,
    "estimated_duration": 3600.0423381447335,
    "input_throughput": 7834.292030725032,
    "output_throughput": 6895.110853832977,
    "total_throughput": 14729.40288455801,
    "itl": 123.68147499606069,
    "ttft": 672701.975605806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3925219234894153,
    "arrivals": 131205,
    "finished_requests": 113457,
    "scheduler_time": 115.29899992228772
}
#Debug simulation 
Total elapsed time: 8.787144215777516. Arrivals time: 0.2627457990311086 Scheduler time: 8.398683849722147 Scheduler overhead time: 0.04626206727698445 Adapter cache time: 0.011007637716829777 Engine time: 0.04692786047235131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.784506608266383,
    "estimated_duration": 3600.0833619991813,
    "input_throughput": 7832.776678910252,
    "output_throughput": 6895.314220228227,
    "total_throughput": 14728.090899138479,
    "itl": 123.70160554254191,
    "ttft": 672879.0679178482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4955691053974507,
    "arrivals": 131205,
    "finished_requests": 113452,
    "scheduler_time": 115.30045841256411
}
#Debug simulation 
Total elapsed time: 8.784596326295286. Arrivals time: 0.2745935502462089 Scheduler time: 8.384643238037825 Scheduler overhead time: 0.04620770178735256 Adapter cache time: 0.010969837196171284 Engine time: 0.046842096373438835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.806103125214577,
    "estimated_duration": 3600.0907252087063,
    "input_throughput": 7832.760658654027,
    "output_throughput": 6895.300117349378,
    "total_throughput": 14728.060776003405,
    "itl": 123.701866492188,
    "ttft": 672878.8568580541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.497458322159955,
    "arrivals": 131205,
    "finished_requests": 113452,
    "scheduler_time": 115.30072665761735
}
#Debug simulation 
Total elapsed time: 8.806191217154264. Arrivals time: 0.26280525512993336 Scheduler time: 8.41710586566478 Scheduler overhead time: 0.04660162376239896 Adapter cache time: 0.011120215989649296 Engine time: 0.04715640936046839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.817398540209979,
    "estimated_duration": 3600.0920265478144,
    "input_throughput": 7834.1839019723775,
    "output_throughput": 6895.015687641428,
    "total_throughput": 14729.199589613805,
    "itl": 123.68269018427826,
    "ttft": 672733.6864084555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4172676334436938,
    "arrivals": 131205,
    "finished_requests": 113457,
    "scheduler_time": 115.30109383376004
}
#Debug simulation 
Total elapsed time: 8.817485466133803. Arrivals time: 0.2638576882891357 Scheduler time: 8.427751216106117 Scheduler overhead time: 0.04617992974817753 Adapter cache time: 0.011034537106752396 Engine time: 0.04719221265986562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.816535172052681,
    "estimated_duration": 3600.1138463716834,
    "input_throughput": 7832.710353984931,
    "output_throughput": 6895.25583337265,
    "total_throughput": 14727.966187357582,
    "itl": 123.70254888246508,
    "ttft": 672911.9291285585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5195909885689651,
    "arrivals": 131205,
    "finished_requests": 113452,
    "scheduler_time": 115.30180151372959
}
#Debug simulation 
Total elapsed time: 8.816637285985053. Arrivals time: 0.27480713929980993 Scheduler time: 8.415985280647874 Scheduler overhead time: 0.04632345121353865 Adapter cache time: 0.011039379984140396 Engine time: 0.046931101474910975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.78141434211284,
    "estimated_duration": 3600.033231402877,
    "input_throughput": 7832.967972079333,
    "output_throughput": 6895.534958805481,
    "total_throughput": 14728.502930884813,
    "itl": 123.6974141191171,
    "ttft": 672732.5321134491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3664529847702827,
    "arrivals": 131205,
    "finished_requests": 113454,
    "scheduler_time": 115.2976390018885
}
#Debug simulation 
Total elapsed time: 8.7815220230259. Arrivals time: 0.26330031361430883 Scheduler time: 8.392580359242857 Scheduler overhead time: 0.04603946255519986 Adapter cache time: 0.010987784713506699 Engine time: 0.04707984207198024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88025496 . Total output tokens: 78878611
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.871829020325094,
    "estimated_duration": 3600.122679798512,
    "input_throughput": 7833.980258022333,
    "output_throughput": 6894.786708043299,
    "total_throughput": 14728.766966065632,
    "itl": 123.68750989734434,
    "ttft": 672871.952516864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5297204771265385,
    "arrivals": 131205,
    "finished_requests": 113454,
    "scheduler_time": 115.3028301187119
}
#Debug simulation 
Total elapsed time: 8.87191591411829. Arrivals time: 0.2754630856215954 Scheduler time: 8.469499627128243 Scheduler overhead time: 0.04631366953253746 Adapter cache time: 0.011097163893282413 Engine time: 0.04809080110862851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.544284314848483,
    "estimated_duration": 3600.075880364596,
    "input_throughput": 7812.08089345932,
    "output_throughput": 6902.388956724828,
    "total_throughput": 14714.469850184149,
    "itl": 123.95065574916556,
    "ttft": 662468.2825772294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4017033867212139,
    "arrivals": 130771,
    "finished_requests": 113385,
    "scheduler_time": 115.04761798577243
}
#Debug simulation 
Total elapsed time: 8.544373392127454. Arrivals time: 0.2658639498986304 Scheduler time: 8.153082764241844 Scheduler overhead time: 0.046357723884284496 Adapter cache time: 0.010963829699903727 Engine time: 0.04684867523610592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.597298081964254,
    "estimated_duration": 3600.0669142737543,
    "input_throughput": 7811.9281306951425,
    "output_throughput": 6902.317537898536,
    "total_throughput": 14714.24566859368,
    "itl": 123.95359472226464,
    "ttft": 662558.981085848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965161791001507,
    "arrivals": 130771,
    "finished_requests": 113383,
    "scheduler_time": 115.04805556378163
}
#Debug simulation 
Total elapsed time: 8.597385545726866. Arrivals time: 0.2813559863716364 Scheduler time: 8.18884802237153 Scheduler overhead time: 0.04764733184129 Adapter cache time: 0.010958580300211906 Engine time: 0.0469476692378521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.603575837798417,
    "estimated_duration": 3600.0706872405494,
    "input_throughput": 7811.919943593276,
    "output_throughput": 6902.310304091997,
    "total_throughput": 14714.230247685273,
    "itl": 123.95369614735813,
    "ttft": 662559.9858769573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4988156035356313,
    "arrivals": 130771,
    "finished_requests": 113383,
    "scheduler_time": 115.04821641821822
}
#Debug simulation 
Total elapsed time: 8.60370164271444. Arrivals time: 0.2654694621451199 Scheduler time: 8.212385482154787 Scheduler overhead time: 0.046204828191548586 Adapter cache time: 0.011037552263587713 Engine time: 0.047193783801048994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.617184788919985,
    "estimated_duration": 3600.1070198533184,
    "input_throughput": 7812.013322077819,
    "output_throughput": 6902.329253815473,
    "total_throughput": 14714.342575893292,
    "itl": 123.95130509596616,
    "ttft": 662613.5869684961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4233776170993175,
    "arrivals": 130771,
    "finished_requests": 113385,
    "scheduler_time": 115.04905768383665
}
#Debug simulation 
Total elapsed time: 8.617296377196908. Arrivals time: 0.2748601036146283 Scheduler time: 8.217277843039483 Scheduler overhead time: 0.045865615364164114 Adapter cache time: 0.01098073460161686 Engine time: 0.04701416986063123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.597173943184316,
    "estimated_duration": 3600.0954819689723,
    "input_throughput": 7811.866141010974,
    "output_throughput": 6902.262766211311,
    "total_throughput": 14714.128907222284,
    "itl": 123.9541710049893,
    "ttft": 662637.2353210342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5213255313038867,
    "arrivals": 130771,
    "finished_requests": 113383,
    "scheduler_time": 115.04930361277884
}
#Debug simulation 
Total elapsed time: 8.597257477231324. Arrivals time: 0.2638377044349909 Scheduler time: 8.208001201041043 Scheduler overhead time: 0.04598104441538453 Adapter cache time: 0.011012658942490816 Engine time: 0.047067155595868826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.576408345252275,
    "estimated_duration": 3600.0399288336166,
    "input_throughput": 7812.158908224102,
    "output_throughput": 6902.457886918746,
    "total_throughput": 14714.616795142849,
    "itl": 123.94982134839611,
    "ttft": 662411.1521742415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3694430350651847,
    "arrivals": 130771,
    "finished_requests": 113385,
    "scheduler_time": 115.04619216133818
}
#Debug simulation 
Total elapsed time: 8.576501027215272. Arrivals time: 0.2746298792771995 Scheduler time: 8.176461823750287 Scheduler overhead time: 0.04607240715995431 Adapter cache time: 0.010999778285622597 Engine time: 0.047032253351062536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87687812 . Total output tokens: 78601416
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.605421769898385,
    "estimated_duration": 3600.005087168039,
    "input_throughput": 7812.062016313275,
    "output_throughput": 6902.356357375929,
    "total_throughput": 14714.418373689205,
    "itl": 123.95515830075765,
    "ttft": 662509.0255004857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5379250311106438,
    "arrivals": 130771,
    "finished_requests": 113382,
    "scheduler_time": 115.04602251739348
}
#Debug simulation 
Total elapsed time: 8.605507366824895. Arrivals time: 0.26144605316221714 Scheduler time: 8.218470060732216 Scheduler overhead time: 0.046249907463788986 Adapter cache time: 0.01095332344993949 Engine time: 0.047004698775708675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.42562404088676,
    "estimated_duration": 3600.0202494211826,
    "input_throughput": 7777.099588398571,
    "output_throughput": 6906.409208114191,
    "total_throughput": 14683.508796512762,
    "itl": 124.30960812200483,
    "ttft": 656234.2625133606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.334372656354691,
    "arrivals": 130530,
    "finished_requests": 113373,
    "scheduler_time": 114.91457436039465
}
#Debug simulation 
Total elapsed time: 8.425721711013466. Arrivals time: 0.27182610612362623 Scheduler time: 8.029551242478192 Scheduler overhead time: 0.04576663626357913 Adapter cache time: 0.010726423468440771 Engine time: 0.04659025324508548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.47436914080754,
    "estimated_duration": 3600.0070478774696,
    "input_throughput": 7776.752552889137,
    "output_throughput": 6906.002590927759,
    "total_throughput": 14682.755143816898,
    "itl": 124.31280325295498,
    "ttft": 656417.7480186512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4246061428356973,
    "arrivals": 130530,
    "finished_requests": 113366,
    "scheduler_time": 114.91461218224889
}
#Debug simulation 
Total elapsed time: 8.474475387949497. Arrivals time: 0.263352632522583 Scheduler time: 8.08678255463019 Scheduler overhead time: 0.0457981675863266 Adapter cache time: 0.010746816173195839 Engine time: 0.04647451359778643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.430220074951649,
    "estimated_duration": 3600.0093269602203,
    "input_throughput": 7776.747629606726,
    "output_throughput": 6905.998218897036,
    "total_throughput": 14682.745848503762,
    "itl": 124.31285901502272,
    "ttft": 656418.801932468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4267994764447296,
    "arrivals": 130530,
    "finished_requests": 113366,
    "scheduler_time": 114.9147126311241
}
#Debug simulation 
Total elapsed time: 8.430311379022896. Arrivals time: 0.2722329688258469 Scheduler time: 8.033444283995777 Scheduler overhead time: 0.04586420813575387 Adapter cache time: 0.01078468980267644 Engine time: 0.046771456487476826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.408615864813328,
    "estimated_duration": 3600.036191786858,
    "input_throughput": 7777.065148365491,
    "output_throughput": 6906.3786238380235,
    "total_throughput": 14683.443772203515,
    "itl": 124.3098908093696,
    "ttft": 656263.3711132888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.349016008924223,
    "arrivals": 130530,
    "finished_requests": 113373,
    "scheduler_time": 114.91528375845932
}
#Debug simulation 
Total elapsed time: 8.408701177686453. Arrivals time: 0.2648251736536622 Scheduler time: 8.019535419531167 Scheduler overhead time: 0.04579037148505449 Adapter cache time: 0.010715915355831385 Engine time: 0.046502791810780764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.414185729809105,
    "estimated_duration": 3600.033897749502,
    "input_throughput": 7776.694552098922,
    "output_throughput": 6905.9510843889075,
    "total_throughput": 14682.645636487829,
    "itl": 124.31339868519007,
    "ttft": 656474.4778432864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4500639269314743,
    "arrivals": 130530,
    "finished_requests": 113366,
    "scheduler_time": 114.91582998421178
}
#Debug simulation 
Total elapsed time: 8.414272997993976. Arrivals time: 0.27262856252491474 Scheduler time: 8.017061051912606 Scheduler overhead time: 0.045741145964711905 Adapter cache time: 0.010825755540281534 Engine time: 0.046651259530335665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.4662015279755,
    "estimated_duration": 3600.121000252833,
    "input_throughput": 7777.259985993152,
    "output_throughput": 6906.361757911427,
    "total_throughput": 14683.62174390458,
    "itl": 124.3074571891952,
    "ttft": 656142.3529382936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3036619285773392,
    "arrivals": 130530,
    "finished_requests": 113379,
    "scheduler_time": 114.91803493118567
}
#Debug simulation 
Total elapsed time: 8.46628892607987. Arrivals time: 0.2648960924707353 Scheduler time: 8.076947514899075 Scheduler overhead time: 0.04579303180798888 Adapter cache time: 0.010772035922855139 Engine time: 0.04647541092708707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87540453 . Total output tokens: 78455184
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.441055785864592,
    "estimated_duration": 3600.046775264977,
    "input_throughput": 7776.666734542459,
    "output_throughput": 6905.926381517665,
    "total_throughput": 14682.593116060125,
    "itl": 124.31373413361425,
    "ttft": 656478.4592494931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4640225972235208,
    "arrivals": 130530,
    "finished_requests": 113366,
    "scheduler_time": 114.91620817142163
}
#Debug simulation 
Total elapsed time: 8.441142443101853. Arrivals time: 0.2733345991000533 Scheduler time: 8.043502690736204 Scheduler overhead time: 0.045849526301026344 Adapter cache time: 0.010808420833200216 Engine time: 0.04636031482368708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.292672656010836,
    "estimated_duration": 3600.101353467741,
    "input_throughput": 7846.438815615728,
    "output_throughput": 6898.700497994895,
    "total_throughput": 14745.139313610624,
    "itl": 123.56565019173158,
    "ttft": 619167.7768446117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.053587276178913,
    "arrivals": 129375,
    "finished_requests": 113324,
    "scheduler_time": 113.47395405269666
}
#Debug simulation 
Total elapsed time: 8.292759420815855. Arrivals time: 0.25854566041380167 Scheduler time: 7.907473359256983 Scheduler overhead time: 0.04611994931474328 Adapter cache time: 0.012297784443944693 Engine time: 0.04683530330657959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.291410529986024,
    "estimated_duration": 3600.0505548837336,
    "input_throughput": 7845.2926061512335,
    "output_throughput": 6897.926465591536,
    "total_throughput": 14743.21907174277,
    "itl": 123.57222811820333,
    "ttft": 619528.97250954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1839517744560797,
    "arrivals": 129375,
    "finished_requests": 113310,
    "scheduler_time": 113.47383235006214
}
#Debug simulation 
Total elapsed time: 8.291533356998116. Arrivals time: 0.26945215789601207 Scheduler time: 7.895068740006536 Scheduler overhead time: 0.04615387646481395 Adapter cache time: 0.012399517931044102 Engine time: 0.047029141802340746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.290010808035731,
    "estimated_duration": 3600.05324682752,
    "input_throughput": 7845.286739825033,
    "output_throughput": 6897.921307659412,
    "total_throughput": 14743.208047484446,
    "itl": 123.57228350277187,
    "ttft": 619530.2533809592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1865099095925737,
    "arrivals": 129375,
    "finished_requests": 113310,
    "scheduler_time": 113.47396534202227
}
#Debug simulation 
Total elapsed time: 8.290095732081681. Arrivals time: 0.25685383938252926 Scheduler time: 7.906460215803236 Scheduler overhead time: 0.04617301654070616 Adapter cache time: 0.01228872174397111 Engine time: 0.04695250978693366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.387880536261946,
    "estimated_duration": 3600.0600284284546,
    "input_throughput": 7845.568345239417,
    "output_throughput": 6898.276085368763,
    "total_throughput": 14743.84443060818,
    "itl": 123.56934125901749,
    "ttft": 619398.1594314808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0768998010246844,
    "arrivals": 129375,
    "finished_requests": 113314,
    "scheduler_time": 113.47270191187557
}
#Debug simulation 
Total elapsed time: 8.387969469185919. Arrivals time: 0.2698896061629057 Scheduler time: 7.990607425104827 Scheduler overhead time: 0.04641875671222806 Adapter cache time: 0.012437131255865097 Engine time: 0.046974748838692904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.291658298112452,
    "estimated_duration": 3600.089816064266,
    "input_throughput": 7845.207048438766,
    "output_throughput": 6897.851239486049,
    "total_throughput": 14743.058287924816,
    "itl": 123.57335305969838,
    "ttft": 619593.0604083893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.219457401633265,
    "arrivals": 129375,
    "finished_requests": 113310,
    "scheduler_time": 113.47575494977606
}
#Debug simulation 
Total elapsed time: 8.29174286685884. Arrivals time: 0.25690011167898774 Scheduler time: 7.908053714782 Scheduler overhead time: 0.04615615168586373 Adapter cache time: 0.012326131574809551 Engine time: 0.046948157250881195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.28519400395453,
    "estimated_duration": 3600.0520837609834,
    "input_throughput": 7845.610936409783,
    "output_throughput": 6898.357418778061,
    "total_throughput": 14743.968355187844,
    "itl": 123.56601814440923,
    "ttft": 619293.7126820375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9943635466997172,
    "arrivals": 129375,
    "finished_requests": 113316,
    "scheduler_time": 113.47177814049589
}
#Debug simulation 
Total elapsed time: 8.285282033029944. Arrivals time: 0.2725843694061041 Scheduler time: 7.885753626935184 Scheduler overhead time: 0.046131741255521774 Adapter cache time: 0.01241068122908473 Engine time: 0.046996891498565674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86782411 . Total output tokens: 77748172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.293140240944922,
    "estimated_duration": 3600.138702746466,
    "input_throughput": 7845.216901908078,
    "output_throughput": 6897.993119280348,
    "total_throughput": 14743.210021188426,
    "itl": 123.57546766730226,
    "ttft": 619574.8771157205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.244859666489068,
    "arrivals": 129375,
    "finished_requests": 113312,
    "scheduler_time": 113.47767912244474
}
#Debug simulation 
Total elapsed time: 8.29323422210291. Arrivals time: 0.25987582420930266 Scheduler time: 7.906512104906142 Scheduler overhead time: 0.04618789441883564 Adapter cache time: 0.012343427632004023 Engine time: 0.046832230407744646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.128628640901297,
    "estimated_duration": 3600.1342114515305,
    "input_throughput": 7744.463223430405,
    "output_throughput": 6909.849616403646,
    "total_throughput": 14654.31283983405,
    "itl": 124.42743134044532,
    "ttft": 625117.2955807116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2127326388634216,
    "arrivals": 128882,
    "finished_requests": 112822,
    "scheduler_time": 113.77718072074937
}
#Debug simulation 
Total elapsed time: 8.128717483952641. Arrivals time: 0.25788802094757557 Scheduler time: 7.744695126544684 Scheduler overhead time: 0.04564016638323665 Adapter cache time: 0.012590308208018541 Engine time: 0.04666130198165774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.147310542874038,
    "estimated_duration": 3600.1051585656414,
    "input_throughput": 7744.347948743856,
    "output_throughput": 6909.693996247315,
    "total_throughput": 14654.041944991171,
    "itl": 124.43496178846127,
    "ttft": 625245.3423313382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.362835259886932,
    "arrivals": 128882,
    "finished_requests": 112818,
    "scheduler_time": 113.77638433484573
}
#Debug simulation 
Total elapsed time: 8.147398013621569. Arrivals time: 0.2805086192674935 Scheduler time: 7.740737909916788 Scheduler overhead time: 0.04565604357048869 Adapter cache time: 0.012712031602859497 Engine time: 0.04663228057324886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.1658427240327,
    "estimated_duration": 3600.1081184092714,
    "input_throughput": 7744.341581696482,
    "output_throughput": 6909.688315414104,
    "total_throughput": 14654.029897110586,
    "itl": 124.4350219334231,
    "ttft": 625247.5745896983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3663898949697595,
    "arrivals": 128882,
    "finished_requests": 112818,
    "scheduler_time": 113.77659434501827
}
#Debug simulation 
Total elapsed time: 8.165925731882453. Arrivals time: 0.2697354918345809 Scheduler time: 7.769848921336234 Scheduler overhead time: 0.04581000469624996 Adapter cache time: 0.012731547933071852 Engine time: 0.04657022329047322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.144993503112346,
    "estimated_duration": 3600.060054095565,
    "input_throughput": 7744.622195477376,
    "output_throughput": 6909.873898270158,
    "total_throughput": 14654.496093747535,
    "itl": 124.42907276490114,
    "ttft": 625125.4282520921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2378050924441557,
    "arrivals": 128882,
    "finished_requests": 112820,
    "scheduler_time": 113.77428827841497
}
#Debug simulation 
Total elapsed time: 8.145078611094505. Arrivals time: 0.28131306637078524 Scheduler time: 7.737303442321718 Scheduler overhead time: 0.04576837783679366 Adapter cache time: 0.012608593795448542 Engine time: 0.04682618472725153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.131399155594409,
    "estimated_duration": 3600.0131033764105,
    "input_throughput": 7744.287089914231,
    "output_throughput": 6909.584294754485,
    "total_throughput": 14653.871384668715,
    "itl": 124.43643392942401,
    "ttft": 625315.9321433359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.404870553612713,
    "arrivals": 128882,
    "finished_requests": 112814,
    "scheduler_time": 113.77320256625806
}
#Debug simulation 
Total elapsed time: 8.131485543679446. Arrivals time: 0.26210530614480376 Scheduler time: 7.743602257221937 Scheduler overhead time: 0.04546956159174442 Adapter cache time: 0.012614564038813114 Engine time: 0.04650429543107748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.161659945268184,
    "estimated_duration": 3600.0742622055495,
    "input_throughput": 7744.592185973108,
    "output_throughput": 6909.964680772927,
    "total_throughput": 14654.556866746034,
    "itl": 124.42574425927147,
    "ttft": 625068.8770510098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1618063632142333,
    "arrivals": 128882,
    "finished_requests": 112822,
    "scheduler_time": 113.77438376581641
}
#Debug simulation 
Total elapsed time: 8.161749653052539. Arrivals time: 0.26258400827646255 Scheduler time: 7.772670472040772 Scheduler overhead time: 0.04582342132925987 Adapter cache time: 0.0126938596367836 Engine time: 0.046733048278838396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86467814 . Total output tokens: 77446717
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.182750719133765,
    "estimated_duration": 3600.0449721533914,
    "input_throughput": 7744.21853494893,
    "output_throughput": 6909.523128851663,
    "total_throughput": 14653.741663800594,
    "itl": 124.4369390064436,
    "ttft": 625328.0988225162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4282607578858824,
    "arrivals": 128882,
    "finished_requests": 112814,
    "scheduler_time": 113.77464800788668
}
#Debug simulation 
Total elapsed time: 8.182835230138153. Arrivals time: 0.26015408942475915 Scheduler time: 7.795895273797214 Scheduler overhead time: 0.04597751144319773 Adapter cache time: 0.012833226472139359 Engine time: 0.046669136732816696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.059558846987784,
    "estimated_duration": 3600.1069762616526,
    "input_throughput": 7852.7363732275135,
    "output_throughput": 6898.147239443332,
    "total_throughput": 14750.883612670847,
    "itl": 123.38157406408952,
    "ttft": 597929.0000691332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.182127761424093,
    "arrivals": 128637,
    "finished_requests": 113290,
    "scheduler_time": 112.87386331867295
}
#Debug simulation 
Total elapsed time: 8.05967615917325. Arrivals time: 0.25553259067237377 Scheduler time: 7.677194537129253 Scheduler overhead time: 0.045838420279324055 Adapter cache time: 0.01260757027193904 Engine time: 0.047007051296532154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.01509360736236,
    "estimated_duration": 3600.1371807300657,
    "input_throughput": 7852.335780790242,
    "output_throughput": 6897.909649921749,
    "total_throughput": 14750.245430711992,
    "itl": 123.38724155596358,
    "ttft": 598117.0296515311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3304831850272683,
    "arrivals": 128637,
    "finished_requests": 113287,
    "scheduler_time": 112.87612893495108
}
#Debug simulation 
Total elapsed time: 8.015182718168944. Arrivals time: 0.25836716080084443 Scheduler time: 7.630177326500416 Scheduler overhead time: 0.04585420107468963 Adapter cache time: 0.012579275295138359 Engine time: 0.04684133129194379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.071283362805843,
    "estimated_duration": 3600.051680294128,
    "input_throughput": 7852.103111389356,
    "output_throughput": 6897.8784765587425,
    "total_throughput": 14749.981587948098,
    "itl": 123.3884009308397,
    "ttft": 598046.3697101554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.330550455171614,
    "arrivals": 128637,
    "finished_requests": 113284,
    "scheduler_time": 112.87268959372413
}
#Debug simulation 
Total elapsed time: 8.071369627024978. Arrivals time: 0.2728779367171228 Scheduler time: 7.672077436000109 Scheduler overhead time: 0.045812061522156 Adapter cache time: 0.012639690190553665 Engine time: 0.04669527988880873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.079633409623057,
    "estimated_duration": 3600.127585673697,
    "input_throughput": 7852.691419187486,
    "output_throughput": 6898.10775007652,
    "total_throughput": 14750.799169264006,
    "itl": 123.38233357270458,
    "ttft": 597958.0860790516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1985068971710042,
    "arrivals": 128637,
    "finished_requests": 113290,
    "scheduler_time": 112.87462443867199
}
#Debug simulation 
Total elapsed time: 8.079728995915502. Arrivals time: 0.24664855748414993 Scheduler time: 7.705606652423739 Scheduler overhead time: 0.046150690875947475 Adapter cache time: 0.012693573255091906 Engine time: 0.04716472653672099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.076998633798212,
    "estimated_duration": 3600.1010655250966,
    "input_throughput": 7851.9953983227815,
    "output_throughput": 6897.7838532924625,
    "total_throughput": 14749.779251615244,
    "itl": 123.38983098937588,
    "ttft": 598158.3779405257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.37116892818362,
    "arrivals": 128637,
    "finished_requests": 113284,
    "scheduler_time": 112.87483916506234
}
#Debug simulation 
Total elapsed time: 8.077086446806788. Arrivals time: 0.26874375995248556 Scheduler time: 7.681860799435526 Scheduler overhead time: 0.04591910447925329 Adapter cache time: 0.012679115403443575 Engine time: 0.04654860217124224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.050997673999518,
    "estimated_duration": 3600.049820838876,
    "input_throughput": 7852.861045520872,
    "output_throughput": 6898.256756406005,
    "total_throughput": 14751.117801926875,
    "itl": 123.38008890732495,
    "ttft": 597812.3594690263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1319058602652126,
    "arrivals": 128637,
    "finished_requests": 113290,
    "scheduler_time": 112.87135266811772
}
#Debug simulation 
Total elapsed time: 8.051077365875244. Arrivals time: 0.24783583683893085 Scheduler time: 7.6768201240338385 Scheduler overhead time: 0.045912591740489006 Adapter cache time: 0.012558397836983204 Engine time: 0.04665274824947119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 17280, 17280, 33, 17280, 33, 270, 33, 17280, 270, 17280, 33, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 17280, 33, 33, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 17280, 270]
Prompts retrieved: 386523 . Total input tokens: 86317287 . Total output tokens: 77314538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.065148056019098,
    "estimated_duration": 3600.123551379779,
    "input_throughput": 7851.94635588716,
    "output_throughput": 6897.740770725116,
    "total_throughput": 14749.687126612276,
    "itl": 123.3904429199992,
    "ttft": 598191.1827365952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.391541041582831,
    "arrivals": 128637,
    "finished_requests": 113284,
    "scheduler_time": 112.87582634909356
}
#Debug simulation 
Total elapsed time: 8.065235817804933. Arrivals time: 0.25633906945586205 Scheduler time: 7.682676601223648 Scheduler overhead time: 0.04581892490386963 Adapter cache time: 0.012506898026913404 Engine time: 0.04662074148654938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.989439136348665,
    "estimated_duration": 3600.0920931410583,
    "input_throughput": 7855.512655879138,
    "output_throughput": 6959.936399332061,
    "total_throughput": 14815.449055211198,
    "itl": 122.76377281824757,
    "ttft": 529025.3423860321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7146526288684107,
    "arrivals": 127906,
    "finished_requests": 114318,
    "scheduler_time": 111.29152688003725
}
#Debug simulation 
Total elapsed time: 7.989524926990271. Arrivals time: 0.25307966908439994 Scheduler time: 7.610481350682676 Scheduler overhead time: 0.04513592133298516 Adapter cache time: 0.013664412312209606 Engine time: 0.04610251355916262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.008223074954003,
    "estimated_duration": 3600.045258022611,
    "input_throughput": 7855.241524250411,
    "output_throughput": 6959.776948404861,
    "total_throughput": 14815.018472655272,
    "itl": 122.7703097556009,
    "ttft": 529187.5644753986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8935245617106626,
    "arrivals": 127906,
    "finished_requests": 114314,
    "scheduler_time": 111.29128999117107
}
#Debug simulation 
Total elapsed time: 8.008323992136866. Arrivals time: 0.25184449553489685 Scheduler time: 7.629806731827557 Scheduler overhead time: 0.04522329522296786 Adapter cache time: 0.013840719126164913 Engine time: 0.04653619276359677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.01501514017582,
    "estimated_duration": 3600.0468197903792,
    "input_throughput": 7855.238116499446,
    "output_throughput": 6959.773929123209,
    "total_throughput": 14815.012045622656,
    "itl": 122.77029248699559,
    "ttft": 529186.3563966851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8982317017391104,
    "arrivals": 127906,
    "finished_requests": 114314,
    "scheduler_time": 111.29111632307664
}
#Debug simulation 
Total elapsed time: 8.015106061007828. Arrivals time: 0.25348455691710114 Scheduler time: 7.635309268254787 Scheduler overhead time: 0.04511784156784415 Adapter cache time: 0.013815509155392647 Engine time: 0.046266317833215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 7.93106896430254,
    "estimated_duration": 3600.006492311943,
    "input_throughput": 7855.450833322982,
    "output_throughput": 6959.863837331358,
    "total_throughput": 14815.31467065434,
    "itl": 122.76490308836493,
    "ttft": 529074.0885958889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7543234411882853,
    "arrivals": 127906,
    "finished_requests": 114315,
    "scheduler_time": 111.2889148587932
}
#Debug simulation 
Total elapsed time: 7.931177590042353. Arrivals time: 0.25133540481328964 Scheduler time: 7.5540744522586465 Scheduler overhead time: 0.044960645493119955 Adapter cache time: 0.013706393539905548 Engine time: 0.04612942645326257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 7.987561950925738,
    "estimated_duration": 3600.095947523647,
    "input_throughput": 7855.13092212225,
    "output_throughput": 6959.678954455262,
    "total_throughput": 14814.809876577512,
    "itl": 122.77176275304673,
    "ttft": 529232.7828038702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9419940194115086,
    "arrivals": 127906,
    "finished_requests": 114314,
    "scheduler_time": 111.29339652256043
}
#Debug simulation 
Total elapsed time: 7.987665261141956. Arrivals time: 0.25132282078266144 Scheduler time: 7.609992494806647 Scheduler overhead time: 0.045204943511635065 Adapter cache time: 0.01381321158260107 Engine time: 0.04626848688349128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.989821892231703,
    "estimated_duration": 3600.0186740237114,
    "input_throughput": 7855.558418087732,
    "output_throughput": 6959.982230313,
    "total_throughput": 14815.540648400733,
    "itl": 122.76141538113892,
    "ttft": 528973.7216205063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6521746115781726,
    "arrivals": 127906,
    "finished_requests": 114317,
    "scheduler_time": 111.28862392549735
}
#Debug simulation 
Total elapsed time: 7.989928345195949. Arrivals time: 0.25190267665311694 Scheduler time: 7.612102767918259 Scheduler overhead time: 0.044984275475144386 Adapter cache time: 0.013796885497868061 Engine time: 0.04604886844754219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 17280, 17280, 66, 17280, 66, 135, 66, 17280, 135, 17280, 66, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 17280, 66, 66, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 17280, 135]
Prompts retrieved: 384381 . Total input tokens: 85824629 . Total output tokens: 76901894
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.021820669062436,
    "estimated_duration": 3600.135775570277,
    "input_throughput": 7855.044021366236,
    "output_throughput": 6959.601960020827,
    "total_throughput": 14814.645981387062,
    "itl": 122.77304410483848,
    "ttft": 529319.118783647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9734324660152476,
    "arrivals": 127906,
    "finished_requests": 114314,
    "scheduler_time": 111.29498897559156
}
#Debug simulation 
Total elapsed time: 8.021957600023597. Arrivals time: 0.254648027010262 Scheduler time: 7.64152695517987 Scheduler overhead time: 0.044893613550812006 Adapter cache time: 0.013776060659438372 Engine time: 0.04606179101392627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.072858469095081,
    "estimated_duration": 3600.093135177931,
    "input_throughput": 8011.956334728108,
    "output_throughput": 7045.448561359621,
    "total_throughput": 15057.40489608773,
    "itl": 120.76730262393703,
    "ttft": 465399.2153440229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2341560530709517,
    "arrivals": 127669,
    "finished_requests": 115769,
    "scheduler_time": 110.77552721256147
}
#Debug simulation 
Total elapsed time: 8.072944469749928. Arrivals time: 0.2517771190032363 Scheduler time: 7.694774710107595 Scheduler overhead time: 0.04537216853350401 Adapter cache time: 0.01299086818471551 Engine time: 0.046792743261903524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.07662775972858,
    "estimated_duration": 3600.1014003835185,
    "input_throughput": 8011.317402595247,
    "output_throughput": 7045.1582272927235,
    "total_throughput": 15056.475629887971,
    "itl": 120.77486423076462,
    "ttft": 465669.30165929603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3973791405256,
    "arrivals": 127669,
    "finished_requests": 115762,
    "scheduler_time": 110.77638536295858
}
#Debug simulation 
Total elapsed time: 8.07671147864312. Arrivals time: 0.26495708152651787 Scheduler time: 7.685604545287788 Scheduler overhead time: 0.04535064147785306 Adapter cache time: 0.013054671231657267 Engine time: 0.04660683078691363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.062048043124378,
    "estimated_duration": 3600.1036595910414,
    "input_throughput": 8011.312375176523,
    "output_throughput": 7045.153806177119,
    "total_throughput": 15056.466181353642,
    "itl": 120.77493700271134,
    "ttft": 465670.6438174077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3995064806193063,
    "arrivals": 127669,
    "finished_requests": 115762,
    "scheduler_time": 110.77652049694612
}
#Debug simulation 
Total elapsed time: 8.062135281041265. Arrivals time: 0.25335976481437683 Scheduler time: 7.682488606777042 Scheduler overhead time: 0.04556699935346842 Adapter cache time: 0.012964769266545773 Engine time: 0.04643939668312669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.015425655990839,
    "estimated_duration": 3600.057228746177,
    "input_throughput": 8011.823470385611,
    "output_throughput": 7045.381056021062,
    "total_throughput": 15057.204526406673,
    "itl": 120.7701028709012,
    "ttft": 465471.7680013416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2470350094604994,
    "arrivals": 127669,
    "finished_requests": 115766,
    "scheduler_time": 110.77483436681165
}
#Debug simulation 
Total elapsed time: 8.01551155000925. Arrivals time: 0.25458412198349833 Scheduler time: 7.635151541326195 Scheduler overhead time: 0.04505077889189124 Adapter cache time: 0.012850292958319187 Engine time: 0.046733589842915535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.094777291174978,
    "estimated_duration": 3600.015930040402,
    "input_throughput": 8011.433993759111,
    "output_throughput": 7045.155769551098,
    "total_throughput": 15056.589763310209,
    "itl": 120.77590963040983,
    "ttft": 465692.15026607516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.443017290718861,
    "arrivals": 127669,
    "finished_requests": 115760,
    "scheduler_time": 110.77390702574517
}
#Debug simulation 
Total elapsed time: 8.09486477309838. Arrivals time: 0.25140325957909226 Scheduler time: 7.716828286182135 Scheduler overhead time: 0.04531764518469572 Adapter cache time: 0.013065704610198736 Engine time: 0.0469873882830143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.03035023342818,
    "estimated_duration": 3600.0466093681644,
    "input_throughput": 8012.059878597601,
    "output_throughput": 7045.539614402832,
    "total_throughput": 15057.599493000433,
    "itl": 120.76651579082974,
    "ttft": 465356.33933245274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1827367152785477,
    "arrivals": 127669,
    "finished_requests": 115769,
    "scheduler_time": 110.77365361455867
}
#Debug simulation 
Total elapsed time: 8.030437591020018. Arrivals time: 0.25645024375990033 Scheduler time: 7.648037393111736 Scheduler overhead time: 0.045183183159679174 Adapter cache time: 0.012972449418157339 Engine time: 0.04656871221959591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 17280, 17280, 33, 17280, 33, 135, 33, 17280, 135, 17280, 33, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 17280, 33, 33, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 17280, 135]
Prompts retrieved: 383688 . Total input tokens: 85672063 . Total output tokens: 76766353
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.035058943089098,
    "estimated_duration": 3600.0388800688065,
    "input_throughput": 8011.382921355773,
    "output_throughput": 7045.110857112535,
    "total_throughput": 15056.493778468308,
    "itl": 120.77641152381953,
    "ttft": 465701.5892251887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4646469419822212,
    "arrivals": 127669,
    "finished_requests": 115760,
    "scheduler_time": 110.77488122433338
}
#Debug simulation 
Total elapsed time: 8.035142205189914. Arrivals time: 0.2518233056180179 Scheduler time: 7.657175162807107 Scheduler overhead time: 0.04544634837657213 Adapter cache time: 0.012954029720276594 Engine time: 0.046636957209557295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.25738854939118,
    "estimated_duration": 3600.0660215051644,
    "input_throughput": 8175.138962505769,
    "output_throughput": 7178.908899341396,
    "total_throughput": 15354.047861847166,
    "itl": 118.47480363997737,
    "ttft": 353491.5350767395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5669697248935883,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.51939754030727
}
#Debug simulation 
Total elapsed time: 8.257471379358321. Arrivals time: 0.25218454096466303 Scheduler time: 7.877987302374095 Scheduler overhead time: 0.04615526972338557 Adapter cache time: 0.011676755733788013 Engine time: 0.047854007221758366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.210673943161964,
    "estimated_duration": 3600.06402393363,
    "input_throughput": 8175.14349865423,
    "output_throughput": 7178.912882710573,
    "total_throughput": 15354.056381364802,
    "itl": 118.47807587675757,
    "ttft": 353535.8086100491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.670236754578079,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.52015366996118
}
#Debug simulation 
Total elapsed time: 8.21076802490279. Arrivals time: 0.2541652317158878 Scheduler time: 7.830142270773649 Scheduler overhead time: 0.04580517532303929 Adapter cache time: 0.011549456045031548 Engine time: 0.047627939842641354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.223748174030334,
    "estimated_duration": 3600.0672167368743,
    "input_throughput": 8175.136248338301,
    "output_throughput": 7178.906515924909,
    "total_throughput": 15354.042764263211,
    "itl": 118.4781258597032,
    "ttft": 353537.5856020772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6732830462046069,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.52032549780957
}
#Debug simulation 
Total elapsed time: 8.223834971897304. Arrivals time: 0.25129286060109735 Scheduler time: 7.845832924358547 Scheduler overhead time: 0.04604390915483236 Adapter cache time: 0.011615495197474957 Engine time: 0.04740152833983302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 8.244173338636756,
    "estimated_duration": 3600.082629306566,
    "input_throughput": 8175.101249181298,
    "output_throughput": 7178.87578179784,
    "total_throughput": 15353.977030979138,
    "itl": 118.47503327355712,
    "ttft": 353521.90426091704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5885176908899936,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.52021756785314
}
#Debug simulation 
Total elapsed time: 8.244260674808174. Arrivals time: 0.2542405086569488 Scheduler time: 7.863063815515488 Scheduler overhead time: 0.04621011484414339 Adapter cache time: 0.011599412653595209 Engine time: 0.047538707964122295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 8.19741307105869,
    "estimated_duration": 3600.095961457942,
    "input_throughput": 8175.070974519585,
    "output_throughput": 7178.849196434657,
    "total_throughput": 15353.920170954241,
    "itl": 118.47898400086359,
    "ttft": 353576.8615108642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6984338034875714,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.52170805290166
}
#Debug simulation 
Total elapsed time: 8.197504394222051. Arrivals time: 0.2546474505215883 Scheduler time: 7.816485713701695 Scheduler overhead time: 0.045716188848018646 Adapter cache time: 0.011515235994011164 Engine time: 0.04768919385969639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 8.18103983066976,
    "estimated_duration": 3600.037218141539,
    "input_throughput": 8175.204370579618,
    "output_throughput": 7178.9663367263265,
    "total_throughput": 15354.170707305944,
    "itl": 118.47425873090636,
    "ttft": 353455.6469898522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5309057509898965,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.51801693903386
}
#Debug simulation 
Total elapsed time: 8.18115270882845. Arrivals time: 0.2533037536777556 Scheduler time: 7.801580427214503 Scheduler overhead time: 0.04568524658679962 Adapter cache time: 0.011461214628070593 Engine time: 0.04757427331060171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 17280, 17280, 33, 17280, 33, 66, 33, 17280, 66, 17280, 33, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 17280, 33, 33, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 17280, 66]
Prompts retrieved: 382239 . Total input tokens: 85334118 . Total output tokens: 76480486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 8.284382562618703,
    "estimated_duration": 3600.112918643178,
    "input_throughput": 8175.032468451591,
    "output_throughput": 7178.815382752043,
    "total_throughput": 15353.847851203633,
    "itl": 118.47935714389823,
    "ttft": 353583.30960774934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7161650873720624,
    "arrivals": 127143,
    "finished_requests": 118166,
    "scheduler_time": 109.52251381026076
}
#Debug simulation 
Total elapsed time: 8.284466070588678. Arrivals time: 0.2528147539123893 Scheduler time: 7.904210126958787 Scheduler overhead time: 0.04627301823347807 Adapter cache time: 0.011566660832613707 Engine time: 0.047907065600156784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 47.19318212522194,
    "estimated_duration": 3600.055421288182,
    "input_throughput": 6643.76466500108,
    "output_throughput": 5830.4060753846325,
    "total_throughput": 12474.170740385713,
    "itl": 84.56853816775441,
    "ttft": 328578.9097496808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7192146198241962,
    "arrivals": 101151,
    "finished_requests": 95800,
    "scheduler_time": 93.17302845103066
}
#Debug simulation 
Total elapsed time: 47.19331221934408. Arrivals time: 0.29584931023418903 Scheduler time: 46.679832165595144 Scheduler overhead time: 0.08490540506318212 Adapter cache time: 0.015089495573192835 Engine time: 0.08282087557017803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 46.45372645929456,
    "estimated_duration": 3599.9487277838375,
    "input_throughput": 6667.940244464881,
    "output_throughput": 5869.610263312836,
    "total_throughput": 12537.550507777718,
    "itl": 88.03158458159398,
    "ttft": 320182.17993463756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7689841439551703,
    "arrivals": 101151,
    "finished_requests": 96174,
    "scheduler_time": 93.90302566599196
}
#Debug simulation 
Total elapsed time: 46.45383317023516. Arrivals time: 0.2616765289567411 Scheduler time: 45.97902584541589 Scheduler overhead time: 0.08366932813078165 Adapter cache time: 0.01467596460133791 Engine time: 0.08086457522585988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 46.28614716604352,
    "estimated_duration": 3599.9557265854733,
    "input_throughput": 6667.927281085708,
    "output_throughput": 5869.5988519953,
    "total_throughput": 12537.526133081008,
    "itl": 88.03209998657141,
    "ttft": 320179.8112035562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7705438099615312,
    "arrivals": 101151,
    "finished_requests": 96174,
    "scheduler_time": 93.90305623585438
}
#Debug simulation 
Total elapsed time: 46.28625840973109. Arrivals time: 0.289233164396137 Scheduler time: 45.78486405406147 Scheduler overhead time: 0.08310898020863533 Adapter cache time: 0.014315029140561819 Engine time: 0.08109224122017622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 46.228837970178574,
    "estimated_duration": 3599.957237171933,
    "input_throughput": 6608.326275200088,
    "output_throughput": 5827.730891737263,
    "total_throughput": 12436.057166937351,
    "itl": 83.54048324447373,
    "ttft": 312088.2166298579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6760869172634573,
    "arrivals": 101151,
    "finished_requests": 95334,
    "scheduler_time": 91.43935699239859
}
#Debug simulation 
Total elapsed time: 46.22896234411746. Arrivals time: 0.2932982537895441 Scheduler time: 45.71865484956652 Scheduler overhead time: 0.08506756694987416 Adapter cache time: 0.015061014797538519 Engine time: 0.08232533046975732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 65.20641278801486,
    "estimated_duration": 3600.036790512418,
    "input_throughput": 6616.022942534937,
    "output_throughput": 5820.94523456724,
    "total_throughput": 12436.968177102177,
    "itl": 85.40352812069128,
    "ttft": 378246.3301576514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5231634094193588,
    "arrivals": 101151,
    "finished_requests": 95456,
    "scheduler_time": 98.0714286052557
}
#Debug simulation 
Total elapsed time: 65.20652037626132. Arrivals time: 0.28844585455954075 Scheduler time: 64.6840344988741 Scheduler overhead time: 0.0929515128955245 Adapter cache time: 0.015398799441754818 Engine time: 0.08960341988131404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 65.46623141737655,
    "estimated_duration": 3600.0767263903326,
    "input_throughput": 6615.954550469094,
    "output_throughput": 5819.551801888024,
    "total_throughput": 12435.506352357119,
    "itl": 85.14073052467614,
    "ttft": 378088.83476582495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 101151,
    "finished_requests": 95435,
    "scheduler_time": 98.03851336034722
}
#Debug simulation 
Total elapsed time: 65.46634278539568. Arrivals time: 0.2984034167602658 Scheduler time: 64.93123680353165 Scheduler overhead time: 0.09546826407313347 Adapter cache time: 0.015007556416094303 Engine time: 0.09017576649785042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [21 21 22]
Adapter prompts. [1080, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 4320]
Prompts retrieved: 303480 . Total input tokens: 67823698 . Total output tokens: 60750181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 64.89845780376345,
    "estimated_duration": 3600.058677629401,
    "input_throughput": 6615.982719393853,
    "output_throughput": 5820.909845224813,
    "total_throughput": 12436.892564618665,
    "itl": 85.40392645626275,
    "ttft": 378247.44827530714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5299541138857604,
    "arrivals": 101151,
    "finished_requests": 95456,
    "scheduler_time": 98.07211413820352
}
#Debug simulation 
Total elapsed time: 64.8985826796852. Arrivals time: 0.31589503306895494 Scheduler time: 64.34743536962196 Scheduler overhead time: 0.09385766228660941 Adapter cache time: 0.015866021625697613 Engine time: 0.08993096416816115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 51.935503986198455,
    "estimated_duration": 3599.9875301445427,
    "input_throughput": 6421.913077868845,
    "output_throughput": 5670.7685315733115,
    "total_throughput": 12092.681609442156,
    "itl": 78.23772186648932,
    "ttft": 292991.19375468686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.501919990004971,
    "arrivals": 97469,
    "finished_requests": 93016,
    "scheduler_time": 90.07264693058045
}
#Debug simulation 
Total elapsed time: 51.93562860786915. Arrivals time: 0.2849800242111087 Scheduler time: 51.418525664135814 Scheduler overhead time: 0.09153957851231098 Adapter cache time: 0.01564411912113428 Engine time: 0.08788179652765393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 51.72294600028545,
    "estimated_duration": 3599.9936299167284,
    "input_throughput": 6426.77414974625,
    "output_throughput": 5670.675311853873,
    "total_throughput": 12097.449461600123,
    "itl": 78.43124740056805,
    "ttft": 290293.9551801146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5395295696426188,
    "arrivals": 97469,
    "finished_requests": 93092,
    "scheduler_time": 90.10884725536194
}
#Debug simulation 
Total elapsed time: 51.72305222321302. Arrivals time: 0.26196429366245866 Scheduler time: 51.230597152374685 Scheduler overhead time: 0.0915909931063652 Adapter cache time: 0.014832453336566687 Engine time: 0.08727950928732753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 51.27096935082227,
    "estimated_duration": 3600.0440013075327,
    "input_throughput": 6428.330873621197,
    "output_throughput": 5670.463192279229,
    "total_throughput": 12098.794065900425,
    "itl": 78.73883446212132,
    "ttft": 289620.9514418211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5402895769290645,
    "arrivals": 97469,
    "finished_requests": 93102,
    "scheduler_time": 90.09331218397361
}
#Debug simulation 
Total elapsed time: 51.2710760938935. Arrivals time: 0.283013254404068 Scheduler time: 50.76176364347339 Scheduler overhead time: 0.08985691610723734 Adapter cache time: 0.014939188957214355 Engine time: 0.08536633756011724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 51.02724387589842,
    "estimated_duration": 3600.0275801458456,
    "input_throughput": 6477.764261754696,
    "output_throughput": 5708.156546724981,
    "total_throughput": 12185.920808479677,
    "itl": 79.50271150732812,
    "ttft": 265749.0944251016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5208640680601826,
    "arrivals": 97469,
    "finished_requests": 93802,
    "scheduler_time": 90.49437045363977
}
#Debug simulation 
Total elapsed time: 51.02736993459985. Arrivals time: 0.2915993258357048 Scheduler time: 50.506771844346076 Scheduler overhead time: 0.0906374785117805 Adapter cache time: 0.015173416584730148 Engine time: 0.08728333190083504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 51.20797980716452,
    "estimated_duration": 3600.008450053621,
    "input_throughput": 6445.641259440483,
    "output_throughput": 5685.2124887915625,
    "total_throughput": 12130.853748232044,
    "itl": 79.12138718356292,
    "ttft": 280291.7866437633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.546743033900858,
    "arrivals": 97469,
    "finished_requests": 93368,
    "scheduler_time": 90.21795915213525
}
#Debug simulation 
Total elapsed time: 51.20812826510519. Arrivals time: 0.2678144332021475 Scheduler time: 50.71145666856319 Scheduler overhead time: 0.09085955424234271 Adapter cache time: 0.014924946706742048 Engine time: 0.0866555031388998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 51.74709746101871,
    "estimated_duration": 3600.0048635516205,
    "input_throughput": 6423.596599585097,
    "output_throughput": 5664.091514555149,
    "total_throughput": 12087.688114140246,
    "itl": 78.67081993824686,
    "ttft": 293028.1711172835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48438814777415307,
    "arrivals": 97469,
    "finished_requests": 93026,
    "scheduler_time": 90.07454556068647
}
#Debug simulation 
Total elapsed time: 51.74720145110041. Arrivals time: 0.2691536769270897 Scheduler time: 51.24717241758481 Scheduler overhead time: 0.09172968659549952 Adapter cache time: 0.015082365833222866 Engine time: 0.08736427733674645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 8640, 4320, 8640, 540, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 540, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 540, 4320, 4320, 540, 4320, 540, 540, 540, 8640, 4320]
Prompts retrieved: 292140 . Total input tokens: 65294059 . Total output tokens: 58446438
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 52.12870449991897,
    "estimated_duration": 3600.042441190837,
    "input_throughput": 6428.580045390967,
    "output_throughput": 5672.318961119023,
    "total_throughput": 12100.89900650999,
    "itl": 78.24188384046056,
    "ttft": 289389.036439095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.550993234664202,
    "arrivals": 97469,
    "finished_requests": 93124,
    "scheduler_time": 90.14206498732902
}
#Debug simulation 
Total elapsed time: 52.12882715091109. Arrivals time: 0.2948659146204591 Scheduler time: 51.60388713609427 Scheduler overhead time: 0.09108762163668871 Adapter cache time: 0.014962401706725359 Engine time: 0.08763555623590946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 38.83786593796685,
    "estimated_duration": 3600.0540782978346,
    "input_throughput": 6322.227806856023,
    "output_throughput": 5557.930954598471,
    "total_throughput": 11880.158761454493,
    "itl": 75.78447475066051,
    "ttft": 238122.67664824953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6029160855547517,
    "arrivals": 95579,
    "finished_requests": 91693,
    "scheduler_time": 84.38152641391527
}
#Debug simulation 
Total elapsed time: 38.83797812880948. Arrivals time: 0.2657249034382403 Scheduler time: 38.352896810509264 Scheduler overhead time: 0.0847484222613275 Adapter cache time: 0.014903371222317219 Engine time: 0.08303223876282573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 42.648598823696375,
    "estimated_duration": 3600.0435570181007,
    "input_throughput": 6305.5742633299105,
    "output_throughput": 5541.592673541003,
    "total_throughput": 11847.166936870914,
    "itl": 75.57780763807318,
    "ttft": 249820.850360192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49657296262448647,
    "arrivals": 95579,
    "finished_requests": 91506,
    "scheduler_time": 85.10327834613162
}
#Debug simulation 
Total elapsed time: 42.64870175300166. Arrivals time: 0.2466893559321761 Scheduler time: 42.17871829774231 Scheduler overhead time: 0.08725435053929687 Adapter cache time: 0.014801066368818283 Engine time: 0.08442101115360856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 42.79638056922704,
    "estimated_duration": 3600.0462277772663,
    "input_throughput": 6305.569585426019,
    "output_throughput": 5541.588562410621,
    "total_throughput": 11847.15814783664,
    "itl": 75.57778518370101,
    "ttft": 249856.070503031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4973513569496589,
    "arrivals": 95579,
    "finished_requests": 91506,
    "scheduler_time": 85.1033642970706
}
#Debug simulation 
Total elapsed time: 42.7964787222445. Arrivals time: 0.27335614478215575 Scheduler time: 42.29617673764005 Scheduler overhead time: 0.08865200914442539 Adapter cache time: 0.015122523065656424 Engine time: 0.08591836597770452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 37.70245675416663,
    "estimated_duration": 3600.0609376233883,
    "input_throughput": 6374.730705294744,
    "output_throughput": 5586.625434534239,
    "total_throughput": 11961.356139828982,
    "itl": 77.26542915538208,
    "ttft": 213650.9920284291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6355818821559671,
    "arrivals": 95579,
    "finished_requests": 92432,
    "scheduler_time": 84.62096019757689
}
#Debug simulation 
Total elapsed time: 37.70256560621783. Arrivals time: 0.26586611149832606 Scheduler time: 37.21993785724044 Scheduler overhead time: 0.08377675525844097 Adapter cache time: 0.014578612055629492 Engine time: 0.0822651362977922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 46.312589331995696,
    "estimated_duration": 3600.0490561343704,
    "input_throughput": 6255.649200564512,
    "output_throughput": 5501.407256174004,
    "total_throughput": 11757.056456738515,
    "itl": 73.49240132589908,
    "ttft": 277098.90160860313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47409813787788213,
    "arrivals": 95579,
    "finished_requests": 90761,
    "scheduler_time": 85.34848406041671
}
#Debug simulation 
Total elapsed time: 46.31269806204364. Arrivals time: 0.2527358611114323 Scheduler time: 45.82922859629616 Scheduler overhead time: 0.08975381217896938 Adapter cache time: 0.01485773827880621 Engine time: 0.08811890427023172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 46.15516662225127,
    "estimated_duration": 3600.057772831118,
    "input_throughput": 6255.634609521713,
    "output_throughput": 5501.603376888119,
    "total_throughput": 11757.237986409831,
    "itl": 73.49138981810947,
    "ttft": 277021.9598706566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42757719217101164,
    "arrivals": 95579,
    "finished_requests": 90763,
    "scheduler_time": 85.34872267854182
}
#Debug simulation 
Total elapsed time: 46.1552793122828. Arrivals time: 0.27936218585819006 Scheduler time: 45.64513966208324 Scheduler overhead time: 0.09110197704285383 Adapter cache time: 0.014841781463474035 Engine time: 0.08710871310904622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 8640, 4320, 8640, 270, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 270, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 8640, 4320]
Prompts retrieved: 286470 . Total input tokens: 64041887 . Total output tokens: 57312412
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 46.60751490294933,
    "estimated_duration": 3600.0329001598593,
    "input_throughput": 6246.556524247717,
    "output_throughput": 5498.853635232322,
    "total_throughput": 11745.41015948004,
    "itl": 73.32109621712529,
    "ttft": 280350.5879505071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4770908007770774,
    "arrivals": 95579,
    "finished_requests": 90620,
    "scheduler_time": 85.28157044829112
}
#Debug simulation 
Total elapsed time: 46.60764057794586. Arrivals time: 0.28434554720297456 Scheduler time: 46.0868642386049 Scheduler overhead time: 0.09324067272245884 Adapter cache time: 0.015660163946449757 Engine time: 0.0894349436275661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 44.86313138296828,
    "estimated_duration": 3600.014970741551,
    "input_throughput": 6252.252610872792,
    "output_throughput": 5605.248912574222,
    "total_throughput": 11857.501523447014,
    "itl": 75.2013115025424,
    "ttft": 231440.80950080132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36725852927193003,
    "arrivals": 94646,
    "finished_requests": 91180,
    "scheduler_time": 85.37028076057071
}
#Debug simulation 
Total elapsed time: 44.8632187647745. Arrivals time: 0.24953995877876878 Scheduler time: 44.384102925658226 Scheduler overhead time: 0.09173868736252189 Adapter cache time: 0.014150969684123993 Engine time: 0.08674893295392394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 40.78060460090637,
    "estimated_duration": 3600.0314622925175,
    "input_throughput": 6275.633765048542,
    "output_throughput": 5612.880946082724,
    "total_throughput": 11888.514711131267,
    "itl": 75.99035043714163,
    "ttft": 222738.82230390483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5421110246190806,
    "arrivals": 94646,
    "finished_requests": 91492,
    "scheduler_time": 85.09417522919198
}
#Debug simulation 
Total elapsed time: 40.78070265986025. Arrivals time: 0.2684139432385564 Scheduler time: 40.29033325333148 Scheduler overhead time: 0.08757047634571791 Adapter cache time: 0.014371916651725769 Engine time: 0.0835999003611505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 40.59325008187443,
    "estimated_duration": 3600.0318765610714,
    "input_throughput": 6275.633042888902,
    "output_throughput": 5612.8803001884235,
    "total_throughput": 11888.513343077326,
    "itl": 75.99045271689896,
    "ttft": 222738.70720409576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5429958482831736,
    "arrivals": 94646,
    "finished_requests": 91492,
    "scheduler_time": 85.09415709419567
}
#Debug simulation 
Total elapsed time: 40.593372700270265. Arrivals time: 0.26740009943023324 Scheduler time: 40.10342769930139 Scheduler overhead time: 0.08613608777523041 Adapter cache time: 0.014699296560138464 Engine time: 0.08502530306577682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 44.479399549774826,
    "estimated_duration": 3600.038323146573,
    "input_throughput": 6252.21205432251,
    "output_throughput": 5605.212552949378,
    "total_throughput": 11857.424607271889,
    "itl": 75.20316480891147,
    "ttft": 231441.22647191683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37392406217055413,
    "arrivals": 94646,
    "finished_requests": 91180,
    "scheduler_time": 85.37090671823287
}
#Debug simulation 
Total elapsed time: 44.47953792894259. Arrivals time: 0.24756087129935622 Scheduler time: 44.00815784512088 Scheduler overhead time: 0.08767403569072485 Adapter cache time: 0.014176602941006422 Engine time: 0.08539784420281649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 40.00341212004423,
    "estimated_duration": 3600.056666443958,
    "input_throughput": 6304.596039156075,
    "output_throughput": 5640.099276564008,
    "total_throughput": 11944.695315720082,
    "itl": 76.5162007512878,
    "ttft": 205200.8044061117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5671076596900834,
    "arrivals": 94646,
    "finished_requests": 91909,
    "scheduler_time": 85.1545572340482
}
#Debug simulation 
Total elapsed time: 40.003529623150826. Arrivals time: 0.26955167250707746 Scheduler time: 39.51481724018231 Scheduler overhead time: 0.08549671107903123 Adapter cache time: 0.014892691746354103 Engine time: 0.08243844797834754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 44.36092837806791,
    "estimated_duration": 3600.050860830382,
    "input_throughput": 6252.275278913205,
    "output_throughput": 5605.27414197295,
    "total_throughput": 11857.549420886155,
    "itl": 75.20243614373162,
    "ttft": 231401.12443140833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3588060353882615,
    "arrivals": 94646,
    "finished_requests": 91181,
    "scheduler_time": 85.37089200015127
}
#Debug simulation 
Total elapsed time: 44.36103659775108. Arrivals time: 0.2533556413836777 Scheduler time: 43.8826842661947 Scheduler overhead time: 0.0883993529714644 Adapter cache time: 0.01415981538593769 Engine time: 0.08541818661615252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 8640, 4320, 8640, 135, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 135, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 8640, 4320]
Prompts retrieved: 283635 . Total input tokens: 63409082 . Total output tokens: 56735307
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 39.89069314720109,
    "estimated_duration": 3600.05330426558,
    "input_throughput": 6304.915811414758,
    "output_throughput": 5642.152013675172,
    "total_throughput": 11947.06782508993,
    "itl": 76.54282996519245,
    "ttft": 204902.1847708497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5741498717293149,
    "arrivals": 94646,
    "finished_requests": 91916,
    "scheduler_time": 85.15041906030197
}
#Debug simulation 
Total elapsed time: 39.89079658407718. Arrivals time: 0.2529055271297693 Scheduler time: 39.41934376489371 Scheduler overhead time: 0.08487019827589393 Adapter cache time: 0.014667086768895388 Engine time: 0.08271034900099039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 50.666029303800315,
    "estimated_duration": 3600.083857917656,
    "input_throughput": 6139.508931545992,
    "output_throughput": 5440.107723304028,
    "total_throughput": 11579.616654850019,
    "itl": 69.3391442655388,
    "ttft": 286554.4423137152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3641980415279973,
    "arrivals": 94180,
    "finished_requests": 89085,
    "scheduler_time": 84.6686428401329
}
#Debug simulation 
Total elapsed time: 50.66615425096825. Arrivals time: 0.2857473841868341 Scheduler time: 50.140670594759285 Scheduler overhead time: 0.09377797972410917 Adapter cache time: 0.015578963328152895 Engine time: 0.09162869909778237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 37.80829711770639,
    "estimated_duration": 3600.0368461322423,
    "input_throughput": 6148.454292566681,
    "output_throughput": 5469.557352212915,
    "total_throughput": 11618.011644779595,
    "itl": 70.33902382910397,
    "ttft": 251810.6675815639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.543745405892842,
    "arrivals": 94180,
    "finished_requests": 89233,
    "scheduler_time": 81.19344013418196
}
#Debug simulation 
Total elapsed time: 37.808384716976434. Arrivals time: 0.2365713156759739 Scheduler time: 37.34387369686738 Scheduler overhead time: 0.08930121315643191 Adapter cache time: 0.014946517068892717 Engine time: 0.08586452342569828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 37.71178327873349,
    "estimated_duration": 3600.0367388261643,
    "input_throughput": 6148.454475833287,
    "output_throughput": 5469.557515243681,
    "total_throughput": 11618.011991076968,
    "itl": 70.33921429940668,
    "ttft": 251810.6779321685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5443448382616063,
    "arrivals": 94180,
    "finished_requests": 89233,
    "scheduler_time": 81.19342182575723
}
#Debug simulation 
Total elapsed time: 37.711893466766924. Arrivals time: 0.2599235801026225 Scheduler time: 37.22453314671293 Scheduler overhead time: 0.08843659982085228 Adapter cache time: 0.01539643993601203 Engine time: 0.08582765469327569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 32.60794853698462,
    "estimated_duration": 3600.0353406997374,
    "input_throughput": 6287.7682738526155,
    "output_throughput": 5569.76671126307,
    "total_throughput": 11857.534985115684,
    "itl": 74.45981841789354,
    "ttft": 185725.14340872166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5780836189817645,
    "arrivals": 94180,
    "finished_requests": 91200,
    "scheduler_time": 81.5985504401199
}
#Debug simulation 
Total elapsed time: 32.60805395571515. Arrivals time: 0.22886626841500401 Scheduler time: 32.16188699379563 Scheduler overhead time: 0.08405692828819156 Adapter cache time: 0.014478779397904873 Engine time: 0.08227459480985999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 37.67300769966096,
    "estimated_duration": 3600.0088554877266,
    "input_throughput": 6148.502097781982,
    "output_throughput": 5469.599878895945,
    "total_throughput": 11618.101976677928,
    "itl": 70.34060914233253,
    "ttft": 251775.88490325506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5518900654464971,
    "arrivals": 94180,
    "finished_requests": 89233,
    "scheduler_time": 81.19301380881105
}
#Debug simulation 
Total elapsed time: 37.673100902698934. Arrivals time: 0.2503405245952308 Scheduler time: 37.19697738671675 Scheduler overhead time: 0.08802313636988401 Adapter cache time: 0.014770430978387594 Engine time: 0.08530867984518409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 32.60034260293469,
    "estimated_duration": 3600.0628540411485,
    "input_throughput": 6287.88382808087,
    "output_throughput": 5569.888030563482,
    "total_throughput": 11857.771858644352,
    "itl": 74.4799010895834,
    "ttft": 185665.2401440956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.550169254262001,
    "arrivals": 94180,
    "finished_requests": 91203,
    "scheduler_time": 81.59974692436951
}
#Debug simulation 
Total elapsed time: 32.6004581800662. Arrivals time: 0.24836330115795135 Scheduler time: 32.13665913278237 Scheduler overhead time: 0.08323129964992404 Adapter cache time: 0.014440666418522596 Engine time: 0.0815421948209405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 8640, 4320, 8640, 66, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 66, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 8640, 4320]
Prompts retrieved: 282186 . Total input tokens: 63078113 . Total output tokens: 56436327
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 50.214606347028166,
    "estimated_duration": 3600.068491576421,
    "input_throughput": 6139.5351370999915,
    "output_throughput": 5440.130943571038,
    "total_throughput": 11579.66608067103,
    "itl": 69.34095744061175,
    "ttft": 286554.64687690226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4001448480412361,
    "arrivals": 94180,
    "finished_requests": 89085,
    "scheduler_time": 84.66847178051572
}
#Debug simulation 
Total elapsed time: 50.21472934121266. Arrivals time: 0.26891132816672325 Scheduler time: 49.70356741780415 Scheduler overhead time: 0.09576663980260491 Adapter cache time: 0.01562562072649598 Engine time: 0.09233738947659731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 31.746279559098184,
    "estimated_duration": 3600.0198118716257,
    "input_throughput": 6216.882175535674,
    "output_throughput": 5526.103754872727,
    "total_throughput": 11742.9859304084,
    "itl": 71.60199344203116,
    "ttft": 198409.4163841691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42540779640665227,
    "arrivals": 93946,
    "finished_requests": 90327,
    "scheduler_time": 80.06136538939994
}
#Debug simulation 
Total elapsed time: 31.746379297226667. Arrivals time: 0.23671953100711107 Scheduler time: 31.291156268678606 Scheduler overhead time: 0.08484791964292526 Adapter cache time: 0.014196994248777628 Engine time: 0.08243664307519794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 31.74514047196135,
    "estimated_duration": 3600.04401169838,
    "input_throughput": 6216.840662856631,
    "output_throughput": 5526.129940454403,
    "total_throughput": 11742.970603311034,
    "itl": 71.60359024192225,
    "ttft": 198372.16227227292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45443354624323545,
    "arrivals": 93946,
    "finished_requests": 90328,
    "scheduler_time": 80.06218803272114
}
#Debug simulation 
Total elapsed time: 31.745248263236135. Arrivals time: 0.2385775768198073 Scheduler time: 31.28799679549411 Scheduler overhead time: 0.08496649516746402 Adapter cache time: 0.014313579071313143 Engine time: 0.08244492253288627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 31.698292785789818,
    "estimated_duration": 3600.039265622588,
    "input_throughput": 6216.848858766396,
    "output_throughput": 5526.13722577259,
    "total_throughput": 11742.986084538985,
    "itl": 71.60328014596358,
    "ttft": 198372.13854920364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4550876319594695,
    "arrivals": 93946,
    "finished_requests": 90328,
    "scheduler_time": 80.061990702624
}
#Debug simulation 
Total elapsed time: 31.69845507480204. Arrivals time: 0.248407200910151 Scheduler time: 31.231723338831216 Scheduler overhead time: 0.08442350849509239 Adapter cache time: 0.014394784811884165 Engine time: 0.08249434595927596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 31.97144130896777,
    "estimated_duration": 3600.0498462529063,
    "input_throughput": 6216.830587302853,
    "output_throughput": 5526.120984326618,
    "total_throughput": 11742.95157162947,
    "itl": 71.60345737507753,
    "ttft": 198370.6397794295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43400378032121834,
    "arrivals": 93946,
    "finished_requests": 90328,
    "scheduler_time": 80.06211543391092
}
#Debug simulation 
Total elapsed time: 31.97153857210651. Arrivals time: 0.23294289829209447 Scheduler time: 31.51849189121276 Scheduler overhead time: 0.08590518496930599 Adapter cache time: 0.01427703257650137 Engine time: 0.08315433841198683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 31.60352495824918,
    "estimated_duration": 3600.05443720936,
    "input_throughput": 6216.822659312039,
    "output_throughput": 5526.113937160738,
    "total_throughput": 11742.936596472777,
    "itl": 71.60395441099178,
    "ttft": 198371.5406022091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4613753212802117,
    "arrivals": 93946,
    "finished_requests": 90328,
    "scheduler_time": 80.06231046722799
}
#Debug simulation 
Total elapsed time: 31.603645057883114. Arrivals time: 0.2367392466403544 Scheduler time: 31.148384425323457 Scheduler overhead time: 0.08489064825698733 Adapter cache time: 0.014314203523099422 Engine time: 0.08239662274718285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 31.845755020622164,
    "estimated_duration": 3599.9943347628396,
    "input_throughput": 6216.926172322549,
    "output_throughput": 5526.142863030528,
    "total_throughput": 11743.069035353077,
    "itl": 71.60136462341882,
    "ttft": 198409.31240027232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4156169909914029,
    "arrivals": 93946,
    "finished_requests": 90327,
    "scheduler_time": 80.06077976265803
}
#Debug simulation 
Total elapsed time: 31.84585498087108. Arrivals time: 0.2432686141692102 Scheduler time: 31.383080984465778 Scheduler overhead time: 0.08503251150250435 Adapter cache time: 0.014451678842306137 Engine time: 0.0830434076488018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 8640, 4320, 8640, 33, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 33, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 8640, 4320]
Prompts retrieved: 281493 . Total input tokens: 62920289 . Total output tokens: 56298982
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 31.72615483403206,
    "estimated_duration": 3600.0040951405226,
    "input_throughput": 6216.90931691187,
    "output_throughput": 5526.127880480495,
    "total_throughput": 11743.037197392365,
    "itl": 71.60442119563221,
    "ttft": 198410.13425882126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4670342416688797,
    "arrivals": 93946,
    "finished_requests": 90327,
    "scheduler_time": 80.0611556012014
}
#Debug simulation 
Total elapsed time: 31.726243193261325. Arrivals time: 0.2504322971217334 Scheduler time: 31.257063020486385 Scheduler overhead time: 0.08461358025670052 Adapter cache time: 0.01444131601601839 Engine time: 0.08283836673945189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.360305957030505,
    "estimated_duration": 3600.03542702672,
    "input_throughput": 5146.797962291964,
    "output_throughput": 4568.582263531688,
    "total_throughput": 9715.380225823652,
    "itl": 47.99342069953609,
    "ttft": 25555.53361695197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1040,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1829072536901384,
    "arrivals": 74944,
    "finished_requests": 74541,
    "scheduler_time": 54.11649377755744
}
#Debug simulation 
Total elapsed time: 7.360384481959045. Arrivals time: 0.1729440540075302 Scheduler time: 6.939050026703626 Scheduler overhead time: 0.09335132734850049 Adapter cache time: 0.021131977904587984 Engine time: 0.09084787545725703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 7.442897499073297,
    "estimated_duration": 3600.009780348268,
    "input_throughput": 5145.073244275502,
    "output_throughput": 4567.43453580543,
    "total_throughput": 9712.507780080932,
    "itl": 47.98322942539888,
    "ttft": 26678.435995893247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3233693441446026,
    "arrivals": 74944,
    "finished_requests": 74521,
    "scheduler_time": 54.11195510858165
}
#Debug simulation 
Total elapsed time: 7.442987682763487. Arrivals time: 0.18156888522207737 Scheduler time: 7.01300565013662 Scheduler overhead time: 0.09279137337580323 Adapter cache time: 0.02095158537849784 Engine time: 0.09174409927800298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 7.378079132176936,
    "estimated_duration": 3600.0176137824265,
    "input_throughput": 5145.062048887917,
    "output_throughput": 4567.424597326914,
    "total_throughput": 9712.486646214831,
    "itl": 47.98334659724168,
    "ttft": 26678.507182134712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3272683626412944,
    "arrivals": 74944,
    "finished_requests": 74521,
    "scheduler_time": 54.11209465363829
}
#Debug simulation 
Total elapsed time: 7.378144996240735. Arrivals time: 0.17472903290763497 Scheduler time: 6.954474410507828 Scheduler overhead time: 0.09313973132520914 Adapter cache time: 0.02096483064815402 Engine time: 0.09173442423343658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 7.403483117930591,
    "estimated_duration": 3600.0136989405764,
    "input_throughput": 5144.060425506086,
    "output_throughput": 4567.581230271152,
    "total_throughput": 9711.641655777239,
    "itl": 47.976259291075834,
    "ttft": 27021.983874247715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1405053629120454,
    "arrivals": 74944,
    "finished_requests": 74514,
    "scheduler_time": 54.10882911384912
}
#Debug simulation 
Total elapsed time: 7.40356769785285. Arrivals time: 0.1817424134351313 Scheduler time: 6.974060712382197 Scheduler overhead time: 0.0929464460350573 Adapter cache time: 0.02086712373420596 Engine time: 0.09107027668505907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 7.377186887897551,
    "estimated_duration": 3600.017878522449,
    "input_throughput": 5145.5638902556875,
    "output_throughput": 4567.395372699804,
    "total_throughput": 9712.959262955492,
    "itl": 47.978574539018645,
    "ttft": 26276.829737587694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4519607403501906,
    "arrivals": 74944,
    "finished_requests": 74526,
    "scheduler_time": 54.09790973099562
}
#Debug simulation 
Total elapsed time: 7.377270427066833. Arrivals time: 0.18842742731794715 Scheduler time: 6.941342301201075 Scheduler overhead time: 0.09275059076026082 Adapter cache time: 0.021021756809204817 Engine time: 0.09078910807147622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_64_slots_32_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.435073228087276,
    "estimated_duration": 3600.0432644216007,
    "input_throughput": 5145.403440860064,
    "output_throughput": 4568.908702446567,
    "total_throughput": 9714.312143306632,
    "itl": 47.979660139302105,
    "ttft": 26166.75599359308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.022940848146029,
    "arrivals": 74944,
    "finished_requests": 74533,
    "scheduler_time": 54.11496820776857
}
#Debug simulation 
Total elapsed time: 7.435154289007187. Arrivals time: 0.17562141129747033 Scheduler time: 7.0111935012973845 Scheduler overhead time: 0.0926251607015729 Adapter cache time: 0.02088115317746997 Engine time: 0.0918837976641953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_64_slots_32_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 8640, 1080, 8640, 540, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 540, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 8640, 1080]
Prompts retrieved: 224100 . Total input tokens: 50148211 . Total output tokens: 44756551
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 7.423704819753766,
    "estimated_duration": 3600.028637922846,
    "input_throughput": 5144.03907927937,
    "output_throughput": 4567.562276251094,
    "total_throughput": 9711.601355530463,
    "itl": 47.98298589051252,
    "ttft": 27022.497519772456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.387998374812347,
    "arrivals": 74944,
    "finished_requests": 74514,
    "scheduler_time": 54.111040604522714
}
#Debug simulation 
Total elapsed time: 7.4237820650450885. Arrivals time: 0.17589009506627917 Scheduler time: 7.001331539358944 Scheduler overhead time: 0.09207558631896973 Adapter cache time: 0.020708170719444752 Engine time: 0.09101595124229789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.493910722900182,
    "estimated_duration": 3600.014207864266,
    "input_throughput": 5036.447623009942,
    "output_throughput": 4429.148630904844,
    "total_throughput": 9465.596253914786,
    "itl": 46.36443388164273,
    "ttft": 18606.86549526064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9051823612582934,
    "arrivals": 73090,
    "finished_requests": 72794,
    "scheduler_time": 51.23051245805336
}
#Debug simulation 
Total elapsed time: 6.493988863192499. Arrivals time: 0.17142168898135424 Scheduler time: 6.073200961109251 Scheduler overhead time: 0.09321650955826044 Adapter cache time: 0.022395774722099304 Engine time: 0.09030374558642507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.476335361134261,
    "estimated_duration": 3600.00078572696,
    "input_throughput": 5036.516956298012,
    "output_throughput": 4428.902922247658,
    "total_throughput": 9465.41987854567,
    "itl": 46.370130191974866,
    "ttft": 18754.21621247057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.191452689270946,
    "arrivals": 73090,
    "finished_requests": 72792,
    "scheduler_time": 51.24290603736293
}
#Debug simulation 
Total elapsed time: 6.476443126332015. Arrivals time: 0.17109785648062825 Scheduler time: 6.056525072082877 Scheduler overhead time: 0.09287428669631481 Adapter cache time: 0.022587613202631474 Engine time: 0.08999702800065279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.499002667143941,
    "estimated_duration": 3600.023453545419,
    "input_throughput": 5036.231356255318,
    "output_throughput": 4429.409754065876,
    "total_throughput": 9465.641110321194,
    "itl": 46.36493928712815,
    "ttft": 18662.817607916004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.168816557209875,
    "arrivals": 73090,
    "finished_requests": 72793,
    "scheduler_time": 51.22512171232937
}
#Debug simulation 
Total elapsed time: 6.499099077191204. Arrivals time: 0.17390835005789995 Scheduler time: 6.07681671762839 Scheduler overhead time: 0.0925796777009964 Adapter cache time: 0.022277704905718565 Engine time: 0.09045348828658462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.511855480726808,
    "estimated_duration": 3600.005318856851,
    "input_throughput": 5036.229781392979,
    "output_throughput": 4429.154567211357,
    "total_throughput": 9465.384348604337,
    "itl": 46.35856766928548,
    "ttft": 18718.63635100028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9673205808759158,
    "arrivals": 73090,
    "finished_requests": 72791,
    "scheduler_time": 51.22552023104198
}
#Debug simulation 
Total elapsed time: 6.5119450581260026. Arrivals time: 0.17485554469749331 Scheduler time: 6.087914203759283 Scheduler overhead time: 0.09276190213859081 Adapter cache time: 0.022371625527739525 Engine time: 0.09097909228876233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.476253703702241,
    "estimated_duration": 3600.0206809314345,
    "input_throughput": 5036.074680356899,
    "output_throughput": 4429.60816432702,
    "total_throughput": 9465.682844683919,
    "itl": 46.35346998726875,
    "ttft": 19025.886766215444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.150446440968661,
    "arrivals": 73090,
    "finished_requests": 72786,
    "scheduler_time": 51.222204683315525
}
#Debug simulation 
Total elapsed time: 6.476346662733704. Arrivals time: 0.17119770171120763 Scheduler time: 6.056296657770872 Scheduler overhead time: 0.09308380167931318 Adapter cache time: 0.022034539375454187 Engine time: 0.09074936341494322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_64_slots_32_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.474187358748168,
    "estimated_duration": 3600.030551232888,
    "input_throughput": 5035.596432311297,
    "output_throughput": 4429.1771342160755,
    "total_throughput": 9464.773566527372,
    "itl": 46.34043844919847,
    "ttft": 18973.815720328355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7794235727562526,
    "arrivals": 73090,
    "finished_requests": 72787,
    "scheduler_time": 51.211738653615505
}
#Debug simulation 
Total elapsed time: 6.4742736970074475. Arrivals time: 0.17055258387699723 Scheduler time: 6.055155450012535 Scheduler overhead time: 0.09236754383891821 Adapter cache time: 0.022295387461781502 Engine time: 0.0905578164383769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_64_slots_32_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 8640, 1080, 8640, 270, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 270, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 8640, 1080]
Prompts retrieved: 218430 . Total input tokens: 48876022 . Total output tokens: 43612074
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.465563513804227,
    "estimated_duration": 3600.0075772756136,
    "input_throughput": 5035.5588456063215,
    "output_throughput": 4429.098455416745,
    "total_throughput": 9464.657301023068,
    "itl": 46.3526281040368,
    "ttft": 19024.399467788513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.249818939268628,
    "arrivals": 73090,
    "finished_requests": 72785,
    "scheduler_time": 51.21537516120553
}
#Debug simulation 
Total elapsed time: 6.465651279781014. Arrivals time: 0.1723840180784464 Scheduler time: 6.043866676278412 Scheduler overhead time: 0.09282745001837611 Adapter cache time: 0.022480566520243883 Engine time: 0.09086317755281925 
