INFO 06-01 00:47:19 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:19 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.111364769749343,
    "estimated_duration": 3600.1807798739546,
    "input_throughput": 3330.5666390507763,
    "output_throughput": 2928.4304440870646,
    "total_throughput": 6258.997083137841,
    "itl": 291.0711362168972,
    "ttft": 2364946.77402674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1885868,
    "finished_requests": 48626,
    "scheduler_time": 29.648499885067395
}
#Debug simulation 
Total elapsed time: 4.111444142181426. Arrivals time: 0.21222116192802787 Scheduler time: 3.7831930345855653 Scheduler overhead time: 0.019952470902353525 Adapter cache time: 0.06573411170393229 Engine time: 0.020988398231565952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7018387890420854,
    "estimated_duration": 3600.0464572524556,
    "input_throughput": 3181.035060514201,
    "output_throughput": 2814.2642380599486,
    "total_throughput": 5995.299298574149,
    "itl": 180.9709653684586,
    "ttft": 2392746.1064834227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149368,
    "arrivals": 1885868,
    "finished_requests": 46459,
    "scheduler_time": 19.253619109013137
}
#Debug simulation 
Total elapsed time: 3.7019400410354137. Arrivals time: 0.20037171244621277 Scheduler time: 3.275202679913491 Scheduler overhead time: 0.03041582414880395 Adapter cache time: 0.15022721327841282 Engine time: 0.03163742367178202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.8159097861498594,
    "estimated_duration": 3600.0028949790176,
    "input_throughput": 3181.073553016336,
    "output_throughput": 2814.2982924070816,
    "total_throughput": 5995.371845423418,
    "itl": 180.96905217781926,
    "ttft": 2392719.419520009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418173,
    "arrivals": 1885868,
    "finished_requests": 46459,
    "scheduler_time": 19.253776534647844
}
#Debug simulation 
Total elapsed time: 3.8159997491165996. Arrivals time: 0.32158428570255637 Scheduler time: 3.270090727135539 Scheduler overhead time: 0.030380900017917156 Adapter cache time: 0.14803763991221786 Engine time: 0.031614115461707115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.689506603870541,
    "estimated_duration": 3600.1642071305587,
    "input_throughput": 3180.931019012462,
    "output_throughput": 2814.1721924609383,
    "total_throughput": 5995.1032114734,
    "itl": 180.96713397113678,
    "ttft": 2392709.347061506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1885868,
    "finished_requests": 46459,
    "scheduler_time": 19.255039213736985
}
#Debug simulation 
Total elapsed time: 3.6896721981465816. Arrivals time: 0.20164451049640775 Scheduler time: 3.2628302108496428 Scheduler overhead time: 0.030243161134421825 Adapter cache time: 0.14937657164409757 Engine time: 0.031577845104038715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.714338667690754,
    "estimated_duration": 3600.1028425502723,
    "input_throughput": 3442.8763682816707,
    "output_throughput": 2999.0868239618153,
    "total_throughput": 6441.963192243486,
    "itl": 282.96416695148827,
    "ttft": 2350921.6896098624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1866718,
    "finished_requests": 49866,
    "scheduler_time": 30.296439114719085
}
#Debug simulation 
Total elapsed time: 3.714453848078847. Arrivals time: 0.2117732153274119 Scheduler time: 3.4011925905942917 Scheduler overhead time: 0.020496081560850143 Adapter cache time: 0.05030691483989358 Engine time: 0.021299349144101143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7525352952070534,
    "estimated_duration": 3600.058796502827,
    "input_throughput": 3261.2261809182314,
    "output_throughput": 2854.762819424949,
    "total_throughput": 6115.989000343181,
    "itl": 177.65706239009222,
    "ttft": 2386112.5261397096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 1866718,
    "finished_requests": 47291,
    "scheduler_time": 19.421038641527893
}
#Debug simulation 
Total elapsed time: 3.7526235752739012. Arrivals time: 0.20392716117203236 Scheduler time: 3.3355382313020527 Scheduler overhead time: 0.030969727784395218 Adapter cache time: 0.13551136618480086 Engine time: 0.03233939502388239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.7406011251732707,
    "estimated_duration": 3600.1258804075455,
    "input_throughput": 3255.611717297282,
    "output_throughput": 2850.4133857781458,
    "total_throughput": 6106.025103075428,
    "itl": 177.20207677791373,
    "ttft": 2386277.344558712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 1866718,
    "finished_requests": 47212,
    "scheduler_time": 19.30314688792966
}
#Debug simulation 
Total elapsed time: 3.740690127015114. Arrivals time: 0.20300522213801742 Scheduler time: 3.32330041192472 Scheduler overhead time: 0.03103702561929822 Adapter cache time: 0.136879475787282 Engine time: 0.03213148796930909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7459967052564025,
    "estimated_duration": 3600.082317683386,
    "input_throughput": 3255.6511117618243,
    "output_throughput": 2850.4478771483723,
    "total_throughput": 6106.098988910197,
    "itl": 177.20022763289782,
    "ttft": 2386252.08192843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1866718,
    "finished_requests": 47212,
    "scheduler_time": 19.303303862840274
}
#Debug simulation 
Total elapsed time: 3.7460999940522015. Arrivals time: 0.20346889086067677 Scheduler time: 3.3293966613709927 Scheduler overhead time: 0.031203681603074074 Adapter cache time: 0.13499867171049118 Engine time: 0.03260347805917263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7632028800435364,
    "estimated_duration": 3600.0074245073256,
    "input_throughput": 3468.7775683432037,
    "output_throughput": 3047.231215502644,
    "total_throughput": 6516.008783845848,
    "itl": 279.9484164501873,
    "ttft": 2346765.4560640296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9548721761070179,
    "arrivals": 1857211,
    "finished_requests": 50484,
    "scheduler_time": 30.81662033689268
}
#Debug simulation 
Total elapsed time: 3.7632902888581157. Arrivals time: 0.21641535498201847 Scheduler time: 3.4490436664782465 Scheduler overhead time: 0.02084924280643463 Adapter cache time: 0.04578956216573715 Engine time: 0.021610433235764503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7654028041288257,
    "estimated_duration": 3600.122852568973,
    "input_throughput": 3266.054932433651,
    "output_throughput": 2883.419101265551,
    "total_throughput": 6149.474033699202,
    "itl": 175.36676477768265,
    "ttft": 2380738.840413836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0148934679501742,
    "arrivals": 1857211,
    "finished_requests": 47550,
    "scheduler_time": 19.58630465714345
}
#Debug simulation 
Total elapsed time: 3.765492355916649. Arrivals time: 0.20336887799203396 Scheduler time: 3.3553643180057406 Scheduler overhead time: 0.03143311943858862 Adapter cache time: 0.12837714655324817 Engine time: 0.032453884836286306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.232913107145578,
    "estimated_duration": 3600.080521203357,
    "input_throughput": 3266.093336176193,
    "output_throughput": 2883.4530058039304,
    "total_throughput": 6149.5463419801235,
    "itl": 175.36487941030262,
    "ttft": 2380713.6270460975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.972399554832376,
    "arrivals": 1857211,
    "finished_requests": 47550,
    "scheduler_time": 19.5864672046429
}
#Debug simulation 
Total elapsed time: 4.232973680365831. Arrivals time: 0.6821502051316202 Scheduler time: 3.344933308660984 Scheduler overhead time: 0.03114844625815749 Adapter cache time: 0.1280823703855276 Engine time: 0.032190967816859484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7636671611107886,
    "estimated_duration": 3600.0381919684364,
    "input_throughput": 3266.131738888811,
    "output_throughput": 2883.4869094330465,
    "total_throughput": 6149.618648321858,
    "itl": 175.36316716393952,
    "ttft": 2380688.9556339453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9299056417145779,
    "arrivals": 1857211,
    "finished_requests": 47550,
    "scheduler_time": 19.586631882838088
}
#Debug simulation 
Total elapsed time: 3.763731960207224. Arrivals time: 0.2042642505839467 Scheduler time: 3.35203786380589 Scheduler overhead time: 0.03131801215931773 Adapter cache time: 0.1289600981399417 Engine time: 0.03270126087591052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.82339427806437,
    "estimated_duration": 3600.214202383028,
    "input_throughput": 3528.483663997416,
    "output_throughput": 3063.841588286269,
    "total_throughput": 6592.325252283685,
    "itl": 276.34822376431555,
    "ttft": 2343164.23417263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8783599825086992,
    "arrivals": 1852456,
    "finished_requests": 50997,
    "scheduler_time": 30.910220630759888
}
#Debug simulation 
Total elapsed time: 3.8234825800172985. Arrivals time: 0.23129354184493423 Scheduler time: 3.502879516221583 Scheduler overhead time: 0.020947740878909826 Adapter cache time: 0.03712422167882323 Engine time: 0.021611918229609728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7669482231140137,
    "estimated_duration": 3600.0839658012114,
    "input_throughput": 3311.470263818364,
    "output_throughput": 2890.193978485261,
    "total_throughput": 6201.6642423036255,
    "itl": 175.649929670873,
    "ttft": 2380296.754357254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9288503708480909,
    "arrivals": 1852456,
    "finished_requests": 47871,
    "scheduler_time": 19.695647641680964
}
#Debug simulation 
Total elapsed time: 3.767034447286278. Arrivals time: 0.20366462273523211 Scheduler time: 3.3691703504882753 Scheduler overhead time: 0.031301542185246944 Adapter cache time: 0.11583905573934317 Engine time: 0.032553971745073795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.746138779912144,
    "estimated_duration": 3600.1239126631194,
    "input_throughput": 3313.964266072863,
    "output_throughput": 2891.9915682286282,
    "total_throughput": 6205.955834301491,
    "itl": 175.5681006997506,
    "ttft": 2379893.906200179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8888080296409344,
    "arrivals": 1852456,
    "finished_requests": 47906,
    "scheduler_time": 19.720639185351722
}
#Debug simulation 
Total elapsed time: 3.746224037837237. Arrivals time: 0.20429312204942107 Scheduler time: 3.3492954042740166 Scheduler overhead time: 0.031194953713566065 Adapter cache time: 0.11469676252454519 Engine time: 0.03227914683520794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7613004981540143,
    "estimated_duration": 3600.0844297049316,
    "input_throughput": 3314.000611085073,
    "output_throughput": 2892.023285368711,
    "total_throughput": 6206.023896453785,
    "itl": 175.56655948131328,
    "ttft": 2379871.577898381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.849174283752219,
    "arrivals": 1852456,
    "finished_requests": 47906,
    "scheduler_time": 19.720789973049726
}
#Debug simulation 
Total elapsed time: 3.7613869230262935. Arrivals time: 0.20616843923926353 Scheduler time: 3.3600932797417045 Scheduler overhead time: 0.03151578502729535 Adapter cache time: 0.1162958019413054 Engine time: 0.0327885402366519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.784228501841426,
    "estimated_duration": 3600.188531040776,
    "input_throughput": 3495.5297178178434,
    "output_throughput": 3078.80043070846,
    "total_throughput": 6574.330148526304,
    "itl": 276.9818803784266,
    "ttft": 2344858.1100318944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171502276300442,
    "arrivals": 1850068,
    "finished_requests": 51073,
    "scheduler_time": 31.177717842186446
}
#Debug simulation 
Total elapsed time: 3.7843262599781156. Arrivals time: 0.21872694976627827 Scheduler time: 3.476936981547624 Scheduler overhead time: 0.02093574358150363 Adapter cache time: 0.036419643089175224 Engine time: 0.02166760852560401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7830048222094774,
    "estimated_duration": 3600.092605620403,
    "input_throughput": 3278.4331662951904,
    "output_throughput": 2906.73661662563,
    "total_throughput": 6185.169782920821,
    "itl": 175.93287264590927,
    "ttft": 2381090.999698345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8646846995130222,
    "arrivals": 1850068,
    "finished_requests": 47913,
    "scheduler_time": 19.990230684775558
}
#Debug simulation 
Total elapsed time: 3.7830993202514946. Arrivals time: 0.20562114799395204 Scheduler time: 3.387440402060747 Scheduler overhead time: 0.03126010624691844 Adapter cache time: 0.11173036089166999 Engine time: 0.032567718997597694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.766830027103424,
    "estimated_duration": 3600.1685905179147,
    "input_throughput": 3277.392906286811,
    "output_throughput": 2905.8305845879922,
    "total_throughput": 6183.223490874803,
    "itl": 175.80586246550112,
    "ttft": 2381033.1931311227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8283197161718293,
    "arrivals": 1850068,
    "finished_requests": 47900,
    "scheduler_time": 19.966500334989178
}
#Debug simulation 
Total elapsed time: 3.7669189828447998. Arrivals time: 0.2055546031333506 Scheduler time: 3.372023031115532 Scheduler overhead time: 0.03140831086784601 Adapter cache time: 0.11099296389147639 Engine time: 0.032397085800766945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.797755351755768,
    "estimated_duration": 3600.1327902443313,
    "input_throughput": 3277.425497185403,
    "output_throughput": 2905.859480613771,
    "total_throughput": 6183.284977799174,
    "itl": 175.80440742316125,
    "ttft": 2381012.300921659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7923633281490776,
    "arrivals": 1850068,
    "finished_requests": 47900,
    "scheduler_time": 19.966656449426516
}
#Debug simulation 
Total elapsed time: 3.7978432159870863. Arrivals time: 0.20696923788636923 Scheduler time: 3.4020144068636 Scheduler overhead time: 0.031155136413872242 Adapter cache time: 0.11087853740900755 Engine time: 0.032402618788182735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.8153879758901894,
    "estimated_duration": 3600.2040325135413,
    "input_throughput": 3491.4754515243494,
    "output_throughput": 3089.2518589384053,
    "total_throughput": 6580.727310462755,
    "itl": 277.03553557630374,
    "ttft": 2343162.4805937237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7436985217756582,
    "arrivals": 1848950,
    "finished_requests": 51004,
    "scheduler_time": 31.307054913380867
}
#Debug simulation 
Total elapsed time: 3.8154746321961284. Arrivals time: 0.21495959162712097 Scheduler time: 3.511940731666982 Scheduler overhead time: 0.02099192375317216 Adapter cache time: 0.03613181272521615 Engine time: 0.02181265503168106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7509617009200156,
    "estimated_duration": 3600.0728213747657,
    "input_throughput": 3270.0216312581383,
    "output_throughput": 2909.7955846347886,
    "total_throughput": 6179.817215892927,
    "itl": 174.78732761879616,
    "ttft": 2380579.8735032137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7770072211371768,
    "arrivals": 1848950,
    "finished_requests": 47747,
    "scheduler_time": 19.878378396306584
}
#Debug simulation 
Total elapsed time: 3.75104996887967. Arrivals time: 0.20520774740725756 Scheduler time: 3.355697076767683 Scheduler overhead time: 0.031445284839719534 Adapter cache time: 0.11158298747614026 Engine time: 0.032578589860349894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.8983940659090877,
    "estimated_duration": 3600.040289003255,
    "input_throughput": 3270.051181360364,
    "output_throughput": 2909.8218794935624,
    "total_throughput": 6179.873060853926,
    "itl": 174.78600301068948,
    "ttft": 2380559.8085954157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7443195956619475,
    "arrivals": 1848950,
    "finished_requests": 47747,
    "scheduler_time": 19.878533650270644
}
#Debug simulation 
Total elapsed time: 3.898506300058216. Arrivals time: 0.34026663890108466 Scheduler time: 3.3686140826903284 Scheduler overhead time: 0.031359738670289516 Adapter cache time: 0.11123048979789019 Engine time: 0.03251702757552266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7694004611112177,
    "estimated_duration": 3600.0077590902397,
    "input_throughput": 3270.0807297634797,
    "output_throughput": 2909.848172840401,
    "total_throughput": 6179.9289026038805,
    "itl": 174.78476323100804,
    "ttft": 2380539.666779776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7116319701867188,
    "arrivals": 1848950,
    "finished_requests": 47747,
    "scheduler_time": 19.87869136272978
}
#Debug simulation 
Total elapsed time: 3.769496873021126. Arrivals time: 0.20529432175680995 Scheduler time: 3.373703812714666 Scheduler overhead time: 0.031470127403736115 Adapter cache time: 0.11181794805452228 Engine time: 0.03263980196788907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.4861619998700917,
    "estimated_duration": 3600.323388549207,
    "input_throughput": 3084.932880008759,
    "output_throughput": 2710.1637677975054,
    "total_throughput": 5795.096647806265,
    "itl": 313.7929889968435,
    "ttft": 2393877.586080796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1692537,
    "finished_requests": 44832,
    "scheduler_time": 27.485822664534957
}
#Debug simulation 
Total elapsed time: 3.486276878044009. Arrivals time: 0.19992627715691924 Scheduler time: 3.120492024347186 Scheduler overhead time: 0.01877158833667636 Adapter cache time: 0.11854726634919643 Engine time: 0.019873705692589283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.677375082857907,
    "estimated_duration": 3600.1696372610954,
    "input_throughput": 3093.5742262614617,
    "output_throughput": 2733.459250960931,
    "total_throughput": 5827.033477222392,
    "itl": 185.8350347796085,
    "ttft": 2402470.2035526303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 1692537,
    "finished_requests": 44949,
    "scheduler_time": 18.67731757077768
}
#Debug simulation 
Total elapsed time: 3.677458768710494. Arrivals time: 0.19648468447849154 Scheduler time: 3.2045112629421055 Scheduler overhead time: 0.029756624717265368 Adapter cache time: 0.20176251186057925 Engine time: 0.0311808199621737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.690550528932363,
    "estimated_duration": 3600.176559067478,
    "input_throughput": 3094.0249227346912,
    "output_throughput": 2733.524269862218,
    "total_throughput": 5827.549192596909,
    "itl": 185.9271439601623,
    "ttft": 2402354.8983959635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 1692537,
    "finished_requests": 44953,
    "scheduler_time": 18.6898775333948
}
#Debug simulation 
Total elapsed time: 3.6906636198982596. Arrivals time: 0.199118469376117 Scheduler time: 3.2132244873791933 Scheduler overhead time: 0.029929863288998604 Adapter cache time: 0.20342974225059152 Engine time: 0.031162305269390345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6730029080063105,
    "estimated_duration": 3600.133013061082,
    "input_throughput": 3094.0623470266787,
    "output_throughput": 2733.5573336587245,
    "total_throughput": 5827.619680685403,
    "itl": 185.92523262884228,
    "ttft": 2402327.756880855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1692537,
    "finished_requests": 44953,
    "scheduler_time": 18.69005122607193
}
#Debug simulation 
Total elapsed time: 3.6730882762931287. Arrivals time: 0.19726342894136906 Scheduler time: 3.1973672886379063 Scheduler overhead time: 0.02981298416852951 Adapter cache time: 0.203580885194242 Engine time: 0.03124380623921752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.018497309181839,
    "estimated_duration": 3600.1160581889976,
    "input_throughput": 3427.7033852646346,
    "output_throughput": 3012.921757154798,
    "total_throughput": 6440.625142419432,
    "itl": 282.26034164585116,
    "ttft": 2345939.4282918265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1577546,
    "finished_requests": 50140,
    "scheduler_time": 30.565884219284303
}
#Debug simulation 
Total elapsed time: 4.018619445152581. Arrivals time: 0.40343934018164873 Scheduler time: 3.4724643705412745 Scheduler overhead time: 0.020818482618778944 Adapter cache time: 0.0905749355442822 Engine time: 0.021746050100773573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.089738164097071,
    "estimated_duration": 3600.179136744198,
    "input_throughput": 3352.4987345254917,
    "output_throughput": 2961.399306824974,
    "total_throughput": 6313.898041350465,
    "itl": 172.32799786145216,
    "ttft": 2367285.7407686883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 1577546,
    "finished_requests": 49007,
    "scheduler_time": 20.3506173759441
}
#Debug simulation 
Total elapsed time: 4.089824179187417. Arrivals time: 0.3931111800484359 Scheduler time: 3.4551556180231273 Scheduler overhead time: 0.03204218624159694 Adapter cache time: 0.16113382764160633 Engine time: 0.0335803790949285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.0861931652762,
    "estimated_duration": 3600.1355871320093,
    "input_throughput": 3352.539288559143,
    "output_throughput": 2961.435129862253,
    "total_throughput": 6313.974418421396,
    "itl": 172.3261074440458,
    "ttft": 2367258.1903566555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 1577546,
    "finished_requests": 49007,
    "scheduler_time": 20.350787462828453
}
#Debug simulation 
Total elapsed time: 4.086280592251569. Arrivals time: 0.39797927252948284 Scheduler time: 3.4463681895285845 Scheduler overhead time: 0.03197073843330145 Adapter cache time: 0.1617137542925775 Engine time: 0.03336838819086552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.102794790174812,
    "estimated_duration": 3600.027244276326,
    "input_throughput": 3351.9662994733058,
    "output_throughput": 2961.099535273898,
    "total_throughput": 6313.065834747204,
    "itl": 172.12294680433158,
    "ttft": 2367258.714477068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1577546,
    "finished_requests": 48997,
    "scheduler_time": 20.314995330048458
}
#Debug simulation 
Total elapsed time: 4.102886142209172. Arrivals time: 0.40701053850352764 Scheduler time: 3.4571690652519464 Scheduler overhead time: 0.031934579368680716 Adapter cache time: 0.15839094575494528 Engine time: 0.033544772770255804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.917874719016254,
    "estimated_duration": 3600.2164011092245,
    "input_throughput": 3564.690443620544,
    "output_throughput": 3124.7393897027864,
    "total_throughput": 6689.42983332333,
    "itl": 272.3873409815227,
    "ttft": 2329974.640908561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 1558275,
    "finished_requests": 51944,
    "scheduler_time": 31.576369050340364
}
#Debug simulation 
Total elapsed time: 3.9179646926932037. Arrivals time: 0.22053069155663252 Scheduler time: 3.5668856822885573 Scheduler overhead time: 0.021453141700476408 Adapter cache time: 0.07644503796473145 Engine time: 0.0228023249655962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.966853952035308,
    "estimated_duration": 3600.107313755577,
    "input_throughput": 3439.7021868445177,
    "output_throughput": 3035.3997944023295,
    "total_throughput": 6475.101981246848,
    "itl": 167.70998956733573,
    "ttft": 2352141.4982678955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0408568469015937,
    "arrivals": 1558275,
    "finished_requests": 50188,
    "scheduler_time": 20.77226381685186
}
#Debug simulation 
Total elapsed time: 3.966938768979162. Arrivals time: 0.20852168556302786 Scheduler time: 3.5283181397244334 Scheduler overhead time: 0.03265248704701662 Adapter cache time: 0.14797582663595676 Engine time: 0.034254117868840694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.989813224878162,
    "estimated_duration": 3600.0731717405256,
    "input_throughput": 3439.886749305373,
    "output_throughput": 3035.680242775821,
    "total_throughput": 6475.566992081194,
    "itl": 167.70151789881,
    "ttft": 2351997.2867619824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9971371478284742,
    "arrivals": 1558275,
    "finished_requests": 50192,
    "scheduler_time": 20.776609312908423
}
#Debug simulation 
Total elapsed time: 3.9899010928347707. Arrivals time: 0.21077285474166274 Scheduler time: 3.546540183480829 Scheduler overhead time: 0.03283273987472057 Adapter cache time: 0.15041625034064054 Engine time: 0.03409557556733489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9768691868521273,
    "estimated_duration": 3600.030029617333,
    "input_throughput": 3439.9279722998162,
    "output_throughput": 3035.7166218309762,
    "total_throughput": 6475.644594130792,
    "itl": 167.6997558386179,
    "ttft": 2351970.0597052737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 1558275,
    "finished_requests": 50192,
    "scheduler_time": 20.776778293469988
}
#Debug simulation 
Total elapsed time: 3.976958897896111. Arrivals time: 0.2095531839877367 Scheduler time: 3.535477109719068 Scheduler overhead time: 0.03277635062113404 Adapter cache time: 0.14945740811526775 Engine time: 0.034467624966055155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9167924127541482,
    "estimated_duration": 3600.078803497345,
    "input_throughput": 3601.485608427339,
    "output_throughput": 3163.142703692319,
    "total_throughput": 6764.6283121196575,
    "itl": 269.7519528877975,
    "ttft": 2326586.718478356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9579326638509507,
    "arrivals": 1548789,
    "finished_requests": 52378,
    "scheduler_time": 31.982360467573784
}
#Debug simulation 
Total elapsed time: 3.916882140096277. Arrivals time: 0.21885955799371004 Scheduler time: 3.5754105923697352 Scheduler overhead time: 0.021690864115953445 Adapter cache time: 0.06865400215610862 Engine time: 0.0223997482098639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.011696430854499,
    "estimated_duration": 3600.036759608515,
    "input_throughput": 3459.9149485780545,
    "output_throughput": 3051.990225009483,
    "total_throughput": 6511.905173587537,
    "itl": 166.36216045958037,
    "ttft": 2353337.4673467143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0187007088819577,
    "arrivals": 1548789,
    "finished_requests": 50299,
    "scheduler_time": 20.8029590681326
}
#Debug simulation 
Total elapsed time: 4.0117894471623. Arrivals time: 0.22195962443947792 Scheduler time: 3.565944850910455 Scheduler overhead time: 0.03305868711322546 Adapter cache time: 0.1404242254793644 Engine time: 0.03499161684885621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.0775723699480295,
    "estimated_duration": 3600.1720663551328,
    "input_throughput": 3459.863242761822,
    "output_throughput": 3051.8874646799104,
    "total_throughput": 6511.750707441733,
    "itl": 166.36065999984643,
    "ttft": 2353359.120415507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9753896051272782,
    "arrivals": 1548789,
    "finished_requests": 50300,
    "scheduler_time": 20.804153266449045
}
#Debug simulation 
Total elapsed time: 4.077662490773946. Arrivals time: 0.3189425552263856 Scheduler time: 3.537379663903266 Scheduler overhead time: 0.03312710393220186 Adapter cache time: 0.13832734199240804 Engine time: 0.03457020781934261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9842590508051217,
    "estimated_duration": 3600.129729334978,
    "input_throughput": 3459.9039302677884,
    "output_throughput": 3051.9233544480066,
    "total_throughput": 6511.827284715795,
    "itl": 166.3590089827429,
    "ttft": 2353333.960334274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9328956920094801,
    "arrivals": 1548789,
    "finished_requests": 50300,
    "scheduler_time": 20.80431015940982
}
#Debug simulation 
Total elapsed time: 3.9843494347296655. Arrivals time: 0.2123990412801504 Scheduler time: 3.549781278707087 Scheduler overhead time: 0.033286604564636946 Adapter cache time: 0.13894679583609104 Engine time: 0.03460886050015688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.038649161811918,
    "estimated_duration": 3600.1407198912148,
    "input_throughput": 3633.8510124668987,
    "output_throughput": 3182.8569746424378,
    "total_throughput": 6816.7079871093365,
    "itl": 267.2170117529717,
    "ttft": 2320212.1864489107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9028438844601612,
    "arrivals": 1544103,
    "finished_requests": 52801,
    "scheduler_time": 32.18993766231075
}
#Debug simulation 
Total elapsed time: 4.03876809310168. Arrivals time: 0.32913185749202967 Scheduler time: 3.5949965650215745 Scheduler overhead time: 0.021726506762206554 Adapter cache time: 0.06044466095045209 Engine time: 0.02247449103742838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.973312098067254,
    "estimated_duration": 3600.1334845675797,
    "input_throughput": 3472.3426377345872,
    "output_throughput": 3059.4404477541098,
    "total_throughput": 6531.783085488697,
    "itl": 164.83716245362677,
    "ttft": 2347719.024247868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9549436328653296,
    "arrivals": 1544103,
    "finished_requests": 50488,
    "scheduler_time": 20.7390842422322
}
#Debug simulation 
Total elapsed time: 3.973395621869713. Arrivals time: 0.20983063988387585 Scheduler time: 3.5528016360476613 Scheduler overhead time: 0.03335312008857727 Adapter cache time: 0.1270681112073362 Engine time: 0.03486630506813526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.984637262765318,
    "estimated_duration": 3600.0948364602177,
    "input_throughput": 3472.3799143834412,
    "output_throughput": 3059.4732917730216,
    "total_throughput": 6531.853206156463,
    "itl": 164.83554798873806,
    "ttft": 2347695.5952551183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9161270776134945,
    "arrivals": 1544103,
    "finished_requests": 50488,
    "scheduler_time": 20.739252690119834
}
#Debug simulation 
Total elapsed time: 3.9847218240611255. Arrivals time: 0.21059977263212204 Scheduler time: 3.5643396792002022 Scheduler overhead time: 0.033416757360100746 Adapter cache time: 0.1261773481965065 Engine time: 0.03467213036492467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.009475449100137,
    "estimated_duration": 3600.054956830412,
    "input_throughput": 3472.418379692219,
    "output_throughput": 3059.507183106276,
    "total_throughput": 6531.925562798495,
    "itl": 164.83395744556307,
    "ttft": 2347671.816294972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8760847364063387,
    "arrivals": 1544103,
    "finished_requests": 50488,
    "scheduler_time": 20.739415401518958
}
#Debug simulation 
Total elapsed time: 4.009564337786287. Arrivals time: 0.21887479536235332 Scheduler time: 3.580336453858763 Scheduler overhead time: 0.03330278676003218 Adapter cache time: 0.12675030436366796 Engine time: 0.034824826288968325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.052982133813202,
    "estimated_duration": 3600.2651109376734,
    "input_throughput": 3645.5409797812563,
    "output_throughput": 3197.9045001498266,
    "total_throughput": 6843.445479931083,
    "itl": 266.0070326595085,
    "ttft": 2316990.199020169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8508155928133044,
    "arrivals": 1541713,
    "finished_requests": 53350,
    "scheduler_time": 32.37534642573356
}
#Debug simulation 
Total elapsed time: 4.05307242507115. Arrivals time: 0.32967334520071745 Scheduler time: 3.610414774157107 Scheduler overhead time: 0.021745747420936823 Adapter cache time: 0.05876293545588851 Engine time: 0.02252928027883172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0055324588902295,
    "estimated_duration": 3600.175560557843,
    "input_throughput": 3496.1311714614576,
    "output_throughput": 3080.4264440597462,
    "total_throughput": 6576.557615521204,
    "itl": 165.64519989354565,
    "ttft": 2343945.593299425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9000268246675884,
    "arrivals": 1541713,
    "finished_requests": 51147,
    "scheduler_time": 21.16345212039728
}
#Debug simulation 
Total elapsed time: 4.005620944779366. Arrivals time: 0.21516049467027187 Scheduler time: 3.586438269354403 Scheduler overhead time: 0.03321366244927049 Adapter cache time: 0.12087879423052073 Engine time: 0.03448221925646067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.990634218789637,
    "estimated_duration": 3600.1046896448775,
    "input_throughput": 3488.150785203616,
    "output_throughput": 3073.521453925129,
    "total_throughput": 6561.672239128746,
    "itl": 164.95938837735264,
    "ttft": 2344495.6530669234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8624360553710746,
    "arrivals": 1541713,
    "finished_requests": 51029,
    "scheduler_time": 20.972152050538693
}
#Debug simulation 
Total elapsed time: 3.9907500240951777. Arrivals time: 0.20798997627571225 Scheduler time: 3.5751996063627303 Scheduler overhead time: 0.03328842530027032 Adapter cache time: 0.12397689511999488 Engine time: 0.034847977571189404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.020769739057869,
    "estimated_duration": 3600.067672394946,
    "input_throughput": 3488.1866516820173,
    "output_throughput": 3073.5530570287883,
    "total_throughput": 6561.739708710806,
    "itl": 164.95805655925906,
    "ttft": 2344473.045730218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8252538813930016,
    "arrivals": 1541713,
    "finished_requests": 51029,
    "scheduler_time": 20.972316974583386
}
#Debug simulation 
Total elapsed time: 4.0208541811443865. Arrivals time: 0.20833883713930845 Scheduler time: 3.6046465318650007 Scheduler overhead time: 0.033397933933883905 Adapter cache time: 0.1244562491774559 Engine time: 0.03451434336602688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.457007823046297,
    "estimated_duration": 3600.1298747527235,
    "input_throughput": 3647.831455219938,
    "output_throughput": 3208.243702817339,
    "total_throughput": 6856.075158037277,
    "itl": 265.9652799162976,
    "ttft": 2314289.97450931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7436985217756582,
    "arrivals": 1540502,
    "finished_requests": 53035,
    "scheduler_time": 32.49144967421588
}
#Debug simulation 
Total elapsed time: 4.457070759031922. Arrivals time: 0.6577511359937489 Scheduler time: 3.693100138567388 Scheduler overhead time: 0.021893534809350967 Adapter cache time: 0.05143163772299886 Engine time: 0.022850547917187214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9900416838936508,
    "estimated_duration": 3600.044513956042,
    "input_throughput": 3485.944951888791,
    "output_throughput": 3084.1624199248927,
    "total_throughput": 6570.107371813683,
    "itl": 165.04648702565078,
    "ttft": 2343108.4827942867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7838045123638618,
    "arrivals": 1540502,
    "finished_requests": 50720,
    "scheduler_time": 21.067128599370697
}
#Debug simulation 
Total elapsed time: 3.990141374990344. Arrivals time: 0.20837533101439476 Scheduler time: 3.5845362353138626 Scheduler overhead time: 0.03312971815466881 Adapter cache time: 0.11406818265095353 Engine time: 0.03463171934708953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.1196975712664425,
    "estimated_duration": 3600.0115747101604,
    "input_throughput": 3485.9768474523235,
    "output_throughput": 3084.190639274242,
    "total_throughput": 6570.167486726566,
    "itl": 165.04522401201655,
    "ttft": 2343088.1723888926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7507082915701919,
    "arrivals": 1540502,
    "finished_requests": 50720,
    "scheduler_time": 21.06728557428131
}
#Debug simulation 
Total elapsed time: 4.11978470440954. Arrivals time: 0.3235618737526238 Scheduler time: 3.5990014909766614 Scheduler overhead time: 0.033206257969141006 Adapter cache time: 0.11387350969016552 Engine time: 0.034641745034605265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.011158999055624,
    "estimated_duration": 3600.1538988315165,
    "input_throughput": 3485.9079230121874,
    "output_throughput": 3084.1875964257592,
    "total_throughput": 6570.095519437947,
    "itl": 165.04448272687853,
    "ttft": 2343064.9799163346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7176120707765231,
    "arrivals": 1540502,
    "finished_requests": 50721,
    "scheduler_time": 21.068403693919997
}
#Debug simulation 
Total elapsed time: 4.0112447128631175. Arrivals time: 0.20822613406926394 Scheduler time: 3.605723591055721 Scheduler overhead time: 0.0333787901327014 Adapter cache time: 0.1136164665222168 Engine time: 0.034821783658117056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.046662467066199,
    "estimated_duration": 3600.02784473293,
    "input_throughput": 3649.1453862559156,
    "output_throughput": 3219.7812072367196,
    "total_throughput": 6868.926593492635,
    "itl": 265.5674181701069,
    "ttft": 2315380.2444519917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1423678,
    "finished_requests": 53209,
    "scheduler_time": 32.653895675761845
}
#Debug simulation 
Total elapsed time: 4.046750776004046. Arrivals time: 0.2184960530139506 Scheduler time: 3.670786782633513 Scheduler overhead time: 0.022204579785466194 Adapter cache time: 0.10208621947094798 Engine time: 0.023066858761012554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.174565658904612,
    "estimated_duration": 3600.0559528569197,
    "input_throughput": 3600.566816111141,
    "output_throughput": 3190.9626268124184,
    "total_throughput": 6791.529442923559,
    "itl": 159.69781626778513,
    "ttft": 2328701.3312603654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 1423678,
    "finished_requests": 52415,
    "scheduler_time": 21.84876541651495
}
#Debug simulation 
Total elapsed time: 4.174695563968271. Arrivals time: 0.22295052791014314 Scheduler time: 3.708072536624968 Scheduler overhead time: 0.03451553825289011 Adapter cache time: 0.15705407271161675 Engine time: 0.03609133046120405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.2795431250706315,
    "estimated_duration": 3600.136358047407,
    "input_throughput": 3600.270298381104,
    "output_throughput": 3190.7666425808015,
    "total_throughput": 6791.036940961906,
    "itl": 159.52016096684753,
    "ttft": 2328571.663012304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 1423678,
    "finished_requests": 52412,
    "scheduler_time": 21.814323235645517
}
#Debug simulation 
Total elapsed time: 4.27965507702902. Arrivals time: 0.3138215821236372 Scheduler time: 3.7218032386153936 Scheduler overhead time: 0.03476942051202059 Adapter cache time: 0.15718941390514374 Engine time: 0.03601367212831974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.191522646229714,
    "estimated_duration": 3600.0928045835763,
    "input_throughput": 3600.3138539922325,
    "output_throughput": 3190.805244068903,
    "total_throughput": 6791.119098061135,
    "itl": 159.51849055860018,
    "ttft": 2328543.636305726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1423678,
    "finished_requests": 52412,
    "scheduler_time": 21.81448947088758
}
#Debug simulation 
Total elapsed time: 4.191651361994445. Arrivals time: 0.21945211198180914 Scheduler time: 3.72939565917477 Scheduler overhead time: 0.03458248730748892 Adapter cache time: 0.15593880647793412 Engine time: 0.0362045937217772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.117591366171837,
    "estimated_duration": 3600.249344791947,
    "input_throughput": 3753.5261327242692,
    "output_throughput": 3318.4023815690475,
    "total_throughput": 7071.928514293317,
    "itl": 257.977155678568,
    "ttft": 2299474.2015714874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1404624,
    "finished_requests": 54821,
    "scheduler_time": 33.63703745754461
}
#Debug simulation 
Total elapsed time: 4.117676455993205. Arrivals time: 0.22278362372890115 Scheduler time: 3.75040100235492 Scheduler overhead time: 0.022717377170920372 Adapter cache time: 0.08798114629462361 Engine time: 0.023455088026821613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.21804562676698,
    "estimated_duration": 3600.1405944807843,
    "input_throughput": 3664.4691099633706,
    "output_throughput": 3255.1692614355065,
    "total_throughput": 6919.638371398877,
    "itl": 156.5753652813981,
    "ttft": 2320025.5238607735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 1404624,
    "finished_requests": 53520,
    "scheduler_time": 22.277544475674095
}
#Debug simulation 
Total elapsed time: 4.2181712868623435. Arrivals time: 0.2143842801451683 Scheduler time: 3.7760637388564646 Scheduler overhead time: 0.03514639474451542 Adapter cache time: 0.13965883385390043 Engine time: 0.03652065573260188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.224251543171704,
    "estimated_duration": 3600.0970176612504,
    "input_throughput": 3664.5134659649752,
    "output_throughput": 3255.2086631301727,
    "total_throughput": 6919.7221290951475,
    "itl": 156.57376597155684,
    "ttft": 2319997.526279437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 1404624,
    "finished_requests": 53520,
    "scheduler_time": 22.277687355212937
}
#Debug simulation 
Total elapsed time: 4.224335515405983. Arrivals time: 0.21450006822124124 Scheduler time: 3.7819737857207656 Scheduler overhead time: 0.03518217196688056 Adapter cache time: 0.139709681738168 Engine time: 0.036633615382015705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.227908384054899,
    "estimated_duration": 3600.0082138806815,
    "input_throughput": 3665.021915540914,
    "output_throughput": 3255.617294096667,
    "total_throughput": 6920.639209637581,
    "itl": 156.83882211181808,
    "ttft": 2319803.5425452176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1404624,
    "finished_requests": 53526,
    "scheduler_time": 22.330892617548407
}
#Debug simulation 
Total elapsed time: 4.228039352688938. Arrivals time: 0.21539907110854983 Scheduler time: 3.7839739439077675 Scheduler overhead time: 0.03529593022540212 Adapter cache time: 0.14011325920000672 Engine time: 0.036753371357917786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.219451520126313,
    "estimated_duration": 3600.1853775791706,
    "input_throughput": 3870.0621047932705,
    "output_throughput": 3371.3352861183575,
    "total_throughput": 7241.397390911628,
    "itl": 251.8604617846716,
    "ttft": 2287545.4909269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9671141270827489,
    "arrivals": 1395198,
    "finished_requests": 56205,
    "scheduler_time": 34.02192488658322
}
#Debug simulation 
Total elapsed time: 4.219540067948401. Arrivals time: 0.2334271795116365 Scheduler time: 3.846819926984608 Scheduler overhead time: 0.02310187229886651 Adapter cache time: 0.08120561903342605 Engine time: 0.024348811246454716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.239162302110344,
    "estimated_duration": 3600.1665891308403,
    "input_throughput": 3757.602784505024,
    "output_throughput": 3289.7997097571424,
    "total_throughput": 7047.402494262166,
    "itl": 154.6390768044014,
    "ttft": 2308956.386184045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0310695053800067,
    "arrivals": 1395198,
    "finished_requests": 54568,
    "scheduler_time": 22.472709096925573
}
#Debug simulation 
Total elapsed time: 4.2392892320640385. Arrivals time: 0.21667529735714197 Scheduler time: 3.803216164931655 Scheduler overhead time: 0.035385929979383945 Adapter cache time: 0.13071032846346498 Engine time: 0.036836384795606136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.236711604055017,
    "estimated_duration": 3600.1230229238117,
    "input_throughput": 3757.648256423566,
    "output_throughput": 3289.8395206453606,
    "total_throughput": 7047.487777068927,
    "itl": 154.6373800213222,
    "ttft": 2308929.2184005976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9873498063068872,
    "arrivals": 1395198,
    "finished_requests": 54568,
    "scheduler_time": 22.47286258896816
}
#Debug simulation 
Total elapsed time: 4.236795627977699. Arrivals time: 0.21782350214198232 Scheduler time: 3.799642445985228 Scheduler overhead time: 0.0352870668284595 Adapter cache time: 0.13090364634990692 Engine time: 0.036737867165356874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.257019168231636,
    "estimated_duration": 3600.0806772169744,
    "input_throughput": 3757.6924555084565,
    "output_throughput": 3289.87821716146,
    "total_throughput": 7047.570672669916,
    "itl": 154.63570947941767,
    "ttft": 2308903.2922214703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9448558931890888,
    "arrivals": 1395198,
    "finished_requests": 54568,
    "scheduler_time": 22.473010795246335
}
#Debug simulation 
Total elapsed time: 4.2571437219157815. Arrivals time: 0.21651500277221203 Scheduler time: 3.821480416227132 Scheduler overhead time: 0.03554602712392807 Adapter cache time: 0.1300542624667287 Engine time: 0.03701579570770264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.227229434065521,
    "estimated_duration": 3600.211606327048,
    "input_throughput": 3903.639990299871,
    "output_throughput": 3431.0894332686817,
    "total_throughput": 7334.729423568552,
    "itl": 248.87648599843217,
    "ttft": 2290839.5590381077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8967229089722957,
    "arrivals": 1390337,
    "finished_requests": 56847,
    "scheduler_time": 34.68486114630963
}
#Debug simulation 
Total elapsed time: 4.227316806092858. Arrivals time: 0.22651172894984484 Scheduler time: 3.8716622344218194 Scheduler overhead time: 0.02328162081539631 Adapter cache time: 0.07085222098976374 Engine time: 0.024352301843464375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.316951246932149,
    "estimated_duration": 3600.0759353090766,
    "input_throughput": 3760.233462641615,
    "output_throughput": 3322.2046464898203,
    "total_throughput": 7082.438109131435,
    "itl": 153.2566045200115,
    "ttft": 2314776.5616065846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9510065088677274,
    "arrivals": 1390337,
    "finished_requests": 54760,
    "scheduler_time": 22.726948005703164
}
#Debug simulation 
Total elapsed time: 4.317081719171256. Arrivals time: 0.2317121047526598 Scheduler time: 3.8813025900162756 Scheduler overhead time: 0.03564190911129117 Adapter cache time: 0.11437093839049339 Engine time: 0.03738892311230302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.256868328899145,
    "estimated_duration": 3600.1487989480884,
    "input_throughput": 3744.2013518826134,
    "output_throughput": 3306.4155580119514,
    "total_throughput": 7050.616909894565,
    "itl": 152.99864620610109,
    "ttft": 2316368.120120945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9097383817052499,
    "arrivals": 1390337,
    "finished_requests": 54500,
    "scheduler_time": 22.472186678368082
}
#Debug simulation 
Total elapsed time: 4.256959419697523. Arrivals time: 0.21475202962756157 Scheduler time: 3.838629422709346 Scheduler overhead time: 0.03586180368438363 Adapter cache time: 0.11388462921604514 Engine time: 0.0372311775572598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.264875472988933,
    "estimated_duration": 3600.1590224767524,
    "input_throughput": 3761.603005714853,
    "output_throughput": 3323.1190414942994,
    "total_throughput": 7084.722047209153,
    "itl": 153.54517253336778,
    "ttft": 2314825.496076814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8701046358165343,
    "arrivals": 1390337,
    "finished_requests": 54781,
    "scheduler_time": 22.795834218473868
}
#Debug simulation 
Total elapsed time: 4.265013743657619. Arrivals time: 0.21470731357112527 Scheduler time: 3.8468369697220623 Scheduler overhead time: 0.03557240404188633 Adapter cache time: 0.11409191461279988 Engine time: 0.037212318275123835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.2271074848249555,
    "estimated_duration": 3600.1346593018893,
    "input_throughput": 3909.0918345618156,
    "output_throughput": 3434.802075541772,
    "total_throughput": 7343.893910103588,
    "itl": 248.71150879060662,
    "ttft": 2285961.945767495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8416341295815062,
    "arrivals": 1387991,
    "finished_requests": 56881,
    "scheduler_time": 34.70243272480405
}
#Debug simulation 
Total elapsed time: 4.22719814395532. Arrivals time: 0.2232703142799437 Scheduler time: 3.8799859541468322 Scheduler overhead time: 0.023295236751437187 Adapter cache time: 0.06554525485262275 Engine time: 0.024385179858654737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.263245737180114,
    "estimated_duration": 3600.05341117499,
    "input_throughput": 3759.8522727423124,
    "output_throughput": 3324.5762306881043,
    "total_throughput": 7084.428503430417,
    "itl": 153.56029768580677,
    "ttft": 2309544.2240665094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8897010047617414,
    "arrivals": 1387991,
    "finished_requests": 54814,
    "scheduler_time": 22.799454946609245
}
#Debug simulation 
Total elapsed time: 4.263357668183744. Arrivals time: 0.2161867842078209 Scheduler time: 3.8477355209179223 Scheduler overhead time: 0.03575068712234497 Adapter cache time: 0.11000655870884657 Engine time: 0.03705360321328044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.249469236005098,
    "estimated_duration": 3600.0143461134267,
    "input_throughput": 3759.893072263198,
    "output_throughput": 3324.612306870763,
    "total_throughput": 7084.505379133961,
    "itl": 153.55888558181974,
    "ttft": 2309520.561764131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8504758541914661,
    "arrivals": 1387991,
    "finished_requests": 54814,
    "scheduler_time": 22.79961503561362
}
#Debug simulation 
Total elapsed time: 4.249555573798716. Arrivals time: 0.21662582084536552 Scheduler time: 3.8343112030997872 Scheduler overhead time: 0.03568412456661463 Adapter cache time: 0.10944403382018209 Engine time: 0.036989932879805565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.269580508116633,
    "estimated_duration": 3600.108529507645,
    "input_throughput": 3760.062756177877,
    "output_throughput": 3324.8783757185843,
    "total_throughput": 7084.941131896461,
    "itl": 153.6886893941014,
    "ttft": 2309417.0351922642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8132936802133929,
    "arrivals": 1387991,
    "finished_requests": 54820,
    "scheduler_time": 22.83066404878423
}
#Debug simulation 
Total elapsed time: 4.269702696241438. Arrivals time: 0.21929050562903285 Scheduler time: 3.8521072026342154 Scheduler overhead time: 0.03572838753461838 Adapter cache time: 0.1086415653117001 Engine time: 0.03727840166538954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.24376983800903,
    "estimated_duration": 3600.0714678423,
    "input_throughput": 3896.5834776629194,
    "output_throughput": 3448.064881734109,
    "total_throughput": 7344.648359397028,
    "itl": 248.8748013901135,
    "ttft": 2286171.1632668516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7865453501907167,
    "arrivals": 1386791,
    "finished_requests": 56864,
    "scheduler_time": 34.89875482012013
}
#Debug simulation 
Total elapsed time: 4.243857868947089. Arrivals time: 0.2227190937846899 Scheduler time: 3.8989651943556964 Scheduler overhead time: 0.023390996269881725 Adapter cache time: 0.06365332612767816 Engine time: 0.024393621366471052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.136249005328864,
    "estimated_duration": 3600.133379157978,
    "input_throughput": 3590.442530499587,
    "output_throughput": 3198.9050924256444,
    "total_throughput": 6789.347622925231,
    "itl": 139.57551333951582,
    "ttft": 2330146.2359110164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8199638281553091,
    "arrivals": 1386791,
    "finished_requests": 52480,
    "scheduler_time": 18.298145022863366
}
#Debug simulation 
Total elapsed time: 4.136334969196469. Arrivals time: 0.21140518132597208 Scheduler time: 3.7272333120927215 Scheduler overhead time: 0.03848366625607014 Adapter cache time: 0.10126709518954158 Engine time: 0.03991881664842367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.1681449338793755,
    "estimated_duration": 3600.098395132607,
    "input_throughput": 3590.477420693908,
    "output_throughput": 3198.936177847383,
    "total_throughput": 6789.413598541291,
    "itl": 139.57418182711976,
    "ttft": 2330124.4072298952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7848246307694373,
    "arrivals": 1386791,
    "finished_requests": 52480,
    "scheduler_time": 18.298300194877587
}
#Debug simulation 
Total elapsed time: 4.168235168792307. Arrivals time: 0.22316962759941816 Scheduler time: 3.745826582890004 Scheduler overhead time: 0.0386380678974092 Adapter cache time: 0.10222693299874663 Engine time: 0.040330950170755386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.127551469951868,
    "estimated_duration": 3600.0642443600414,
    "input_throughput": 3590.5114805243647,
    "output_throughput": 3198.966523456363,
    "total_throughput": 6789.478003980727,
    "itl": 139.57291547560948,
    "ttft": 2330103.384069647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7505026240204471,
    "arrivals": 1386791,
    "finished_requests": 52480,
    "scheduler_time": 18.298471429059642
}
#Debug simulation 
Total elapsed time: 4.127638753969222. Arrivals time: 0.21054211119189858 Scheduler time: 3.7192035489715636 Scheduler overhead time: 0.03846989292651415 Adapter cache time: 0.10156671237200499 Engine time: 0.039958483539521694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.766321808099747,
    "estimated_duration": 3600.0063989668733,
    "input_throughput": 4382.664432076523,
    "output_throughput": 3879.2175491709468,
    "total_throughput": 8261.88198124747,
    "itl": 221.6125814082953,
    "ttft": 2232855.2563685444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1289387,
    "finished_requests": 63741,
    "scheduler_time": 39.22375300861567
}
#Debug simulation 
Total elapsed time: 4.766409777104855. Arrivals time: 0.2581451521255076 Scheduler time: 4.373431094456464 Scheduler overhead time: 0.026230478193610907 Adapter cache time: 0.0693963784724474 Engine time: 0.027138751465827227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.645977857057005,
    "estimated_duration": 3600.0774164751106,
    "input_throughput": 4138.69349914937,
    "output_throughput": 3678.432841304304,
    "total_throughput": 7817.126340453675,
    "itl": 138.25086479766915,
    "ttft": 2261969.5639586803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 1289387,
    "finished_requests": 60218,
    "scheduler_time": 25.061472790358266
}
#Debug simulation 
Total elapsed time: 4.646070599090308. Arrivals time: 0.2276013740338385 Scheduler time: 4.230475846212357 Scheduler overhead time: 0.03944034827873111 Adapter cache time: 0.08949808357283473 Engine time: 0.0407901918515563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.645313195884228,
    "estimated_duration": 3600.0337308893113,
    "input_throughput": 4138.743721248236,
    "output_throughput": 3678.477478245374,
    "total_throughput": 7817.221199493611,
    "itl": 138.24947907123433,
    "ttft": 2261941.1236342173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 1289387,
    "finished_requests": 60218,
    "scheduler_time": 25.061613814316967
}
#Debug simulation 
Total elapsed time: 4.645405550021678. Arrivals time: 0.23062557633966208 Scheduler time: 4.2247833870351315 Scheduler overhead time: 0.03974307095631957 Adapter cache time: 0.09122845064848661 Engine time: 0.04061769088730216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.642151745967567,
    "estimated_duration": 3600.130353011721,
    "input_throughput": 4152.0254919367735,
    "output_throughput": 3689.628068296991,
    "total_throughput": 7841.6535602337635,
    "itl": 138.24363944921583,
    "ttft": 2263215.6477437112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1289387,
    "finished_requests": 60401,
    "scheduler_time": 25.207140883513723
}
#Debug simulation 
Total elapsed time: 4.642239870969206. Arrivals time: 0.2247693850658834 Scheduler time: 4.22798791853711 Scheduler overhead time: 0.039496943820267916 Adapter cache time: 0.09080516686663032 Engine time: 0.04082175251096487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.865754186175764,
    "estimated_duration": 3600.2287880967497,
    "input_throughput": 4469.666775957006,
    "output_throughput": 3969.8546512527687,
    "total_throughput": 8439.521427209775,
    "itl": 216.64939799294532,
    "ttft": 2217764.6988910125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1279697,
    "finished_requests": 65907,
    "scheduler_time": 40.180310416275766
}
#Debug simulation 
Total elapsed time: 4.865843336097896. Arrivals time: 0.24998674634844065 Scheduler time: 4.48806640598923 Scheduler overhead time: 0.02672550641000271 Adapter cache time: 0.060710280667990446 Engine time: 0.028057921677827835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.709125499706715,
    "estimated_duration": 3600.0908388910266,
    "input_throughput": 4192.7169828441365,
    "output_throughput": 3748.4190271590196,
    "total_throughput": 7941.136010003155,
    "itl": 136.79112446760942,
    "ttft": 2251724.126253208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149359,
    "arrivals": 1279697,
    "finished_requests": 61874,
    "scheduler_time": 25.776191602393418
}
#Debug simulation 
Total elapsed time: 4.7092150039970875. Arrivals time: 0.23020905628800392 Scheduler time: 4.299714982043952 Scheduler overhead time: 0.039659328293055296 Adapter cache time: 0.08002408687025309 Engine time: 0.04104376956820488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.727700223214924,
    "estimated_duration": 3600.042808577239,
    "input_throughput": 4193.050417077043,
    "output_throughput": 3748.5707025059846,
    "total_throughput": 7941.621119583027,
    "itl": 136.79134696349124,
    "ttft": 2251678.1358561264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 1279697,
    "finished_requests": 61877,
    "scheduler_time": 25.776487862770914
}
#Debug simulation 
Total elapsed time: 4.727793120313436. Arrivals time: 0.23543058475479484 Scheduler time: 4.312960241455585 Scheduler overhead time: 0.03969406243413687 Adapter cache time: 0.07997010368853807 Engine time: 0.041190764866769314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7305268119089305,
    "estimated_duration": 3600.074972240801,
    "input_throughput": 4186.176709153257,
    "output_throughput": 3742.001514933707,
    "total_throughput": 7928.178224086964,
    "itl": 136.94344473614746,
    "ttft": 2250419.0238717645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1279697,
    "finished_requests": 61781,
    "scheduler_time": 25.736523789616193
}
#Debug simulation 
Total elapsed time: 4.730612539686263. Arrivals time: 0.23011675383895636 Scheduler time: 4.321179786231369 Scheduler overhead time: 0.039933360647410154 Adapter cache time: 0.07966747647151351 Engine time: 0.041157050989568233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.966910282149911,
    "estimated_duration": 3600.033153127531,
    "input_throughput": 4604.084266724206,
    "output_throughput": 4038.9772486867164,
    "total_throughput": 8643.061515410922,
    "itl": 211.42091508665706,
    "ttft": 2212125.761572702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9609931515948834,
    "arrivals": 1274994,
    "finished_requests": 66759,
    "scheduler_time": 40.74019106108956
}
#Debug simulation 
Total elapsed time: 4.9669982539489865. Arrivals time: 0.2623588414862752 Scheduler time: 4.582579613197595 Scheduler overhead time: 0.02746355812996626 Adapter cache time: 0.05369269335642457 Engine time: 0.028343369252979755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.770660997834057,
    "estimated_duration": 3600.029935929058,
    "input_throughput": 4303.958932497425,
    "output_throughput": 3793.1909575846084,
    "total_throughput": 8097.149890082033,
    "itl": 134.2717439758726,
    "ttft": 2247971.937985221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0216907591768596,
    "arrivals": 1274994,
    "finished_requests": 62444,
    "scheduler_time": 25.88795779377107
}
#Debug simulation 
Total elapsed time: 4.770769136026502. Arrivals time: 0.22948853531852365 Scheduler time: 4.36687857657671 Scheduler overhead time: 0.040460641495883465 Adapter cache time: 0.07310115545988083 Engine time: 0.04201080836355686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.775833670981228,
    "estimated_duration": 3600.1360042339493,
    "input_throughput": 4304.091562590051,
    "output_throughput": 3793.1880862111416,
    "total_throughput": 8097.279648801192,
    "itl": 134.27108717679351,
    "ttft": 2247995.906883061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.978788250740621,
    "arrivals": 1274994,
    "finished_requests": 62449,
    "scheduler_time": 25.889104344130377
}
#Debug simulation 
Total elapsed time: 4.775921809952706. Arrivals time: 0.23479594243690372 Scheduler time: 4.366702291648835 Scheduler overhead time: 0.04053161712363362 Adapter cache time: 0.07294737407937646 Engine time: 0.04204105073586106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.778080354910344,
    "estimated_duration": 3600.1280615984942,
    "input_throughput": 4303.874677480301,
    "output_throughput": 3793.100902620878,
    "total_throughput": 8096.975580101179,
    "itl": 134.25083619050588,
    "ttft": 2247991.414521115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9358857423043823,
    "arrivals": 1274994,
    "finished_requests": 62445,
    "scheduler_time": 25.8841395746915
}
#Debug simulation 
Total elapsed time: 4.778165391646326. Arrivals time: 0.23237850330770016 Scheduler time: 4.373510888312012 Scheduler overhead time: 0.04043650534003973 Adapter cache time: 0.07110542012378573 Engine time: 0.04195588268339634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.949331870302558,
    "estimated_duration": 3600.0034141831234,
    "input_throughput": 4621.138672940648,
    "output_throughput": 4059.7000387335115,
    "total_throughput": 8680.83871167416,
    "itl": 211.04849731759884,
    "ttft": 2213555.8204192687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8844809579965647,
    "arrivals": 1272675,
    "finished_requests": 67182,
    "scheduler_time": 40.94980304587397
}
#Debug simulation 
Total elapsed time: 4.949420706368983. Arrivals time: 0.24845358869060874 Scheduler time: 4.585399534087628 Scheduler overhead time: 0.02741043781861663 Adapter cache time: 0.047062259167432785 Engine time: 0.028430091217160225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.7595771457999945,
    "estimated_duration": 3600.0213658116986,
    "input_throughput": 4295.948114883753,
    "output_throughput": 3793.2227651990743,
    "total_throughput": 8089.170880082827,
    "itl": 134.35044859217302,
    "ttft": 2250093.5613294146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9416277626645801,
    "arrivals": 1272675,
    "finished_requests": 62521,
    "scheduler_time": 25.907920231133122
}
#Debug simulation 
Total elapsed time: 4.759665060788393. Arrivals time: 0.22995040332898498 Scheduler time: 4.3660649745725095 Scheduler overhead time: 0.040493802167475224 Adapter cache time: 0.062196433544158936 Engine time: 0.042105036322027445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.768151910044253,
    "estimated_duration": 3600.126759266872,
    "input_throughput": 4296.248169647699,
    "output_throughput": 3793.29921227023,
    "total_throughput": 8089.547381917929,
    "itl": 134.34747227066936,
    "ttft": 2250151.944367589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9015854214574238,
    "arrivals": 1272675,
    "finished_requests": 62525,
    "scheduler_time": 25.909095083439887
}
#Debug simulation 
Total elapsed time: 4.768251109868288. Arrivals time: 0.23221222078427672 Scheduler time: 4.37174056796357 Scheduler overhead time: 0.040643978863954544 Adapter cache time: 0.06293441588059068 Engine time: 0.04183040605857968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.741060162894428,
    "estimated_duration": 3600.0209621679314,
    "input_throughput": 4293.815553421473,
    "output_throughput": 3791.45125637835,
    "total_throughput": 8085.266809799823,
    "itl": 134.06272338371048,
    "ttft": 2250374.1590153635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8611344849318278,
    "arrivals": 1272675,
    "finished_requests": 62490,
    "scheduler_time": 25.813969723190503
}
#Debug simulation 
Total elapsed time: 4.741148337256163. Arrivals time: 0.2305990494787693 Scheduler time: 4.345128407236189 Scheduler overhead time: 0.04045695345848799 Adapter cache time: 0.06426191003993154 Engine time: 0.04196217702701688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.033967457711697,
    "estimated_duration": 3600.185211060144,
    "input_throughput": 4613.442649832197,
    "output_throughput": 4069.9064467534195,
    "total_throughput": 8683.349096585616,
    "itl": 210.35120438934078,
    "ttft": 2207575.082640836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8416341295815062,
    "arrivals": 1271499,
    "finished_requests": 67449,
    "scheduler_time": 41.10427825595082
}
#Debug simulation 
Total elapsed time: 5.034058696124703. Arrivals time: 0.2733700405806303 Scheduler time: 4.645523899234831 Scheduler overhead time: 0.02745499089360237 Adapter cache time: 0.046608705539256334 Engine time: 0.02847069874405861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.739758711308241,
    "estimated_duration": 3600.042598480585,
    "input_throughput": 4295.974443893349,
    "output_throughput": 3804.349705689701,
    "total_throughput": 8100.32414958305,
    "itl": 133.96072930194666,
    "ttft": 2243883.2531737518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8820865228981755,
    "arrivals": 1271499,
    "finished_requests": 62785,
    "scheduler_time": 26.06396483458872
}
#Debug simulation 
Total elapsed time: 4.739844908006489. Arrivals time: 0.23295932821929455 Scheduler time: 4.34518665028736 Scheduler overhead time: 0.04039459628984332 Adapter cache time: 0.060263313353061676 Engine time: 0.0421878038905561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.7443771762773395,
    "estimated_duration": 3600.008015265299,
    "input_throughput": 4296.0157128595365,
    "output_throughput": 3804.3862518985807,
    "total_throughput": 8100.401964758118,
    "itl": 133.95968237353568,
    "ttft": 2243861.508456446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8473559208307444,
    "arrivals": 1271499,
    "finished_requests": 62785,
    "scheduler_time": 26.064112221368536
}
#Debug simulation 
Total elapsed time: 4.74446416227147. Arrivals time: 0.2326476718299091 Scheduler time: 4.349673088639975 Scheduler overhead time: 0.04027331667020917 Adapter cache time: 0.06122160516679287 Engine time: 0.04176834039390087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.749697361141443,
    "estimated_duration": 3600.1111227865053,
    "input_throughput": 4295.463243376407,
    "output_throughput": 3803.980358639649,
    "total_throughput": 8099.443602016056,
    "itl": 133.8958848588958,
    "ttft": 2243646.2638627356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8073135796235885,
    "arrivals": 1271499,
    "finished_requests": 62780,
    "scheduler_time": 26.042529583425214
}
#Debug simulation 
Total elapsed time: 4.749781146179885. Arrivals time: 0.22969041718170047 Scheduler time: 4.358292432036251 Scheduler overhead time: 0.040456831920892 Adapter cache time: 0.06059363903477788 Engine time: 0.04192941542714834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.156883426010609,
    "estimated_duration": 3600.026361202777,
    "input_throughput": 4667.901096809068,
    "output_throughput": 4156.998449033595,
    "total_throughput": 8824.899545842663,
    "itl": 207.34201475988007,
    "ttft": 2198726.441525056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9732351025706144,
    "arrivals": 1260602,
    "finished_requests": 68432,
    "scheduler_time": 42.04976091485395
}
#Debug simulation 
Total elapsed time: 5.15697282878682. Arrivals time: 0.3479262636974454 Scheduler time: 4.692295315209776 Scheduler overhead time: 0.027808021754026413 Adapter cache time: 0.047398457769304514 Engine time: 0.028756278567016125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.923985170200467,
    "estimated_duration": 3600.0159343906394,
    "input_throughput": 4328.675840330058,
    "output_throughput": 3862.2120716678105,
    "total_throughput": 8190.887911997868,
    "itl": 132.07557910851426,
    "ttft": 2238895.8311631004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.038275391925132,
    "arrivals": 1260602,
    "finished_requests": 63377,
    "scheduler_time": 26.414243531676792
}
#Debug simulation 
Total elapsed time: 4.924073275178671. Arrivals time: 0.32312276074662805 Scheduler time: 4.437075133901089 Scheduler overhead time: 0.04123197169974446 Adapter cache time: 0.06105540553107858 Engine time: 0.04258120618760586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.209590013604611,
    "estimated_duration": 3600.1214143121997,
    "input_throughput": 4328.78039558489,
    "output_throughput": 3862.463067139807,
    "total_throughput": 8191.2434627246985,
    "itl": 132.0745082049689,
    "ttft": 2238875.2616300704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9945556928520128,
    "arrivals": 1260602,
    "finished_requests": 63380,
    "scheduler_time": 26.415482521414948
}
#Debug simulation 
Total elapsed time: 5.2097017569467425. Arrivals time: 0.6326444149017334 Scheduler time: 4.413446119055152 Scheduler overhead time: 0.04108039569109678 Adapter cache time: 0.06085027474910021 Engine time: 0.04252031212672591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.905648103915155,
    "estimated_duration": 3600.0979173718583,
    "input_throughput": 4323.847394507448,
    "output_throughput": 3858.7739330549666,
    "total_throughput": 8182.621327562415,
    "itl": 131.55492081454787,
    "ttft": 2239237.6707795574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9508359937788932,
    "arrivals": 1260602,
    "finished_requests": 63318,
    "scheduler_time": 26.233314988809948
}
#Debug simulation 
Total elapsed time: 4.905764381866902. Arrivals time: 0.3227104782126844 Scheduler time: 4.4184270915575325 Scheduler overhead time: 0.041068722028285265 Adapter cache time: 0.06165996007621288 Engine time: 0.042747128289192915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.2221708172000945,
    "estimated_duration": 3600.0370708561354,
    "input_throughput": 4775.47415807903,
    "output_throughput": 4211.827462208356,
    "total_throughput": 8987.301620287386,
    "itl": 203.63107505845292,
    "ttft": 2192340.66497159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456907128752197,
    "arrivals": 1256018,
    "finished_requests": 69652,
    "scheduler_time": 42.542668037514275
}
#Debug simulation 
Total elapsed time: 5.222261171322316. Arrivals time: 0.35196253890171647 Scheduler time: 4.760149156674743 Scheduler overhead time: 0.028386465273797512 Adapter cache time: 0.03936919942498207 Engine time: 0.029280902817845345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9237820650450885,
    "estimated_duration": 3600.087415821508,
    "input_throughput": 4395.461046433811,
    "output_throughput": 3895.0718080827955,
    "total_throughput": 8290.532854516607,
    "itl": 131.61199464952787,
    "ttft": 2232858.907681369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0046975311101471,
    "arrivals": 1256018,
    "finished_requests": 64166,
    "scheduler_time": 26.778184111967548
}
#Debug simulation 
Total elapsed time: 4.9238944463431835. Arrivals time: 0.32038349378854036 Scheduler time: 4.44794964697212 Scheduler overhead time: 0.04122418351471424 Adapter cache time: 0.052509816363453865 Engine time: 0.04258903069421649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.989594967104495,
    "estimated_duration": 3600.0642889589735,
    "input_throughput": 4395.4892829360615,
    "output_throughput": 3895.0968300776926,
    "total_throughput": 8290.586113013755,
    "itl": 131.61703940533417,
    "ttft": 2232896.429023231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9638379992661101,
    "arrivals": 1256018,
    "finished_requests": 64166,
    "scheduler_time": 26.780780109628882
}
#Debug simulation 
Total elapsed time: 4.989688631147146. Arrivals time: 0.3440611162222922 Scheduler time: 4.489997910801321 Scheduler overhead time: 0.04121068073436618 Adapter cache time: 0.05250403517857194 Engine time: 0.04272967204451561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.947468874976039,
    "estimated_duration": 3600.0215305183515,
    "input_throughput": 4395.541489364805,
    "output_throughput": 3895.143093208375,
    "total_throughput": 8290.68458257318,
    "itl": 131.61571496263318,
    "ttft": 2232870.132221147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 1256018,
    "finished_requests": 64166,
    "scheduler_time": 26.780924177440344
}
#Debug simulation 
Total elapsed time: 4.947561817243695. Arrivals time: 0.32084746612235904 Scheduler time: 4.471474364865571 Scheduler overhead time: 0.04138889769092202 Adapter cache time: 0.052021995186805725 Engine time: 0.04261410050094128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.340289323125035,
    "estimated_duration": 3600.106625601569,
    "input_throughput": 4823.071038096987,
    "output_throughput": 4234.515414512937,
    "total_throughput": 9057.586452609925,
    "itl": 202.0231035574891,
    "ttft": 2187885.7398334937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9059043722040939,
    "arrivals": 1253655,
    "finished_requests": 70207,
    "scheduler_time": 42.65866955416895
}
#Debug simulation 
Total elapsed time: 5.3403852130286396. Arrivals time: 0.41552007384598255 Scheduler time: 4.817479018587619 Scheduler overhead time: 0.028503382112830877 Adapter cache time: 0.0361657883040607 Engine time: 0.02946170186623931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.876067263074219,
    "estimated_duration": 3600.126497464746,
    "input_throughput": 4432.804239306114,
    "output_throughput": 3904.5505789585523,
    "total_throughput": 8337.354818264666,
    "itl": 130.38778333610503,
    "ttft": 2230799.0220870697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9633753053657763,
    "arrivals": 1253655,
    "finished_requests": 64557,
    "scheduler_time": 26.687862037433664
}
#Debug simulation 
Total elapsed time: 4.8761530769988894. Arrivals time: 0.2356894677504897 Scheduler time: 4.48769090231508 Scheduler overhead time: 0.04144094372168183 Adapter cache time: 0.04920694185420871 Engine time: 0.04276408860459924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.984388500917703,
    "estimated_duration": 3600.0857686019185,
    "input_throughput": 4432.8543889657085,
    "output_throughput": 3904.594752324176,
    "total_throughput": 8337.449141289884,
    "itl": 130.38645936060004,
    "ttft": 2230774.271963356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9225157735217393,
    "arrivals": 1253655,
    "finished_requests": 64557,
    "scheduler_time": 26.687992706446963
}
#Debug simulation 
Total elapsed time: 4.984476495999843. Arrivals time: 0.3787061953917146 Scheduler time: 4.4528252594172955 Scheduler overhead time: 0.04156705550849438 Adapter cache time: 0.04918542085215449 Engine time: 0.042893837206065655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.727483413182199,
    "estimated_duration": 3600.0063452667587,
    "input_throughput": 4267.996921783612,
    "output_throughput": 3757.6880990185045,
    "total_throughput": 8025.685020802117,
    "itl": 121.1823567515176,
    "ttft": 2233803.732276571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8730946861114365,
    "arrivals": 1253655,
    "finished_requests": 62111,
    "scheduler_time": 22.024177453252936
}
#Debug simulation 
Total elapsed time: 4.727569238748401. Arrivals time: 0.22856565518304706 Scheduler time: 4.341211495921016 Scheduler overhead time: 0.04409412434324622 Adapter cache time: 0.04755750624462962 Engine time: 0.045662631280720234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.276673959102482,
    "estimated_duration": 3600.1534996202904,
    "input_throughput": 4888.646276292459,
    "output_throughput": 4293.7605303858245,
    "total_throughput": 9182.406806678284,
    "itl": 199.13792657217306,
    "ttft": 2178214.481591806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7865453501907167,
    "arrivals": 1252442,
    "finished_requests": 70826,
    "scheduler_time": 43.2884016588407
}
#Debug simulation 
Total elapsed time: 5.276768324896693. Arrivals time: 0.34542923932895064 Scheduler time: 4.830547157209367 Scheduler overhead time: 0.028875109739601612 Adapter cache time: 0.028624532278627157 Engine time: 0.030013381969183683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.308172923978418,
    "estimated_duration": 3600.1092362469726,
    "input_throughput": 4473.713418982245,
    "output_throughput": 3937.8485678336956,
    "total_throughput": 8411.56198681594,
    "itl": 128.9696688095313,
    "ttft": 2222804.3892711415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8229538784502111,
    "arrivals": 1252442,
    "finished_requests": 64829,
    "scheduler_time": 26.854699277924123
}
#Debug simulation 
Total elapsed time: 5.308292869944125. Arrivals time: 0.6320649068802595 Scheduler time: 4.5314692300744355 Scheduler overhead time: 0.041979828383773565 Adapter cache time: 0.040022734086960554 Engine time: 0.04318854631856084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.053870327305049,
    "estimated_duration": 3600.1147931072423,
    "input_throughput": 4470.428284901798,
    "output_throughput": 3935.3409027749203,
    "total_throughput": 8405.769187676719,
    "itl": 128.59770333872413,
    "ttft": 2223419.244218803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7886318717012204,
    "arrivals": 1252442,
    "finished_requests": 64784,
    "scheduler_time": 26.71844427507441
}
#Debug simulation 
Total elapsed time: 5.05396335804835. Arrivals time: 0.34586299303919077 Scheduler time: 4.561098106671125 Scheduler overhead time: 0.04191229119896889 Adapter cache time: 0.040874653961509466 Engine time: 0.04453518334776163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.901697454974055,
    "estimated_duration": 3600.138260066345,
    "input_throughput": 4470.54941709472,
    "output_throughput": 3935.5330202620876,
    "total_throughput": 8406.082437356808,
    "itl": 128.574202041099,
    "ttft": 2223449.0854110257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7534926743153493,
    "arrivals": 1252442,
    "finished_requests": 64787,
    "scheduler_time": 26.712873005454146
}
#Debug simulation 
Total elapsed time: 4.901784464716911. Arrivals time: 0.23700819024816155 Scheduler time: 4.519509186502546 Scheduler overhead time: 0.04199202684685588 Adapter cache time: 0.0402868059463799 Engine time: 0.04336464637890458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.318447035737336,
    "estimated_duration": 3600.0673004936925,
    "input_throughput": 4944.736171337358,
    "output_throughput": 4341.865775080498,
    "total_throughput": 9286.601946417855,
    "itl": 197.31552047314628,
    "ttft": 2175806.6478349427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9548721761070179,
    "arrivals": 1246365,
    "finished_requests": 71867,
    "scheduler_time": 43.768751673979565
}
#Debug simulation 
Total elapsed time: 5.318538318853825. Arrivals time: 0.3467981549911201 Scheduler time: 4.870524511672556 Scheduler overhead time: 0.029181701131165028 Adapter cache time: 0.02847118303179741 Engine time: 0.030081413220614195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.935872832778841,
    "estimated_duration": 3600.1195589267368,
    "input_throughput": 4503.670984980739,
    "output_throughput": 3968.006274841249,
    "total_throughput": 8471.677259821987,
    "itl": 127.98392519710269,
    "ttft": 2223517.1985837216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.00850477204193,
    "arrivals": 1246365,
    "finished_requests": 65495,
    "scheduler_time": 26.951750926099294
}
#Debug simulation 
Total elapsed time: 4.935960308182985. Arrivals time: 0.23437637463212013 Scheduler time: 4.555966881569475 Scheduler overhead time: 0.04245382687076926 Adapter cache time: 0.03968119155615568 Engine time: 0.043720435816794634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.943332510069013,
    "estimated_duration": 3600.07678860339,
    "input_throughput": 4503.724490357315,
    "output_throughput": 3968.053416311107,
    "total_throughput": 8471.777906668422,
    "itl": 127.98254537531945,
    "ttft": 2223491.71873346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9656022636056912,
    "arrivals": 1246365,
    "finished_requests": 65495,
    "scheduler_time": 26.951883111184554
}
#Debug simulation 
Total elapsed time: 4.943422473035753. Arrivals time: 0.2421506019309163 Scheduler time: 4.555855716578662 Scheduler overhead time: 0.042252007871866226 Adapter cache time: 0.039871086832135916 Engine time: 0.04363233083859086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.929774411953986,
    "estimated_duration": 3600.01775218613,
    "input_throughput": 4510.814978659139,
    "output_throughput": 3973.783182405918,
    "total_throughput": 8484.598161065058,
    "itl": 128.625884644896,
    "ttft": 2222797.904556998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9239255411247735,
    "arrivals": 1246365,
    "finished_requests": 65604,
    "scheduler_time": 27.195588010533058
}
#Debug simulation 
Total elapsed time: 4.929885535035282. Arrivals time: 0.23679943522438407 Scheduler time: 4.548392708878964 Scheduler overhead time: 0.04209763836115599 Adapter cache time: 0.03935304982587695 Engine time: 0.04359107045456767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.294020352885127,
    "estimated_duration": 3600.1491068362325,
    "input_throughput": 4960.438990176625,
    "output_throughput": 4368.8743252698505,
    "total_throughput": 9329.313315446476,
    "itl": 196.39240382558674,
    "ttft": 2178611.1659171986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9273277864116232,
    "arrivals": 1243986,
    "finished_requests": 71894,
    "scheduler_time": 44.06336551572929
}
#Debug simulation 
Total elapsed time: 5.294109096750617. Arrivals time: 0.2656329437159002 Scheduler time: 4.929809516761452 Scheduler overhead time: 0.029051157645881176 Adapter cache time: 0.02589163649827242 Engine time: 0.030273763928562403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.951228319201618,
    "estimated_duration": 3600.026548544564,
    "input_throughput": 4515.195591146843,
    "output_throughput": 3982.2836878233466,
    "total_throughput": 8497.47927897019,
    "itl": 127.66017420890053,
    "ttft": 2227559.70323101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9791427474771681,
    "arrivals": 1243986,
    "finished_requests": 65389,
    "scheduler_time": 27.08884028239233
}
#Debug simulation 
Total elapsed time: 4.951344249304384. Arrivals time: 0.24075225833803415 Scheduler time: 4.567910665646195 Scheduler overhead time: 0.042315547820180655 Adapter cache time: 0.0370710389688611 Engine time: 0.04358085058629513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.954820147249848,
    "estimated_duration": 3600.124456395746,
    "input_throughput": 4515.584168519361,
    "output_throughput": 3982.440933265326,
    "total_throughput": 8498.025101784686,
    "itl": 127.655578906219,
    "ttft": 2227564.9958363376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9391004062700118,
    "arrivals": 1243986,
    "finished_requests": 65396,
    "scheduler_time": 27.08994456420558
}
#Debug simulation 
Total elapsed time: 4.954907692037523. Arrivals time: 0.23905405635014176 Scheduler time: 4.573520815931261 Scheduler overhead time: 0.042364724446088076 Adapter cache time: 0.0365605466067791 Engine time: 0.04363021859899163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.957044528331608,
    "estimated_duration": 3600.0581468962037,
    "input_throughput": 4515.345124082151,
    "output_throughput": 3982.514841423024,
    "total_throughput": 8497.859965505175,
    "itl": 127.69106190142313,
    "ttft": 2227331.6126576117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8970150884706539,
    "arrivals": 1243986,
    "finished_requests": 65392,
    "scheduler_time": 27.09800692738177
}
#Debug simulation 
Total elapsed time: 4.957131759263575. Arrivals time: 0.23927281191572547 Scheduler time: 4.573342139367014 Scheduler overhead time: 0.04239167319610715 Adapter cache time: 0.03765413165092468 Engine time: 0.04450750024989247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.294613359030336,
    "estimated_duration": 3600.0340896792495,
    "input_throughput": 5001.5287498581,
    "output_throughput": 4400.541107490311,
    "total_throughput": 9402.069857348411,
    "itl": 194.98587247516576,
    "ttft": 2174513.813203044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8110292521421787,
    "arrivals": 1242821,
    "finished_requests": 72776,
    "scheduler_time": 44.34020853427466
}
#Debug simulation 
Total elapsed time: 5.294751851819456. Arrivals time: 0.25950561184436083 Scheduler time: 4.9399131634272635 Scheduler overhead time: 0.029443074017763138 Adapter cache time: 0.021815392654389143 Engine time: 0.030392245389521122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.974865943193436,
    "estimated_duration": 3600.03841590093,
    "input_throughput": 4537.036862678157,
    "output_throughput": 4004.0939386455384,
    "total_throughput": 8541.130801323696,
    "itl": 127.64524342298739,
    "ttft": 2223666.880981277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.841711370856505,
    "arrivals": 1242821,
    "finished_requests": 66024,
    "scheduler_time": 27.417182152385354
}
#Debug simulation 
Total elapsed time: 4.974987247958779. Arrivals time: 0.23941877763718367 Scheduler time: 4.598025253973901 Scheduler overhead time: 0.04262978816404939 Adapter cache time: 0.031163683626800776 Engine time: 0.04381723655387759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.957836837042123,
    "estimated_duration": 3600.0058521016595,
    "input_throughput": 4537.077902377467,
    "output_throughput": 4004.1301576175724,
    "total_throughput": 8541.208059995039,
    "itl": 127.64431212667759,
    "ttft": 2223646.6554483003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8090237453812759,
    "arrivals": 1242821,
    "finished_requests": 66024,
    "scheduler_time": 27.417305978587358
}
#Debug simulation 
Total elapsed time: 4.957925857976079. Arrivals time: 0.2391396164894104 Scheduler time: 4.580210153479129 Scheduler overhead time: 0.042772707995027304 Adapter cache time: 0.03167124977335334 Engine time: 0.04433336015790701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.001371833961457,
    "estimated_duration": 3600.0236760399675,
    "input_throughput": 4533.519073394785,
    "output_throughput": 4000.8703542315525,
    "total_throughput": 8534.389427626336,
    "itl": 127.32929938161477,
    "ttft": 2223872.172609428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7714329760847624,
    "arrivals": 1242821,
    "finished_requests": 65975,
    "scheduler_time": 27.29160706280786
}
#Debug simulation 
Total elapsed time: 5.0014875661581755. Arrivals time: 0.24256147164851427 Scheduler time: 4.621846832334995 Scheduler overhead time: 0.04248839430510998 Adapter cache time: 0.030877819284796715 Engine time: 0.04383142990991473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.370370617136359,
    "estimated_duration": 3600.1904049426735,
    "input_throughput": 5012.570994918629,
    "output_throughput": 4441.388427136428,
    "total_throughput": 9453.959422055057,
    "itl": 193.69069753049413,
    "ttft": 2166748.089783417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8875414457404974,
    "arrivals": 1239193,
    "finished_requests": 73368,
    "scheduler_time": 44.90328858959028
}
#Debug simulation 
Total elapsed time: 5.370461212005466. Arrivals time: 0.2651203633286059 Scheduler time: 5.011939521878958 Scheduler overhead time: 0.02979696774855256 Adapter cache time: 0.019201801624149084 Engine time: 0.030684716068208218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0024306159466505,
    "estimated_duration": 3600.0840145757925,
    "input_throughput": 4537.031617559248,
    "output_throughput": 4028.622371389011,
    "total_throughput": 8565.65398894826,
    "itl": 127.23341750651576,
    "ttft": 2215785.4346113205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9374119264143571,
    "arrivals": 1239193,
    "finished_requests": 66408,
    "scheduler_time": 27.684661329109453
}
#Debug simulation 
Total elapsed time: 5.00251802476123. Arrivals time: 0.23668862506747246 Scheduler time: 4.629900799598545 Scheduler overhead time: 0.0427748360671103 Adapter cache time: 0.029518140014261007 Engine time: 0.043831618037074804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.983901469968259,
    "estimated_duration": 3600.0444953138294,
    "input_throughput": 4537.081422538398,
    "output_throughput": 4028.6665953376464,
    "total_throughput": 8565.748017876045,
    "itl": 127.23220492648782,
    "ttft": 2215763.6560113737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8977781805256412,
    "arrivals": 1239193,
    "finished_requests": 66408,
    "scheduler_time": 27.684775813030164
}
#Debug simulation 
Total elapsed time: 4.983985751867294. Arrivals time: 0.24446784844622016 Scheduler time: 4.604020345490426 Scheduler overhead time: 0.04242247762158513 Adapter cache time: 0.02965874969959259 Engine time: 0.04375638114288449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.968613804318011,
    "estimated_duration": 3600.0049969490756,
    "input_throughput": 4537.131202274009,
    "output_throughput": 4028.7107968714745,
    "total_throughput": 8565.841999145483,
    "itl": 127.23091814871005,
    "ttft": 2215741.590777205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8581444346369256,
    "arrivals": 1239193,
    "finished_requests": 66408,
    "scheduler_time": 27.684911194159024
}
#Debug simulation 
Total elapsed time: 4.968723895959556. Arrivals time: 0.24074231926351786 Scheduler time: 4.592639148700982 Scheduler overhead time: 0.042352430522441864 Adapter cache time: 0.029583212453871965 Engine time: 0.04362935572862625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.417214013170451,
    "estimated_duration": 3600.0617739232976,
    "input_throughput": 5066.593337958822,
    "output_throughput": 4465.790314058799,
    "total_throughput": 9532.383652017621,
    "itl": 192.2879028489012,
    "ttft": 2166466.6289467635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8232712031179097,
    "arrivals": 1238058,
    "finished_requests": 73442,
    "scheduler_time": 45.03554561509262
}
#Debug simulation 
Total elapsed time: 5.417306935414672. Arrivals time: 0.2834588149562478 Scheduler time: 5.043140749447048 Scheduler overhead time: 0.029798758681863546 Adapter cache time: 0.01597102452069521 Engine time: 0.031152804847806692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.090846996288747,
    "estimated_duration": 3600.131762714619,
    "input_throughput": 4576.518329311507,
    "output_throughput": 4036.48698375486,
    "total_throughput": 8613.005313066367,
    "itl": 126.00550272604025,
    "ttft": 2220367.934720202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8493258527200709,
    "arrivals": 1238058,
    "finished_requests": 66298,
    "scheduler_time": 27.49784983867652
}
#Debug simulation 
Total elapsed time: 5.090937854256481. Arrivals time: 0.32950543286278844 Scheduler time: 4.628686850890517 Scheduler overhead time: 0.04285460151731968 Adapter cache time: 0.025923671666532755 Engine time: 0.044068644754588604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.973119869828224,
    "estimated_duration": 3600.1173079430378,
    "input_throughput": 4573.78901617184,
    "output_throughput": 4034.0952134968015,
    "total_throughput": 8607.884229668642,
    "itl": 125.80327660546381,
    "ttft": 2220208.320582015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8121436787419977,
    "arrivals": 1238058,
    "finished_requests": 66256,
    "scheduler_time": 27.40844639396381
}
#Debug simulation 
Total elapsed time: 4.9732436230406165. Arrivals time: 0.23989633983001113 Scheduler time: 4.5997530105523765 Scheduler overhead time: 0.043023860082030296 Adapter cache time: 0.026375235989689827 Engine time: 0.044140446931123734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.991852855775505,
    "estimated_duration": 3600.090152748625,
    "input_throughput": 4575.725968257502,
    "output_throughput": 4035.9458745516968,
    "total_throughput": 8611.671842809199,
    "itl": 125.91510956999008,
    "ttft": 2220251.4822467053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7774130766745667,
    "arrivals": 1238058,
    "finished_requests": 66285,
    "scheduler_time": 27.462459024519728
}
#Debug simulation 
Total elapsed time: 4.991981194820255. Arrivals time: 0.2417210740968585 Scheduler time: 4.617664479650557 Scheduler overhead time: 0.042735511902719736 Adapter cache time: 0.025889437645673752 Engine time: 0.04403932765126228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.4158769669011235,
    "estimated_duration": 3600.0777776559767,
    "input_throughput": 5117.717765530068,
    "output_throughput": 4507.825664412853,
    "total_throughput": 9625.543429942922,
    "itl": 190.3802631723454,
    "ttft": 2160445.736427999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7375775462877927,
    "arrivals": 1235689,
    "finished_requests": 74485,
    "scheduler_time": 45.422999940601926
}
#Debug simulation 
Total elapsed time: 5.415965397842228. Arrivals time: 0.2637028619647026 Scheduler time: 5.065297824330628 Scheduler overhead time: 0.030284110456705093 Adapter cache time: 0.01183113269507885 Engine time: 0.03099267603829503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0213454947806895,
    "estimated_duration": 3600.047472580575,
    "input_throughput": 4602.435141813025,
    "output_throughput": 4060.4836773226266,
    "total_throughput": 8662.918819135652,
    "itl": 125.43927206218483,
    "ttft": 2213970.0743501405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7553895615018003,
    "arrivals": 1235689,
    "finished_requests": 66904,
    "scheduler_time": 27.729341494175255
}
#Debug simulation 
Total elapsed time: 5.021438988856971. Arrivals time: 0.25431900937110186 Scheduler time: 4.6382289421744645 Scheduler overhead time: 0.042899202555418015 Adapter cache time: 0.021825509145855904 Engine time: 0.04426422296091914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.099484129343182,
    "estimated_duration": 3600.0185774524884,
    "input_throughput": 4602.472082720432,
    "output_throughput": 4060.516268319985,
    "total_throughput": 8662.988351040416,
    "itl": 125.43841281314714,
    "ttft": 2213953.8004949386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7263792938925345,
    "arrivals": 1235689,
    "finished_requests": 66904,
    "scheduler_time": 27.729456633694657
}
#Debug simulation 
Total elapsed time: 5.099574932362884. Arrivals time: 0.3252254989929497 Scheduler time: 4.6453504133969545 Scheduler overhead time: 0.04305523866787553 Adapter cache time: 0.021726575680077076 Engine time: 0.04421429382637143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.019326406996697,
    "estimated_duration": 3600.1287397568226,
    "input_throughput": 4602.495687728996,
    "output_throughput": 4060.750338885793,
    "total_throughput": 8663.246026614788,
    "itl": 125.43871590550457,
    "ttft": 2213939.1796722235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6936916684173057,
    "arrivals": 1235689,
    "finished_requests": 66909,
    "scheduler_time": 27.730701921849334
}
#Debug simulation 
Total elapsed time: 5.0194169650785625. Arrivals time: 0.24283400597050786 Scheduler time: 4.6475799777545035 Scheduler overhead time: 0.04297898057848215 Adapter cache time: 0.021828509867191315 Engine time: 0.044202351942658424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.2544962391257286,
    "estimated_duration": 3600.2995860798455,
    "input_throughput": 2874.1333193516393,
    "output_throughput": 2506.1236667319654,
    "total_throughput": 5380.256986083605,
    "itl": 337.8318186723,
    "ttft": 2413179.692549276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 1075699,
    "finished_requests": 41611,
    "scheduler_time": 25.454324477365674
}
#Debug simulation 
Total elapsed time: 3.254586256109178. Arrivals time: 0.19067035987973213 Scheduler time: 2.915925159584731 Scheduler overhead time: 0.0175743424333632 Adapter cache time: 0.1040130048058927 Engine time: 0.01835368713364005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4462214508093894,
    "estimated_duration": 3600.130969736082,
    "input_throughput": 2846.9880918669387,
    "output_throughput": 2498.901588755118,
    "total_throughput": 5345.889680622057,
    "itl": 203.50151871343814,
    "ttft": 2428589.4945968897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149354,
    "arrivals": 1075699,
    "finished_requests": 41219,
    "scheduler_time": 17.176411697276766
}
#Debug simulation 
Total elapsed time: 3.4463094039820135. Arrivals time: 0.18745577707886696 Scheduler time: 2.975011301692575 Scheduler overhead time: 0.02751192171126604 Adapter cache time: 0.21456911554560065 Engine time: 0.029101142659783363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.4568391530774534,
    "estimated_duration": 3600.0624962324237,
    "input_throughput": 2845.3197717317294,
    "output_throughput": 2497.406922632363,
    "total_throughput": 5342.7266943640925,
    "itl": 203.0127086111297,
    "ttft": 2428755.120597216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 1075699,
    "finished_requests": 41198,
    "scheduler_time": 17.116361828468047
}
#Debug simulation 
Total elapsed time: 3.456922839861363. Arrivals time: 0.1861870288848877 Scheduler time: 2.9846529364585876 Scheduler overhead time: 0.02757185511291027 Adapter cache time: 0.2169566168449819 Engine time: 0.028855098877102137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.461529183201492,
    "estimated_duration": 3600.018967845242,
    "input_throughput": 2845.3541749339865,
    "output_throughput": 2497.4371191664504,
    "total_throughput": 5342.791294100437,
    "itl": 203.01073312455145,
    "ttft": 2428728.6736876382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 1075699,
    "finished_requests": 41198,
    "scheduler_time": 17.116553140359887
}
#Debug simulation 
Total elapsed time: 3.461614757310599. Arrivals time: 0.1866672863252461 Scheduler time: 2.988486292306334 Scheduler overhead time: 0.027545523829758167 Adapter cache time: 0.2172883665189147 Engine time: 0.028889098670333624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6640772661194205,
    "estimated_duration": 3600.073095406514,
    "input_throughput": 3180.968746054555,
    "output_throughput": 2803.220582625546,
    "total_throughput": 5984.189328680101,
    "itl": 303.9804048407272,
    "ttft": 2361856.181786307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 961706,
    "finished_requests": 46308,
    "scheduler_time": 28.547345538572916
}
#Debug simulation 
Total elapsed time: 3.6641710069961846. Arrivals time: 0.20155060663819313 Scheduler time: 3.3308768230490386 Scheduler overhead time: 0.019399790558964014 Adapter cache time: 0.08311486942693591 Engine time: 0.02031337795779109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.670873510185629,
    "estimated_duration": 3600.1010752883185,
    "input_throughput": 3078.6916167658865,
    "output_throughput": 2731.412756018936,
    "total_throughput": 5810.104372784822,
    "itl": 185.17893138343877,
    "ttft": 2386636.358067317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149365,
    "arrivals": 961706,
    "finished_requests": 44812,
    "scheduler_time": 18.676455765988536
}
#Debug simulation 
Total elapsed time: 3.670958699192852. Arrivals time: 0.19476838363334537 Scheduler time: 3.2281042472459376 Scheduler overhead time: 0.029941880144178867 Adapter cache time: 0.1729260692372918 Engine time: 0.03131064819172025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.6860334230586886,
    "estimated_duration": 3600.057535428161,
    "input_throughput": 3078.728851115933,
    "output_throughput": 2731.44579030471,
    "total_throughput": 5810.174641420644,
    "itl": 185.17688591448814,
    "ttft": 2386609.394727661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 961706,
    "finished_requests": 44812,
    "scheduler_time": 18.676635604903357
}
#Debug simulation 
Total elapsed time: 3.6861195880919695. Arrivals time: 0.19836943177506328 Scheduler time: 3.239866206422448 Scheduler overhead time: 0.03005065117031336 Adapter cache time: 0.17216843040660024 Engine time: 0.031793869100511074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.686481180600822,
    "estimated_duration": 3600.013993969981,
    "input_throughput": 3078.7660877332746,
    "output_throughput": 2731.478826602027,
    "total_throughput": 5810.2449143353015,
    "itl": 185.1747783885802,
    "ttft": 2386582.4309963062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 961706,
    "finished_requests": 44812,
    "scheduler_time": 18.676813845796374
}
#Debug simulation 
Total elapsed time: 3.686566535849124. Arrivals time: 0.1946508907712996 Scheduler time: 3.2436439669691026 Scheduler overhead time: 0.029869087040424347 Adapter cache time: 0.17315957508981228 Engine time: 0.03134170267730951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7472459501586854,
    "estimated_duration": 3600.261253489865,
    "input_throughput": 3339.9492851647997,
    "output_throughput": 2924.3027821368737,
    "total_throughput": 6264.252067301673,
    "itl": 290.2052758326665,
    "ttft": 2335395.354332687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 942321,
    "finished_requests": 48722,
    "scheduler_time": 29.679733684275686
}
#Debug simulation 
Total elapsed time: 3.747333492152393. Arrivals time: 0.27072726748883724 Scheduler time: 3.3618302918039262 Scheduler overhead time: 0.02018519164994359 Adapter cache time: 0.06441335240378976 Engine time: 0.020982495043426752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.721399259287864,
    "estimated_duration": 3600.165461369976,
    "input_throughput": 3166.172811308072,
    "output_throughput": 2783.350684161854,
    "total_throughput": 5949.523495469926,
    "itl": 178.4325565465281,
    "ttft": 2368875.937078163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 942321,
    "finished_requests": 46121,
    "scheduler_time": 18.677407437470908
}
#Debug simulation 
Total elapsed time: 3.721516932360828. Arrivals time: 0.19968409417197108 Scheduler time: 3.293593999929726 Scheduler overhead time: 0.030868501868098974 Adapter cache time: 0.1507283840328455 Engine time: 0.03229391807690263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.809995503164828,
    "estimated_duration": 3600.062074712344,
    "input_throughput": 3190.356655424539,
    "output_throughput": 2806.0543930502026,
    "total_throughput": 5996.411048474742,
    "itl": 180.4509965131638,
    "ttft": 2363924.7155524176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 942321,
    "finished_requests": 46482,
    "scheduler_time": 19.288258331028203
}
#Debug simulation 
Total elapsed time: 3.810079686809331. Arrivals time: 0.19451207155361772 Scheduler time: 3.3838060800917447 Scheduler overhead time: 0.030639948789030313 Adapter cache time: 0.15476995753124356 Engine time: 0.03208932327106595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.718185397796333,
    "estimated_duration": 3600.018533622939,
    "input_throughput": 3190.3952417826563,
    "output_throughput": 2806.0883313935924,
    "total_throughput": 5996.483573176249,
    "itl": 180.4491860060777,
    "ttft": 2363897.8009229843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 942321,
    "finished_requests": 46482,
    "scheduler_time": 19.288436940695483
}
#Debug simulation 
Total elapsed time: 3.7182739437557757. Arrivals time: 0.19607082847505808 Scheduler time: 3.291698408778757 Scheduler overhead time: 0.030685745179653168 Adapter cache time: 0.15356957027688622 Engine time: 0.03205428784713149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.779788269661367,
    "estimated_duration": 3600.0192691238913,
    "input_throughput": 3417.2964310254715,
    "output_throughput": 2997.1861796800495,
    "total_throughput": 6414.482610705521,
    "itl": 284.1043475318119,
    "ttft": 2320872.510403772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 932854,
    "finished_requests": 49673,
    "scheduler_time": 30.419581260787723
}
#Debug simulation 
Total elapsed time: 3.77987661678344. Arrivals time: 0.2101012454368174 Scheduler time: 3.463829061947763 Scheduler overhead time: 0.020959068555384874 Adapter cache time: 0.05409312527626753 Engine time: 0.02141196932643652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8556155930273235,
    "estimated_duration": 3600.1780067860077,
    "input_throughput": 3234.0250893299944,
    "output_throughput": 2851.9259271754922,
    "total_throughput": 6085.951016505486,
    "itl": 177.68989624151996,
    "ttft": 2355885.884275888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 932854,
    "finished_requests": 47019,
    "scheduler_time": 19.55000852605487
}
#Debug simulation 
Total elapsed time: 3.855708311777562. Arrivals time: 0.2587430705316365 Scheduler time: 3.3770549087785184 Scheduler overhead time: 0.03135651210322976 Adapter cache time: 0.14141396805644035 Engine time: 0.03265146957710385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.768445301335305,
    "estimated_duration": 3600.1344546743508,
    "input_throughput": 3234.064212485967,
    "output_throughput": 2851.9604279415,
    "total_throughput": 6086.024640427467,
    "itl": 177.68788537318528,
    "ttft": 2355859.929766332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 932854,
    "finished_requests": 47019,
    "scheduler_time": 19.55017611346923
}
#Debug simulation 
Total elapsed time: 3.7685323851183057. Arrivals time: 0.1976756565272808 Scheduler time: 3.350695308763534 Scheduler overhead time: 0.03136759530752897 Adapter cache time: 0.14191737305372953 Engine time: 0.03245376842096448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7570423558354378,
    "estimated_duration": 3600.134927033281,
    "input_throughput": 3236.488141737996,
    "output_throughput": 2853.647212735432,
    "total_throughput": 6090.1353544734275,
    "itl": 178.16425915974907,
    "ttft": 2355510.192715862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 932854,
    "finished_requests": 47051,
    "scheduler_time": 19.638209559969663
}
#Debug simulation 
Total elapsed time: 3.75712738186121. Arrivals time: 0.1976976222358644 Scheduler time: 3.341633961070329 Scheduler overhead time: 0.030998985283076763 Adapter cache time: 0.1401145881973207 Engine time: 0.03232092596590519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.8313436252065003,
    "estimated_duration": 3600.20133836214,
    "input_throughput": 3467.0963723597242,
    "output_throughput": 3052.8284301455496,
    "total_throughput": 6519.924802505274,
    "itl": 279.7657455131221,
    "ttft": 2316650.09856477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9609931515948834,
    "arrivals": 928080,
    "finished_requests": 50510,
    "scheduler_time": 30.989161820919993
}
#Debug simulation 
Total elapsed time: 3.831430984195322. Arrivals time: 0.2077676048502326 Scheduler time: 3.525293454993516 Scheduler overhead time: 0.020817944314330816 Adapter cache time: 0.046244644559919834 Engine time: 0.021690277848392725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.802594469860196,
    "estimated_duration": 3600.15023364416,
    "input_throughput": 3266.4245203169276,
    "output_throughput": 2889.4210865946247,
    "total_throughput": 6155.845606911552,
    "itl": 175.63921354109138,
    "ttft": 2354090.481336386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.018292113563517,
    "arrivals": 928080,
    "finished_requests": 47529,
    "scheduler_time": 19.84092578255044
}
#Debug simulation 
Total elapsed time: 3.80268240487203. Arrivals time: 0.1985885570757091 Scheduler time: 3.3944274545647204 Scheduler overhead time: 0.03144032880663872 Adapter cache time: 0.13089512242004275 Engine time: 0.03271405352279544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.85977970296517,
    "estimated_duration": 3600.121531383599,
    "input_throughput": 3265.153105951492,
    "output_throughput": 2888.325549388805,
    "total_throughput": 6153.478655340296,
    "itl": 175.97414311650633,
    "ttft": 2354109.6290928884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9757982004457186,
    "arrivals": 928080,
    "finished_requests": 47513,
    "scheduler_time": 19.874838773929557
}
#Debug simulation 
Total elapsed time: 3.8598676580004394. Arrivals time: 0.2569158901460469 Scheduler time: 3.394474889151752 Scheduler overhead time: 0.031387226190418005 Adapter cache time: 0.12987657636404037 Engine time: 0.03256393736228347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7696094028651714,
    "estimated_duration": 3600.0788037970897,
    "input_throughput": 3265.1918584675905,
    "output_throughput": 2888.3598295216866,
    "total_throughput": 6153.5516879892775,
    "itl": 175.97229508710353,
    "ttft": 2354084.3259204244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9328956920094801,
    "arrivals": 928080,
    "finished_requests": 47513,
    "scheduler_time": 19.87501369585422
}
#Debug simulation 
Total elapsed time: 3.769695173949003. Arrivals time: 0.19555064849555492 Scheduler time: 3.3654669355601072 Scheduler overhead time: 0.03132889233529568 Adapter cache time: 0.1301530208438635 Engine time: 0.032625957392156124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.8034728220663965,
    "estimated_duration": 3600.185085684478,
    "input_throughput": 3496.813552741694,
    "output_throughput": 3064.8021524988376,
    "total_throughput": 6561.6157052405315,
    "itl": 277.8807659683833,
    "ttft": 2309395.7001410243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8906019334844302,
    "arrivals": 925677,
    "finished_requests": 50894,
    "scheduler_time": 31.110592060609054
}
#Debug simulation 
Total elapsed time: 3.8035964560694993. Arrivals time: 0.2107979292050004 Scheduler time: 3.5016949619166553 Scheduler overhead time: 0.021463030949234962 Adapter cache time: 0.038278643041849136 Engine time: 0.02171042375266552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7688601412810385,
    "estimated_duration": 3600.017029275671,
    "input_throughput": 3274.1270122190354,
    "output_throughput": 2886.8282887236824,
    "total_throughput": 6160.955300942717,
    "itl": 175.13933876387654,
    "ttft": 2348929.9810023485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9408105720276997,
    "arrivals": 925677,
    "finished_requests": 47704,
    "scheduler_time": 19.737510243154247
}
#Debug simulation 
Total elapsed time: 3.7689499612897635. Arrivals time: 0.19828594895079732 Scheduler time: 3.374187314417213 Scheduler overhead time: 0.031454882118850946 Adapter cache time: 0.1177009497769177 Engine time: 0.03276490094140172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.835850486997515,
    "estimated_duration": 3600.0837656692715,
    "input_throughput": 3279.295641001637,
    "output_throughput": 2891.0685632519135,
    "total_throughput": 6170.36420425355,
    "itl": 175.54941842350448,
    "ttft": 2348135.724826117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8999510401836623,
    "arrivals": 925677,
    "finished_requests": 47773,
    "scheduler_time": 19.855636683525592
}
#Debug simulation 
Total elapsed time: 3.8359555997885764. Arrivals time: 0.26458986615762115 Scheduler time: 3.3747720145620406 Scheduler overhead time: 0.03145763883367181 Adapter cache time: 0.11787716951221228 Engine time: 0.03269831510260701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.761343006975949,
    "estimated_duration": 3600.045115718039,
    "input_throughput": 3279.3308473983698,
    "output_throughput": 2891.0996016570966,
    "total_throughput": 6170.430449055467,
    "itl": 175.5479277660491,
    "ttft": 2348113.1536325337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8611344849318278,
    "arrivals": 925677,
    "finished_requests": 47773,
    "scheduler_time": 19.855803287541917
}
#Debug simulation 
Total elapsed time: 3.761428572703153. Arrivals time: 0.1983427396044135 Scheduler time: 3.366696683689952 Scheduler overhead time: 0.031368354335427284 Adapter cache time: 0.1177614089101553 Engine time: 0.03268452873453498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.817614627070725,
    "estimated_duration": 3600.222270000518,
    "input_throughput": 3493.6476297054264,
    "output_throughput": 3075.5542768192495,
    "total_throughput": 6569.201906524676,
    "itl": 277.69332028609875,
    "ttft": 2314715.582783642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171502276300442,
    "arrivals": 924451,
    "finished_requests": 50748,
    "scheduler_time": 31.22931809914432
}
#Debug simulation 
Total elapsed time: 3.8177054449915886. Arrivals time: 0.21170943276956677 Scheduler time: 3.5186990038491786 Scheduler overhead time: 0.020870039239525795 Adapter cache time: 0.03492675814777613 Engine time: 0.021874791476875544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8419300839304924,
    "estimated_duration": 3600.008973267095,
    "input_throughput": 3279.101826595411,
    "output_throughput": 2898.756385745752,
    "total_throughput": 6177.8582123411625,
    "itl": 175.67713921088776,
    "ttft": 2356775.608345804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8616946492181199,
    "arrivals": 924451,
    "finished_requests": 47643,
    "scheduler_time": 19.938657690138687
}
#Debug simulation 
Total elapsed time: 3.8420215616934. Arrivals time: 0.255921951495111 Scheduler time: 3.394806888885796 Scheduler overhead time: 0.031454788986593485 Adapter cache time: 0.11248765420168638 Engine time: 0.032748023979365826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.7661186465993524,
    "estimated_duration": 3600.1748627516704,
    "input_throughput": 3279.25460569895,
    "output_throughput": 2898.754198851215,
    "total_throughput": 6178.008804550164,
    "itl": 175.67674916833727,
    "ttft": 2356795.4014086477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8245124752400467,
    "arrivals": 924451,
    "finished_requests": 47646,
    "scheduler_time": 19.940029508803935
}
#Debug simulation 
Total elapsed time: 3.7662160247564316. Arrivals time: 0.19592891167849302 Scheduler time: 3.3807856724597514 Scheduler overhead time: 0.03123582387343049 Adapter cache time: 0.11114562163129449 Engine time: 0.03256042441353202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7747582639567554,
    "estimated_duration": 3600.139890568051,
    "input_throughput": 3279.286460765056,
    "output_throughput": 2898.7823576914793,
    "total_throughput": 6178.068818456535,
    "itl": 175.67534926061796,
    "ttft": 2356774.470569144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7893732778541754,
    "arrivals": 924451,
    "finished_requests": 47646,
    "scheduler_time": 19.940196522569444
}
#Debug simulation 
Total elapsed time: 3.7748429370112717. Arrivals time: 0.19522196287289262 Scheduler time: 3.3905870872549713 Scheduler overhead time: 0.031313317362219095 Adapter cache time: 0.11072225403040648 Engine time: 0.032405116595327854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9902289239689708,
    "estimated_duration": 3600.2546495340403,
    "input_throughput": 3254.736995205763,
    "output_throughput": 2860.200458690537,
    "total_throughput": 6114.9374538963,
    "itl": 297.6324687275576,
    "ttft": 2329141.1225009137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 807771,
    "finished_requests": 47316,
    "scheduler_time": 29.122033625148106
}
#Debug simulation 
Total elapsed time: 3.990290811751038. Arrivals time: 0.19828433683142066 Scheduler time: 3.636119751725346 Scheduler overhead time: 0.019751060754060745 Adapter cache time: 0.10637798486277461 Engine time: 0.020718087442219257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8133271387778223,
    "estimated_duration": 3600.0998947756466,
    "input_throughput": 3233.7813783707547,
    "output_throughput": 2856.823782841431,
    "total_throughput": 6090.6051612121855,
    "itl": 176.96625005034755,
    "ttft": 2343842.783281942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149368,
    "arrivals": 807771,
    "finished_requests": 46989,
    "scheduler_time": 19.557902786263686
}
#Debug simulation 
Total elapsed time: 3.8134142458438873. Arrivals time: 0.19389986107125878 Scheduler time: 3.355522833764553 Scheduler overhead time: 0.03129716729745269 Adapter cache time: 0.18549086200073361 Engine time: 0.0327564780600369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.868579728063196,
    "estimated_duration": 3600.056356636435,
    "input_throughput": 3233.8204868762573,
    "output_throughput": 2856.8583325204468,
    "total_throughput": 6090.678819396704,
    "itl": 176.96434166242614,
    "ttft": 2343815.6002028747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 807771,
    "finished_requests": 46989,
    "scheduler_time": 19.55808434612506
}
#Debug simulation 
Total elapsed time: 3.868668329436332. Arrivals time: 0.19210404669865966 Scheduler time: 3.411233044695109 Scheduler overhead time: 0.031350874342024326 Adapter cache time: 0.1865218300372362 Engine time: 0.032930048648267984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.819087604060769,
    "estimated_duration": 3600.1804531936077,
    "input_throughput": 3232.857116835775,
    "output_throughput": 2856.187386629039,
    "total_throughput": 6089.044503464814,
    "itl": 177.061691488367,
    "ttft": 2343612.346427593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 807771,
    "finished_requests": 46975,
    "scheduler_time": 19.558945734652482
}
#Debug simulation 
Total elapsed time: 3.8191761798225343. Arrivals time: 0.19563034921884537 Scheduler time: 3.3594454508274794 Scheduler overhead time: 0.031161445658653975 Adapter cache time: 0.18558607762679458 Engine time: 0.03286883607506752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.8192744459956884,
    "estimated_duration": 3600.014542064786,
    "input_throughput": 3472.187640895105,
    "output_throughput": 3018.2203080124286,
    "total_throughput": 6490.407948907533,
    "itl": 280.5077744606575,
    "ttft": 2302257.629639432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 788657,
    "finished_requests": 50415,
    "scheduler_time": 30.598163269868795
}
#Debug simulation 
Total elapsed time: 3.8193763280287385. Arrivals time: 0.20666065299883485 Scheduler time: 3.469213154632598 Scheduler overhead time: 0.020963041111826897 Adapter cache time: 0.0910267848521471 Engine time: 0.021887862589210272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9171284451149404,
    "estimated_duration": 3600.161226733938,
    "input_throughput": 3386.8433195314537,
    "output_throughput": 2959.5380120423206,
    "total_throughput": 6346.381331573774,
    "itl": 171.4733201615053,
    "ttft": 2325559.2490172395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 788657,
    "finished_requests": 49179,
    "scheduler_time": 20.431661113585847
}
#Debug simulation 
Total elapsed time: 3.9172169072553515. Arrivals time: 0.19831068674102426 Scheduler time: 3.475884494371712 Scheduler overhead time: 0.03223661798983812 Adapter cache time: 0.1621216987259686 Engine time: 0.03374171629548073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.894925939850509,
    "estimated_duration": 3600.1438941943156,
    "input_throughput": 3386.7254638522254,
    "output_throughput": 2959.382822775846,
    "total_throughput": 6346.108286628071,
    "itl": 171.19421899650303,
    "ttft": 2325527.5952991815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 788657,
    "finished_requests": 49178,
    "scheduler_time": 20.38657052696527
}
#Debug simulation 
Total elapsed time: 3.8950108871795237. Arrivals time: 0.19490727921947837 Scheduler time: 3.4558644723147154 Scheduler overhead time: 0.032292654272168875 Adapter cache time: 0.1630707671865821 Engine time: 0.03393912175670266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9165814560838044,
    "estimated_duration": 3600.0913447336966,
    "input_throughput": 3391.1456213073043,
    "output_throughput": 2962.8945431074967,
    "total_throughput": 6354.040164414801,
    "itl": 171.12194236966616,
    "ttft": 2324572.286695173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 788657,
    "finished_requests": 49236,
    "scheduler_time": 20.429862958085884
}
#Debug simulation 
Total elapsed time: 3.916696523781866. Arrivals time: 0.19910292513668537 Scheduler time: 3.4725408419035375 Scheduler overhead time: 0.032265265472233295 Adapter cache time: 0.1640460784547031 Engine time: 0.03379651950672269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.873030544258654,
    "estimated_duration": 3600.1064482242873,
    "input_throughput": 3520.7872829015673,
    "output_throughput": 3103.5365650121234,
    "total_throughput": 6624.323847913691,
    "itl": 275.34664025714386,
    "ttft": 2294076.4952940205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 779141,
    "finished_requests": 51346,
    "scheduler_time": 31.56741229231809
}
#Debug simulation 
Total elapsed time: 3.873119124211371. Arrivals time: 0.20517455972731113 Scheduler time: 3.5395402782596648 Scheduler overhead time: 0.021279958076775074 Adapter cache time: 0.07531007844954729 Engine time: 0.022073468659073114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.301466157659888,
    "estimated_duration": 3600.012486005136,
    "input_throughput": 3400.774593864154,
    "output_throughput": 3016.628981765289,
    "total_throughput": 6417.403575629443,
    "itl": 169.06505995973265,
    "ttft": 2320363.1278890683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149365,
    "arrivals": 779141,
    "finished_requests": 49630,
    "scheduler_time": 20.85733311364128
}
#Debug simulation 
Total elapsed time: 4.3015267117880285. Arrivals time: 0.5256040031090379 Scheduler time: 3.545504789799452 Scheduler overhead time: 0.03271503979340196 Adapter cache time: 0.14818939985707402 Engine time: 0.03438330115750432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.004139183089137,
    "estimated_duration": 3600.1616294546975,
    "input_throughput": 3400.7470386418277,
    "output_throughput": 3016.5104008524504,
    "total_throughput": 6417.2574394942785,
    "itl": 169.0636873228536,
    "ttft": 2320299.4129523947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 779141,
    "finished_requests": 49631,
    "scheduler_time": 20.858609460795762
}
#Debug simulation 
Total elapsed time: 4.004227487370372. Arrivals time: 0.21012107701972127 Scheduler time: 3.5624319720081985 Scheduler overhead time: 0.032810572534799576 Adapter cache time: 0.14929761365056038 Engine time: 0.03434464568272233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.940936805680394,
    "estimated_duration": 3600.118090905738,
    "input_throughput": 3400.7881660681237,
    "output_throughput": 3016.54688145738,
    "total_throughput": 6417.335047525504,
    "itl": 169.06195709027537,
    "ttft": 2320272.6225448037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 779141,
    "finished_requests": 49631,
    "scheduler_time": 20.858790610907956
}
#Debug simulation 
Total elapsed time: 3.941024124622345. Arrivals time: 0.19832029286772013 Scheduler time: 3.513617657124996 Scheduler overhead time: 0.03265274176374078 Adapter cache time: 0.14722816040739417 Engine time: 0.034116947557777166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9722186671569943,
    "estimated_duration": 3600.1198163188924,
    "input_throughput": 3600.9795955223494,
    "output_throughput": 3149.1579665235668,
    "total_throughput": 6750.137562045917,
    "itl": 270.189439599588,
    "ttft": 2283302.4466215344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9640536393388162,
    "arrivals": 774377,
    "finished_requests": 52232,
    "scheduler_time": 31.94217227719244
}
#Debug simulation 
Total elapsed time: 3.9723123419098556. Arrivals time: 0.25317731825634837 Scheduler time: 3.597213637083769 Scheduler overhead time: 0.021749644074589014 Adapter cache time: 0.0678418236784637 Engine time: 0.022392097394913435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.961002343799919,
    "estimated_duration": 3600.0707430892953,
    "input_throughput": 3449.733876435648,
    "output_throughput": 3036.865600762674,
    "total_throughput": 6486.599477198322,
    "itl": 167.6123712102662,
    "ttft": 2312849.997305879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0212821638584193,
    "arrivals": 774377,
    "finished_requests": 50107,
    "scheduler_time": 20.985383653251024
}
#Debug simulation 
Total elapsed time: 3.9610909977927804. Arrivals time: 0.20089393062517047 Scheduler time: 3.541785593610257 Scheduler overhead time: 0.032901475206017494 Adapter cache time: 0.13592491252347827 Engine time: 0.034293740056455135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.9675049809738994,
    "estimated_duration": 3600.0825926041675,
    "input_throughput": 3459.3489676000117,
    "output_throughput": 3044.821533405647,
    "total_throughput": 6504.170501005659,
    "itl": 166.56422949628717,
    "ttft": 2310914.1967985714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9787882507406208,
    "arrivals": 774377,
    "finished_requests": 50237,
    "scheduler_time": 20.95499965211658
}
#Debug simulation 
Total elapsed time: 3.967590699903667. Arrivals time: 0.1987884296104312 Scheduler time: 3.5498333876021206 Scheduler overhead time: 0.03316092910245061 Adapter cache time: 0.1359214475378394 Engine time: 0.0345436604693532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.028158022090793,
    "estimated_duration": 3600.0398762038108,
    "input_throughput": 3459.390014627421,
    "output_throughput": 3044.8576618431393,
    "total_throughput": 6504.247676470561,
    "itl": 166.56246766046556,
    "ttft": 2310888.3559795176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9358857423043823,
    "arrivals": 774377,
    "finished_requests": 50237,
    "scheduler_time": 20.955185760193846
}
#Debug simulation 
Total elapsed time: 4.02824743045494. Arrivals time: 0.24919283343479037 Scheduler time: 3.5601255712099373 Scheduler overhead time: 0.03294669138267636 Adapter cache time: 0.1363923237659037 Engine time: 0.03421085141599178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.286456092726439,
    "estimated_duration": 3600.0601057750423,
    "input_throughput": 3608.865023991864,
    "output_throughput": 3182.7307498615355,
    "total_throughput": 6791.5957738534,
    "itl": 268.95479984923793,
    "ttft": 2287050.9292348586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089648599480267,
    "arrivals": 771975,
    "finished_requests": 52654,
    "scheduler_time": 32.346882685413554
}
#Debug simulation 
Total elapsed time: 4.286524544004351. Arrivals time: 0.5359190423041582 Scheduler time: 3.6367277805693448 Scheduler overhead time: 0.02170340996235609 Adapter cache time: 0.059794805478304625 Engine time: 0.022443639114499092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.039220890961587,
    "estimated_duration": 3600.164639398906,
    "input_throughput": 3454.2945241738603,
    "output_throughput": 3061.2588878268925,
    "total_throughput": 6515.553412000752,
    "itl": 166.46901396730703,
    "ttft": 2316815.581269401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9625581147288956,
    "arrivals": 771975,
    "finished_requests": 50378,
    "scheduler_time": 21.152514001046896
}
#Debug simulation 
Total elapsed time: 4.039310506079346. Arrivals time: 0.2486258214339614 Scheduler time: 3.582031622994691 Scheduler overhead time: 0.033124024514108896 Adapter cache time: 0.12559729954227805 Engine time: 0.034646724350750446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.007862050551921,
    "estimated_duration": 3600.073459823745,
    "input_throughput": 3453.3231443029126,
    "output_throughput": 3060.3911622790633,
    "total_throughput": 6513.7143065819755,
    "itl": 166.26454936481448,
    "ttft": 2316948.0549750123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9212899875664181,
    "arrivals": 771975,
    "finished_requests": 50365,
    "scheduler_time": 21.11606410039983
}
#Debug simulation 
Total elapsed time: 4.007950534578413. Arrivals time: 0.24544049194082618 Scheduler time: 3.5552208027802408 Scheduler overhead time: 0.03300625365227461 Adapter cache time: 0.12466261675581336 Engine time: 0.03432493610307574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.311711935792118,
    "estimated_duration": 3600.00469682072,
    "input_throughput": 3454.6946594218175,
    "output_throughput": 3061.297672676017,
    "total_throughput": 6515.992332097834,
    "itl": 166.47083443346548,
    "ttft": 2316846.4015621184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.882064836996143,
    "arrivals": 771975,
    "finished_requests": 50380,
    "scheduler_time": 21.155587295347075
}
#Debug simulation 
Total elapsed time: 4.311773885972798. Arrivals time: 0.5247927503660321 Scheduler time: 3.578815773129463 Scheduler overhead time: 0.033043162897229195 Adapter cache time: 0.12515252362936735 Engine time: 0.034633468836545944 
