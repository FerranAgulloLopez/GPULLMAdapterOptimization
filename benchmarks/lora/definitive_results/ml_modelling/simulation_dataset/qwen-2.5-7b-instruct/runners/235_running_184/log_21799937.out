INFO 06-01 00:47:28 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:28 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.527431341819465,
    "estimated_duration": 3600.2510147749003,
    "input_throughput": 3099.98218296393,
    "output_throughput": 2713.307477703958,
    "total_throughput": 5813.289660667888,
    "itl": 312.808017087385,
    "ttft": 2376483.5409977306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.245618511780638,
    "arrivals": 1110230,
    "finished_requests": 45097,
    "scheduler_time": 39.1657479265384
}
#Debug simulation 
Total elapsed time: 3.527594421058893. Arrivals time: 0.26141255907714367 Scheduler time: 3.1583508481271565 Scheduler overhead time: 0.018361795227974653 Adapter cache time: 0.06159521406516433 Engine time: 0.019221059046685696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5381000488996506,
    "estimated_duration": 3600.0869309804993,
    "input_throughput": 2973.7929125739743,
    "output_throughput": 2614.54325421982,
    "total_throughput": 5588.336166793794,
    "itl": 194.06777496330568,
    "ttft": 2405564.9560280056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3221082960511616,
    "arrivals": 1110230,
    "finished_requests": 43214,
    "scheduler_time": 36.815546789478724
}
#Debug simulation 
Total elapsed time: 3.5382218598388135. Arrivals time: 0.19169528456404805 Scheduler time: 3.112562889698893 Scheduler overhead time: 0.027834291104227304 Adapter cache time: 0.16315274545922875 Engine time: 0.0296153393574059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5459064920432866,
    "estimated_duration": 3600.0313466683283,
    "input_throughput": 2973.838827794612,
    "output_throughput": 2614.583622642879,
    "total_throughput": 5588.422450437491,
    "itl": 194.06515616832846,
    "ttft": 2405536.5202629664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2665393327432675,
    "arrivals": 1110230,
    "finished_requests": 43214,
    "scheduler_time": 36.81553144060961
}
#Debug simulation 
Total elapsed time: 3.5460165799595416. Arrivals time: 0.1911472980864346 Scheduler time: 3.1198836341500282 Scheduler overhead time: 0.027954347897320986 Adapter cache time: 0.16399378282949328 Engine time: 0.029612346086651087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5488691427744925,
    "estimated_duration": 3600.197090025497,
    "input_throughput": 2973.744973479821,
    "output_throughput": 2614.626300898803,
    "total_throughput": 5588.371274378624,
    "itl": 194.06312762113583,
    "ttft": 2405639.2292215982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.210970369435375,
    "arrivals": 1110230,
    "finished_requests": 43216,
    "scheduler_time": 36.817750567390185
}
#Debug simulation 
Total elapsed time: 3.5489767477847636. Arrivals time: 0.19061624677851796 Scheduler time: 3.1234652805142105 Scheduler overhead time: 0.02802046574652195 Adapter cache time: 0.16390092531219125 Engine time: 0.029639203567057848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5699042840860784,
    "estimated_duration": 3600.0625091740862,
    "input_throughput": 3124.719632321259,
    "output_throughput": 2738.774111525633,
    "total_throughput": 5863.493743846892,
    "itl": 309.9535371520142,
    "ttft": 2369161.0548741594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0099609554978077,
    "arrivals": 1107373,
    "finished_requests": 45632,
    "scheduler_time": 39.58510490759951
}
#Debug simulation 
Total elapsed time: 3.570022725034505. Arrivals time: 0.1993130836635828 Scheduler time: 3.2663524891249835 Scheduler overhead time: 0.018482584971934557 Adapter cache time: 0.057812334038317204 Engine time: 0.019380772951990366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5899631991051137,
    "estimated_duration": 3600.048498738182,
    "input_throughput": 2997.623505289569,
    "output_throughput": 2635.6164377578993,
    "total_throughput": 5633.239943047468,
    "itl": 192.57662885316893,
    "ttft": 2400444.7523059244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0702188714663552,
    "arrivals": 1107373,
    "finished_requests": 43737,
    "scheduler_time": 37.13740150795701
}
#Debug simulation 
Total elapsed time: 3.5900767100974917. Arrivals time: 0.19735386269167066 Scheduler time: 3.1618614182807505 Scheduler overhead time: 0.028345631901174784 Adapter cache time: 0.15925313532352448 Engine time: 0.02980602579191327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5496331178583205,
    "estimated_duration": 3600.0038855659254,
    "input_throughput": 2982.8228916791695,
    "output_throughput": 2623.1830020693087,
    "total_throughput": 5606.005893748478,
    "itl": 191.79222285455134,
    "ttft": 2402291.2015016405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.026090577074795,
    "arrivals": 1107373,
    "finished_requests": 43532,
    "scheduler_time": 36.954135014992694
}
#Debug simulation 
Total elapsed time: 3.549739087931812. Arrivals time: 0.19440309749916196 Scheduler time: 3.126526564825326 Scheduler overhead time: 0.028223953675478697 Adapter cache time: 0.15746020758524537 Engine time: 0.029651057440787554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.542824252974242,
    "estimated_duration": 3600.1722712745245,
    "input_throughput": 2982.9730887289256,
    "output_throughput": 2623.1597513684305,
    "total_throughput": 5606.132840097356,
    "itl": 191.78928110787749,
    "ttft": 2402223.569348899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.980736496727915,
    "arrivals": 1107373,
    "finished_requests": 43535,
    "scheduler_time": 36.95628062704855
}
#Debug simulation 
Total elapsed time: 3.5429288567975163. Arrivals time: 0.19311398174613714 Scheduler time: 3.122898987494409 Scheduler overhead time: 0.02805742435157299 Adapter cache time: 0.1557463868521154 Engine time: 0.029639198444783688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.512715162243694,
    "estimated_duration": 3600.182412398648,
    "input_throughput": 3134.9936495246234,
    "output_throughput": 2752.9952276491827,
    "total_throughput": 5887.988877173806,
    "itl": 309.46000388390195,
    "ttft": 2371669.2691916823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9242672986676904,
    "arrivals": 1105887,
    "finished_requests": 45710,
    "scheduler_time": 39.74548321847124
}
#Debug simulation 
Total elapsed time: 3.512852890882641. Arrivals time: 0.20091498270630836 Scheduler time: 3.2092402572743595 Scheduler overhead time: 0.018618869595229626 Adapter cache time: 0.055690051056444645 Engine time: 0.019609882961958647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9630025480873883,
    "estimated_duration": 3600.141343058239,
    "input_throughput": 2998.5931026890144,
    "output_throughput": 2647.3388380645647,
    "total_throughput": 5645.9319407535795,
    "itl": 193.35006689653724,
    "ttft": 2401258.3984528095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.984714252748532,
    "arrivals": 1105887,
    "finished_requests": 43677,
    "scheduler_time": 37.31260972093176
}
#Debug simulation 
Total elapsed time: 3.9630778110586107. Arrivals time: 0.5747296181507409 Scheduler time: 3.160617141518742 Scheduler overhead time: 0.028194621205329895 Adapter cache time: 0.15658803982660174 Engine time: 0.029596010223031044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.581156807951629,
    "estimated_duration": 3600.2078551406657,
    "input_throughput": 2997.71941905791,
    "output_throughput": 2646.544972784001,
    "total_throughput": 5644.264391841911,
    "itl": 192.90562611085272,
    "ttft": 2401587.3905036026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9450805068598156,
    "arrivals": 1105887,
    "finished_requests": 43667,
    "scheduler_time": 37.29587603905897
}
#Debug simulation 
Total elapsed time: 3.581266270019114. Arrivals time: 0.19674140866845846 Scheduler time: 3.156783379148692 Scheduler overhead time: 0.028090768959373236 Adapter cache time: 0.15663687093183398 Engine time: 0.029574847780168056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5762404748238623,
    "estimated_duration": 3600.16820520949,
    "input_throughput": 2998.019088214225,
    "output_throughput": 2646.7263352339774,
    "total_throughput": 5644.745423448203,
    "itl": 193.17670501964804,
    "ttft": 2401612.4910602155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9029951890604583,
    "arrivals": 1105887,
    "finished_requests": 43670,
    "scheduler_time": 37.299792986112955
}
#Debug simulation 
Total elapsed time: 3.5763499778695405. Arrivals time: 0.1951466854661703 Scheduler time: 3.155112244654447 Scheduler overhead time: 0.027977547608315945 Adapter cache time: 0.15511258225888014 Engine time: 0.029551660176366568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.48437808919698,
    "estimated_duration": 3600.009607392798,
    "input_throughput": 2937.4574385257115,
    "output_throughput": 2612.077195763434,
    "total_throughput": 5549.534634289145,
    "itl": 327.8553825359792,
    "ttft": 2390150.579804057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6917277114490386,
    "arrivals": 966726,
    "finished_requests": 42985,
    "scheduler_time": 37.76605626593619
}
#Debug simulation 
Total elapsed time: 3.484493400901556. Arrivals time: 0.19002284249290824 Scheduler time: 3.136176886036992 Scheduler overhead time: 0.017902472987771034 Adapter cache time: 0.11353970319032669 Engine time: 0.018483556807041168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.625829156022519,
    "estimated_duration": 3600.022803596849,
    "input_throughput": 2944.8963460474897,
    "output_throughput": 2635.3994176150404,
    "total_throughput": 5580.29576366253,
    "itl": 192.099656040226,
    "ttft": 2400082.4077781346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.04930220531523,
    "arrivals": 966726,
    "finished_requests": 43081,
    "scheduler_time": 37.1207121559337
}
#Debug simulation 
Total elapsed time: 3.625964163802564. Arrivals time: 0.1929851877503097 Scheduler time: 3.1629923982545733 Scheduler overhead time: 0.02863504085689783 Adapter cache time: 0.19760684529319406 Engine time: 0.0300742844119668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.613268360029906,
    "estimated_duration": 3600.163998759727,
    "input_throughput": 2944.780849886931,
    "output_throughput": 2635.296059642974,
    "total_throughput": 5580.076909529905,
    "itl": 192.0361646121066,
    "ttft": 2400176.0396371186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8302951146311965,
    "arrivals": 966726,
    "finished_requests": 43081,
    "scheduler_time": 37.12146343383391
}
#Debug simulation 
Total elapsed time: 3.613376911729574. Arrivals time: 0.19241481693461537 Scheduler time: 3.150925229303539 Scheduler overhead time: 0.028598163276910782 Adapter cache time: 0.19796216348186135 Engine time: 0.02990354225039482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.685638930182904,
    "estimated_duration": 3600.168182870983,
    "input_throughput": 2945.1976856104507,
    "output_throughput": 2635.5910385367783,
    "total_throughput": 5580.788724147229,
    "itl": 192.02637693433135,
    "ttft": 2400091.453556436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.634577957098244,
    "arrivals": 966726,
    "finished_requests": 43085,
    "scheduler_time": 37.123552027214565
}
#Debug simulation 
Total elapsed time: 3.685756958089769. Arrivals time: 0.2583013470284641 Scheduler time: 3.1566642224788666 Scheduler overhead time: 0.02850599493831396 Adapter cache time: 0.19865402346476912 Engine time: 0.029970047529786825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6681041279807687,
    "estimated_duration": 3600.1526842356234,
    "input_throughput": 3103.9486322154658,
    "output_throughput": 2737.989986692149,
    "total_throughput": 5841.938618907615,
    "itl": 311.4471590326967,
    "ttft": 2362980.604917606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5861121436232306,
    "arrivals": 943309,
    "finished_requests": 45134,
    "scheduler_time": 39.552934699334855
}
#Debug simulation 
Total elapsed time: 3.6682184049859643. Arrivals time: 0.19675794476643205 Scheduler time: 3.3260283125564456 Scheduler overhead time: 0.018743698950856924 Adapter cache time: 0.09810648206621408 Engine time: 0.01983185950666666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8318621539510787,
    "estimated_duration": 3600.1745819215066,
    "input_throughput": 3068.827288398672,
    "output_throughput": 2722.3960330192926,
    "total_throughput": 5791.223321417965,
    "itl": 185.65039468390665,
    "ttft": 2380551.434983042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7352737699705196,
    "arrivals": 943309,
    "finished_requests": 44628,
    "scheduler_time": 38.30482470660974
}
#Debug simulation 
Total elapsed time: 3.8319679852575064. Arrivals time: 0.19769731210544705 Scheduler time: 3.3790756538510323 Scheduler overhead time: 0.02948700776323676 Adapter cache time: 0.1805019462481141 Engine time: 0.031158934347331524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.689417967107147,
    "estimated_duration": 3600.0626095433204,
    "input_throughput": 3068.922737819139,
    "output_throughput": 2722.480707423947,
    "total_throughput": 5791.403445243086,
    "itl": 185.6446166376497,
    "ttft": 2380505.2097943467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.623318652717835,
    "arrivals": 943309,
    "finished_requests": 44628,
    "scheduler_time": 38.3048074456547
}
#Debug simulation 
Total elapsed time: 3.68952874885872. Arrivals time: 0.19493195693939924 Scheduler time: 3.240902959369123 Scheduler overhead time: 0.02939154300838709 Adapter cache time: 0.17933852737769485 Engine time: 0.030932768248021603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7608758378773928,
    "estimated_duration": 3600.0806783150174,
    "input_throughput": 3068.787893156565,
    "output_throughput": 2722.2451038477657,
    "total_throughput": 5791.032997004331,
    "itl": 185.45678591929317,
    "ttft": 2380483.880856875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5116422477177753,
    "arrivals": 943309,
    "finished_requests": 44627,
    "scheduler_time": 38.301509970542725
}
#Debug simulation 
Total elapsed time: 3.7609833269380033. Arrivals time: 0.25819528941065073 Scheduler time: 3.248749738559127 Scheduler overhead time: 0.029322948772460222 Adapter cache time: 0.1794664803892374 Engine time: 0.031203314661979675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9742489652708173,
    "estimated_duration": 3600.065017506171,
    "input_throughput": 3213.2536339616736,
    "output_throughput": 2800.626086187822,
    "total_throughput": 6013.879720149495,
    "itl": 302.9705345111692,
    "ttft": 2355330.9468847928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7812038669688885,
    "arrivals": 931969,
    "finished_requests": 46813,
    "scheduler_time": 40.36895557686319
}
#Debug simulation 
Total elapsed time: 3.9743634620681405. Arrivals time: 0.5592224667780101 Scheduler time: 3.2776976353488863 Scheduler overhead time: 0.019167063757777214 Adapter cache time: 0.08916297042742372 Engine time: 0.020079635083675385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8039745772257447,
    "estimated_duration": 3600.023586941406,
    "input_throughput": 3147.681321062532,
    "output_throughput": 2759.7049741667993,
    "total_throughput": 5907.386295229331,
    "itl": 184.1912846147698,
    "ttft": 2374691.3728061086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8532061931933328,
    "arrivals": 931969,
    "finished_requests": 45868,
    "scheduler_time": 38.84883015911251
}
#Debug simulation 
Total elapsed time: 3.804087497293949. Arrivals time: 0.2614774536341429 Scheduler time: 3.2960640508681536 Scheduler overhead time: 0.02975180232897401 Adapter cache time: 0.171375943813473 Engine time: 0.03124943980947137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8160736709833145,
    "estimated_duration": 3600.0492698566354,
    "input_throughput": 3148.0085827967887,
    "output_throughput": 2759.8269510338287,
    "total_throughput": 5907.835533830617,
    "itl": 184.46341534364754,
    "ttft": 2374528.698380873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7747558920527702,
    "arrivals": 931969,
    "finished_requests": 45872,
    "scheduler_time": 38.85779276365068
}
#Debug simulation 
Total elapsed time: 3.8161998209543526. Arrivals time: 0.2132417787797749 Scheduler time: 3.3601985280402005 Scheduler overhead time: 0.029524854384362698 Adapter cache time: 0.16792933689430356 Engine time: 0.031220302917063236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.08079976728186,
    "estimated_duration": 3600.1800253434067,
    "input_throughput": 3148.0606303622094,
    "output_throughput": 2759.972259735041,
    "total_throughput": 5908.032890097251,
    "itl": 184.46064064951855,
    "ttft": 2374484.599796559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6983485675044123,
    "arrivals": 931969,
    "finished_requests": 45874,
    "scheduler_time": 38.86002274640416
}
#Debug simulation 
Total elapsed time: 4.080874715931714. Arrivals time: 0.5519820633344352 Scheduler time: 3.285573268774897 Scheduler overhead time: 0.02946766884997487 Adapter cache time: 0.16877081152051687 Engine time: 0.03107182076200843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.683160974178463,
    "estimated_duration": 3600.233445906798,
    "input_throughput": 3224.9928162854403,
    "output_throughput": 2859.295419218905,
    "total_throughput": 6084.288235504345,
    "itl": 299.67563996221196,
    "ttft": 2343856.716792483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3466146073304224,
    "arrivals": 926257,
    "finished_requests": 47158,
    "scheduler_time": 41.23792181638007
}
#Debug simulation 
Total elapsed time: 3.6832714988850057. Arrivals time: 0.2042630324140191 Scheduler time: 3.3477867231704295 Scheduler overhead time: 0.019404351711273193 Adapter cache time: 0.08227739809080958 Engine time: 0.020421950612217188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.763913620263338,
    "estimated_duration": 3600.043109962161,
    "input_throughput": 3139.689068923067,
    "output_throughput": 2798.4056557883523,
    "total_throughput": 5938.094724711419,
    "itl": 181.46098077355134,
    "ttft": 2366071.3508558045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.423380356880377,
    "arrivals": 926257,
    "finished_requests": 45903,
    "scheduler_time": 39.39141655489785
}
#Debug simulation 
Total elapsed time: 3.764056266285479. Arrivals time: 0.2022928143851459 Scheduler time: 3.3234019256196916 Scheduler overhead time: 0.02994190016761422 Adapter cache time: 0.1623852550983429 Engine time: 0.03165479330345988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.12270259577781,
    "estimated_duration": 3600.1869963035037,
    "input_throughput": 3139.6260837577647,
    "output_throughput": 2798.3796425975097,
    "total_throughput": 5938.005726355274,
    "itl": 181.45858262431986,
    "ttft": 2366037.924197455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3641340357065175,
    "arrivals": 926257,
    "finished_requests": 45904,
    "scheduler_time": 39.393596258595345
}
#Debug simulation 
Total elapsed time: 4.122779106721282. Arrivals time: 0.552501448430121 Scheduler time: 3.330849803984165 Scheduler overhead time: 0.029996282421052456 Adapter cache time: 0.16351289208978415 Engine time: 0.03168450016528368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7773896856233478,
    "estimated_duration": 3600.12650714788,
    "input_throughput": 3139.6788356070133,
    "output_throughput": 2798.4266608401626,
    "total_throughput": 5938.105496447176,
    "itl": 181.4558332173485,
    "ttft": 2366007.389294601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3036619285773392,
    "arrivals": 926257,
    "finished_requests": 45904,
    "scheduler_time": 39.393579210094295
}
#Debug simulation 
Total elapsed time: 3.7774952379986644. Arrivals time: 0.19787707272917032 Scheduler time: 3.3398699294775724 Scheduler overhead time: 0.030022930819541216 Adapter cache time: 0.16367374826222658 Engine time: 0.031702817883342505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6858180798590183,
    "estimated_duration": 3600.033159791577,
    "input_throughput": 3311.208944722646,
    "output_throughput": 2886.4692459115035,
    "total_throughput": 6197.678190634149,
    "itl": 293.78687145676093,
    "ttft": 2340899.869009785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0864731490961292,
    "arrivals": 923309,
    "finished_requests": 47983,
    "scheduler_time": 41.61816599208989
}
#Debug simulation 
Total elapsed time: 3.6859301482327282. Arrivals time: 0.2043551942333579 Scheduler time: 3.3532656100578606 Scheduler overhead time: 0.0196981905028224 Adapter cache time: 0.07876876601949334 Engine time: 0.020599513314664364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7217713040299714,
    "estimated_duration": 3600.1627872662993,
    "input_throughput": 3162.591158453026,
    "output_throughput": 2769.135338896713,
    "total_throughput": 5931.7264973497395,
    "itl": 175.79676479784314,
    "ttft": 2374563.173600215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.139956048072787,
    "arrivals": 923309,
    "finished_requests": 45782,
    "scheduler_time": 38.891248982807106
}
#Debug simulation 
Total elapsed time: 3.721876983065158. Arrivals time: 0.19915677141398191 Scheduler time: 3.2917693024501204 Scheduler overhead time: 0.030898509081453085 Adapter cache time: 0.1531408028677106 Engine time: 0.03226159326732159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7291581300087273,
    "estimated_duration": 3600.115374241769,
    "input_throughput": 3162.6328093437855,
    "output_throughput": 2769.171808028422,
    "total_throughput": 5931.804617372208,
    "itl": 175.79445370639172,
    "ttft": 2374537.406257109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0925589911337028,
    "arrivals": 923309,
    "finished_requests": 45782,
    "scheduler_time": 38.891233015212336
}
#Debug simulation 
Total elapsed time: 3.729268350638449. Arrivals time: 0.19941399106755853 Scheduler time: 3.2968696979805827 Scheduler overhead time: 0.03053568070754409 Adapter cache time: 0.15542350942268968 Engine time: 0.03230030369013548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.73111033719033,
    "estimated_duration": 3600.0663246853337,
    "input_throughput": 3162.6758990322733,
    "output_throughput": 2769.2095369580106,
    "total_throughput": 5931.885435990284,
    "itl": 175.79219142125925,
    "ttft": 2374509.786968888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0435275529208592,
    "arrivals": 923309,
    "finished_requests": 45782,
    "scheduler_time": 38.89121489698681
}
#Debug simulation 
Total elapsed time: 3.731217631138861. Arrivals time: 0.19877424743026495 Scheduler time: 3.2999787740409374 Scheduler overhead time: 0.030748621094971895 Adapter cache time: 0.1539665344171226 Engine time: 0.033026560209691525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.691934745758772,
    "estimated_duration": 3600.284348214074,
    "input_throughput": 3275.5884978501654,
    "output_throughput": 2885.5634708834605,
    "total_throughput": 6161.151968733626,
    "itl": 295.83118076166147,
    "ttft": 2340981.2463813927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9671141270827489,
    "arrivals": 921853,
    "finished_requests": 47635,
    "scheduler_time": 41.598239987483694
}
#Debug simulation 
Total elapsed time: 3.692046436946839. Arrivals time: 0.20567210391163826 Scheduler time: 3.3617418059147894 Scheduler overhead time: 0.019745097495615482 Adapter cache time: 0.0751483766362071 Engine time: 0.020527916494756937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.836994861252606,
    "estimated_duration": 3600.0201447417476,
    "input_throughput": 3162.1484164824396,
    "output_throughput": 2802.832927126256,
    "total_throughput": 5964.981343608695,
    "itl": 181.12230366039444,
    "ttft": 2366681.180001051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.031478100698447,
    "arrivals": 921853,
    "finished_requests": 45986,
    "scheduler_time": 39.464584873537774
}
#Debug simulation 
Total elapsed time: 3.8371027959510684. Arrivals time: 0.19837400177493691 Scheduler time: 3.404044264461845 Scheduler overhead time: 0.029994080774486065 Adapter cache time: 0.15866457112133503 Engine time: 0.031656213104724884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7788025797344744,
    "estimated_duration": 3600.1775026985647,
    "input_throughput": 3162.365464332287,
    "output_throughput": 2803.165952910787,
    "total_throughput": 5965.531417243074,
    "itl": 181.12193808850074,
    "ttft": 2366720.533085021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9902099735359697,
    "arrivals": 921853,
    "finished_requests": 45993,
    "scheduler_time": 39.46678366818752
}
#Debug simulation 
Total elapsed time: 3.7789118248037994. Arrivals time: 0.19757483806461096 Scheduler time: 3.3472768580541015 Scheduler overhead time: 0.030235909391194582 Adapter cache time: 0.1577374767512083 Engine time: 0.0317007377743721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7978645088151097,
    "estimated_duration": 3600.132131692719,
    "input_throughput": 3162.4053183422843,
    "output_throughput": 2803.201280074953,
    "total_throughput": 5965.606598417237,
    "itl": 181.11996199387679,
    "ttft": 2366694.1626389227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9448558931890888,
    "arrivals": 921853,
    "finished_requests": 45993,
    "scheduler_time": 39.46676674268615
}
#Debug simulation 
Total elapsed time: 3.797991754952818. Arrivals time: 0.21060767443850636 Scheduler time: 3.353863258846104 Scheduler overhead time: 0.03016999550163746 Adapter cache time: 0.15706488024443388 Engine time: 0.0318945050239563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.081309541128576,
    "estimated_duration": 3600.269666564145,
    "input_throughput": 3655.341465729489,
    "output_throughput": 3196.59916224638,
    "total_throughput": 6851.940627975869,
    "itl": 266.49049699260905,
    "ttft": 2281496.062247555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5501657829620816,
    "arrivals": 805539,
    "finished_requests": 53067,
    "scheduler_time": 46.03219775654416
}
#Debug simulation 
Total elapsed time: 4.081422686111182. Arrivals time: 0.22357588494196534 Scheduler time: 3.706204667221755 Scheduler overhead time: 0.021625695284456015 Adapter cache time: 0.09701017383486032 Engine time: 0.022793814539909363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.165548148564994,
    "estimated_duration": 3600.1837678624274,
    "input_throughput": 3566.7840388115133,
    "output_throughput": 3133.700035178624,
    "total_throughput": 6700.484073990137,
    "itl": 161.33002519028926,
    "ttft": 2303948.7770844027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6649413314554864,
    "arrivals": 805539,
    "finished_requests": 51745,
    "scheduler_time": 44.03578247073509
}
#Debug simulation 
Total elapsed time: 4.165659032762051. Arrivals time: 0.22080957749858499 Scheduler time: 3.714422568678856 Scheduler overhead time: 0.03367554349824786 Adapter cache time: 0.14515580888837576 Engine time: 0.035417279694229364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.14736754912883,
    "estimated_duration": 3600.1750960619593,
    "input_throughput": 3569.625547951079,
    "output_throughput": 3136.0613577794975,
    "total_throughput": 6705.686905730577,
    "itl": 162.06587589623973,
    "ttft": 2303672.097034778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5171597092458566,
    "arrivals": 805539,
    "finished_requests": 51787,
    "scheduler_time": 44.078080128370146
}
#Debug simulation 
Total elapsed time: 4.147479095030576. Arrivals time: 0.21023948397487402 Scheduler time: 3.709166973363608 Scheduler overhead time: 0.0335716693662107 Adapter cache time: 0.1427018316462636 Engine time: 0.03579912381246686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.143873724155128,
    "estimated_duration": 3600.1886235322677,
    "input_throughput": 3569.9043422314194,
    "output_throughput": 3136.100404906689,
    "total_throughput": 6706.0047471381085,
    "itl": 162.0555861126841,
    "ttft": 2303688.373225573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.363806581764865,
    "arrivals": 805539,
    "finished_requests": 51788,
    "scheduler_time": 44.08086664345646
}
#Debug simulation 
Total elapsed time: 4.143981925211847. Arrivals time: 0.21057138498872519 Scheduler time: 3.7064034659415483 Scheduler overhead time: 0.03366091242060065 Adapter cache time: 0.14211246510967612 Engine time: 0.03516839072108269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.243144871201366,
    "estimated_duration": 3600.0836732431935,
    "input_throughput": 3761.2681340268628,
    "output_throughput": 3324.595505642149,
    "total_throughput": 7085.863639669012,
    "itl": 258.12878577190827,
    "ttft": 2260893.970305223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3504545873404004,
    "arrivals": 794133,
    "finished_requests": 54948,
    "scheduler_time": 47.8241289352109
}
#Debug simulation 
Total elapsed time: 4.243253298103809. Arrivals time: 0.26900004828348756 Scheduler time: 3.83372516091913 Scheduler overhead time: 0.022191637195646763 Adapter cache time: 0.08444007346406579 Engine time: 0.023390717338770628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.213633323088288,
    "estimated_duration": 3600.080724730823,
    "input_throughput": 3621.5654583620044,
    "output_throughput": 3216.4439870624824,
    "total_throughput": 6838.009445424487,
    "itl": 158.6804860022793,
    "ttft": 2288383.610276405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4280778879905176,
    "arrivals": 794133,
    "finished_requests": 52866,
    "scheduler_time": 45.21362276011256
}
#Debug simulation 
Total elapsed time: 4.213742092251778. Arrivals time: 0.21196528291329741 Scheduler time: 3.7881164280697703 Scheduler overhead time: 0.03502014838159084 Adapter cache time: 0.12593534123152494 Engine time: 0.03637683857232332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.206881116144359,
    "estimated_duration": 3600.075494329383,
    "input_throughput": 3622.9143029206357,
    "output_throughput": 3217.421695251882,
    "total_throughput": 6840.335998172517,
    "itl": 159.0079716572562,
    "ttft": 2288267.3028591033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.321972988261819,
    "arrivals": 794133,
    "finished_requests": 52882,
    "scheduler_time": 45.231176641087565
}
#Debug simulation 
Total elapsed time: 4.207018432207406. Arrivals time: 0.21144900238141418 Scheduler time: 3.783081900794059 Scheduler overhead time: 0.03451179061084986 Adapter cache time: 0.1256084805354476 Engine time: 0.03595730755478144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.259271397255361,
    "estimated_duration": 3600.156034148607,
    "input_throughput": 3623.1907384771894,
    "output_throughput": 3217.5877628980134,
    "total_throughput": 6840.778501375203,
    "itl": 159.0018820559409,
    "ttft": 2288320.7852101168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2275874697020788,
    "arrivals": 794133,
    "finished_requests": 52888,
    "scheduler_time": 45.233353102066225
}
#Debug simulation 
Total elapsed time: 4.259378376416862. Arrivals time: 0.2623228752054274 Scheduler time: 3.785079327877611 Scheduler overhead time: 0.0342127219773829 Adapter cache time: 0.12532554287463427 Engine time: 0.03612809022888541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.348746663890779,
    "estimated_duration": 3600.155370910729,
    "input_throughput": 3828.381994667464,
    "output_throughput": 3381.656552483797,
    "total_throughput": 7210.038547151261,
    "itl": 252.91248072761212,
    "ttft": 2258860.31077764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 788332,
    "finished_requests": 55946,
    "scheduler_time": 48.65383644506695
}
#Debug simulation 
Total elapsed time: 4.348874614108354. Arrivals time: 0.23020591819658875 Scheduler time: 3.984468265902251 Scheduler overhead time: 0.023177499417215586 Adapter cache time: 0.07631940813735127 Engine time: 0.023927147034555674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.211627847049385,
    "estimated_duration": 3600.0247166639383,
    "input_throughput": 3590.315072052481,
    "output_throughput": 3186.433400554577,
    "total_throughput": 6776.748472607058,
    "itl": 153.50774935190447,
    "ttft": 2292747.06744265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5860878048813942,
    "arrivals": 788332,
    "finished_requests": 52440,
    "scheduler_time": 44.6880850503539
}
#Debug simulation 
Total elapsed time: 4.21173734171316. Arrivals time: 0.25843727495521307 Scheduler time: 3.7540992069989443 Scheduler overhead time: 0.03517840430140495 Adapter cache time: 0.11074678739532828 Engine time: 0.03660537442192435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.221939219161868,
    "estimated_duration": 3600.132008561955,
    "input_throughput": 3590.2486267893655,
    "output_throughput": 3186.4592666929098,
    "total_throughput": 6776.707893482276,
    "itl": 153.50527214117147,
    "ttft": 2292708.905725483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5182609820202853,
    "arrivals": 788332,
    "finished_requests": 52441,
    "scheduler_time": 44.690255699074186
}
#Debug simulation 
Total elapsed time: 4.22205154504627. Arrivals time: 0.263748649507761 Scheduler time: 3.758192832581699 Scheduler overhead time: 0.03514992678537965 Adapter cache time: 0.11162082618102431 Engine time: 0.036569212563335896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.211513218935579,
    "estimated_duration": 3600.0698851033308,
    "input_throughput": 3590.310580770576,
    "output_throughput": 3186.514252811716,
    "total_throughput": 6776.824833582292,
    "itl": 153.50287376333623,
    "ttft": 2292675.8610022324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4561544936173447,
    "arrivals": 788332,
    "finished_requests": 52441,
    "scheduler_time": 44.69023872884566
}
#Debug simulation 
Total elapsed time: 4.211666667833924. Arrivals time: 0.26118905656039715 Scheduler time: 3.7513345861807466 Scheduler overhead time: 0.03474972164258361 Adapter cache time: 0.11087532620877028 Engine time: 0.03673190250992775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.314504370093346,
    "estimated_duration": 3600.1818352431897,
    "input_throughput": 3900.5321516076788,
    "output_throughput": 3436.732800237636,
    "total_throughput": 7337.264951845315,
    "itl": 248.87296038404887,
    "ttft": 2244126.4618723597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1415619284869207,
    "arrivals": 785377,
    "finished_requests": 56869,
    "scheduler_time": 49.4203216118878
}
#Debug simulation 
Total elapsed time: 4.3146153232082725. Arrivals time: 0.22300508059561253 Scheduler time: 3.9617507574148476 Scheduler overhead time: 0.023196804337203503 Adapter cache time: 0.0715262359008193 Engine time: 0.024233472533524036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.267960907891393,
    "estimated_duration": 3600.164199689413,
    "input_throughput": 3700.776203804652,
    "output_throughput": 3281.025071306204,
    "total_throughput": 6981.801275110856,
    "itl": 155.37412603769215,
    "ttft": 2276129.5029294947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1940556656336463,
    "arrivals": 785377,
    "finished_requests": 54010,
    "scheduler_time": 46.10681539536651
}
#Debug simulation 
Total elapsed time: 4.2680656728334725. Arrivals time: 0.21473093144595623 Scheduler time: 3.8533615902997553 Scheduler overhead time: 0.034812654834240675 Adapter cache time: 0.11203299788758159 Engine time: 0.03657824732363224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.270770769100636,
    "estimated_duration": 3600.1532263948066,
    "input_throughput": 3705.7414396108675,
    "output_throughput": 3285.269613883638,
    "total_throughput": 6991.011053494506,
    "itl": 155.0537724531641,
    "ttft": 2275636.34493031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1446156321023597,
    "arrivals": 785377,
    "finished_requests": 54081,
    "scheduler_time": 46.17348759755938
}
#Debug simulation 
Total elapsed time: 4.2708871508948505. Arrivals time: 0.21436777617782354 Scheduler time: 3.856719500385225 Scheduler overhead time: 0.03475480014458299 Adapter cache time: 0.11176751693710685 Engine time: 0.036572666838765144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.355334223713726,
    "estimated_duration": 3600.0890321219226,
    "input_throughput": 3706.6613855754426,
    "output_throughput": 3286.2728933753015,
    "total_throughput": 6992.934278950745,
    "itl": 155.12757625766426,
    "ttft": 2275454.5586114447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0943584079341944,
    "arrivals": 785377,
    "finished_requests": 54094,
    "scheduler_time": 46.181761117123145
}
#Debug simulation 
Total elapsed time: 4.355440472718328. Arrivals time: 0.2703953683376312 Scheduler time: 3.883601287845522 Scheduler overhead time: 0.034964276012033224 Adapter cache time: 0.11328680254518986 Engine time: 0.036580463871359825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.336420386098325,
    "estimated_duration": 3600.2139734229904,
    "input_throughput": 3930.0425209303608,
    "output_throughput": 3448.5453063767936,
    "total_throughput": 7378.587827307154,
    "itl": 246.7443434613544,
    "ttft": 2240888.0310638566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069004677538749,
    "arrivals": 784050,
    "finished_requests": 57421,
    "scheduler_time": 49.60347429494618
}
#Debug simulation 
Total elapsed time: 4.336532385088503. Arrivals time: 0.2258789404295385 Scheduler time: 3.9823012771084905 Scheduler overhead time: 0.023068353533744812 Adapter cache time: 0.07004646072164178 Engine time: 0.024249244015663862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.283666853327304,
    "estimated_duration": 3600.1050368041933,
    "input_throughput": 3732.224160861558,
    "output_throughput": 3293.3919646203,
    "total_throughput": 7025.616125481858,
    "itl": 153.99130260128297,
    "ttft": 2273258.9189457046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.060431529944768,
    "arrivals": 784050,
    "finished_requests": 54522,
    "scheduler_time": 46.27508637566707
}
#Debug simulation 
Total elapsed time: 4.2837766809388995. Arrivals time: 0.21549136424437165 Scheduler time: 3.8691611322574317 Scheduler overhead time: 0.03480742685496807 Adapter cache time: 0.11083663906902075 Engine time: 0.03672931808978319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.276489404961467,
    "estimated_duration": 3600.028164637076,
    "input_throughput": 3731.7105271464807,
    "output_throughput": 3292.6453510662964,
    "total_throughput": 7024.3558782127775,
    "itl": 153.80872913114595,
    "ttft": 2273472.967615299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0179376168269694,
    "arrivals": 784050,
    "finished_requests": 54511,
    "scheduler_time": 46.265781470578425
}
#Debug simulation 
Total elapsed time: 4.276602804195136. Arrivals time: 0.21470331819728017 Scheduler time: 3.8632585466839373 Scheduler overhead time: 0.035124288871884346 Adapter cache time: 0.10986350476741791 Engine time: 0.036845563910901546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.288320433814079,
    "estimated_duration": 3600.1506612767753,
    "input_throughput": 3731.68799420063,
    "output_throughput": 3292.84413774944,
    "total_throughput": 7024.53213195007,
    "itl": 153.808093248768,
    "ttft": 2273432.8186866674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9717663458432084,
    "arrivals": 784050,
    "finished_requests": 54514,
    "scheduler_time": 46.26791356912285
}
#Debug simulation 
Total elapsed time: 4.288428328931332. Arrivals time: 0.21406951500102878 Scheduler time: 3.8755697729066014 Scheduler overhead time: 0.0351906456053257 Adapter cache time: 0.11012810049578547 Engine time: 0.03677936643362045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.4640106852166355,
    "estimated_duration": 3600.233534490108,
    "input_throughput": 4072.148892440211,
    "output_throughput": 3534.075742062104,
    "total_throughput": 7606.224634502315,
    "itl": 239.7340858805156,
    "ttft": 2217012.449168651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3718780015479304,
    "arrivals": 771112,
    "finished_requests": 59183,
    "scheduler_time": 50.81074353483299
}
#Debug simulation 
Total elapsed time: 4.464115695096552. Arrivals time: 0.23636053362861276 Scheduler time: 4.098483287729323 Scheduler overhead time: 0.024006431456655264 Adapter cache time: 0.06898924289271235 Engine time: 0.024939884431660175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.356084683910012,
    "estimated_duration": 3600.1444025383935,
    "input_throughput": 3857.031954109767,
    "output_throughput": 3363.4864733376107,
    "total_throughput": 7220.518427447378,
    "itl": 151.33071934948362,
    "ttft": 2251402.1576642157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.452406885668174,
    "arrivals": 771112,
    "finished_requests": 56093,
    "scheduler_time": 47.25508795054018
}
#Debug simulation 
Total elapsed time: 4.35619457392022. Arrivals time: 0.22023055981844664 Scheduler time: 3.944010685198009 Scheduler overhead time: 0.03585767559707165 Adapter cache time: 0.10150957200676203 Engine time: 0.03754237852990627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.360111465211958,
    "estimated_duration": 3600.1224245845065,
    "input_throughput": 3855.908039461215,
    "output_throughput": 3362.7064783490473,
    "total_throughput": 7218.614517810262,
    "itl": 151.20835565716095,
    "ttft": 2251448.842147304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3435906478971957,
    "arrivals": 771112,
    "finished_requests": 56080,
    "scheduler_time": 47.24231655592871
}
#Debug simulation 
Total elapsed time: 4.360222027171403. Arrivals time: 0.22007193975150585 Scheduler time: 3.946759338490665 Scheduler overhead time: 0.03566391905769706 Adapter cache time: 0.10333131160587072 Engine time: 0.03734920173883438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.355817432049662,
    "estimated_duration": 3600.074960900466,
    "input_throughput": 3856.1122062102013,
    "output_throughput": 3362.972752370622,
    "total_throughput": 7219.084958580824,
    "itl": 151.15477622849826,
    "ttft": 2251468.378508103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2485178217663933,
    "arrivals": 771112,
    "finished_requests": 56082,
    "scheduler_time": 47.24169590413615
}
#Debug simulation 
Total elapsed time: 4.355921864975244. Arrivals time: 0.22080468526110053 Scheduler time: 3.9431001748889685 Scheduler overhead time: 0.03539941646158695 Adapter cache time: 0.10233393870294094 Engine time: 0.03721688035875559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.526991666760296,
    "estimated_duration": 3600.0164978041107,
    "input_throughput": 4099.7745452007375,
    "output_throughput": 3637.3294422364934,
    "total_throughput": 7737.103987437231,
    "itl": 236.5334574145056,
    "ttft": 2221247.151320266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6679658204433727,
    "arrivals": 765327,
    "finished_requests": 59728,
    "scheduler_time": 52.28253660163965
}
#Debug simulation 
Total elapsed time: 4.527106307912618. Arrivals time: 0.23043152736499906 Scheduler time: 4.1754092667251825 Scheduler overhead time: 0.02441508462652564 Adapter cache time: 0.06007081037387252 Engine time: 0.025363562628626823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.409795095678419,
    "estimated_duration": 3600.14987135876,
    "input_throughput": 3837.616625328323,
    "output_throughput": 3427.398980849369,
    "total_throughput": 7265.015606177692,
    "itl": 148.84447923671553,
    "ttft": 2259690.108111684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7126548832119508,
    "arrivals": 765327,
    "finished_requests": 55973,
    "scheduler_time": 48.14438346214044
}
#Debug simulation 
Total elapsed time: 4.4099029479548335. Arrivals time: 0.2213988807052374 Scheduler time: 4.0079443897120655 Scheduler overhead time: 0.03628000011667609 Adapter cache time: 0.08900111494585872 Engine time: 0.03796653216704726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.405038802418858,
    "estimated_duration": 3600.071884925065,
    "input_throughput": 3837.7175349896042,
    "output_throughput": 3427.5337811086074,
    "total_throughput": 7265.251316098212,
    "itl": 148.8428405923526,
    "ttft": 2259715.824228728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6336661036871294,
    "arrivals": 765327,
    "finished_requests": 55973,
    "scheduler_time": 48.144589716715984
}
#Debug simulation 
Total elapsed time: 4.405150852166116. Arrivals time: 0.21957004396244884 Scheduler time: 4.0059017380699515 Scheduler overhead time: 0.03604015987366438 Adapter cache time: 0.08852394903078675 Engine time: 0.037778555415570736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.4256460489705205,
    "estimated_duration": 3600.0535331265296,
    "input_throughput": 3837.3040491991114,
    "output_throughput": 3427.0273723639043,
    "total_throughput": 7264.331421563015,
    "itl": 148.75436492038378,
    "ttft": 2259639.5684351684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5667863545287213,
    "arrivals": 765327,
    "finished_requests": 55966,
    "scheduler_time": 48.13434027313884
}
#Debug simulation 
Total elapsed time: 4.4257551790215075. Arrivals time: 0.21895143250003457 Scheduler time: 4.026987749617547 Scheduler overhead time: 0.03630621265619993 Adapter cache time: 0.08810150623321533 Engine time: 0.03802551981061697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.917062202002853,
    "estimated_duration": 3600.077064174752,
    "input_throughput": 4182.13936302258,
    "output_throughput": 3679.6309534103284,
    "total_throughput": 7861.770316432909,
    "itl": 232.5404022384525,
    "ttft": 2203890.9803972202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2058321711095108,
    "arrivals": 762451,
    "finished_requests": 61110,
    "scheduler_time": 52.891064901528786
}
#Debug simulation 
Total elapsed time: 4.9171368991956115. Arrivals time: 0.5643075732514262 Scheduler time: 4.235160313080996 Scheduler overhead time: 0.02460103202611208 Adapter cache time: 0.055793098639696836 Engine time: 0.025737378746271133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.452519520651549,
    "estimated_duration": 3600.0095484873555,
    "input_throughput": 3914.1960070413666,
    "output_throughput": 3453.266396258189,
    "total_throughput": 7367.462403299555,
    "itl": 147.86038087943592,
    "ttft": 2246862.6688904967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2497896644682671,
    "arrivals": 762451,
    "finished_requests": 57161,
    "scheduler_time": 48.50282197689048
}
#Debug simulation 
Total elapsed time: 4.452640090603381. Arrivals time: 0.22944635013118386 Scheduler time: 4.043463360518217 Scheduler overhead time: 0.03651647828519344 Adapter cache time: 0.08779995003715158 Engine time: 0.03799194609746337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.426564352121204,
    "estimated_duration": 3600.149533337664,
    "input_throughput": 3908.3712689442573,
    "output_throughput": 3448.195661053857,
    "total_throughput": 7356.566929998114,
    "itl": 147.05979050735414,
    "ttft": 2247021.2555090524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.197080868389457,
    "arrivals": 762451,
    "finished_requests": 57082,
    "scheduler_time": 48.42626652887215
}
#Debug simulation 
Total elapsed time: 4.426676628179848. Arrivals time: 0.22135472856462002 Scheduler time: 4.02909787511453 Scheduler overhead time: 0.03642043890431523 Adapter cache time: 0.08392524672672153 Engine time: 0.03825898328796029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.43786225002259,
    "estimated_duration": 3600.0976256267218,
    "input_throughput": 3908.4276214733213,
    "output_throughput": 3448.2453785788407,
    "total_throughput": 7356.673000052162,
    "itl": 147.05789261365103,
    "ttft": 2246990.8933952516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1451892629475295,
    "arrivals": 762451,
    "finished_requests": 57082,
    "scheduler_time": 48.42625042336864
}
#Debug simulation 
Total elapsed time: 4.4379651779308915. Arrivals time: 0.22427063900977373 Scheduler time: 4.036721537355334 Scheduler overhead time: 0.03675965638831258 Adapter cache time: 0.08415827853605151 Engine time: 0.03858587983995676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.625395251903683,
    "estimated_duration": 3600.1760545169514,
    "input_throughput": 4206.245130984801,
    "output_throughput": 3708.8675103116766,
    "total_throughput": 7915.112641296478,
    "itl": 230.30479262732337,
    "ttft": 2203396.5102314465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0191424187296063,
    "arrivals": 761080,
    "finished_requests": 61531,
    "scheduler_time": 53.31532419040379
}
#Debug simulation 
Total elapsed time: 4.625505499076098. Arrivals time: 0.23540444066748023 Scheduler time: 4.277690520975739 Scheduler overhead time: 0.02479117689654231 Adapter cache time: 0.05001887073740363 Engine time: 0.02596365613862872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.461185416672379,
    "estimated_duration": 3600.0879610543593,
    "input_throughput": 3915.2896130548647,
    "output_throughput": 3465.9680916089683,
    "total_throughput": 7381.2577046638335,
    "itl": 146.6543632196088,
    "ttft": 2245253.8901936472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0736175170796978,
    "arrivals": 761080,
    "finished_requests": 57235,
    "scheduler_time": 48.69330692791746
}
#Debug simulation 
Total elapsed time: 4.461295631714165. Arrivals time: 0.228111841250211 Scheduler time: 4.0619686199352145 Scheduler overhead time: 0.03637800272554159 Adapter cache time: 0.07900550076738 Engine time: 0.03833488654345274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.4415565291419625,
    "estimated_duration": 3600.0442281570513,
    "input_throughput": 3915.3371755145813,
    "output_throughput": 3466.0101957657557,
    "total_throughput": 7381.347371280337,
    "itl": 146.65277088836288,
    "ttft": 2245228.5398295373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.029897818006578,
    "arrivals": 761080,
    "finished_requests": 57235,
    "scheduler_time": 48.69329372967911
}
#Debug simulation 
Total elapsed time: 4.441670817323029. Arrivals time: 0.22207462415099144 Scheduler time: 4.047798289451748 Scheduler overhead time: 0.036850227043032646 Adapter cache time: 0.0790843521244824 Engine time: 0.03837556159123778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.44874744489789,
    "estimated_duration": 3600.1587934456365,
    "input_throughput": 3915.4353484805133,
    "output_throughput": 3465.974340553327,
    "total_throughput": 7381.40968903384,
    "itl": 146.64819239836123,
    "ttft": 2245281.6282807114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9837265470228171,
    "arrivals": 761080,
    "finished_requests": 57240,
    "scheduler_time": 48.69550942665005
}
#Debug simulation 
Total elapsed time: 4.448874869849533. Arrivals time: 0.22169731371104717 Scheduler time: 4.0552933514118195 Scheduler overhead time: 0.036864559166133404 Adapter cache time: 0.07922986336052418 Engine time: 0.03828950738534331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.092155710794032,
    "estimated_duration": 3600.1060257485674,
    "input_throughput": 4294.786845002728,
    "output_throughput": 3796.199306979657,
    "total_throughput": 8090.986151982385,
    "itl": 225.96016906964692,
    "ttft": 2193614.448583116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6863287469069699,
    "arrivals": 753814,
    "finished_requests": 62943,
    "scheduler_time": 54.527489806416504
}
#Debug simulation 
Total elapsed time: 5.092259733006358. Arrivals time: 0.5909741288051009 Scheduler time: 4.3917518076486886 Scheduler overhead time: 0.02517314674332738 Adapter cache time: 0.0458658030256629 Engine time: 0.026549499947577715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.535984816029668,
    "estimated_duration": 3600.136125063656,
    "input_throughput": 3970.85568528252,
    "output_throughput": 3527.2460703900383,
    "total_throughput": 7498.101755672558,
    "itl": 145.71094276051977,
    "ttft": 2238844.2698003408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.721884800228294,
    "arrivals": 753814,
    "finished_requests": 58255,
    "scheduler_time": 49.541813074747694
}
#Debug simulation 
Total elapsed time: 4.536099657882005. Arrivals time: 0.23298333398997784 Scheduler time: 4.137467370834202 Scheduler overhead time: 0.03707747347652912 Adapter cache time: 0.07221659645438194 Engine time: 0.03875543689355254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.498833158053458,
    "estimated_duration": 3600.0468972117196,
    "input_throughput": 3968.8332979957067,
    "output_throughput": 3524.4401982171753,
    "total_throughput": 7493.273496212882,
    "itl": 145.1647416192893,
    "ttft": 2239678.2508681524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6503806195012196,
    "arrivals": 753814,
    "finished_requests": 58210,
    "scheduler_time": 49.480544185596145
}
#Debug simulation 
Total elapsed time: 4.498945388011634. Arrivals time: 0.22572388593107462 Scheduler time: 4.110564052127302 Scheduler overhead time: 0.03715803101658821 Adapter cache time: 0.06908607156947255 Engine time: 0.03873891290277243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.828660051338375,
    "estimated_duration": 3600.0771565377627,
    "input_throughput": 3971.0101696121924,
    "output_throughput": 3527.59106202417,
    "total_throughput": 7498.601231636362,
    "itl": 145.7029264623641,
    "ttft": 2238867.76334043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5817366060032316,
    "arrivals": 753814,
    "finished_requests": 58257,
    "scheduler_time": 49.54177775391011
}
#Debug simulation 
Total elapsed time: 4.828736774157733. Arrivals time: 0.5533979698084295 Scheduler time: 4.11280133575201 Scheduler overhead time: 0.036676489282399416 Adapter cache time: 0.06993613298982382 Engine time: 0.03830382460728288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.828462552744895,
    "estimated_duration": 3600.088665189597,
    "input_throughput": 4375.611954315686,
    "output_throughput": 3856.678068585509,
    "total_throughput": 8232.290022901194,
    "itl": 222.07611335442797,
    "ttft": 2186332.778260539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.199711195621645,
    "arrivals": 750842,
    "finished_requests": 63752,
    "scheduler_time": 55.38997339992052
}
#Debug simulation 
Total elapsed time: 4.828610461670905. Arrivals time: 0.2885237233713269 Scheduler time: 4.434681045357138 Scheduler overhead time: 0.025706952437758446 Adapter cache time: 0.04033644776791334 Engine time: 0.027189903426915407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.595425262115896,
    "estimated_duration": 3600.1003217959665,
    "input_throughput": 4022.2506890519576,
    "output_throughput": 3555.7456336700084,
    "total_throughput": 7577.996322721966,
    "itl": 142.98907513129433,
    "ttft": 2235287.2580915242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.246391018854925,
    "arrivals": 750842,
    "finished_requests": 58628,
    "scheduler_time": 49.90992323470622
}
#Debug simulation 
Total elapsed time: 4.5955331469886005. Arrivals time: 0.27314679604023695 Scheduler time: 4.165264145471156 Scheduler overhead time: 0.03753593936562538 Adapter cache time: 0.06218678317964077 Engine time: 0.039493223652243614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.8991172960959375,
    "estimated_duration": 3600.0508684598385,
    "input_throughput": 4022.3059420810355,
    "output_throughput": 3555.7944783920507,
    "total_throughput": 7578.100420473086,
    "itl": 142.98729973408373,
    "ttft": 2235260.418029756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.196950985323638,
    "arrivals": 750842,
    "finished_requests": 58628,
    "scheduler_time": 49.909909932104505
}
#Debug simulation 
Total elapsed time: 4.899220155086368. Arrivals time: 0.5561130424030125 Scheduler time: 4.185985906049609 Scheduler overhead time: 0.037238080985844135 Adapter cache time: 0.06257212115451694 Engine time: 0.03933296678587794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.581184308975935,
    "estimated_duration": 3600.011159324841,
    "input_throughput": 4021.945866055441,
    "output_throughput": 3555.6900891386836,
    "total_throughput": 7577.635955194124,
    "itl": 142.94499349600397,
    "ttft": 2235249.211998805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1421992126526275,
    "arrivals": 750842,
    "finished_requests": 58624,
    "scheduler_time": 49.90518949453256
}
#Debug simulation 
Total elapsed time: 4.58131391974166. Arrivals time: 0.2735170950181782 Scheduler time: 4.148691232781857 Scheduler overhead time: 0.0376497944816947 Adapter cache time: 0.0641022939234972 Engine time: 0.03939554328098893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.804582593031228,
    "estimated_duration": 3600.0676916067187,
    "input_throughput": 4376.4057650172535,
    "output_throughput": 3878.6356802552577,
    "total_throughput": 8255.04144527251,
    "itl": 221.58017602775425,
    "ttft": 2188154.3518336434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.046686808425002,
    "arrivals": 749452,
    "finished_requests": 64132,
    "scheduler_time": 55.71169626126309
}
#Debug simulation 
Total elapsed time: 4.804693795274943. Arrivals time: 0.24822810711339116 Scheduler time: 4.455397758167237 Scheduler overhead time: 0.025789530482143164 Adapter cache time: 0.03591910935938358 Engine time: 0.027163760736584663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.535118171945214,
    "estimated_duration": 3600.066784175461,
    "input_throughput": 3997.518341398244,
    "output_throughput": 3567.5857615907016,
    "total_throughput": 7565.104102988946,
    "itl": 142.49157842910495,
    "ttft": 2237922.761612541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0948265813966338,
    "arrivals": 749452,
    "finished_requests": 58708,
    "scheduler_time": 50.05860488794464
}
#Debug simulation 
Total elapsed time: 4.535240158904344. Arrivals time: 0.2283501923084259 Scheduler time: 4.15235651191324 Scheduler overhead time: 0.03739052405580878 Adapter cache time: 0.06000879034399986 Engine time: 0.03914896585047245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.546819808892906,
    "estimated_duration": 3600.076168141806,
    "input_throughput": 4001.8869954732877,
    "output_throughput": 3571.3061056250317,
    "total_throughput": 7573.19310109832,
    "itl": 143.00521087219508,
    "ttft": 2236898.757062298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0482467150944315,
    "arrivals": 749452,
    "finished_requests": 58770,
    "scheduler_time": 50.13083796213648
}
#Debug simulation 
Total elapsed time: 4.546932111959904. Arrivals time: 0.2243763250298798 Scheduler time: 4.167178967967629 Scheduler overhead time: 0.0375971170142293 Adapter cache time: 0.060591769870370626 Engine time: 0.03929180232807994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.612124596256763,
    "estimated_duration": 3600.0411757188945,
    "input_throughput": 4000.811739916791,
    "output_throughput": 3570.484161874398,
    "total_throughput": 7571.295901791189,
    "itl": 142.96829415062646,
    "ttft": 2237119.3173068142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0016668487922302,
    "arrivals": 749452,
    "finished_requests": 58757,
    "scheduler_time": 50.12521739337565
}
#Debug simulation 
Total elapsed time: 4.612245698925108. Arrivals time: 0.2856898531317711 Scheduler time: 4.172043491154909 Scheduler overhead time: 0.03749568806961179 Adapter cache time: 0.060260075610131025 Engine time: 0.038844808004796505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.839655493851751,
    "estimated_duration": 3600.1223475076335,
    "input_throughput": 4459.58260588419,
    "output_throughput": 3936.764818510088,
    "total_throughput": 8396.347424394278,
    "itl": 218.15740040112405,
    "ttft": 2176073.175237295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2394975362927723,
    "arrivals": 745115,
    "finished_requests": 64928,
    "scheduler_time": 56.55869592082044
}
#Debug simulation 
Total elapsed time: 4.83976784395054. Arrivals time: 0.24247327214106917 Scheduler time: 4.500859162770212 Scheduler overhead time: 0.02606845973059535 Adapter cache time: 0.030625960789620876 Engine time: 0.027406719513237476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.584474727977067,
    "estimated_duration": 3600.03580527873,
    "input_throughput": 4061.902100684197,
    "output_throughput": 3604.0627654244786,
    "total_throughput": 7665.964866108676,
    "itl": 142.18086363537574,
    "ttft": 2228619.991307373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2855403849412743,
    "arrivals": 745115,
    "finished_requests": 59197,
    "scheduler_time": 50.631133564777656
}
#Debug simulation 
Total elapsed time: 4.584584836382419. Arrivals time: 0.22870399756357074 Scheduler time: 4.209230132866651 Scheduler overhead time: 0.037878931034356356 Adapter cache time: 0.05094791576266289 Engine time: 0.039744355250149965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.565776304807514,
    "estimated_duration": 3600.02537585765,
    "input_throughput": 4060.5672110067985,
    "output_throughput": 3602.977103157198,
    "total_throughput": 7663.544314163997,
    "itl": 142.02511132905016,
    "ttft": 2228548.2756730723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2336487794993438,
    "arrivals": 745115,
    "finished_requests": 59176,
    "scheduler_time": 50.6139034574249
}
#Debug simulation 
Total elapsed time: 4.565852284897119. Arrivals time: 0.2249420452862978 Scheduler time: 4.19529908709228 Scheduler overhead time: 0.03780728206038475 Adapter cache time: 0.050604020711034536 Engine time: 0.039254793897271156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.560520044062287,
    "estimated_duration": 3600.1082035535583,
    "input_throughput": 4043.6523506795284,
    "output_throughput": 3588.7929666244518,
    "total_throughput": 7632.44531730398,
    "itl": 142.52883230103268,
    "ttft": 2229819.7794980174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1750897658965502,
    "arrivals": 745115,
    "finished_requests": 58946,
    "scheduler_time": 50.42483785032283
}
#Debug simulation 
Total elapsed time: 4.560628082137555. Arrivals time: 0.22389947203919291 Scheduler time: 4.189624343067408 Scheduler overhead time: 0.03783931862562895 Adapter cache time: 0.05182920955121517 Engine time: 0.0394927179440856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.929743360728025,
    "estimated_duration": 3600.1607400419566,
    "input_throughput": 4538.2384787101455,
    "output_throughput": 3981.038635467418,
    "total_throughput": 8519.277114177563,
    "itl": 215.00759595886544,
    "ttft": 2166010.50550369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.068110222632532,
    "arrivals": 743719,
    "finished_requests": 65989,
    "scheduler_time": 57.17382472794991
}
#Debug simulation 
Total elapsed time: 4.929880301002413. Arrivals time: 0.2900892966426909 Scheduler time: 4.547690557315946 Scheduler overhead time: 0.02638948429375887 Adapter cache time: 0.025264449883252382 Engine time: 0.027860249392688274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.606559274252504,
    "estimated_duration": 3600.1536563432383,
    "input_throughput": 4129.415691412541,
    "output_throughput": 3632.7324465600827,
    "total_throughput": 7762.148137972624,
    "itl": 141.03048246736455,
    "ttft": 2220812.5621889564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0999894913495567,
    "arrivals": 743719,
    "finished_requests": 60062,
    "scheduler_time": 51.01087717786488
}
#Debug simulation 
Total elapsed time: 4.606668303254992. Arrivals time: 0.23583913873881102 Scheduler time: 4.229315797332674 Scheduler overhead time: 0.038139164447784424 Adapter cache time: 0.0457565956749022 Engine time: 0.03957615606486797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.590870640706271,
    "estimated_duration": 3600.0625328190918,
    "input_throughput": 4124.039753380049,
    "output_throughput": 3628.420306847045,
    "total_throughput": 7752.460060227094,
    "itl": 140.35679088429552,
    "ttft": 2222208.323049527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0550440063211162,
    "arrivals": 743719,
    "finished_requests": 59988,
    "scheduler_time": 50.91519956657247
}
#Debug simulation 
Total elapsed time: 4.59099212475121. Arrivals time: 0.22923490684479475 Scheduler time: 4.218053176999092 Scheduler overhead time: 0.038255786057561636 Adapter cache time: 0.047485290095210075 Engine time: 0.039817470125854015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.591770036146045,
    "estimated_duration": 3600.051855012674,
    "input_throughput": 4123.805322228542,
    "output_throughput": 3628.265793397583,
    "total_throughput": 7752.071115626125,
    "itl": 140.31448880256102,
    "ttft": 2222105.030805591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0076469493820344,
    "arrivals": 743719,
    "finished_requests": 59986,
    "scheduler_time": 50.911736293486115
}
#Debug simulation 
Total elapsed time: 4.591877127066255. Arrivals time: 0.2248903107829392 Scheduler time: 4.224510714877397 Scheduler overhead time: 0.03795574279502034 Adapter cache time: 0.04639892978593707 Engine time: 0.03989245556294918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.009421232622117,
    "estimated_duration": 3600.1142772507615,
    "input_throughput": 4605.35825342223,
    "output_throughput": 4044.6724405425734,
    "total_throughput": 8650.030693964804,
    "itl": 211.3632683390953,
    "ttft": 2158856.9159851614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9885375412902782,
    "arrivals": 740875,
    "finished_requests": 67198,
    "scheduler_time": 58.05827614130349
}
#Debug simulation 
Total elapsed time: 5.00953097268939. Arrivals time: 0.29364936240017414 Scheduler time: 4.630745651200414 Scheduler overhead time: 0.026829408016055822 Adapter cache time: 0.017596411053091288 Engine time: 0.028066490776836872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.650140226818621,
    "estimated_duration": 3600.1076080159646,
    "input_throughput": 4167.110718189809,
    "output_throughput": 3663.0407854024124,
    "total_throughput": 7830.151503592221,
    "itl": 139.04364414133397,
    "ttft": 2217114.4484099727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0348767463117894,
    "arrivals": 740875,
    "finished_requests": 60723,
    "scheduler_time": 51.428559705738095
}
#Debug simulation 
Total elapsed time: 4.6502653690986335. Arrivals time: 0.23429670417681336 Scheduler time: 4.281234009191394 Scheduler overhead time: 0.038380073849111795 Adapter cache time: 0.03768435912206769 Engine time: 0.04028032533824444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.621575166005641,
    "estimated_duration": 3600.0426855040564,
    "input_throughput": 4169.399451967439,
    "output_throughput": 3665.1984858764345,
    "total_throughput": 7834.597937843873,
    "itl": 139.3776897674152,
    "ttft": 2216577.328214131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9923828331939911,
    "arrivals": 740875,
    "finished_requests": 60756,
    "scheduler_time": 51.47716795188081
}
#Debug simulation 
Total elapsed time: 4.621687552891672. Arrivals time: 0.2243816968984902 Scheduler time: 4.263900292105973 Scheduler overhead time: 0.0381999290548265 Adapter cache time: 0.03670572256669402 Engine time: 0.040166194550693035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.688099971972406,
    "estimated_duration": 3600.1434464058234,
    "input_throughput": 4169.355255826097,
    "output_throughput": 3665.141457953062,
    "total_throughput": 7834.496713779159,
    "itl": 139.37650709724193,
    "ttft": 2216566.3669042173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.947845943483991,
    "arrivals": 740875,
    "finished_requests": 60757,
    "scheduler_time": 51.47917482092059
}
#Debug simulation 
Total elapsed time: 4.6882079928182065. Arrivals time: 0.2798727862536907 Scheduler time: 4.274713425897062 Scheduler overhead time: 0.03849480580538511 Adapter cache time: 0.03675853740423918 Engine time: 0.04012858774513006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.216523617040366,
    "estimated_duration": 3600.040262296535,
    "input_throughput": 2720.0993007098195,
    "output_throughput": 2389.3124446649554,
    "total_throughput": 5109.411745374775,
    "itl": 355.9767219161357,
    "ttft": 2409186.8478071606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.837129619945974,
    "arrivals": 599139,
    "finished_requests": 39472,
    "scheduler_time": 34.569869981334975
}
#Debug simulation 
Total elapsed time: 3.2166396593675017. Arrivals time: 0.2160992012359202 Scheduler time: 2.845447659958154 Scheduler overhead time: 0.01672756765037775 Adapter cache time: 0.11335092224180698 Engine time: 0.017240967135876417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.379793598782271,
    "estimated_duration": 3600.140272700335,
    "input_throughput": 2723.200558140043,
    "output_throughput": 2408.1872769632632,
    "total_throughput": 5131.387835103306,
    "itl": 210.05734519407386,
    "ttft": 2420935.429102956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.186173527326624,
    "arrivals": 599139,
    "finished_requests": 39521,
    "scheduler_time": 33.94479793284846
}
#Debug simulation 
Total elapsed time: 3.379904503002763. Arrivals time: 0.17831461410969496 Scheduler time: 2.9173703878186643 Scheduler overhead time: 0.026358915492892265 Adapter cache time: 0.21732455864548683 Engine time: 0.02797170029953122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.3961623567156494,
    "estimated_duration": 3600.0832412637365,
    "input_throughput": 2723.920349285502,
    "output_throughput": 2408.5945848730353,
    "total_throughput": 5132.5149341585375,
    "itl": 210.1724945068091,
    "ttft": 2420939.0427320804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.891836068862824,
    "arrivals": 599139,
    "finished_requests": 39528,
    "scheduler_time": 33.95391029937756
}
#Debug simulation 
Total elapsed time: 3.3962372969835997. Arrivals time: 0.18170385854318738 Scheduler time: 2.929434136953205 Scheduler overhead time: 0.026423963252454996 Adapter cache time: 0.2182228323072195 Engine time: 0.027949918061494827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.43438473995775,
    "estimated_duration": 3600.1449600889064,
    "input_throughput": 2724.4866828245094,
    "output_throughput": 2409.165490876737,
    "total_throughput": 5133.652173701246,
    "itl": 210.45485614713726,
    "ttft": 2420761.96719257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6319315540928265,
    "arrivals": 599139,
    "finished_requests": 39539,
    "scheduler_time": 33.966187087938124
}
#Debug simulation 
Total elapsed time: 3.434522297233343. Arrivals time: 0.21875423286110163 Scheduler time: 2.93099794536829 Scheduler overhead time: 0.026189236901700497 Adapter cache time: 0.21804262371733785 Engine time: 0.028023699764162302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2984326533041894,
    "estimated_duration": 3600.1545102143186,
    "input_throughput": 2888.6354656430876,
    "output_throughput": 2524.1838855019087,
    "total_throughput": 5412.819351144996,
    "itl": 335.42254776135604,
    "ttft": 2367201.764631217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.589952123633209,
    "arrivals": 576120,
    "finished_requests": 42086,
    "scheduler_time": 36.517263591212945
}
#Debug simulation 
Total elapsed time: 3.298544204328209. Arrivals time: 0.18675654102116823 Scheduler time: 2.9755911780521274 Scheduler overhead time: 0.01741320686414838 Adapter cache time: 0.0926687209866941 Engine time: 0.01796164270490408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7644686438143253,
    "estimated_duration": 3600.222354950378,
    "input_throughput": 2845.83117093089,
    "output_throughput": 2503.580365697783,
    "total_throughput": 5349.411536628673,
    "itl": 202.75652549935586,
    "ttft": 2384953.9255268616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7254296449245916,
    "arrivals": 576120,
    "finished_requests": 41460,
    "scheduler_time": 35.27808489922418
}
#Debug simulation 
Total elapsed time: 3.7645778716541827. Arrivals time: 0.4754115776158869 Scheduler time: 3.030556044075638 Scheduler overhead time: 0.0269121783785522 Adapter cache time: 0.1904220781289041 Engine time: 0.028480352833867073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.454541569110006,
    "estimated_duration": 3600.074220338578,
    "input_throughput": 2836.7712371884186,
    "output_throughput": 2496.313534101195,
    "total_throughput": 5333.084771289614,
    "itl": 202.239373645188,
    "ttft": 2385856.932429846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.537402753739109,
    "arrivals": 576120,
    "finished_requests": 41334,
    "scheduler_time": 35.1627939273114
}
#Debug simulation 
Total elapsed time: 3.454652954824269. Arrivals time: 0.18367188796401024 Scheduler time: 3.0145590445026755 Scheduler overhead time: 0.027027980890125036 Adapter cache time: 0.1879508071579039 Engine time: 0.028576030861586332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.484857506118715,
    "estimated_duration": 3600.0074866079367,
    "input_throughput": 2846.009636956018,
    "output_throughput": 2503.8209041318187,
    "total_throughput": 5349.8305410878365,
    "itl": 202.73924269512946,
    "ttft": 2384809.3737560026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4176274870731023,
    "arrivals": 576120,
    "finished_requests": 41461,
    "scheduler_time": 35.27762908889933
}
#Debug simulation 
Total elapsed time: 3.484965220093727. Arrivals time: 0.18172856653109193 Scheduler time: 3.048231587279588 Scheduler overhead time: 0.026816497091203928 Adapter cache time: 0.18713496858254075 Engine time: 0.028244396205991507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.3991464129649103,
    "estimated_duration": 3600.2646002049805,
    "input_throughput": 2990.188276546971,
    "output_throughput": 2624.5168200865082,
    "total_throughput": 5614.705096633479,
    "itl": 323.5042606194457,
    "ttft": 2351011.695272021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2157931266073545,
    "arrivals": 564654,
    "finished_requests": 43536,
    "scheduler_time": 37.91613996114542
}
#Debug simulation 
Total elapsed time: 3.3992597120814025. Arrivals time: 0.19338998151943088 Scheduler time: 3.0835391846485436 Scheduler overhead time: 0.01806839695200324 Adapter cache time: 0.07709432020783424 Engine time: 0.0187473027035594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.48245883686468,
    "estimated_duration": 3600.2253277711943,
    "input_throughput": 2911.4333258938045,
    "output_throughput": 2565.808570020446,
    "total_throughput": 5477.241895914251,
    "itl": 196.69640839956503,
    "ttft": 2378201.413196728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.320138419000436,
    "arrivals": 564654,
    "finished_requests": 42347,
    "scheduler_time": 36.12000563265417
}
#Debug simulation 
Total elapsed time: 3.4825713126920164. Arrivals time: 0.17944730259478092 Scheduler time: 3.055605861824006 Scheduler overhead time: 0.027630727738142014 Adapter cache time: 0.17771971505135298 Engine time: 0.029043384827673435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.478554234839976,
    "estimated_duration": 3600.0666147533934,
    "input_throughput": 2914.7643982467807,
    "output_throughput": 2568.477472640712,
    "total_throughput": 5483.241870887493,
    "itl": 197.0690996357723,
    "ttft": 2377466.1911872383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2190854922798264,
    "arrivals": 564654,
    "finished_requests": 42391,
    "scheduler_time": 36.16376725369121
}
#Debug simulation 
Total elapsed time: 3.4786641015671194. Arrivals time: 0.1705101071856916 Scheduler time: 3.062195047736168 Scheduler overhead time: 0.02733665145933628 Adapter cache time: 0.1770211597904563 Engine time: 0.028572739101946354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4742634128779173,
    "estimated_duration": 3600.1574202027136,
    "input_throughput": 2914.6911579797397,
    "output_throughput": 2568.2668619194374,
    "total_throughput": 5482.958019899177,
    "itl": 197.0754661858973,
    "ttft": 2377417.4737694124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1259257596754084,
    "arrivals": 564654,
    "finished_requests": 42391,
    "scheduler_time": 36.16631726502738
}
#Debug simulation 
Total elapsed time: 3.474374028854072. Arrivals time: 0.16907336236909032 Scheduler time: 3.05913353106007 Scheduler overhead time: 0.027165379375219345 Adapter cache time: 0.17727216007187963 Engine time: 0.028566577937453985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4042207254096866,
    "estimated_duration": 3600.1231441851546,
    "input_throughput": 3058.055116192933,
    "output_throughput": 2688.022773784957,
    "total_throughput": 5746.07788997789,
    "itl": 316.40062411852614,
    "ttft": 2333536.694938649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6006350900768498,
    "arrivals": 558926,
    "finished_requests": 44592,
    "scheduler_time": 38.81607153766984
}
#Debug simulation 
Total elapsed time: 3.4043342932127416. Arrivals time: 0.17172240698710084 Scheduler time: 3.122640243265778 Scheduler overhead time: 0.01785496575757861 Adapter cache time: 0.06510533345863223 Engine time: 0.018553950358182192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5165268890559673,
    "estimated_duration": 3600.093417373578,
    "input_throughput": 2954.171952504194,
    "output_throughput": 2609.0086870168934,
    "total_throughput": 5563.180639521088,
    "itl": 194.59370408576453,
    "ttft": 2363444.5939565287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.672409614236099,
    "arrivals": 558926,
    "finished_requests": 43065,
    "scheduler_time": 36.73345218771687
}
#Debug simulation 
Total elapsed time: 3.516633532010019. Arrivals time: 0.1707090586423874 Scheduler time: 3.1089579686522484 Scheduler overhead time: 0.027604338247328997 Adapter cache time: 0.16698277881368995 Engine time: 0.029200235847383738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.513808032963425,
    "estimated_duration": 3600.160744060607,
    "input_throughput": 2954.1167064680817,
    "output_throughput": 2608.9598958867705,
    "total_throughput": 5563.076602354852,
    "itl": 194.80368368524918,
    "ttft": 2363396.3713398036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599271052235263,
    "arrivals": 558926,
    "finished_requests": 43065,
    "scheduler_time": 36.73663938119342
}
#Debug simulation 
Total elapsed time: 3.513924676924944. Arrivals time: 0.1703790700994432 Scheduler time: 3.105415588244796 Scheduler overhead time: 0.02764236694201827 Adapter cache time: 0.16848468407988548 Engine time: 0.028836716897785664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5105081647634506,
    "estimated_duration": 3600.0192024236458,
    "input_throughput": 2954.847016604383,
    "output_throughput": 2609.5146919426043,
    "total_throughput": 5564.361708546987,
    "itl": 194.91524234101254,
    "ttft": 2363163.585952328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5338958012847985,
    "arrivals": 558926,
    "finished_requests": 43073,
    "scheduler_time": 36.7501104327297
}
#Debug simulation 
Total elapsed time: 3.510616042651236. Arrivals time: 0.1704928483814001 Scheduler time: 3.102893973700702 Scheduler overhead time: 0.027522317599505186 Adapter cache time: 0.16751018119975924 Engine time: 0.02894718199968338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4380991640500724,
    "estimated_duration": 3600.058133466948,
    "input_throughput": 3129.744460306628,
    "output_throughput": 2728.9895428823907,
    "total_throughput": 5858.734003189019,
    "itl": 310.2058341061633,
    "ttft": 2323970.874088691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 556060,
    "finished_requests": 45443,
    "scheduler_time": 39.38997096017082
}
#Debug simulation 
Total elapsed time: 3.438239503186196. Arrivals time: 0.1759778787381947 Scheduler time: 3.1553831873461604 Scheduler overhead time: 0.018150643445551395 Adapter cache time: 0.06127487262710929 Engine time: 0.018847015220671892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5664643007330596,
    "estimated_duration": 3600.208808420607,
    "input_throughput": 3002.328357932621,
    "output_throughput": 2634.866616017611,
    "total_throughput": 5637.194973950232,
    "itl": 192.47372699151623,
    "ttft": 2356240.814213157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2383679416729187,
    "arrivals": 556060,
    "finished_requests": 43596,
    "scheduler_time": 37.089226677983824
}
#Debug simulation 
Total elapsed time: 3.566590229049325. Arrivals time: 0.1696534533984959 Scheduler time: 3.162882539909333 Scheduler overhead time: 0.027879326604306698 Adapter cache time: 0.16387362545356154 Engine time: 0.02899427665397525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5463007879443467,
    "estimated_duration": 3600.011723871482,
    "input_throughput": 3002.4032778360647,
    "output_throughput": 2634.958085580568,
    "total_throughput": 5637.361363416633,
    "itl": 192.46839489360767,
    "ttft": 2356189.887897019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1881107175047507,
    "arrivals": 556060,
    "finished_requests": 43595,
    "scheduler_time": 37.08855981476021
}
#Debug simulation 
Total elapsed time: 3.5464035640470684. Arrivals time: 0.17448182962834835 Scheduler time: 3.1382556413300335 Scheduler overhead time: 0.027761782053858042 Adapter cache time: 0.163387147244066 Engine time: 0.029021894093602896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.529952115379274,
    "estimated_duration": 3600.043733757329,
    "input_throughput": 3001.595480264352,
    "output_throughput": 2634.1474441208084,
    "total_throughput": 5635.74292438516,
    "itl": 191.95550726226102,
    "ttft": 2356230.8878658414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1362191120628233,
    "arrivals": 556060,
    "finished_requests": 43577,
    "scheduler_time": 37.06530182262776
}
#Debug simulation 
Total elapsed time: 3.5300531331449747. Arrivals time: 0.17314738687127829 Scheduler time: 3.122280526906252 Scheduler overhead time: 0.0280369920656085 Adapter cache time: 0.16403775522485375 Engine time: 0.029229401145130396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4654871919192374,
    "estimated_duration": 3600.1816687243836,
    "input_throughput": 3129.2918070969945,
    "output_throughput": 2741.0513990802388,
    "total_throughput": 5870.343206177234,
    "itl": 309.9958244602692,
    "ttft": 2331985.9511725847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.028323881961405,
    "arrivals": 554588,
    "finished_requests": 45188,
    "scheduler_time": 39.55048261780504
}
#Debug simulation 
Total elapsed time: 3.4655893058516085. Arrivals time: 0.17536447430029511 Scheduler time: 3.1869325102306902 Scheduler overhead time: 0.01830042479559779 Adapter cache time: 0.0576205151155591 Engine time: 0.018769501242786646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5453153480775654,
    "estimated_duration": 3600.1156647528,
    "input_throughput": 2995.2490431277365,
    "output_throughput": 2635.9878080893873,
    "total_throughput": 5631.236851217123,
    "itl": 191.6739482166494,
    "ttft": 2364976.5213062484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0876206948515086,
    "arrivals": 554588,
    "finished_requests": 43205,
    "scheduler_time": 37.09989287014847
}
#Debug simulation 
Total elapsed time: 3.545417138375342. Arrivals time: 0.17101887427270412 Scheduler time: 3.1392730087973177 Scheduler overhead time: 0.02799369115382433 Adapter cache time: 0.16446975246071815 Engine time: 0.02923548361286521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5474066049791873,
    "estimated_duration": 3600.1142603080684,
    "input_throughput": 2993.599986206484,
    "output_throughput": 2634.5730480199736,
    "total_throughput": 5628.173034226457,
    "itl": 191.47582458880072,
    "ttft": 2365897.238481817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0443095910968287,
    "arrivals": 554588,
    "finished_requests": 43180,
    "scheduler_time": 37.064290284858565
}
#Debug simulation 
Total elapsed time: 3.547509760130197. Arrivals time: 0.17286171671003103 Scheduler time: 3.141064708121121 Scheduler overhead time: 0.028170475736260414 Adapter cache time: 0.16263521881774068 Engine time: 0.02933877846226096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.536859250161797,
    "estimated_duration": 3600.0365466113976,
    "input_throughput": 2993.6840530534073,
    "output_throughput": 2634.701030723689,
    "total_throughput": 5628.385083777096,
    "itl": 191.47425662799472,
    "ttft": 2365857.4630743694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9956867482024259,
    "arrivals": 554588,
    "finished_requests": 43181,
    "scheduler_time": 37.065217980807574
}
#Debug simulation 
Total elapsed time: 3.5369625110179186. Arrivals time: 0.1706299432553351 Scheduler time: 3.1323975026607513 Scheduler overhead time: 0.02813022118061781 Adapter cache time: 0.16307090362533927 Engine time: 0.02931684022769332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.596512026153505,
    "estimated_duration": 3600.1667427622897,
    "input_throughput": 3177.2958913629063,
    "output_throughput": 2798.41010704687,
    "total_throughput": 5975.705998409776,
    "itl": 304.372736511172,
    "ttft": 2288707.616534096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.692507203715084,
    "arrivals": 438250,
    "finished_requests": 46454,
    "scheduler_time": 40.39394253202131
}
#Debug simulation 
Total elapsed time: 3.596620353870094. Arrivals time: 0.1798461815342307 Scheduler time: 3.2521230853162706 Scheduler overhead time: 0.018775242380797863 Adapter cache time: 0.11755981668829918 Engine time: 0.01939498446881771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7667537410743535,
    "estimated_duration": 3600.0395591784813,
    "input_throughput": 3178.425351140068,
    "output_throughput": 2816.63043789272,
    "total_throughput": 5995.055789032788,
    "itl": 180.2099466780477,
    "ttft": 2296983.537048723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1830,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.952300134156658,
    "arrivals": 438250,
    "finished_requests": 46469,
    "scheduler_time": 39.62750834820154
}
#Debug simulation 
Total elapsed time: 3.766857164911926. Arrivals time: 0.17752824630588293 Scheduler time: 3.3347313115373254 Scheduler overhead time: 0.029982110485434532 Adapter cache time: 0.17933566076681018 Engine time: 0.030968928709626198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7611283287405968,
    "estimated_duration": 3600.054414341235,
    "input_throughput": 3186.972106392305,
    "output_throughput": 2824.03703663473,
    "total_throughput": 6011.009143027035,
    "itl": 180.17366116147534,
    "ttft": 2296015.545619806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.710671471771628,
    "arrivals": 438250,
    "finished_requests": 46598,
    "scheduler_time": 39.727807385377965
}
#Debug simulation 
Total elapsed time: 3.7612289511598647. Arrivals time: 0.17722532944753766 Scheduler time: 3.330178502947092 Scheduler overhead time: 0.029893672093749046 Adapter cache time: 0.17877138266339898 Engine time: 0.030909386929124594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7903337976895273,
    "estimated_duration": 3600.0861213420617,
    "input_throughput": 3186.3262748069355,
    "output_throughput": 2823.799114064051,
    "total_throughput": 6010.125388870986,
    "itl": 179.83909359161737,
    "ttft": 2295920.1867822534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.483752240850432,
    "arrivals": 438250,
    "finished_requests": 46591,
    "scheduler_time": 39.72198779535384
}
#Debug simulation 
Total elapsed time: 3.79045493202284. Arrivals time: 0.19769328134134412 Scheduler time: 3.339003801345825 Scheduler overhead time: 0.030113098677247763 Adapter cache time: 0.17809880431741476 Engine time: 0.031110215932130814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.950760317966342,
    "estimated_duration": 3600.2018579730766,
    "input_throughput": 3330.244934307698,
    "output_throughput": 2932.6297292519635,
    "total_throughput": 6262.874663559662,
    "itl": 291.09670528825177,
    "ttft": 2262943.9665777986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4461091996683644,
    "arrivals": 426621,
    "finished_requests": 48481,
    "scheduler_time": 42.26296317342752
}
#Debug simulation 
Total elapsed time: 3.95083579281345. Arrivals time: 0.413240029476583 Scheduler time: 3.3868343327194452 Scheduler overhead time: 0.01939975842833519 Adapter cache time: 0.10189015790820122 Engine time: 0.02022480219602585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8945550182834268,
    "estimated_duration": 3600.1933736698716,
    "input_throughput": 3307.7564908300906,
    "output_throughput": 2928.671853326631,
    "total_throughput": 6236.428344156722,
    "itl": 173.61778531670626,
    "ttft": 2277212.3341572303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5863828331511525,
    "arrivals": 426621,
    "finished_requests": 48177,
    "scheduler_time": 41.183707950359974
}
#Debug simulation 
Total elapsed time: 3.8946521901525557. Arrivals time: 0.20331323379650712 Scheduler time: 3.4522039857693017 Scheduler overhead time: 0.030898614786565304 Adapter cache time: 0.16133305709809065 Engine time: 0.032123074401170015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.875477039720863,
    "estimated_duration": 3600.072252591045,
    "input_throughput": 3305.8380957311133,
    "output_throughput": 2927.399579943146,
    "total_throughput": 6233.237675674259,
    "itl": 172.85941788359625,
    "ttft": 2277309.620792953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.433010759549174,
    "arrivals": 426621,
    "finished_requests": 48152,
    "scheduler_time": 41.15769350137195
}
#Debug simulation 
Total elapsed time: 3.8755818968638778. Arrivals time: 0.19833991210907698 Scheduler time: 3.4358572461642325 Scheduler overhead time: 0.031074172351509333 Adapter cache time: 0.1633153036236763 Engine time: 0.03212723648175597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.978904746938497,
    "estimated_duration": 3600.1536618652017,
    "input_throughput": 3176.406918718953,
    "output_throughput": 2822.663128977435,
    "total_throughput": 5999.0700476963875,
    "itl": 162.99053673647168,
    "ttft": 2288965.6696663788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1754334131860347,
    "arrivals": 426621,
    "finished_requests": 46342,
    "scheduler_time": 39.458167802327345
}
#Debug simulation 
Total elapsed time: 3.9789779628627002. Arrivals time: 0.17995898239314556 Scheduler time: 3.5620959107764065 Scheduler overhead time: 0.032465987373143435 Adapter cache time: 0.1552309487015009 Engine time: 0.033675923477858305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.0705079841427505,
    "estimated_duration": 3600.038580932426,
    "input_throughput": 3443.8622590508053,
    "output_throughput": 3043.58932652385,
    "total_throughput": 6487.451585574655,
    "itl": 280.6623082015969,
    "ttft": 2238186.568756266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9311677664215987,
    "arrivals": 420933,
    "finished_requests": 50378,
    "scheduler_time": 43.863530606300905
}
#Debug simulation 
Total elapsed time: 4.070603928994387. Arrivals time: 0.18817292666062713 Scheduler time: 3.74091571662575 Scheduler overhead time: 0.020349155645817518 Adapter cache time: 0.09066078905016184 Engine time: 0.02084921021014452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9315284877084196,
    "estimated_duration": 3600.0272952656537,
    "input_throughput": 3371.74276871817,
    "output_throughput": 3001.300021866277,
    "total_throughput": 6373.042790584447,
    "itl": 169.32283376699226,
    "ttft": 2259039.85450587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0528901476226786,
    "arrivals": 420933,
    "finished_requests": 49375,
    "scheduler_time": 42.1707043007845
}
#Debug simulation 
Total elapsed time: 3.931621056050062. Arrivals time: 0.1832453841343522 Scheduler time: 3.523571876809001 Scheduler overhead time: 0.031503190752118826 Adapter cache time: 0.14538596803322434 Engine time: 0.03279154887422919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.163163212127984,
    "estimated_duration": 3600.127002958564,
    "input_throughput": 3364.0066003358693,
    "output_throughput": 2994.8746227951046,
    "total_throughput": 6358.881223130974,
    "itl": 169.7364489767024,
    "ttft": 2259103.68365018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.964095080455285,
    "arrivals": 420933,
    "finished_requests": 49271,
    "scheduler_time": 42.095849104519
}
#Debug simulation 
Total elapsed time: 4.1632569171488285. Arrivals time: 0.417589926160872 Scheduler time: 3.520300316158682 Scheduler overhead time: 0.031588208861649036 Adapter cache time: 0.14584300015121698 Engine time: 0.032835100777447224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9419427230022848,
    "estimated_duration": 3600.1304520802305,
    "input_throughput": 3372.330297915948,
    "output_throughput": 3002.16954464936,
    "total_throughput": 6374.4998425653075,
    "itl": 169.71243688376694,
    "ttft": 2258873.4491122924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8837316857883406,
    "arrivals": 420933,
    "finished_requests": 49391,
    "scheduler_time": 42.18972563112139
}
#Debug simulation 
Total elapsed time: 3.942042436916381. Arrivals time: 0.18684470746666193 Scheduler time: 3.528010934125632 Scheduler overhead time: 0.03178565436974168 Adapter cache time: 0.14738819748163223 Engine time: 0.032913270406425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.896830542013049,
    "estimated_duration": 3600.2590797173534,
    "input_throughput": 3523.9125071510193,
    "output_throughput": 3106.3711672877735,
    "total_throughput": 6630.283674438792,
    "itl": 275.30255612190183,
    "ttft": 2224780.756325333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4261872886726767,
    "arrivals": 418062,
    "finished_requests": 51476,
    "scheduler_time": 44.724679079297026
}
#Debug simulation 
Total elapsed time: 3.8969268817454576. Arrivals time: 0.18912634858861566 Scheduler time: 3.570514793507755 Scheduler overhead time: 0.020571827422827482 Adapter cache time: 0.08570081181824207 Engine time: 0.021227673161774874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9676144272089005,
    "estimated_duration": 3600.163763930834,
    "input_throughput": 3423.762864204198,
    "output_throughput": 3036.3032675115855,
    "total_throughput": 6460.066131715784,
    "itl": 167.58516591198054,
    "ttft": 2249157.839027782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5046691393479759,
    "arrivals": 418062,
    "finished_requests": 50051,
    "scheduler_time": 42.64339231477203
}
#Debug simulation 
Total elapsed time: 3.9677326111122966. Arrivals time: 0.18643973022699356 Scheduler time: 3.5562612833455205 Scheduler overhead time: 0.032023193780332804 Adapter cache time: 0.14427988231182098 Engine time: 0.03334219567477703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.9645035448484123,
    "estimated_duration": 3600.1044476555076,
    "input_throughput": 3423.316789607574,
    "output_throughput": 3035.6541480670285,
    "total_throughput": 6458.970937674602,
    "itl": 167.50328786257066,
    "ttft": 2248998.3171316455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4395726006501317,
    "arrivals": 418062,
    "finished_requests": 50041,
    "scheduler_time": 42.63550286307087
}
#Debug simulation 
Total elapsed time: 3.96460605179891. Arrivals time: 0.18649451015517116 Scheduler time: 3.554856418631971 Scheduler overhead time: 0.031793837901204824 Adapter cache time: 0.14293988095596433 Engine time: 0.03311258414760232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.992280647624284,
    "estimated_duration": 3600.1534857215493,
    "input_throughput": 3423.6270894794043,
    "output_throughput": 3036.0569468357917,
    "total_throughput": 6459.684036315196,
    "itl": 167.5830247025507,
    "ttft": 2249033.765743684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.378413185949891,
    "arrivals": 418062,
    "finished_requests": 50048,
    "scheduler_time": 42.64505130552227
}
#Debug simulation 
Total elapsed time: 3.9923762320540845. Arrivals time: 0.18519009463489056 Scheduler time: 3.5824741483666003 Scheduler overhead time: 0.03191400179639459 Adapter cache time: 0.14428654266521335 Engine time: 0.03318228246644139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.921909152995795,
    "estimated_duration": 3600.187636633074,
    "input_throughput": 3542.582856022364,
    "output_throughput": 3127.8314178455366,
    "total_throughput": 6670.414273867901,
    "itl": 272.85248187742405,
    "ttft": 2220319.1447631917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0589287594007335,
    "arrivals": 416618,
    "finished_requests": 51720,
    "scheduler_time": 45.06961159778152
}
#Debug simulation 
Total elapsed time: 3.922009176108986. Arrivals time: 0.18816795526072383 Scheduler time: 3.601688974071294 Scheduler overhead time: 0.020638787653297186 Adapter cache time: 0.08032406447455287 Engine time: 0.021397247910499573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9742511468939483,
    "estimated_duration": 3600.0988984236606,
    "input_throughput": 3435.456732984598,
    "output_throughput": 3047.533778809229,
    "total_throughput": 6482.990511793827,
    "itl": 166.97397956418507,
    "ttft": 2247640.366859519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1203813650296126,
    "arrivals": 416618,
    "finished_requests": 50139,
    "scheduler_time": 42.830220323082514
}
#Debug simulation 
Total elapsed time: 3.9743522056378424. Arrivals time: 0.18860958563163877 Scheduler time: 3.5656930189579725 Scheduler overhead time: 0.03183718817308545 Adapter cache time: 0.139548365958035 Engine time: 0.03333803405985236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.9960620109923184,
    "estimated_duration": 3600.1768395465983,
    "input_throughput": 3435.4745756204716,
    "output_throughput": 3047.722511703576,
    "total_throughput": 6483.197087324047,
    "itl": 166.96601392679403,
    "ttft": 2247575.09671634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0738014987274094,
    "arrivals": 416618,
    "finished_requests": 50142,
    "scheduler_time": 42.83195603406135
}
#Debug simulation 
Total elapsed time: 3.9961649579927325. Arrivals time: 0.2058754889294505 Scheduler time: 3.5710851131007075 Scheduler overhead time: 0.03267701854929328 Adapter cache time: 0.1379247442819178 Engine time: 0.03323163324967027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9748660712502897,
    "estimated_duration": 3600.0577545450633,
    "input_throughput": 3435.588216434871,
    "output_throughput": 3047.8233262084336,
    "total_throughput": 6483.4115426433045,
    "itl": 166.97053905101674,
    "ttft": 2247571.556573394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0255872511514468,
    "arrivals": 416618,
    "finished_requests": 50142,
    "scheduler_time": 42.83125545447768
}
#Debug simulation 
Total elapsed time: 3.9749627453275025. Arrivals time: 0.18749872175976634 Scheduler time: 3.5677762147970498 Scheduler overhead time: 0.03199082054197788 Adapter cache time: 0.13875723304226995 Engine time: 0.03355510625988245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.0121029037982225,
    "estimated_duration": 3600.0159899177524,
    "input_throughput": 3704.825488929207,
    "output_throughput": 3192.0847107855598,
    "total_throughput": 6896.910199714767,
    "itl": 264.30006713139704,
    "ttft": 2202861.657589864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7735813882691804,
    "arrivals": 403575,
    "finished_requests": 53283,
    "scheduler_time": 45.93653643059946
}
#Debug simulation 
Total elapsed time: 4.01221542712301. Arrivals time: 0.1919170725159347 Scheduler time: 3.672394184861332 Scheduler overhead time: 0.021437485236674547 Adapter cache time: 0.09417666913941503 Engine time: 0.02208178397268057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.072085877880454,
    "estimated_duration": 3600.0581242135454,
    "input_throughput": 3616.6291072992926,
    "output_throughput": 3126.8161822968063,
    "total_throughput": 6743.4452895960985,
    "itl": 161.41357258272967,
    "ttft": 2226528.104684542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.881488630885728,
    "arrivals": 403575,
    "finished_requests": 51972,
    "scheduler_time": 43.92012977902349
}
#Debug simulation 
Total elapsed time: 4.072184027172625. Arrivals time: 0.1912217023782432 Scheduler time: 3.661249046679586 Scheduler overhead time: 0.03328819153830409 Adapter cache time: 0.13624651776626706 Engine time: 0.03424937557429075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.0598772880621254,
    "estimated_duration": 3600.029214262419,
    "input_throughput": 3608.232107822315,
    "output_throughput": 3118.91607865756,
    "total_throughput": 6727.148186479875,
    "itl": 161.68103440450795,
    "ttft": 2229031.9126419113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.723622008780903,
    "arrivals": 403575,
    "finished_requests": 51845,
    "scheduler_time": 43.788724810664434
}
#Debug simulation 
Total elapsed time: 4.059984690975398. Arrivals time: 0.18867122055962682 Scheduler time: 3.6500420258380473 Scheduler overhead time: 0.03308287123218179 Adapter cache time: 0.13809278747066855 Engine time: 0.03424484981223941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.082866303157061,
    "estimated_duration": 3600.0747075340655,
    "input_throughput": 3617.2779894670493,
    "output_throughput": 3127.180660012309,
    "total_throughput": 6744.458649479358,
    "itl": 161.4714242853959,
    "ttft": 2226501.1300418144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5641399515233037,
    "arrivals": 403575,
    "finished_requests": 51982,
    "scheduler_time": 43.93065960430914
}
#Debug simulation 
Total elapsed time: 4.082960734143853. Arrivals time: 0.18889026110991836 Scheduler time: 3.674289950169623 Scheduler overhead time: 0.032907324843108654 Adapter cache time: 0.13681800896301866 Engine time: 0.0341923413798213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.120439037680626,
    "estimated_duration": 3600.10859811813,
    "input_throughput": 3768.063832044124,
    "output_throughput": 3307.912435259609,
    "total_throughput": 7075.976267303733,
    "itl": 257.8371333653712,
    "ttft": 2178783.41266529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.448390195146252,
    "arrivals": 397780,
    "finished_requests": 54722,
    "scheduler_time": 47.56260169118103
}
#Debug simulation 
Total elapsed time: 4.120538353919983. Arrivals time: 0.1948886625468731 Scheduler time: 3.789604776073247 Scheduler overhead time: 0.02201998047530651 Adapter cache time: 0.0810345453210175 Engine time: 0.02257173042744398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.141582480166107,
    "estimated_duration": 3600.012386405312,
    "input_throughput": 3630.4030645433877,
    "output_throughput": 3207.9289625810156,
    "total_throughput": 6838.332027124404,
    "itl": 158.42183839753034,
    "ttft": 2208771.2401717086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5345128587726555,
    "arrivals": 397780,
    "finished_requests": 52783,
    "scheduler_time": 45.02530575667608
}
#Debug simulation 
Total elapsed time: 4.14168811077252. Arrivals time: 0.19211721466854215 Scheduler time: 3.7422435875050724 Scheduler overhead time: 0.033713086508214474 Adapter cache time: 0.12251406721770763 Engine time: 0.03495409386232495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.1378537733107805,
    "estimated_duration": 3600.153887692988,
    "input_throughput": 3630.4025904779814,
    "output_throughput": 3207.838709194879,
    "total_throughput": 6838.241299672861,
    "itl": 158.4189212070777,
    "ttft": 2208702.5085104867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.421331955564649,
    "arrivals": 397780,
    "finished_requests": 52786,
    "scheduler_time": 45.02939201468829
}
#Debug simulation 
Total elapsed time: 4.137951785232872. Arrivals time: 0.19054458290338516 Scheduler time: 3.7405742132104933 Scheduler overhead time: 0.03338197432458401 Adapter cache time: 0.12233494268730283 Engine time: 0.03483869647607207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.175381200388074,
    "estimated_duration": 3600.0190570191057,
    "input_throughput": 3630.542447967557,
    "output_throughput": 3208.041906745581,
    "total_throughput": 6838.584354713138,
    "itl": 158.41924659743944,
    "ttft": 2208763.287338759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.323269079138945,
    "arrivals": 397780,
    "finished_requests": 52784,
    "scheduler_time": 45.02667850804281
}
#Debug simulation 
Total elapsed time: 4.175480983220041. Arrivals time: 0.21982673276215792 Scheduler time: 3.746619688346982 Scheduler overhead time: 0.034030838403850794 Adapter cache time: 0.1237113862298429 Engine time: 0.03507175017148256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.213163021020591,
    "estimated_duration": 3600.0044995887306,
    "input_throughput": 3824.9216081738437,
    "output_throughput": 3383.0918826327475,
    "total_throughput": 7208.013490806591,
    "itl": 253.61121887469196,
    "ttft": 2170355.937015135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4476107028802068,
    "arrivals": 394936,
    "finished_requests": 55768,
    "scheduler_time": 48.668343386807344
}
#Debug simulation 
Total elapsed time: 4.213259330019355. Arrivals time: 0.2019912307150662 Scheduler time: 3.881451870780438 Scheduler overhead time: 0.02236935030668974 Adapter cache time: 0.07381722517311573 Engine time: 0.02304711239412427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.422280401922762,
    "estimated_duration": 3600.0049238224815,
    "input_throughput": 3665.713319632874,
    "output_throughput": 3255.993602240417,
    "total_throughput": 6921.706921873291,
    "itl": 156.92032831011562,
    "ttft": 2204729.8815362724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5230180364358283,
    "arrivals": 394936,
    "finished_requests": 53441,
    "scheduler_time": 45.71832125882375
}
#Debug simulation 
Total elapsed time: 4.422354876995087. Arrivals time: 0.424863348249346 Scheduler time: 3.797946184873581 Scheduler overhead time: 0.03389905858784914 Adapter cache time: 0.11400012345984578 Engine time: 0.03527296055108309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.184544939082116,
    "estimated_duration": 3600.1700076690922,
    "input_throughput": 3666.675176972179,
    "output_throughput": 3256.589265236063,
    "total_throughput": 6923.264442208242,
    "itl": 157.0503265678429,
    "ttft": 2204636.5989575186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4588685714406837,
    "arrivals": 394936,
    "finished_requests": 53455,
    "scheduler_time": 45.7285202492369
}
#Debug simulation 
Total elapsed time: 4.184643074404448. Arrivals time: 0.19617438036948442 Scheduler time: 3.7906854823231697 Scheduler overhead time: 0.033962704706937075 Adapter cache time: 0.11222021840512753 Engine time: 0.03535488434135914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.206719001755118,
    "estimated_duration": 3600.029633517904,
    "input_throughput": 3663.771508211504,
    "output_throughput": 3254.6295982987576,
    "total_throughput": 6918.401106510261,
    "itl": 156.69117686014405,
    "ttft": 2204706.8471016544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3933634374244013,
    "arrivals": 394936,
    "finished_requests": 53417,
    "scheduler_time": 45.703137878224055
}
#Debug simulation 
Total elapsed time: 4.206819107756019. Arrivals time: 0.21220172941684723 Scheduler time: 3.795511547010392 Scheduler overhead time: 0.034228489734232426 Adapter cache time: 0.11301784310489893 Engine time: 0.03550870670005679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.264923297800124,
    "estimated_duration": 3600.1158924920114,
    "input_throughput": 3932.8236709067046,
    "output_throughput": 3434.5891546955077,
    "total_throughput": 7367.412825602212,
    "itl": 247.41044030683307,
    "ttft": 2153256.058302536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1385014407429879,
    "arrivals": 393551,
    "finished_requests": 57343,
    "scheduler_time": 49.364764464541736
}
#Debug simulation 
Total elapsed time: 4.265026479959488. Arrivals time: 0.2020850325934589 Scheduler time: 3.9366545216180384 Scheduler overhead time: 0.022682237904518843 Adapter cache time: 0.06927937734872103 Engine time: 0.023501685354858637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.226368197239935,
    "estimated_duration": 3600.1587758189767,
    "input_throughput": 3742.071347099221,
    "output_throughput": 3287.9110997840025,
    "total_throughput": 7029.982446883224,
    "itl": 154.45340778165794,
    "ttft": 2190625.0424941354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2106402983819193,
    "arrivals": 393551,
    "finished_requests": 54586,
    "scheduler_time": 46.13977090672931
}
#Debug simulation 
Total elapsed time: 4.226463867817074. Arrivals time: 0.19909673649817705 Scheduler time: 3.8302074731327593 Scheduler overhead time: 0.0346280406229198 Adapter cache time: 0.11014843313023448 Engine time: 0.03579577337950468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.224387167021632,
    "estimated_duration": 3600.102426031637,
    "input_throughput": 3744.652069485739,
    "output_throughput": 3289.336690637794,
    "total_throughput": 7033.988760123533,
    "itl": 155.09642752419884,
    "ttft": 2189587.6630885215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.15915728825843,
    "arrivals": 393551,
    "finished_requests": 54618,
    "scheduler_time": 46.176422461668984
}
#Debug simulation 
Total elapsed time: 4.224497241899371. Arrivals time: 0.1969585125334561 Scheduler time: 3.8314145589247346 Scheduler overhead time: 0.03465262707322836 Adapter cache time: 0.10928139742463827 Engine time: 0.035631861072033644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.239488793071359,
    "estimated_duration": 3600.0863320443773,
    "input_throughput": 3742.8699639956026,
    "output_throughput": 3288.4005849041037,
    "total_throughput": 7031.270548899706,
    "itl": 154.56060464549995,
    "ttft": 2190111.037977375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1093086594087047,
    "arrivals": 393551,
    "finished_requests": 54599,
    "scheduler_time": 46.1529669064079
}
#Debug simulation 
Total elapsed time: 4.239586699754. Arrivals time: 0.2153084329329431 Scheduler time: 3.827999046072364 Scheduler overhead time: 0.034195379819720984 Adapter cache time: 0.11008570250123739 Engine time: 0.035494948737323284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.38625822076574,
    "estimated_duration": 3600.034861837694,
    "input_throughput": 4038.384504026354,
    "output_throughput": 3548.8942441735744,
    "total_throughput": 7587.2787481999285,
    "itl": 240.73556206041735,
    "ttft": 2133109.482611489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5708097049035663,
    "arrivals": 386177,
    "finished_requests": 58842,
    "scheduler_time": 50.970693956521934
}
#Debug simulation 
Total elapsed time: 4.38635810976848. Arrivals time: 0.20707875536754727 Scheduler time: 4.054530141875148 Scheduler overhead time: 0.023542411625385284 Adapter cache time: 0.06587447971105576 Engine time: 0.024146834388375282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.322817577980459,
    "estimated_duration": 3600.0683879889657,
    "input_throughput": 3821.5324036344855,
    "output_throughput": 3370.3706964238895,
    "total_throughput": 7191.9031000583755,
    "itl": 151.35619098827033,
    "ttft": 2173346.156902285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.613628781582234,
    "arrivals": 386177,
    "finished_requests": 55667,
    "scheduler_time": 47.29957772674617
}
#Debug simulation 
Total elapsed time: 4.32291897572577. Arrivals time: 0.21740805078297853 Scheduler time: 3.918712379410863 Scheduler overhead time: 0.03511517262086272 Adapter cache time: 0.09841609047725797 Engine time: 0.03637878177687526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.312186190858483,
    "estimated_duration": 3600.014686121839,
    "input_throughput": 3821.589409908974,
    "output_throughput": 3370.4209726630406,
    "total_throughput": 7192.010382572015,
    "itl": 151.37793896467997,
    "ttft": 2173353.2022446273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.505351022195514,
    "arrivals": 386177,
    "finished_requests": 55667,
    "scheduler_time": 47.301932077744
}
#Debug simulation 
Total elapsed time: 4.312291532754898. Arrivals time: 0.20253691915422678 Scheduler time: 3.9234851035289466 Scheduler overhead time: 0.034981179516762495 Adapter cache time: 0.09815350640565157 Engine time: 0.03617794066667557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.313581596128643,
    "estimated_duration": 3600.091033613677,
    "input_throughput": 3821.5825298700947,
    "output_throughput": 3370.533102275467,
    "total_throughput": 7192.115632145562,
    "itl": 151.3750086437338,
    "ttft": 2173352.898883701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3950302862165946,
    "arrivals": 386177,
    "finished_requests": 55670,
    "scheduler_time": 47.30594825165779
}
#Debug simulation 
Total elapsed time: 4.313692071009427. Arrivals time: 0.21437679138034582 Scheduler time: 3.9113434315659106 Scheduler overhead time: 0.03518912987783551 Adapter cache time: 0.09971336647868156 Engine time: 0.0362705304287374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.458713104017079,
    "estimated_duration": 3600.0742493411854,
    "input_throughput": 4107.996384437462,
    "output_throughput": 3623.0352755604717,
    "total_throughput": 7731.031659997934,
    "itl": 236.3910450040593,
    "ttft": 2118534.9485521447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7903853302006871,
    "arrivals": 383371,
    "finished_requests": 59972,
    "scheduler_time": 52.043638115753055
}
#Debug simulation 
Total elapsed time: 4.458812620956451. Arrivals time: 0.20713061932474375 Scheduler time: 4.132393548730761 Scheduler overhead time: 0.02398652955889702 Adapter cache time: 0.059368666261434555 Engine time: 0.024609681218862534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.342956808861345,
    "estimated_duration": 3600.070023508119,
    "input_throughput": 3854.083367656115,
    "output_throughput": 3416.8632609021415,
    "total_throughput": 7270.946628558257,
    "itl": 149.3714442822496,
    "ttft": 2163169.7215410336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8192197370599068,
    "arrivals": 383371,
    "finished_requests": 56349,
    "scheduler_time": 47.95933794703095
}
#Debug simulation 
Total elapsed time: 4.343085807748139. Arrivals time: 0.19961001025512815 Scheduler time: 3.966234266292304 Scheduler overhead time: 0.03534989105537534 Adapter cache time: 0.08798282593488693 Engine time: 0.03669299837201834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.344641369301826,
    "estimated_duration": 3600.0528835162086,
    "input_throughput": 3854.53782180184,
    "output_throughput": 3417.3020225147507,
    "total_throughput": 7271.839844316591,
    "itl": 149.44891986823743,
    "ttft": 2163120.953265803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7399522452824634,
    "arrivals": 383371,
    "finished_requests": 56354,
    "scheduler_time": 47.96406815031888
}
#Debug simulation 
Total elapsed time: 4.344736990984529. Arrivals time: 0.19891899405047297 Scheduler time: 3.968030686955899 Scheduler overhead time: 0.035632127430289984 Adapter cache time: 0.08830305095762014 Engine time: 0.03682641917839646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.3440551701933146,
    "estimated_duration": 3600.0784316023896,
    "input_throughput": 3855.0657336158874,
    "output_throughput": 3417.624986165547,
    "total_throughput": 7272.690719781434,
    "itl": 149.5137189293151,
    "ttft": 2163162.7553091208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6684480645553916,
    "arrivals": 383371,
    "finished_requests": 56363,
    "scheduler_time": 47.97044761535253
}
#Debug simulation 
Total elapsed time: 4.344152105040848. Arrivals time: 0.19732800079509616 Scheduler time: 3.9682524050585926 Scheduler overhead time: 0.03562067402526736 Adapter cache time: 0.08910197811201215 Engine time: 0.03680992824956775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.492960154078901,
    "estimated_duration": 3600.1298142024475,
    "input_throughput": 4165.270080218488,
    "output_throughput": 3647.8123505969525,
    "total_throughput": 7813.082430815441,
    "itl": 233.62142072112206,
    "ttft": 2113349.938169879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3190702176350266,
    "arrivals": 381963,
    "finished_requests": 60568,
    "scheduler_time": 52.39225384897149
}
#Debug simulation 
Total elapsed time: 4.49305629497394. Arrivals time: 0.20941162621602416 Scheduler time: 4.167462831363082 Scheduler overhead time: 0.02404682245105505 Adapter cache time: 0.055982692167162895 Engine time: 0.02471577376127243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.353126260917634,
    "estimated_duration": 3600.062267321683,
    "input_throughput": 3900.6261440158682,
    "output_throughput": 3430.128448635687,
    "total_throughput": 7330.754592651556,
    "itl": 148.33020834336853,
    "ttft": 2160041.3824779997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3944269276340544,
    "arrivals": 381963,
    "finished_requests": 56749,
    "scheduler_time": 48.13391452901826
}
#Debug simulation 
Total elapsed time: 4.353221706114709. Arrivals time: 0.1997638107277453 Scheduler time: 3.979852539487183 Scheduler overhead time: 0.035700997337698936 Adapter cache time: 0.08376081893220544 Engine time: 0.036965092178434134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.371929086744785,
    "estimated_duration": 3600.139013124403,
    "input_throughput": 3900.879368491963,
    "output_throughput": 3430.580028986571,
    "total_throughput": 7331.459397478534,
    "itl": 148.41664517374753,
    "ttft": 2159885.90537168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3335462251864336,
    "arrivals": 381963,
    "finished_requests": 56755,
    "scheduler_time": 48.14436380962534
}
#Debug simulation 
Total elapsed time: 4.372027436736971. Arrivals time: 0.2056689327582717 Scheduler time: 3.9921838343143463 Scheduler overhead time: 0.035850110463798046 Adapter cache time: 0.08421055786311626 Engine time: 0.03695281082764268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.3694213149137795,
    "estimated_duration": 3600.05298133706,
    "input_throughput": 3900.9725892378856,
    "output_throughput": 3430.662010816574,
    "total_throughput": 7331.63460005446,
    "itl": 148.41569127501754,
    "ttft": 2159874.8963437616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2767514759232206,
    "arrivals": 381963,
    "finished_requests": 56755,
    "scheduler_time": 48.144683927840106
}
#Debug simulation 
Total elapsed time: 4.3695275518111885. Arrivals time: 0.2020045225508511 Scheduler time: 3.993207191117108 Scheduler overhead time: 0.03563298797234893 Adapter cache time: 0.08461899822577834 Engine time: 0.03692492516711354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.6412682379595935,
    "estimated_duration": 3600.0569408555166,
    "input_throughput": 4323.3096741801355,
    "output_throughput": 3788.4025791989166,
    "total_throughput": 8111.7122533790525,
    "itl": 225.16840489870035,
    "ttft": 2084181.1720249357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7750828914810228,
    "arrivals": 377711,
    "finished_requests": 62931,
    "scheduler_time": 54.394950132016824
}
#Debug simulation 
Total elapsed time: 4.641369407996535. Arrivals time: 0.22544109728187323 Scheduler time: 4.309188562911004 Scheduler overhead time: 0.02497462509199977 Adapter cache time: 0.04438025690615177 Engine time: 0.025562254711985588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.442482199985534,
    "estimated_duration": 3600.0251169804483,
    "input_throughput": 4001.0137518377283,
    "output_throughput": 3519.548222104477,
    "total_throughput": 7520.561973942205,
    "itl": 144.6836028601733,
    "ttft": 2139997.413469953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.777618799062916,
    "arrivals": 377711,
    "finished_requests": 58239,
    "scheduler_time": 49.37596981706411
}
#Debug simulation 
Total elapsed time: 4.442579687573016. Arrivals time: 0.20466883527114987 Scheduler time: 4.077655255328864 Scheduler overhead time: 0.03662169212475419 Adapter cache time: 0.0683806142769754 Engine time: 0.03771416936069727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.429727885872126,
    "estimated_duration": 3600.149834686222,
    "input_throughput": 4000.957088291691,
    "output_throughput": 3519.53906971329,
    "total_throughput": 7520.49615800498,
    "itl": 144.67820490724688,
    "ttft": 2139951.318629039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7048888323805202,
    "arrivals": 377711,
    "finished_requests": 58242,
    "scheduler_time": 49.37831136152196
}
#Debug simulation 
Total elapsed time: 4.429828958120197. Arrivals time: 0.2030131071805954 Scheduler time: 4.067421081010252 Scheduler overhead time: 0.0365751925855875 Adapter cache time: 0.06759537244215608 Engine time: 0.037663469556719065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.438348685856909,
    "estimated_duration": 3600.0095614314378,
    "input_throughput": 3999.4827108945206,
    "output_throughput": 3518.4889883913256,
    "total_throughput": 7517.971699285847,
    "itl": 144.444029665817,
    "ttft": 2140026.9859867417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6295774107216647,
    "arrivals": 377711,
    "finished_requests": 58219,
    "scheduler_time": 49.35166685712003
}
#Debug simulation 
Total elapsed time: 4.4384455708786845. Arrivals time: 0.203744329046458 Scheduler time: 4.076130425091833 Scheduler overhead time: 0.03659231308847666 Adapter cache time: 0.06657771486788988 Engine time: 0.03785265889018774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.726491816341877,
    "estimated_duration": 3600.005924975586,
    "input_throughput": 4389.722775277702,
    "output_throughput": 3865.4050271026626,
    "total_throughput": 8255.127802380364,
    "itl": 221.54452799526368,
    "ttft": 2074825.7124871593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2639814382442351,
    "arrivals": 376270,
    "finished_requests": 63982,
    "scheduler_time": 55.46448292676477
}
#Debug simulation 
Total elapsed time: 4.72658769832924. Arrivals time: 0.21896500932052732 Scheduler time: 4.403800859116018 Scheduler overhead time: 0.025367875583469868 Adapter cache time: 0.04033473553135991 Engine time: 0.026056522969156504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.498184915166348,
    "estimated_duration": 3600.1031120513353,
    "input_throughput": 4028.9923784252906,
    "output_throughput": 3564.3990187514996,
    "total_throughput": 7593.391397176791,
    "itl": 142.64350514711006,
    "ttft": 2134441.1714167725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2999521580315252,
    "arrivals": 376270,
    "finished_requests": 58690,
    "scheduler_time": 49.98823968546091
}
#Debug simulation 
Total elapsed time: 4.498291522730142. Arrivals time: 0.2060564453713596 Scheduler time: 4.134311342146248 Scheduler overhead time: 0.03701727883890271 Adapter cache time: 0.06479356717318296 Engine time: 0.03825157880783081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.48847135854885,
    "estimated_duration": 3600.0737027565374,
    "input_throughput": 4030.796921987724,
    "output_throughput": 3565.804219555485,
    "total_throughput": 7596.601141543209,
    "itl": 142.8469440060446,
    "ttft": 2134268.8924627434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2443831947236312,
    "arrivals": 376270,
    "finished_requests": 58716,
    "scheduler_time": 50.017421079003554
}
#Debug simulation 
Total elapsed time: 4.488566051702946. Arrivals time: 0.20774844335392118 Scheduler time: 4.124246421735734 Scheduler overhead time: 0.03704706998541951 Adapter cache time: 0.06361334724351764 Engine time: 0.03818856133148074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.488862281199545,
    "estimated_duration": 3600.0966096373286,
    "input_throughput": 4030.9834911519006,
    "output_throughput": 3566.1484654694696,
    "total_throughput": 7597.131956621371,
    "itl": 142.89769603448613,
    "ttft": 2134228.662886447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1900400173710606,
    "arrivals": 376270,
    "finished_requests": 58722,
    "scheduler_time": 50.02676045276562
}
#Debug simulation 
Total elapsed time: 4.488956958986819. Arrivals time: 0.20492056151852012 Scheduler time: 4.126998087391257 Scheduler overhead time: 0.037081122398376465 Adapter cache time: 0.06393708288669586 Engine time: 0.03823946509510279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.035132292192429,
    "estimated_duration": 3600.0919836602025,
    "input_throughput": 4497.315089026952,
    "output_throughput": 3949.8568549192246,
    "total_throughput": 8447.171943946178,
    "itl": 216.31972111619052,
    "ttft": 2057211.2018928027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2394975362927723,
    "arrivals": 373284,
    "finished_requests": 65514,
    "scheduler_time": 56.69851605661018
}
#Debug simulation 
Total elapsed time: 5.0352310268208385. Arrivals time: 0.4495801152661443 Scheduler time: 4.4915063749067485 Scheduler overhead time: 0.025810495484620333 Adapter cache time: 0.029573338106274605 Engine time: 0.026489897165447474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.5210573840886354,
    "estimated_duration": 3600.141383791095,
    "input_throughput": 4099.929260127217,
    "output_throughput": 3607.7469230729735,
    "total_throughput": 7707.67618320019,
    "itl": 141.14083601996924,
    "ttft": 2121620.3784889225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2753444481012461,
    "arrivals": 373284,
    "finished_requests": 59679,
    "scheduler_time": 50.619229194054085
}
#Debug simulation 
Total elapsed time: 4.521156630013138. Arrivals time: 0.20942840352654457 Scheduler time: 4.165446023922414 Scheduler overhead time: 0.03749410342425108 Adapter cache time: 0.051982059609144926 Engine time: 0.03879675129428506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.527488505933434,
    "estimated_duration": 3600.10165047764,
    "input_throughput": 4099.7459052418135,
    "output_throughput": 3607.7806298265996,
    "total_throughput": 7707.526535068413,
    "itl": 141.1421837972966,
    "ttft": 2121608.4715717654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2226356520224353,
    "arrivals": 373284,
    "finished_requests": 59677,
    "scheduler_time": 50.62034072310133
}
#Debug simulation 
Total elapsed time: 4.527584969997406. Arrivals time: 0.20794380782172084 Scheduler time: 4.17360205296427 Scheduler overhead time: 0.03744805185124278 Adapter cache time: 0.05193906603381038 Engine time: 0.038613610435277224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.745202255900949,
    "estimated_duration": 3600.1484781544436,
    "input_throughput": 4099.859794551175,
    "output_throughput": 3607.9903589584032,
    "total_throughput": 7707.8501535095775,
    "itl": 141.14220332316046,
    "ttft": 2121561.4240351375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 373284,
    "finished_requests": 59681,
    "scheduler_time": 50.62014199948265
}
#Debug simulation 
Total elapsed time: 4.74527672259137. Arrivals time: 0.21010588947683573 Scheduler time: 4.389864418655634 Scheduler overhead time: 0.03732905862852931 Adapter cache time: 0.051240125205367804 Engine time: 0.038642935920506716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.248100667260587,
    "estimated_duration": 3600.0465455586586,
    "input_throughput": 2808.99951487453,
    "output_throughput": 2464.2720275227202,
    "total_throughput": 5273.27154239725,
    "itl": 343.9004199583579,
    "ttft": 2286506.5198963806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2715,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.309224224777589,
    "arrivals": 253064,
    "finished_requests": 40961,
    "scheduler_time": 35.597247280346224
}
#Debug simulation 
Total elapsed time: 3.2482021041214466. Arrivals time: 0.16937073040753603 Scheduler time: 2.904637450352311 Scheduler overhead time: 0.0170386815443635 Adapter cache time: 0.13201022846624255 Engine time: 0.017154926899820566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.89325689105317,
    "estimated_duration": 3600.0166920040506,
    "input_throughput": 2170.579102412453,
    "output_throughput": 1930.0407732643318,
    "total_throughput": 4100.619875676784,
    "itl": 136.43807517327494,
    "ttft": 2467412.8048923165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.71927919376152,
    "arrivals": 253064,
    "finished_requests": 31703,
    "scheduler_time": 25.957760159950865
}
#Debug simulation 
Total elapsed time: 2.89335577795282. Arrivals time: 0.14830967038869858 Scheduler time: 2.483238815329969 Scheduler overhead time: 0.03599737538024783 Adapter cache time: 0.17111625522375107 Engine time: 0.03726018685847521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.004633527714759,
    "estimated_duration": 3600.148024477628,
    "input_throughput": 2287.505109236426,
    "output_throughput": 2030.501510020738,
    "total_throughput": 4318.006619257164,
    "itl": 145.83127194043266,
    "ttft": 2432970.2157597123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.734886847561934,
    "arrivals": 253064,
    "finished_requests": 33373,
    "scheduler_time": 27.577548129091536
}
#Debug simulation 
Total elapsed time: 3.0047294148243964. Arrivals time: 0.14377472968772054 Scheduler time: 2.5985765527002513 Scheduler overhead time: 0.034566591028124094 Adapter cache time: 0.17544713150709867 Engine time: 0.03572788741439581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.9855944928713143,
    "estimated_duration": 3600.0813501642847,
    "input_throughput": 2375.0624411889507,
    "output_throughput": 2104.6896619861745,
    "total_throughput": 4479.752103175126,
    "itl": 153.7312663075981,
    "ttft": 2408747.207388387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.682762409106162,
    "arrivals": 253064,
    "finished_requests": 34640,
    "scheduler_time": 28.80113793832005
}
#Debug simulation 
Total elapsed time: 2.98569372901693. Arrivals time: 0.14337881235405803 Scheduler time: 2.5832608877681196 Scheduler overhead time: 0.03319717664271593 Adapter cache time: 0.17569483304396272 Engine time: 0.03410781268030405 
