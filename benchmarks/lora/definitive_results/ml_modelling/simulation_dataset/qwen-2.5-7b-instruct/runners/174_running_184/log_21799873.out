INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.14604457002133,
    "estimated_duration": 3600.1360272117076,
    "input_throughput": 6161.6605129169275,
    "output_throughput": 5476.044752472538,
    "total_throughput": 11637.705265389464,
    "itl": 152.6536740977374,
    "ttft": 1922708.3568143274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7136019569146501,
    "arrivals": 481654,
    "finished_requests": 89795,
    "scheduler_time": 168.51661343263802
}
#Debug simulation 
Total elapsed time: 83.14626159379259. Arrivals time: 0.47782848589122295 Scheduler time: 82.5093673155643 Scheduler overhead time: 0.06120169162750244 Adapter cache time: 0.017886448185890913 Engine time: 0.05803076038137078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.90552082378417,
    "estimated_duration": 3600.1387368861097,
    "input_throughput": 6161.655875291828,
    "output_throughput": 5476.04063088185,
    "total_throughput": 11637.69650617368,
    "itl": 152.65379772144078,
    "ttft": 1922709.3672261217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7165585136786208,
    "arrivals": 481654,
    "finished_requests": 89795,
    "scheduler_time": 168.51661773768083
}
#Debug simulation 
Total elapsed time: 82.90572908613831. Arrivals time: 0.48500449396669865 Scheduler time: 82.25948204193264 Scheduler overhead time: 0.06248839106410742 Adapter cache time: 0.01784461084753275 Engine time: 0.05901253269985318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 83.11073352722451,
    "estimated_duration": 3600.070673843518,
    "input_throughput": 6159.320749202554,
    "output_throughput": 5476.57248599253,
    "total_throughput": 11635.893235195084,
    "itl": 152.65093983023164,
    "ttft": 1922285.1860307972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.639924916529556,
    "arrivals": 481654,
    "finished_requests": 89805,
    "scheduler_time": 168.58965153232708
}
#Debug simulation 
Total elapsed time: 83.1109050642699. Arrivals time: 0.5161793953739107 Scheduler time: 82.43266356224194 Scheduler overhead time: 0.06275614909827709 Adapter cache time: 0.01809696713462472 Engine time: 0.058969523292034864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 83.4181992681697,
    "estimated_duration": 3600.160204356132,
    "input_throughput": 6161.619133826093,
    "output_throughput": 5476.007977685489,
    "total_throughput": 11637.627111511581,
    "itl": 152.65474882305355,
    "ttft": 1922717.9788798527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7381881649419708,
    "arrivals": 481654,
    "finished_requests": 89795,
    "scheduler_time": 168.51707212387606
}
#Debug simulation 
Total elapsed time: 83.41836777795106. Arrivals time: 0.4930206532590091 Scheduler time: 82.76292716758326 Scheduler overhead time: 0.0631342139095068 Adapter cache time: 0.017592930234968662 Engine time: 0.05964295892044902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.66638082172722,
    "estimated_duration": 3600.001345311195,
    "input_throughput": 6160.834364377933,
    "output_throughput": 5484.318228301469,
    "total_throughput": 11645.152592679402,
    "itl": 152.97122654699882,
    "ttft": 1920832.4835335244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5787465557083296,
    "arrivals": 481654,
    "finished_requests": 90012,
    "scheduler_time": 168.31729115182907
}
#Debug simulation 
Total elapsed time: 84.66655908804387. Arrivals time: 0.4924541236832738 Scheduler time: 84.01434886548668 Scheduler overhead time: 0.06195549573749304 Adapter cache time: 0.017782357521355152 Engine time: 0.05839654337614775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.19776920322329,
    "estimated_duration": 3600.029847847389,
    "input_throughput": 6148.317079436142,
    "output_throughput": 5469.384375180516,
    "total_throughput": 11617.701454616657,
    "itl": 152.03417970736987,
    "ttft": 1924709.1462436004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.777893445864317,
    "arrivals": 481654,
    "finished_requests": 89688,
    "scheduler_time": 168.84804063660133
}
#Debug simulation 
Total elapsed time: 83.19793931720778. Arrivals time: 0.4709162060171366 Scheduler time: 82.56547462940216 Scheduler overhead time: 0.0630428227595985 Adapter cache time: 0.017957160715013742 Engine time: 0.058693752624094486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.4741454590112,
    "estimated_duration": 3600.077537953575,
    "input_throughput": 6178.454426468755,
    "output_throughput": 5489.331491241576,
    "total_throughput": 11667.785917710331,
    "itl": 153.24155770549257,
    "ttft": 1911068.739121196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5180019209906626,
    "arrivals": 472156,
    "finished_requests": 90243,
    "scheduler_time": 168.01907542959313
}
#Debug simulation 
Total elapsed time: 81.47431745287031. Arrivals time: 0.511685237288475 Scheduler time: 80.80460383743048 Scheduler overhead time: 0.061739956960082054 Adapter cache time: 0.016823901794850826 Engine time: 0.05791738862171769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.54482157574967,
    "estimated_duration": 3600.1173928292856,
    "input_throughput": 6172.186230443203,
    "output_throughput": 5482.153731795235,
    "total_throughput": 11654.339962238439,
    "itl": 153.03495427671615,
    "ttft": 1912405.7488876218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6203529732674424,
    "arrivals": 472156,
    "finished_requests": 90146,
    "scheduler_time": 168.24411075532447
}
#Debug simulation 
Total elapsed time: 81.5449866130948. Arrivals time: 0.5255146459676325 Scheduler time: 80.86299450229853 Scheduler overhead time: 0.060729749500751495 Adapter cache time: 0.016776866745203733 Engine time: 0.05750181432813406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.80134059395641,
    "estimated_duration": 3600.1221482132005,
    "input_throughput": 6172.178077632295,
    "output_throughput": 5482.146490444914,
    "total_throughput": 11654.324568077209,
    "itl": 153.03533994746806,
    "ttft": 1912408.1065999386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6229005071520903,
    "arrivals": 472156,
    "finished_requests": 90146,
    "scheduler_time": 168.24436927426245
}
#Debug simulation 
Total elapsed time: 81.80151326674968. Arrivals time: 0.4845713460817933 Scheduler time: 81.15962618263438 Scheduler overhead time: 0.061391061171889305 Adapter cache time: 0.01675034500658512 Engine time: 0.05719229578971863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 82.49052920425311,
    "estimated_duration": 3600.0948714617084,
    "input_throughput": 6174.694777133581,
    "output_throughput": 5482.954673354349,
    "total_throughput": 11657.64945048793,
    "itl": 153.0397613289209,
    "ttft": 1912049.5005482184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5559247960196758,
    "arrivals": 472156,
    "finished_requests": 90157,
    "scheduler_time": 168.21241492920132
}
#Debug simulation 
Total elapsed time: 82.490694349166. Arrivals time: 0.49350903276354074 Scheduler time: 81.83956483844668 Scheduler overhead time: 0.061012569814920425 Adapter cache time: 0.01670880103483796 Engine time: 0.05794361839070916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 81.08595818094909,
    "estimated_duration": 3600.141594828555,
    "input_throughput": 6172.144737840008,
    "output_throughput": 5482.116877944597,
    "total_throughput": 11654.261615784606,
    "itl": 153.035978402861,
    "ttft": 1912416.264874084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6437756356969515,
    "arrivals": 472156,
    "finished_requests": 90146,
    "scheduler_time": 168.24475085423015
}
#Debug simulation 
Total elapsed time: 81.08622350916266. Arrivals time: 0.5257149673998356 Scheduler time: 80.40051255235448 Scheduler overhead time: 0.06200015265494585 Adapter cache time: 0.017008530907332897 Engine time: 0.05866160709410906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.05380914406851,
    "estimated_duration": 3600.077338161943,
    "input_throughput": 6178.860871738133,
    "output_throughput": 5488.790974165214,
    "total_throughput": 11667.651845903347,
    "itl": 153.22530626940457,
    "ttft": 1911251.0402589124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890450468612675,
    "arrivals": 472156,
    "finished_requests": 90237,
    "scheduler_time": 168.02910338454797
}
#Debug simulation 
Total elapsed time: 82.0539717990905. Arrivals time: 0.5197589322924614 Scheduler time: 81.3769952300936 Scheduler overhead time: 0.06106752622872591 Adapter cache time: 0.0169344712048769 Engine time: 0.057602886110544205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.32873222930357,
    "estimated_duration": 3600.023065686638,
    "input_throughput": 6169.529637656298,
    "output_throughput": 5482.114597572939,
    "total_throughput": 11651.644235229238,
    "itl": 153.01141099003004,
    "ttft": 1912471.882664276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.685266897603867,
    "arrivals": 472156,
    "finished_requests": 90100,
    "scheduler_time": 168.2267629115297
}
#Debug simulation 
Total elapsed time: 81.32899864530191. Arrivals time: 0.5139809767715633 Scheduler time: 80.6550547531806 Scheduler overhead time: 0.06280078273266554 Adapter cache time: 0.016979935579001904 Engine time: 0.05777448462322354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.67498122388497,
    "estimated_duration": 3600.0044631383767,
    "input_throughput": 6193.185655265397,
    "output_throughput": 5485.318199518288,
    "total_throughput": 11678.503854783685,
    "itl": 153.2261211567965,
    "ttft": 1911859.8985192047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5363648474542597,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96611010959606
}
#Debug simulation 
Total elapsed time: 82.67514854576439. Arrivals time: 0.4717056662775576 Scheduler time: 82.04547822289169 Scheduler overhead time: 0.061350930482149124 Adapter cache time: 0.016830867622047663 Engine time: 0.05848724348470569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.05439592292532,
    "estimated_duration": 3600.0779356124135,
    "input_throughput": 6193.059261148269,
    "output_throughput": 5485.206251969872,
    "total_throughput": 11678.265513118142,
    "itl": 153.23020479326124,
    "ttft": 1911883.676838307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6408747300133164,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96474117002657
}
#Debug simulation 
Total elapsed time: 82.0545681938529. Arrivals time: 0.4827029793523252 Scheduler time: 81.41313743824139 Scheduler overhead time: 0.06228832248598337 Adapter cache time: 0.016576269641518593 Engine time: 0.057876158971339464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.28491950407624,
    "estimated_duration": 3600.0818182621683,
    "input_throughput": 6193.052582000062,
    "output_throughput": 5485.200336233568,
    "total_throughput": 11678.25291823363,
    "itl": 153.2304609036616,
    "ttft": 1911885.337029543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6438678915985028,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96489874267624
}
#Debug simulation 
Total elapsed time: 82.28508364083245. Arrivals time: 0.47461510077118874 Scheduler time: 81.65195836359635 Scheduler overhead time: 0.061387557070702314 Adapter cache time: 0.016946472693234682 Engine time: 0.05834288941696286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 82.33225384214893,
    "estimated_duration": 3600.03685139278,
    "input_throughput": 6193.12993737115,
    "output_throughput": 5485.268850056417,
    "total_throughput": 11678.398787427566,
    "itl": 153.22688167987587,
    "ttft": 1911874.384837727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5680148802651026,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96653902935572
}
#Debug simulation 
Total elapsed time: 82.3324297722429. Arrivals time: 0.4689646237529814 Scheduler time: 81.7059421907179 Scheduler overhead time: 0.061721546575427055 Adapter cache time: 0.016493726521730423 Engine time: 0.05724403541535139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 82.29564594104886,
    "estimated_duration": 3600.1014696724237,
    "input_throughput": 6193.018776781501,
    "output_throughput": 5485.170394876901,
    "total_throughput": 11678.189171658403,
    "itl": 153.23111927852423,
    "ttft": 1911892.850818423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6618652689456979,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96495446770223
}
#Debug simulation 
Total elapsed time: 82.29581013508141. Arrivals time: 0.48541471268981695 Scheduler time: 81.65136742126197 Scheduler overhead time: 0.06179801980033517 Adapter cache time: 0.01672801747918129 Engine time: 0.058613700326532125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.24814114393666,
    "estimated_duration": 3600.1380650046535,
    "input_throughput": 6193.355253993899,
    "output_throughput": 5485.210467886452,
    "total_throughput": 11678.56572188035,
    "itl": 153.2240751169401,
    "ttft": 1911880.0238524585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5010052480408758,
    "arrivals": 467317,
    "finished_requests": 90403,
    "scheduler_time": 167.97325059266467
}
#Debug simulation 
Total elapsed time: 82.24831374874339. Arrivals time: 0.4718268201686442 Scheduler time: 81.61881403066218 Scheduler overhead time: 0.06137584941461682 Adapter cache time: 0.016644338611513376 Engine time: 0.05791973415762186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.47176779573783,
    "estimated_duration": 3600.1221745691228,
    "input_throughput": 6192.983159708578,
    "output_throughput": 5485.1388487568265,
    "total_throughput": 11678.122008465403,
    "itl": 153.23138421747962,
    "ttft": 1911901.1162943395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.68248888991773,
    "arrivals": 467317,
    "finished_requests": 90400,
    "scheduler_time": 167.96531476510913
}
#Debug simulation 
Total elapsed time: 82.47193977003917. Arrivals time: 0.47327017690986395 Scheduler time: 81.84129548398778 Scheduler overhead time: 0.061036435421556234 Adapter cache time: 0.01660309685394168 Engine time: 0.058345685712993145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.15802950412035,
    "estimated_duration": 3600.1474505154165,
    "input_throughput": 6205.816097004977,
    "output_throughput": 5488.831296943397,
    "total_throughput": 11694.647393948375,
    "itl": 153.49900604394549,
    "ttft": 1903508.3861920745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5241228964785283,
    "arrivals": 464889,
    "finished_requests": 90318,
    "scheduler_time": 167.83922807983774
}
#Debug simulation 
Total elapsed time: 81.15820183930919. Arrivals time: 0.4657700965180993 Scheduler time: 80.53393575642258 Scheduler overhead time: 0.06159666972234845 Adapter cache time: 0.016290776897221804 Engine time: 0.05875863088294864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.62965859891847,
    "estimated_duration": 3600.030627896612,
    "input_throughput": 6202.5086195020185,
    "output_throughput": 5484.5963939857465,
    "total_throughput": 11687.105013487766,
    "itl": 153.44162065694363,
    "ttft": 1903497.2015643676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6502534762164636,
    "arrivals": 464889,
    "finished_requests": 90240,
    "scheduler_time": 167.97772997791336
}
#Debug simulation 
Total elapsed time: 81.62982507795095. Arrivals time: 0.4609866729006171 Scheduler time: 81.0107618868351 Scheduler overhead time: 0.061852363869547844 Adapter cache time: 0.016327797435224056 Engine time: 0.05824382742866874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.74756855610758,
    "estimated_duration": 3600.034317792544,
    "input_throughput": 6202.5022621705875,
    "output_throughput": 5484.590772486578,
    "total_throughput": 11687.093034657166,
    "itl": 153.44174179811532,
    "ttft": 1903498.944677477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6533356956392626,
    "arrivals": 464889,
    "finished_requests": 90240,
    "scheduler_time": 167.9777807026601
}
#Debug simulation 
Total elapsed time: 81.74774034973234. Arrivals time: 0.4576621511951089 Scheduler time: 81.1331226839684 Scheduler overhead time: 0.06116339471191168 Adapter cache time: 0.016234890557825565 Engine time: 0.05760560929775238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 81.44711086386815,
    "estimated_duration": 3600.0063662268453,
    "input_throughput": 6205.892914410536,
    "output_throughput": 5488.990015512336,
    "total_throughput": 11694.882929922871,
    "itl": 153.49945975730188,
    "ttft": 1903455.5982270422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5534732241090328,
    "arrivals": 464889,
    "finished_requests": 90317,
    "scheduler_time": 167.83160321265834
}
#Debug simulation 
Total elapsed time: 81.44737435411662. Arrivals time: 0.4735776851885021 Scheduler time: 80.81678681913763 Scheduler overhead time: 0.06049838289618492 Adapter cache time: 0.016641143709421158 Engine time: 0.057757276110351086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 80.58776191016659,
    "estimated_duration": 3600.038068102258,
    "input_throughput": 6202.532189269545,
    "output_throughput": 5484.9206109670295,
    "total_throughput": 11687.452800236573,
    "itl": 153.2615081134813,
    "ttft": 1904823.0489904857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6871851483546239,
    "arrivals": 464889,
    "finished_requests": 90249,
    "scheduler_time": 168.02331771106165
}
#Debug simulation 
Total elapsed time: 80.58793222205713. Arrivals time: 0.4725521202199161 Scheduler time: 79.9578002942726 Scheduler overhead time: 0.06101275607943535 Adapter cache time: 0.0167208812199533 Engine time: 0.05761761078611016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.45913372654468,
    "estimated_duration": 3600.108230140332,
    "input_throughput": 6205.883704537715,
    "output_throughput": 5488.89109348519,
    "total_throughput": 11694.774798022905,
    "itl": 153.49798011887933,
    "ttft": 1903491.3381668222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890450468612675,
    "arrivals": 464889,
    "finished_requests": 90318,
    "scheduler_time": 167.83869430741404
}
#Debug simulation 
Total elapsed time: 81.45930804964155. Arrivals time: 0.47300299955531955 Scheduler time: 80.82893548207358 Scheduler overhead time: 0.06106100045144558 Adapter cache time: 0.016831415705382824 Engine time: 0.05795041285455227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.1554539850913,
    "estimated_duration": 3600.1402784160477,
    "input_throughput": 6206.065117504286,
    "output_throughput": 5484.4029601777165,
    "total_throughput": 11690.468077682002,
    "itl": 153.1379191312151,
    "ttft": 1904590.9024045493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.660523766577243,
    "arrivals": 464889,
    "finished_requests": 90249,
    "scheduler_time": 168.07005689492507
}
#Debug simulation 
Total elapsed time: 82.15562802227214. Arrivals time: 0.4644999331794679 Scheduler time: 81.53285586740822 Scheduler overhead time: 0.061665832065045834 Adapter cache time: 0.016286364756524563 Engine time: 0.05854731937870383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.8839634587057,
    "estimated_duration": 3600.1153648166796,
    "input_throughput": 6173.14523228665,
    "output_throughput": 5497.39160956243,
    "total_throughput": 11670.53684184908,
    "itl": 153.7308688833516,
    "ttft": 1909210.0419535968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3833404602576167,
    "arrivals": 463720,
    "finished_requests": 90142,
    "scheduler_time": 167.39609224305968
}
#Debug simulation 
Total elapsed time: 78.88413318386301. Arrivals time: 0.45719384122639894 Scheduler time: 78.27212759573013 Scheduler overhead time: 0.06010411074385047 Adapter cache time: 0.015868395566940308 Engine time: 0.057547970674932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.80955182993785,
    "estimated_duration": 3600.045293515734,
    "input_throughput": 6175.193139942321,
    "output_throughput": 5497.436389382889,
    "total_throughput": 11672.62952932521,
    "itl": 153.77369925544906,
    "ttft": 1912049.4981988096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5160908621433253,
    "arrivals": 463720,
    "finished_requests": 90177,
    "scheduler_time": 167.23933100565228
}
#Debug simulation 
Total elapsed time: 76.80972210457548. Arrivals time: 0.4641761211678386 Scheduler time: 76.1903659380041 Scheduler overhead time: 0.05969717679545283 Adapter cache time: 0.016031775157898664 Engine time: 0.05719197681173682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.9528878456913,
    "estimated_duration": 3600.04778362106,
    "input_throughput": 6175.188868643091,
    "output_throughput": 5497.432586879018,
    "total_throughput": 11672.62145552211,
    "itl": 153.7737918442304,
    "ttft": 1912050.562467823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5184257066063673,
    "arrivals": 463720,
    "finished_requests": 90177,
    "scheduler_time": 167.2393470285533
}
#Debug simulation 
Total elapsed time: 76.95305509492755. Arrivals time: 0.46631912933662534 Scheduler time: 76.33250756701455 Scheduler overhead time: 0.0602082465775311 Adapter cache time: 0.016097233165055513 Engine time: 0.05667887534946203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.74808779824525,
    "estimated_duration": 3600.1457121076664,
    "input_throughput": 6173.093195994331,
    "output_throughput": 5497.345269509503,
    "total_throughput": 11670.438465503834,
    "itl": 153.73182048513593,
    "ttft": 1909221.9093097625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.415243602972475,
    "arrivals": 463720,
    "finished_requests": 90142,
    "scheduler_time": 167.39671499904043
}
#Debug simulation 
Total elapsed time: 78.7482612230815. Arrivals time: 0.4616555101238191 Scheduler time: 78.12864280864596 Scheduler overhead time: 0.061279705725610256 Adapter cache time: 0.016448481008410454 Engine time: 0.0583064341917634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 80.93746171984822,
    "estimated_duration": 3600.1060626658655,
    "input_throughput": 6180.119311130693,
    "output_throughput": 5491.980696079581,
    "total_throughput": 11672.100007210274,
    "itl": 153.58512525209042,
    "ttft": 1908314.2028568878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5096798990294378,
    "arrivals": 463720,
    "finished_requests": 90175,
    "scheduler_time": 167.47380078988638
}
#Debug simulation 
Total elapsed time: 80.93762580025941. Arrivals time: 0.47634449508041143 Scheduler time: 80.30174831440672 Scheduler overhead time: 0.06226055230945349 Adapter cache time: 0.01628771983087063 Engine time: 0.05896200146526098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.89033380476758,
    "estimated_duration": 3600.1571017590013,
    "input_throughput": 6174.646097843561,
    "output_throughput": 5496.707071569539,
    "total_throughput": 11671.3531694131,
    "itl": 153.7038010706685,
    "ttft": 1909533.8791913453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3574828338855764,
    "arrivals": 463720,
    "finished_requests": 90157,
    "scheduler_time": 167.40623576878787
}
#Debug simulation 
Total elapsed time: 78.89058423275128. Arrivals time: 0.4775059879757464 Scheduler time: 78.25858600856736 Scheduler overhead time: 0.059644042514264584 Adapter cache time: 0.01615866646170616 Engine time: 0.05747838271781802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.02104587992653,
    "estimated_duration": 3600.056330556418,
    "input_throughput": 6180.141630328673,
    "output_throughput": 5492.06767465889,
    "total_throughput": 11672.209304987562,
    "itl": 153.58738674537292,
    "ttft": 1908278.304861866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5217814343050118,
    "arrivals": 463720,
    "finished_requests": 90173,
    "scheduler_time": 167.46939272361578
}
#Debug simulation 
Total elapsed time: 81.0212180968374. Arrivals time: 0.4885974423959851 Scheduler time: 80.37409241171554 Scheduler overhead time: 0.0622018757276237 Adapter cache time: 0.0161594171077013 Engine time: 0.058071890845894814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.7355318381451,
    "estimated_duration": 3600.110093271769,
    "input_throughput": 6216.795992385911,
    "output_throughput": 5467.226137551948,
    "total_throughput": 11684.022129937859,
    "itl": 151.07595681276047,
    "ttft": 1832094.0721320426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.615937528796514,
    "arrivals": 366022,
    "finished_requests": 90102,
    "scheduler_time": 167.59738988436214
}
#Debug simulation 
Total elapsed time: 78.73569779098034. Arrivals time: 0.469993500970304 Scheduler time: 78.10951796127483 Scheduler overhead time: 0.06006742920726538 Adapter cache time: 0.017607495188713074 Engine time: 0.05671274522319436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.94706711079925,
    "estimated_duration": 3600.105134384426,
    "input_throughput": 6230.844978874637,
    "output_throughput": 5487.705848173261,
    "total_throughput": 11718.550827047899,
    "itl": 152.17671902993047,
    "ttft": 1832418.4351111983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.706266187303706,
    "arrivals": 366022,
    "finished_requests": 90426,
    "scheduler_time": 166.90405375958227
}
#Debug simulation 
Total elapsed time: 76.9472298277542. Arrivals time: 0.45568740647286177 Scheduler time: 76.33635649550706 Scheduler overhead time: 0.05907776765525341 Adapter cache time: 0.017309310380369425 Engine time: 0.05696183629333973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.79693383909762,
    "estimated_duration": 3600.1101522986332,
    "input_throughput": 6230.836294183275,
    "output_throughput": 5487.698199285873,
    "total_throughput": 11718.534493469147,
    "itl": 152.17685740147783,
    "ttft": 1832421.1393573952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7087769471109018,
    "arrivals": 366022,
    "finished_requests": 90426,
    "scheduler_time": 166.90419386909025
}
#Debug simulation 
Total elapsed time: 76.79711034102365. Arrivals time: 0.46834068512544036 Scheduler time: 76.17521365033463 Scheduler overhead time: 0.05889922147616744 Adapter cache time: 0.01732626138255 Engine time: 0.05593351973220706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.66748652374372,
    "estimated_duration": 3600.1531309522443,
    "input_throughput": 6216.694175472528,
    "output_throughput": 5467.113837681113,
    "total_throughput": 11683.80801315364,
    "itl": 151.07745516275472,
    "ttft": 1832142.8027156915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6498421411169608,
    "arrivals": 366022,
    "finished_requests": 90102,
    "scheduler_time": 167.59856325312117
}
#Debug simulation 
Total elapsed time: 78.66764931706712. Arrivals time: 0.4639228009618819 Scheduler time: 78.047470823396 Scheduler overhead time: 0.05969908135011792 Adapter cache time: 0.017832585144788027 Engine time: 0.056790243834257126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 78.81108643813059,
    "estimated_duration": 3600.076631940722,
    "input_throughput": 6218.0581939258545,
    "output_throughput": 5469.330798490683,
    "total_throughput": 11687.388992416538,
    "itl": 151.1836663723442,
    "ttft": 1832562.3422794149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7574870307929853,
    "arrivals": 366022,
    "finished_requests": 90160,
    "scheduler_time": 167.49623444514017
}
#Debug simulation 
Total elapsed time: 78.81125571997836. Arrivals time: 0.46443399507552385 Scheduler time: 78.19055293686688 Scheduler overhead time: 0.05989385349676013 Adapter cache time: 0.01761104492470622 Engine time: 0.05702100694179535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.01361459074542,
    "estimated_duration": 3600.068874158012,
    "input_throughput": 6216.867171807797,
    "output_throughput": 5467.288734747718,
    "total_throughput": 11684.155906555516,
    "itl": 151.07482757568482,
    "ttft": 1832078.4139109086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5787465557083296,
    "arrivals": 366022,
    "finished_requests": 90102,
    "scheduler_time": 167.59670930253006
}
#Debug simulation 
Total elapsed time: 79.01378092681989. Arrivals time: 0.46294328989461064 Scheduler time: 78.39429505402222 Scheduler overhead time: 0.05937251355499029 Adapter cache time: 0.017970053479075432 Engine time: 0.057265843730419874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 79.06737702013925,
    "estimated_duration": 3600.063455785845,
    "input_throughput": 6216.428481012664,
    "output_throughput": 5466.928081050683,
    "total_throughput": 11683.356562063347,
    "itl": 151.0807003927083,
    "ttft": 1832111.6924118851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7727324107289284,
    "arrivals": 366022,
    "finished_requests": 90097,
    "scheduler_time": 167.58892295651964
}
#Debug simulation 
Total elapsed time: 79.06753988703713. Arrivals time: 0.46487344801425934 Scheduler time: 78.44657623255625 Scheduler overhead time: 0.06017315806820989 Adapter cache time: 0.01726059429347515 Engine time: 0.05724902218207717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.62790980516002,
    "estimated_duration": 3600.055209131976,
    "input_throughput": 6230.733335172497,
    "output_throughput": 5480.955389225156,
    "total_throughput": 11711.688724397654,
    "itl": 152.0395455032076,
    "ttft": 1824565.5847116208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5057599700149311,
    "arrivals": 356416,
    "finished_requests": 90247,
    "scheduler_time": 167.06051228778963
}
#Debug simulation 
Total elapsed time: 79.62806744826958. Arrivals time: 0.4595321654342115 Scheduler time: 79.00994424847886 Scheduler overhead time: 0.061833728570491076 Adapter cache time: 0.017315126955509186 Engine time: 0.057558541651815176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.67925597308204,
    "estimated_duration": 3600.1454957158976,
    "input_throughput": 6230.42041681142,
    "output_throughput": 5488.432071290731,
    "total_throughput": 11718.852488102151,
    "itl": 152.61431870812459,
    "ttft": 1826772.8151421063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6586851487169094,
    "arrivals": 356416,
    "finished_requests": 90304,
    "scheduler_time": 166.6949431916017
}
#Debug simulation 
Total elapsed time: 74.67942002601922. Arrivals time: 0.450673536863178 Scheduler time: 74.07380979508162 Scheduler overhead time: 0.060680149123072624 Adapter cache time: 0.01714398292824626 Engine time: 0.055645660031586885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.84157974505797,
    "estimated_duration": 3600.148466386951,
    "input_throughput": 6230.415275765223,
    "output_throughput": 5488.427542497979,
    "total_throughput": 11718.842818263201,
    "itl": 152.61435751737815,
    "ttft": 1826774.0516125204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6614462183043461,
    "arrivals": 356416,
    "finished_requests": 90304,
    "scheduler_time": 166.69499851647197
}
#Debug simulation 
Total elapsed time: 74.84174023801461. Arrivals time: 0.45800671679899096 Scheduler time: 74.22822891036049 Scheduler overhead time: 0.05990302097052336 Adapter cache time: 0.017198091838508844 Engine time: 0.056363738141953945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 79.63568544667214,
    "estimated_duration": 3600.0889558044487,
    "input_throughput": 6230.674929249836,
    "output_throughput": 5480.90401160404,
    "total_throughput": 11711.578940853875,
    "itl": 152.04069961999818,
    "ttft": 1824579.236007077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5377057819976412,
    "arrivals": 356416,
    "finished_requests": 90247,
    "scheduler_time": 167.06082488158302
}
#Debug simulation 
Total elapsed time: 79.63585478207096. Arrivals time: 0.46554270712658763 Scheduler time: 79.0115776960738 Scheduler overhead time: 0.061273491475731134 Adapter cache time: 0.017473982647061348 Engine time: 0.05840893927961588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 74.77622071187943,
    "estimated_duration": 3600.0000885047702,
    "input_throughput": 6230.209846832419,
    "output_throughput": 5488.458476179234,
    "total_throughput": 11718.668323011654,
    "itl": 152.6142900799919,
    "ttft": 1826755.9892027716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6830758695676968,
    "arrivals": 356416,
    "finished_requests": 90300,
    "scheduler_time": 166.68717203589785
}
#Debug simulation 
Total elapsed time: 74.77646742481738. Arrivals time: 0.45445003220811486 Scheduler time: 74.16747142188251 Scheduler overhead time: 0.05898126121610403 Adapter cache time: 0.017266963608562946 Engine time: 0.056828910019248724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.00504000810906,
    "estimated_duration": 3600.162345064929,
    "input_throughput": 6224.211813869151,
    "output_throughput": 5479.558172436865,
    "total_throughput": 11703.769986306017,
    "itl": 152.07003478145873,
    "ttft": 1825532.8837958728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4800748959765613,
    "arrivals": 356416,
    "finished_requests": 90205,
    "scheduler_time": 167.12114348367356
}
#Debug simulation 
Total elapsed time: 78.0052034938708. Arrivals time: 0.4625573963858187 Scheduler time: 77.38683676160872 Scheduler overhead time: 0.06014192942529917 Adapter cache time: 0.017249178607016802 Engine time: 0.056909252889454365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.10116797080263,
    "estimated_duration": 3600.040738869599,
    "input_throughput": 6236.217762093833,
    "output_throughput": 5494.607821080133,
    "total_throughput": 11730.825583173966,
    "itl": 152.90525188554724,
    "ttft": 1826728.339335555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7180170924961549,
    "arrivals": 356416,
    "finished_requests": 90393,
    "scheduler_time": 166.40735392178146
}
#Debug simulation 
Total elapsed time: 74.10141794383526. Arrivals time: 0.4606207525357604 Scheduler time: 73.48768282681704 Scheduler overhead time: 0.0578979542478919 Adapter cache time: 0.017363972030580044 Engine time: 0.05665113124996424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.87088913097978,
    "estimated_duration": 3600.141308045591,
    "input_throughput": 6217.181239519433,
    "output_throughput": 5481.152352520411,
    "total_throughput": 11698.333592039844,
    "itl": 152.54979835209554,
    "ttft": 1823044.0202299054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5822721636132526,
    "arrivals": 351637,
    "finished_requests": 90245,
    "scheduler_time": 166.94797696530517
}
#Debug simulation 
Total elapsed time: 74.87104674195871. Arrivals time: 0.44735457515344024 Scheduler time: 74.27192241325974 Scheduler overhead time: 0.05817958479747176 Adapter cache time: 0.016896008513867855 Engine time: 0.055521683767437935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.89482745807618,
    "estimated_duration": 3600.1203996354625,
    "input_throughput": 6227.795048818441,
    "output_throughput": 5486.308180693059,
    "total_throughput": 11714.103229511498,
    "itl": 152.94450376517352,
    "ttft": 1823017.87156767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7575056376354818,
    "arrivals": 351637,
    "finished_requests": 90364,
    "scheduler_time": 166.62154005799536
}
#Debug simulation 
Total elapsed time: 72.89499968988821. Arrivals time: 0.43978067161515355 Scheduler time: 72.30116482265294 Scheduler overhead time: 0.05924642086029053 Adapter cache time: 0.01764513272792101 Engine time: 0.05565628595650196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.90523846726865,
    "estimated_duration": 3600.1246375677742,
    "input_throughput": 6227.787717690626,
    "output_throughput": 5486.3017224159,
    "total_throughput": 11714.089440106527,
    "itl": 152.94462877074332,
    "ttft": 1823019.706621074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7608540150337029,
    "arrivals": 351637,
    "finished_requests": 90364,
    "scheduler_time": 166.62159418527833
}
#Debug simulation 
Total elapsed time: 72.90541259106249. Arrivals time: 0.4451167327351868 Scheduler time: 72.30584970116615 Scheduler overhead time: 0.059626728761941195 Adapter cache time: 0.017611716873943806 Engine time: 0.055716145783662796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 74.0980539098382,
    "estimated_duration": 3600.0221579892504,
    "input_throughput": 6223.038641660187,
    "output_throughput": 5483.212084179328,
    "total_throughput": 11706.250725839514,
    "itl": 152.8304683429706,
    "ttft": 1823229.9279243527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6488950674142606,
    "arrivals": 351637,
    "finished_requests": 90308,
    "scheduler_time": 166.79573962087298
}
#Debug simulation 
Total elapsed time: 74.09822038607672. Arrivals time: 0.43700696248561144 Scheduler time: 73.50864621857181 Scheduler overhead time: 0.05836659902706742 Adapter cache time: 0.017043284606188536 Engine time: 0.055670471861958504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 72.9717887500301,
    "estimated_duration": 3600.1488667063727,
    "input_throughput": 6227.7458044427685,
    "output_throughput": 5486.264799396951,
    "total_throughput": 11714.01060383972,
    "itl": 152.94513602262091,
    "ttft": 1823028.4454994574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.782986681442712,
    "arrivals": 351637,
    "finished_requests": 90364,
    "scheduler_time": 166.62189349885358
}
#Debug simulation 
Total elapsed time: 72.97195401182398. Arrivals time: 0.4390964452177286 Scheduler time: 72.37916054297239 Scheduler overhead time: 0.058909266255795956 Adapter cache time: 0.017256068997085094 Engine time: 0.056003866251558065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.75834890687838,
    "estimated_duration": 3600.1013888241696,
    "input_throughput": 6217.2501778652495,
    "output_throughput": 5481.213129512716,
    "total_throughput": 11698.463307377964,
    "itl": 152.54907762292538,
    "ttft": 1823029.2258448177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5458560024644068,
    "arrivals": 351637,
    "finished_requests": 90245,
    "scheduler_time": 166.9474720100601
}
#Debug simulation 
Total elapsed time: 74.7585070966743. Arrivals time: 0.43921088986098766 Scheduler time: 74.16535795899108 Scheduler overhead time: 0.05874171433970332 Adapter cache time: 0.017251471523195505 Engine time: 0.05595612432807684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.05682271812111,
    "estimated_duration": 3600.0009848141267,
    "input_throughput": 6227.663574141371,
    "output_throughput": 5486.268221401542,
    "total_throughput": 11713.931795542914,
    "itl": 152.9457754109515,
    "ttft": 1823011.1825157409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.805748116783795,
    "arrivals": 351637,
    "finished_requests": 90360,
    "scheduler_time": 166.61405337328898
}
#Debug simulation 
Total elapsed time: 73.05699310684577. Arrivals time: 0.4472704525105655 Scheduler time: 72.45770452078432 Scheduler overhead time: 0.05779100442305207 Adapter cache time: 0.017279184889048338 Engine time: 0.05553086521103978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 77.4515476450324,
    "estimated_duration": 3600.115347748051,
    "input_throughput": 6196.986442102556,
    "output_throughput": 5483.532357469778,
    "total_throughput": 11680.518799572334,
    "itl": 152.86514070609113,
    "ttft": 1816488.835375176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4537316783680725,
    "arrivals": 349246,
    "finished_requests": 90238,
    "scheduler_time": 166.7486998368786
}
#Debug simulation 
Total elapsed time: 77.45171761699021. Arrivals time: 0.4584591006860137 Scheduler time: 76.83833854226395 Scheduler overhead time: 0.05976175609976053 Adapter cache time: 0.01681034080684185 Engine time: 0.05664467951282859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.45099038397893,
    "estimated_duration": 3600.0173883072093,
    "input_throughput": 6196.372293215273,
    "output_throughput": 5483.243237689467,
    "total_throughput": 11679.615530904739,
    "itl": 152.62141026300068,
    "ttft": 1815264.534957809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.491483152213046,
    "arrivals": 349246,
    "finished_requests": 90232,
    "scheduler_time": 166.72422316968857
}
#Debug simulation 
Total elapsed time: 76.45115594007075. Arrivals time: 0.44774353597313166 Scheduler time: 75.85058307880536 Scheduler overhead time: 0.05905366875231266 Adapter cache time: 0.016678969375789165 Engine time: 0.05580593412742019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.60537293413654,
    "estimated_duration": 3600.020306558173,
    "input_throughput": 6196.367270307656,
    "output_throughput": 5483.238792859021,
    "total_throughput": 11679.606063166677,
    "itl": 152.62149813672937,
    "ttft": 1815265.6993430338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4940858472138732,
    "arrivals": 349246,
    "finished_requests": 90232,
    "scheduler_time": 166.7242602497616
}
#Debug simulation 
Total elapsed time: 76.60554066114128. Arrivals time: 0.44644703809171915 Scheduler time: 76.00636158464476 Scheduler overhead time: 0.05850404081866145 Adapter cache time: 0.01647305255755782 Engine time: 0.05622109305113554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 74.95067075593397,
    "estimated_duration": 3600.114349527933,
    "input_throughput": 6208.058364293517,
    "output_throughput": 5497.97925240775,
    "total_throughput": 11706.037616701267,
    "itl": 153.74485735356498,
    "ttft": 1816695.324449506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6089285106910316,
    "arrivals": 349246,
    "finished_requests": 90490,
    "scheduler_time": 165.92924750726354
}
#Debug simulation 
Total elapsed time: 74.95092141721398. Arrivals time: 0.44765642657876015 Scheduler time: 74.35066858772188 Scheduler overhead time: 0.05812499159947038 Adapter cache time: 0.017591299954801798 Engine time: 0.05540790734812617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.65331564377993,
    "estimated_duration": 3600.1644469635858,
    "input_throughput": 6198.615737906518,
    "output_throughput": 5484.036157473808,
    "total_throughput": 11682.651895380326,
    "itl": 152.59484073720716,
    "ttft": 1815895.3014977842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5691529807634699,
    "arrivals": 349246,
    "finished_requests": 90246,
    "scheduler_time": 166.72319260879715
}
#Debug simulation 
Total elapsed time: 76.6534727057442. Arrivals time: 0.46287604328244925 Scheduler time: 76.03684360487387 Scheduler overhead time: 0.0591685906983912 Adapter cache time: 0.01696273172274232 Engine time: 0.056261319667100906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.91518410434946,
    "estimated_duration": 3600.1544946144695,
    "input_throughput": 6197.473756578137,
    "output_throughput": 5481.254771015929,
    "total_throughput": 11678.728527594065,
    "itl": 152.71211812136124,
    "ttft": 1816578.3475622165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4352241415530302,
    "arrivals": 349246,
    "finished_requests": 90201,
    "scheduler_time": 166.90528205975858
}
#Debug simulation 
Total elapsed time: 75.91535891406238. Arrivals time: 0.45050160167738795 Scheduler time: 75.31266585178673 Scheduler overhead time: 0.05820996453985572 Adapter cache time: 0.016918628942221403 Engine time: 0.055410823319107294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.34708302468061,
    "estimated_duration": 3600.014061038058,
    "input_throughput": 6198.345234675488,
    "output_throughput": 5483.997747027492,
    "total_throughput": 11682.34298170298,
    "itl": 152.59547004585193,
    "ttft": 1815891.3642755155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.589399340376257,
    "arrivals": 349246,
    "finished_requests": 90240,
    "scheduler_time": 166.71544464520545
}
#Debug simulation 
Total elapsed time: 76.34725049696863. Arrivals time: 0.44651660043746233 Scheduler time: 75.74753108387813 Scheduler overhead time: 0.059184650890529156 Adapter cache time: 0.01692029321566224 Engine time: 0.0559895308688283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.08645535307005,
    "estimated_duration": 3600.139985677199,
    "input_throughput": 6203.300729651803,
    "output_throughput": 5514.907219993922,
    "total_throughput": 11718.207949645725,
    "itl": 154.7228155049347,
    "ttft": 1813364.071140319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5149414332467297,
    "arrivals": 348063,
    "finished_requests": 90656,
    "scheduler_time": 165.27249049197488
}
#Debug simulation 
Total elapsed time: 74.08663278073072. Arrivals time: 0.4428605008870363 Scheduler time: 73.48864411888644 Scheduler overhead time: 0.059220587369054556 Adapter cache time: 0.01705596875399351 Engine time: 0.057315559592098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.02422755304724,
    "estimated_duration": 3600.0185569368555,
    "input_throughput": 6206.830783398078,
    "output_throughput": 5515.026016114018,
    "total_throughput": 11721.856799512096,
    "itl": 154.7549306330413,
    "ttft": 1813165.3163036418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6297317194705891,
    "arrivals": 348063,
    "finished_requests": 90686,
    "scheduler_time": 165.24206128950573
}
#Debug simulation 
Total elapsed time: 74.02439832594246. Arrivals time: 0.46690684370696545 Scheduler time: 73.4028727770783 Scheduler overhead time: 0.059346642810851336 Adapter cache time: 0.01709544053301215 Engine time: 0.05646447604522109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.54041459411383,
    "estimated_duration": 3600.01823406578,
    "input_throughput": 6206.831340063628,
    "output_throughput": 5515.026510734396,
    "total_throughput": 11721.857850798024,
    "itl": 154.75486197994456,
    "ttft": 1813165.473168222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6323683111928502,
    "arrivals": 348063,
    "finished_requests": 90686,
    "scheduler_time": 165.242025823269
}
#Debug simulation 
Total elapsed time: 73.54058195417747. Arrivals time: 0.4513490558601916 Scheduler time: 72.93370631756261 Scheduler overhead time: 0.059917283710092306 Adapter cache time: 0.017383988946676254 Engine time: 0.05665847333148122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 73.51336073735729,
    "estimated_duration": 3600.096439079854,
    "input_throughput": 6199.844470195571,
    "output_throughput": 5515.606133338795,
    "total_throughput": 11715.450603534367,
    "itl": 154.82120650121865,
    "ttft": 1812072.0049373496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5098482556408226,
    "arrivals": 348063,
    "finished_requests": 90622,
    "scheduler_time": 165.2397359684926
}
#Debug simulation 
Total elapsed time: 73.51352348644286. Arrivals time: 0.4546315320767462 Scheduler time: 72.90239117247984 Scheduler overhead time: 0.060821699909865856 Adapter cache time: 0.016980732325464487 Engine time: 0.05699331499636173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 73.65342090791091,
    "estimated_duration": 3600.0765758614807,
    "input_throughput": 6201.987243745532,
    "output_throughput": 5517.218753950261,
    "total_throughput": 11719.205997695793,
    "itl": 154.79213069058235,
    "ttft": 1812953.865613075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5518635962903544,
    "arrivals": 348063,
    "finished_requests": 90637,
    "scheduler_time": 165.2693970567859
}
#Debug simulation 
Total elapsed time: 73.65359974792227. Arrivals time: 0.4527472658082843 Scheduler time: 73.04678463190794 Scheduler overhead time: 0.05924703646451235 Adapter cache time: 0.016519789583981037 Engine time: 0.057067712768912315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.73988938331604,
    "estimated_duration": 3600.160468994518,
    "input_throughput": 6199.75586983592,
    "output_throughput": 5513.820611875128,
    "total_throughput": 11713.576481711047,
    "itl": 154.8125099563081,
    "ttft": 1810046.5932851776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890450468612675,
    "arrivals": 348063,
    "finished_requests": 90617,
    "scheduler_time": 165.2599053458161
}
#Debug simulation 
Total elapsed time: 74.74015003396198. Arrivals time: 0.4522485467605293 Scheduler time: 74.1312828976661 Scheduler overhead time: 0.06008198065683246 Adapter cache time: 0.01720754336565733 Engine time: 0.057478897739201784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.37209120206535,
    "estimated_duration": 3600.0965719028004,
    "input_throughput": 6201.952796004836,
    "output_throughput": 5517.188109623929,
    "total_throughput": 11719.140905628767,
    "itl": 154.79267683480788,
    "ttft": 1812961.636856646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5729902324080458,
    "arrivals": 348063,
    "finished_requests": 90637,
    "scheduler_time": 165.26954301548093
}
#Debug simulation 
Total elapsed time: 73.37225539796054. Arrivals time: 0.7144790277816355 Scheduler time: 72.50274716923013 Scheduler overhead time: 0.06021701544523239 Adapter cache time: 0.016631518956273794 Engine time: 0.056508285459131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.32441415730864,
    "estimated_duration": 3600.099710686074,
    "input_throughput": 6210.177716366461,
    "output_throughput": 5468.969079261386,
    "total_throughput": 11679.146795627847,
    "itl": 152.27400394955427,
    "ttft": 1801235.7959382308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7230545998341642,
    "arrivals": 337149,
    "finished_requests": 90132,
    "scheduler_time": 167.2700443659155
}
#Debug simulation 
Total elapsed time: 80.32458073133603. Arrivals time: 0.4498258577659726 Scheduler time: 79.71807836461812 Scheduler overhead time: 0.05911827879026532 Adapter cache time: 0.018849319778382778 Engine time: 0.05685328971594572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.50597346108407,
    "estimated_duration": 3600.075328566388,
    "input_throughput": 6222.657015602192,
    "output_throughput": 5479.275348345323,
    "total_throughput": 11701.932363947515,
    "itl": 152.56940770504806,
    "ttft": 1803124.9586456083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8629935347149205,
    "arrivals": 337149,
    "finished_requests": 90290,
    "scheduler_time": 166.7780290042441
}
#Debug simulation 
Total elapsed time: 77.50613296590745. Arrivals time: 0.44933296320959926 Scheduler time: 76.90299005666748 Scheduler overhead time: 0.05836771335452795 Adapter cache time: 0.01818754430860281 Engine time: 0.05562442447990179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.60120864398777,
    "estimated_duration": 3600.076333742814,
    "input_throughput": 6222.65527817566,
    "output_throughput": 5479.273818478204,
    "total_throughput": 11701.929096653865,
    "itl": 152.56958468048416,
    "ttft": 1803124.738030919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8663405580632504,
    "arrivals": 337149,
    "finished_requests": 90290,
    "scheduler_time": 166.77815798510406
}
#Debug simulation 
Total elapsed time: 77.60136726498604. Arrivals time: 0.45799400890246034 Scheduler time: 76.98958921525627 Scheduler overhead time: 0.058849025052040815 Adapter cache time: 0.017927525099366903 Engine time: 0.05551639525219798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.8409876767546,
    "estimated_duration": 3600.1459331674055,
    "input_throughput": 6214.699741439516,
    "output_throughput": 5472.403720775474,
    "total_throughput": 11687.10346221499,
    "itl": 152.45648814467492,
    "ttft": 1801962.0668367012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7458024628064495,
    "arrivals": 337149,
    "finished_requests": 90146,
    "scheduler_time": 167.16686993090877
}
#Debug simulation 
Total elapsed time: 78.84115418000147. Arrivals time: 0.44940931629389524 Scheduler time: 78.23790528718382 Scheduler overhead time: 0.05828226404264569 Adapter cache time: 0.01783980429172516 Engine time: 0.055980915669351816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 79.72815773077309,
    "estimated_duration": 3600.0252834022126,
    "input_throughput": 6212.855810518793,
    "output_throughput": 5472.861007626081,
    "total_throughput": 11685.716818144874,
    "itl": 152.48665866271512,
    "ttft": 1801521.2341646233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8402825172431807,
    "arrivals": 337149,
    "finished_requests": 90157,
    "scheduler_time": 167.14644824859846
}
#Debug simulation 
Total elapsed time: 79.72832086402923. Arrivals time: 0.45592373982071877 Scheduler time: 79.11606825049967 Scheduler overhead time: 0.059403903782367706 Adapter cache time: 0.01790192723274231 Engine time: 0.057489225175231695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.73641350865364,
    "estimated_duration": 3600.0755129714576,
    "input_throughput": 6222.60808677032,
    "output_throughput": 5479.019517487655,
    "total_throughput": 11701.627604257976,
    "itl": 152.55309643709626,
    "ttft": 1802306.4723066792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.683398316029902,
    "arrivals": 337149,
    "finished_requests": 90307,
    "scheduler_time": 166.78046943423652
}
#Debug simulation 
Total elapsed time: 79.73657731385902. Arrivals time: 0.45905435364693403 Scheduler time: 79.12352786492556 Scheduler overhead time: 0.05833399435505271 Adapter cache time: 0.018240461125969887 Engine time: 0.055769503116607666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.85264816088602,
    "estimated_duration": 3600.0482223579857,
    "input_throughput": 6212.1898426548705,
    "output_throughput": 5471.144213479208,
    "total_throughput": 11683.334056134077,
    "itl": 152.4743169012604,
    "ttft": 1802116.6318813493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8660874714329803,
    "arrivals": 337149,
    "finished_requests": 90133,
    "scheduler_time": 167.14661507265436
}
#Debug simulation 
Total elapsed time: 78.85280967177823. Arrivals time: 0.457003153860569 Scheduler time: 78.24073288077489 Scheduler overhead time: 0.0592374699190259 Adapter cache time: 0.018261936958879232 Engine time: 0.056290756445378065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.96344714425504,
    "estimated_duration": 3600.138210149795,
    "input_throughput": 6223.30968762107,
    "output_throughput": 5485.938274347038,
    "total_throughput": 11709.247961968107,
    "itl": 153.11358274662422,
    "ttft": 1799371.4117431808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7414175262977614,
    "arrivals": 332464,
    "finished_requests": 90027,
    "scheduler_time": 166.42163453770706
}
#Debug simulation 
Total elapsed time: 79.96370135713369. Arrivals time: 0.44353542011231184 Scheduler time: 79.36532758269459 Scheduler overhead time: 0.05872158333659172 Adapter cache time: 0.0185429691337049 Engine time: 0.05598516995087266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.36661599576473,
    "estimated_duration": 3600.0365191831897,
    "input_throughput": 6240.414195880778,
    "output_throughput": 5493.07594370926,
    "total_throughput": 11733.490139590038,
    "itl": 153.4278254288146,
    "ttft": 1796525.0347046491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.896162800211465,
    "arrivals": 332464,
    "finished_requests": 90143,
    "scheduler_time": 166.0125994494758
}
#Debug simulation 
Total elapsed time: 73.36678548669443. Arrivals time: 0.45629303297027946 Scheduler time: 72.75223247427493 Scheduler overhead time: 0.06049284338951111 Adapter cache time: 0.018457639031112194 Engine time: 0.05733673553913832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.84010606165975,
    "estimated_duration": 3600.0400262293697,
    "input_throughput": 6240.408116664823,
    "output_throughput": 5493.070592526811,
    "total_throughput": 11733.478709191633,
    "itl": 153.42787144859608,
    "ttft": 1796526.3380234253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.899473726507288,
    "arrivals": 332464,
    "finished_requests": 90143,
    "scheduler_time": 166.01263394288003
}
#Debug simulation 
Total elapsed time: 72.84026723587885. Arrivals time: 0.4571744208224118 Scheduler time: 72.22527963668108 Scheduler overhead time: 0.05968984216451645 Adapter cache time: 0.018669175449758768 Engine time: 0.057406630367040634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 79.54749270901084,
    "estimated_duration": 3600.1273568900397,
    "input_throughput": 6211.78524620818,
    "output_throughput": 5479.28532646144,
    "total_throughput": 11691.07057266962,
    "itl": 152.84885936808354,
    "ttft": 1799859.3868740913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7887590698245817,
    "arrivals": 332464,
    "finished_requests": 89914,
    "scheduler_time": 166.81832026288512
}
#Debug simulation 
Total elapsed time: 79.54765476007015. Arrivals time: 0.44665904343128204 Scheduler time: 78.94672771403566 Scheduler overhead time: 0.05823443736881018 Adapter cache time: 0.018208167050033808 Engine time: 0.056473408825695515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 72.99733684537932,
    "estimated_duration": 3600.0698838541834,
    "input_throughput": 6240.356361068336,
    "output_throughput": 5493.0250350665065,
    "total_throughput": 11733.381396134842,
    "itl": 153.42824612171734,
    "ttft": 1796536.544365438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.924121468644593,
    "arrivals": 332464,
    "finished_requests": 90143,
    "scheduler_time": 166.01301602763863
}
#Debug simulation 
Total elapsed time: 72.99750707531348. Arrivals time: 0.44472097139805555 Scheduler time: 72.3946739542298 Scheduler overhead time: 0.06090182298794389 Adapter cache time: 0.018036160618066788 Engine time: 0.05745850596576929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.03977018920705,
    "estimated_duration": 3600.1005441213465,
    "input_throughput": 6223.374798958063,
    "output_throughput": 5485.995670940431,
    "total_throughput": 11709.370469898495,
    "itl": 153.11230657735916,
    "ttft": 1799361.899557748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7013386177993144,
    "arrivals": 332464,
    "finished_requests": 90027,
    "scheduler_time": 166.42078036159276
}
#Debug simulation 
Total elapsed time: 80.03992725722492. Arrivals time: 0.4550538817420602 Scheduler time: 79.43020435189828 Scheduler overhead time: 0.05855535855516791 Adapter cache time: 0.018103465903550386 Engine time: 0.05613945936784148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.02803692035377,
    "estimated_duration": 3600.092886717181,
    "input_throughput": 6240.316488190901,
    "output_throughput": 5492.989937277005,
    "total_throughput": 11733.306425467905,
    "itl": 153.42859994547328,
    "ttft": 1796544.9097126313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9483919494226531,
    "arrivals": 332464,
    "finished_requests": 90143,
    "scheduler_time": 166.01320238113232
}
#Debug simulation 
Total elapsed time: 73.028206365183. Arrivals time: 0.4469208447262645 Scheduler time: 72.42468059575185 Scheduler overhead time: 0.05927984323352575 Adapter cache time: 0.018478923477232456 Engine time: 0.05761028127744794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 77.68292394792661,
    "estimated_duration": 3600.0670898379467,
    "input_throughput": 6205.9751783697175,
    "output_throughput": 5512.998926054292,
    "total_throughput": 11718.974104424009,
    "itl": 154.54396461724974,
    "ttft": 1796052.5530611805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6955102101387685,
    "arrivals": 329992,
    "finished_requests": 90394,
    "scheduler_time": 165.15393008217805
}
#Debug simulation 
Total elapsed time: 77.68308401014656. Arrivals time: 0.4334925222210586 Scheduler time: 77.096508319024 Scheduler overhead time: 0.05845311051234603 Adapter cache time: 0.018178691156208515 Engine time: 0.05537691479548812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.34783384483308,
    "estimated_duration": 3600.0078856051605,
    "input_throughput": 6205.073352567098,
    "output_throughput": 5513.02764623354,
    "total_throughput": 11718.100998800637,
    "itl": 154.5917196383104,
    "ttft": 1796381.5236177207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7378010715264893,
    "arrivals": 329992,
    "finished_requests": 90397,
    "scheduler_time": 165.11456499128792
}
#Debug simulation 
Total elapsed time: 77.34800206776708. Arrivals time: 0.4443660438992083 Scheduler time: 76.75085169216618 Scheduler overhead time: 0.058224018197506666 Adapter cache time: 0.01781957410275936 Engine time: 0.05521484790369868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.29391085775569,
    "estimated_duration": 3600.0115508377185,
    "input_throughput": 6205.067035077123,
    "output_throughput": 5513.022033326987,
    "total_throughput": 11718.089068404111,
    "itl": 154.59182783128355,
    "ttft": 1796383.3294223403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7405611255765068,
    "arrivals": 329992,
    "finished_requests": 90397,
    "scheduler_time": 165.11463474217044
}
#Debug simulation 
Total elapsed time: 77.29413952864707. Arrivals time: 0.45564291439950466 Scheduler time: 76.68644787091762 Scheduler overhead time: 0.057664166670292616 Adapter cache time: 0.017566219437867403 Engine time: 0.055540835950523615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 77.53993490710855,
    "estimated_duration": 3600.1056181510444,
    "input_throughput": 6205.908762053056,
    "output_throughput": 5512.939925966167,
    "total_throughput": 11718.848688019223,
    "itl": 154.54469213934277,
    "ttft": 1796065.4634981642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7341209738794634,
    "arrivals": 329992,
    "finished_requests": 90394,
    "scheduler_time": 165.1543166624252
}
#Debug simulation 
Total elapsed time: 77.54009607201442. Arrivals time: 0.4475312936119735 Scheduler time: 76.94003887055442 Scheduler overhead time: 0.057782212272286415 Adapter cache time: 0.018067291472107172 Engine time: 0.055067457258701324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.80035186232999,
    "estimated_duration": 3600.142441851259,
    "input_throughput": 6203.864530569807,
    "output_throughput": 5512.912425152315,
    "total_throughput": 11716.776955722122,
    "itl": 154.5647187664097,
    "ttft": 1796347.054150794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.785724675264213,
    "arrivals": 329992,
    "finished_requests": 90385,
    "scheduler_time": 165.14355494785354
}
#Debug simulation 
Total elapsed time: 76.80051936721429. Arrivals time: 0.43433445086702704 Scheduler time: 76.21512482361868 Scheduler overhead time: 0.05714345118030906 Adapter cache time: 0.017853679601103067 Engine time: 0.055259653367102146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.93160995980725,
    "estimated_duration": 3600.0542958933147,
    "input_throughput": 6208.033591464006,
    "output_throughput": 5515.195152097892,
    "total_throughput": 11723.228743561898,
    "itl": 154.76113632190777,
    "ttft": 1795825.1560361683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.638547561606371,
    "arrivals": 329992,
    "finished_requests": 90448,
    "scheduler_time": 164.9035629247634
}
#Debug simulation 
Total elapsed time: 78.9317765799351. Arrivals time: 0.4512407793663442 Scheduler time: 78.32805384648964 Scheduler overhead time: 0.05796424625441432 Adapter cache time: 0.017351382412016392 Engine time: 0.0553600313141942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.69965134933591,
    "estimated_duration": 3600.1675654012315,
    "input_throughput": 6203.821237279224,
    "output_throughput": 5512.873953628895,
    "total_throughput": 11716.695190908118,
    "itl": 154.5653606188895,
    "ttft": 1796356.405552529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8089891257509556,
    "arrivals": 329992,
    "finished_requests": 90385,
    "scheduler_time": 165.14384207521132
}
#Debug simulation 
Total elapsed time: 76.6998110790737. Arrivals time: 0.4466453972272575 Scheduler time: 76.10011438420042 Scheduler overhead time: 0.0587305654771626 Adapter cache time: 0.0176148759201169 Engine time: 0.05570837389677763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.45546541688964,
    "estimated_duration": 3600.1413389885715,
    "input_throughput": 6216.027898028878,
    "output_throughput": 5520.025501438538,
    "total_throughput": 11736.053399467415,
    "itl": 155.13348970611233,
    "ttft": 1790203.3058147144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7352965508098956,
    "arrivals": 328805,
    "finished_requests": 90575,
    "scheduler_time": 164.50516926366444
}
#Debug simulation 
Total elapsed time: 75.45563007285818. Arrivals time: 0.44202806893736124 Scheduler time: 74.86349556129426 Scheduler overhead time: 0.05675965314731002 Adapter cache time: 0.017636645585298538 Engine time: 0.054137044586241245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.3687093439512,
    "estimated_duration": 3600.079820238403,
    "input_throughput": 6215.448300398578,
    "output_throughput": 5524.008353426747,
    "total_throughput": 11739.456653825326,
    "itl": 155.11778886392517,
    "ttft": 1789486.0955344248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7170006025279934,
    "arrivals": 328805,
    "finished_requests": 90541,
    "scheduler_time": 164.51673400584133
}
#Debug simulation 
Total elapsed time: 72.368883643765. Arrivals time: 0.44913463294506073 Scheduler time: 71.76939749112353 Scheduler overhead time: 0.05699220532551408 Adapter cache time: 0.017175721004605293 Engine time: 0.05486562242731452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.38063495606184,
    "estimated_duration": 3600.082767769296,
    "input_throughput": 6215.443211563943,
    "output_throughput": 5524.003830701487,
    "total_throughput": 11739.447042265429,
    "itl": 155.1178766135897,
    "ttft": 1789487.133737522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7199392800219462,
    "arrivals": 328805,
    "finished_requests": 90541,
    "scheduler_time": 164.51674285921442
}
#Debug simulation 
Total elapsed time: 72.38080718833953. Arrivals time: 0.4423754126764834 Scheduler time: 71.78838367387652 Scheduler overhead time: 0.05700850626453757 Adapter cache time: 0.017125493846833706 Engine time: 0.05470216227695346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.2989817080088,
    "estimated_duration": 3600.002431714607,
    "input_throughput": 6216.229412195594,
    "output_throughput": 5520.151826823936,
    "total_throughput": 11736.381239019529,
    "itl": 155.13337444569947,
    "ttft": 1790175.5267229532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7701314604841072,
    "arrivals": 328805,
    "finished_requests": 90574,
    "scheduler_time": 164.4973568085326
}
#Debug simulation 
Total elapsed time: 75.2991529381834. Arrivals time: 0.44317214004695415 Scheduler time: 74.70609572855756 Scheduler overhead time: 0.05639832792803645 Adapter cache time: 0.017741589341312647 Engine time: 0.05436965124681592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 77.88220787327737,
    "estimated_duration": 3600.1238527681985,
    "input_throughput": 6214.856186904804,
    "output_throughput": 5517.766558149306,
    "total_throughput": 11732.62274505411,
    "itl": 154.8933671995976,
    "ttft": 1787753.6645607532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8403542535752093,
    "arrivals": 328805,
    "finished_requests": 90559,
    "scheduler_time": 164.60648791099374
}
#Debug simulation 
Total elapsed time: 77.88245161110535. Arrivals time: 0.4413203774020076 Scheduler time: 77.29075097339228 Scheduler overhead time: 0.056708904914557934 Adapter cache time: 0.017928268294781446 Engine time: 0.05455111991614103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 66.70198563067243,
    "estimated_duration": 3600.130631193284,
    "input_throughput": 6214.466165796983,
    "output_throughput": 5524.245655888327,
    "total_throughput": 11738.71182168531,
    "itl": 155.19573233672847,
    "ttft": 1788819.8961819094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7103087686840206,
    "arrivals": 328805,
    "finished_requests": 90600,
    "scheduler_time": 164.4991270998367
}
#Debug simulation 
Total elapsed time: 66.70214983774349. Arrivals time: 0.43262476148083806 Scheduler time: 66.11949140811339 Scheduler overhead time: 0.05669609969481826 Adapter cache time: 0.017919201869517565 Engine time: 0.05479742540046573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.86801623133942,
    "estimated_duration": 3600.143272829784,
    "input_throughput": 6214.822662436263,
    "output_throughput": 5517.736793954313,
    "total_throughput": 11732.559456390576,
    "itl": 154.89399408608756,
    "ttft": 1787760.3647584715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8632414427027069,
    "arrivals": 328805,
    "finished_requests": 90559,
    "scheduler_time": 164.6066125343831
}
#Debug simulation 
Total elapsed time: 77.86817909032106. Arrivals time: 0.43808268941938877 Scheduler time: 77.27723727701232 Scheduler overhead time: 0.058155018370598555 Adapter cache time: 0.018131813500076532 Engine time: 0.05549932923167944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.508474746719,
    "estimated_duration": 3600.0683402895233,
    "input_throughput": 6213.681487557815,
    "output_throughput": 5499.671153022533,
    "total_throughput": 11713.352640580348,
    "itl": 154.03271631172896,
    "ttft": 1780932.3048506516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8975024012383372,
    "arrivals": 322791,
    "finished_requests": 90641,
    "scheduler_time": 165.43910711004125
}
#Debug simulation 
Total elapsed time: 78.50863910187036. Arrivals time: 0.45716390758752823 Scheduler time: 77.89980982197449 Scheduler overhead time: 0.0570493065752089 Adapter cache time: 0.01864372519776225 Engine time: 0.05483354348689318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 79.21143501903862,
    "estimated_duration": 3600.0515322334004,
    "input_throughput": 6210.1124941759745,
    "output_throughput": 5495.1316176652535,
    "total_throughput": 11705.244111841228,
    "itl": 153.9578762126846,
    "ttft": 1779774.6698087053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9722886727261415,
    "arrivals": 322791,
    "finished_requests": 90589,
    "scheduler_time": 165.65482523238026
}
#Debug simulation 
Total elapsed time: 79.21160180307925. Arrivals time: 0.44256467977538705 Scheduler time: 78.61378063168377 Scheduler overhead time: 0.058847824577242136 Adapter cache time: 0.01891828142106533 Engine time: 0.055972328409552574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 79.51602598745376,
    "estimated_duration": 3600.054789717212,
    "input_throughput": 6210.106875000129,
    "output_throughput": 5495.126645434737,
    "total_throughput": 11705.233520434866,
    "itl": 153.9580089623733,
    "ttft": 1779775.6439972112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9755451149307315,
    "arrivals": 322791,
    "finished_requests": 90589,
    "scheduler_time": 165.65482627395355
}
#Debug simulation 
Total elapsed time: 79.51618719100952. Arrivals time: 0.43345321901142597 Scheduler time: 78.92886800365523 Scheduler overhead time: 0.05839643068611622 Adapter cache time: 0.018779083620756865 Engine time: 0.05541658727452159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 77.73009642632678,
    "estimated_duration": 3600.0471407034133,
    "input_throughput": 6216.731927467779,
    "output_throughput": 5501.834066575566,
    "total_throughput": 11718.565994043345,
    "itl": 154.19008652080504,
    "ttft": 1781686.482628578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.949423541233396,
    "arrivals": 322791,
    "finished_requests": 90708,
    "scheduler_time": 165.2784088915213
}
#Debug simulation 
Total elapsed time: 77.73026370815933. Arrivals time: 0.4517894429154694 Scheduler time: 77.12653597816825 Scheduler overhead time: 0.057337818667292595 Adapter cache time: 0.01852769311517477 Engine time: 0.05482391361147165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 79.6933021126315,
    "estimated_duration": 3600.106224686797,
    "input_throughput": 6209.741214495667,
    "output_throughput": 5496.624200782176,
    "total_throughput": 11706.365415277842,
    "itl": 154.00434928479066,
    "ttft": 1779909.7831025722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9878072879649737,
    "arrivals": 322791,
    "finished_requests": 90604,
    "scheduler_time": 165.5850055219247
}
#Debug simulation 
Total elapsed time: 79.6934644957073. Arrivals time: 0.45278016244992614 Scheduler time: 79.08581979200244 Scheduler overhead time: 0.05868759052827954 Adapter cache time: 0.018393960781395435 Engine time: 0.05636986391618848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.60609490983188,
    "estimated_duration": 3600.041537639914,
    "input_throughput": 6213.731637847974,
    "output_throughput": 5499.773486774805,
    "total_throughput": 11713.505124622778,
    "itl": 154.03248571187538,
    "ttft": 1780909.8193633284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85383118283932,
    "arrivals": 322791,
    "finished_requests": 90642,
    "scheduler_time": 165.43923602596635
}
#Debug simulation 
Total elapsed time: 78.60625746287405. Arrivals time: 0.44346882682293653 Scheduler time: 78.0107316444628 Scheduler overhead time: 0.05719635961577296 Adapter cache time: 0.018631977029144764 Engine time: 0.054977838415652514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 79.72080331901088,
    "estimated_duration": 3600.1361838013804,
    "input_throughput": 6210.7789423650265,
    "output_throughput": 5495.816821881529,
    "total_throughput": 11706.595764246556,
    "itl": 153.9596095968003,
    "ttft": 1780068.1425269607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.03466594882309,
    "arrivals": 322791,
    "finished_requests": 90604,
    "scheduler_time": 165.5974044248364
}
#Debug simulation 
Total elapsed time: 79.72104154294357. Arrivals time: 0.44389244448393583 Scheduler time: 79.12150448607281 Scheduler overhead time: 0.05921571096405387 Adapter cache time: 0.0186201105825603 Engine time: 0.05621411092579365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.8681055912748,
    "estimated_duration": 3600.0070699198327,
    "input_throughput": 6268.938799751459,
    "output_throughput": 5513.113061870174,
    "total_throughput": 11782.051861621632,
    "itl": 154.17346888456234,
    "ttft": 1778144.3798869306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9954380090441888,
    "arrivals": 320386,
    "finished_requests": 91042,
    "scheduler_time": 164.7874430789269
}
#Debug simulation 
Total elapsed time: 75.86826591519639. Arrivals time: 0.43318871688097715 Scheduler time: 75.28425864782184 Scheduler overhead time: 0.05719351535663009 Adapter cache time: 0.018652888480573893 Engine time: 0.054086362943053246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.25662329094484,
    "estimated_duration": 3600.073806198994,
    "input_throughput": 6271.64975371396,
    "output_throughput": 5513.813068448737,
    "total_throughput": 11785.462822162697,
    "itl": 154.20502878720762,
    "ttft": 1777675.2240058717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.093395182730168,
    "arrivals": 320386,
    "finished_requests": 91067,
    "scheduler_time": 164.769225813109
}
#Debug simulation 
Total elapsed time: 76.25678686192259. Arrivals time: 0.4299948955886066 Scheduler time: 75.67628044681624 Scheduler overhead time: 0.05709700472652912 Adapter cache time: 0.018592895474284887 Engine time: 0.05374228488653898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.95549659524113,
    "estimated_duration": 3600.0784786474155,
    "input_throughput": 6271.641613902519,
    "output_throughput": 5513.80591221386,
    "total_throughput": 11785.447526116379,
    "itl": 154.20507294349017,
    "ttft": 1777676.6335766441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.097952072471389,
    "arrivals": 320386,
    "finished_requests": 91067,
    "scheduler_time": 164.7692985669092
}
#Debug simulation 
Total elapsed time: 75.95566193806008. Arrivals time: 0.43267446011304855 Scheduler time: 75.3727773502469 Scheduler overhead time: 0.056484288070350885 Adapter cache time: 0.01817056629806757 Engine time: 0.054468986578285694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 76.3265552027151,
    "estimated_duration": 3600.0457073339135,
    "input_throughput": 6268.871518498957,
    "output_throughput": 5513.053892501348,
    "total_throughput": 11781.925411000304,
    "itl": 154.17473125254364,
    "ttft": 1778157.1035484402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0336834278749145,
    "arrivals": 320386,
    "finished_requests": 91042,
    "scheduler_time": 164.787637176017
}
#Debug simulation 
Total elapsed time: 76.32672484684736. Arrivals time: 0.4296199004165828 Scheduler time: 75.74622328253463 Scheduler overhead time: 0.05672389641404152 Adapter cache time: 0.018554771784693003 Engine time: 0.05416931863874197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.5949924197048,
    "estimated_duration": 3600.1063153840646,
    "input_throughput": 6271.593120324644,
    "output_throughput": 5513.763278372061,
    "total_throughput": 11785.356398696704,
    "itl": 154.20588167054683,
    "ttft": 1777685.4911537562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.124989136550579,
    "arrivals": 320386,
    "finished_requests": 91067,
    "scheduler_time": 164.76956613030055
}
#Debug simulation 
Total elapsed time: 76.5951590789482. Arrivals time: 0.4359607696533203 Scheduler time: 76.00988802453503 Scheduler overhead time: 0.056481828447431326 Adapter cache time: 0.017907394096255302 Engine time: 0.05394582403823733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.40614920621738,
    "estimated_duration": 3600.013131100404,
    "input_throughput": 6268.385746999274,
    "output_throughput": 5513.827388160821,
    "total_throughput": 11782.213135160095,
    "itl": 154.22751231975022,
    "ttft": 1777856.2009431263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9554928928659903,
    "arrivals": 320386,
    "finished_requests": 91083,
    "scheduler_time": 164.75838153429004
}
#Debug simulation 
Total elapsed time: 76.40631882986054. Arrivals time: 0.4401030414737761 Scheduler time: 75.8161883642897 Scheduler overhead time: 0.05651185242459178 Adapter cache time: 0.018249190878123045 Engine time: 0.053876455407589674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.2294243350625,
    "estimated_duration": 3600.131877739059,
    "input_throughput": 6271.548589542115,
    "output_throughput": 5513.724128480039,
    "total_throughput": 11785.272718022154,
    "itl": 154.20652576884592,
    "ttft": 1777694.1580481473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1505171551927917,
    "arrivals": 320386,
    "finished_requests": 91067,
    "scheduler_time": 164.76988608384715
}
#Debug simulation 
Total elapsed time: 76.22968172794208. Arrivals time: 0.43583794636651874 Scheduler time: 75.64148020278662 Scheduler overhead time: 0.05764358676970005 Adapter cache time: 0.018712567165493965 Engine time: 0.05481085227802396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 70.13562337169424,
    "estimated_duration": 3600.0004326993417,
    "input_throughput": 6234.556195086567,
    "output_throughput": 5517.852670119106,
    "total_throughput": 11752.408865205673,
    "itl": 154.97234990929206,
    "ttft": 1786624.9612093768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9311677664215987,
    "arrivals": 319202,
    "finished_requests": 90558,
    "scheduler_time": 164.54082485916774
}
#Debug simulation 
Total elapsed time: 70.13579559791833. Arrivals time: 0.42684748163446784 Scheduler time: 69.56162985228002 Scheduler overhead time: 0.05524074099957943 Adapter cache time: 0.018181148450821638 Engine time: 0.053200132213532925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.16724647954106,
    "estimated_duration": 3600.165329430656,
    "input_throughput": 6236.704413669477,
    "output_throughput": 5515.827519826819,
    "total_throughput": 11752.531933496297,
    "itl": 154.94039207592672,
    "ttft": 1784829.038747115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.012663824767812,
    "arrivals": 319202,
    "finished_requests": 90514,
    "scheduler_time": 164.55829811831123
}
#Debug simulation 
Total elapsed time: 74.16741334181279. Arrivals time: 0.442679098341614 Scheduler time: 73.57583261979744 Scheduler overhead time: 0.05609502037987113 Adapter cache time: 0.018150118179619312 Engine time: 0.05346242943778634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.88754062540829,
    "estimated_duration": 3600.168306330567,
    "input_throughput": 6236.699256675905,
    "output_throughput": 5515.82295891048,
    "total_throughput": 11752.522215586387,
    "itl": 154.94050542769355,
    "ttft": 1784829.9815090573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0157770635560275,
    "arrivals": 319202,
    "finished_requests": 90514,
    "scheduler_time": 164.55830101732522
}
#Debug simulation 
Total elapsed time: 73.88770590024069. Arrivals time: 0.42470940202474594 Scheduler time: 73.31386073492467 Scheduler overhead time: 0.05621065478771925 Adapter cache time: 0.018037331756204367 Engine time: 0.053851962089538574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 70.78614898677915,
    "estimated_duration": 3600.029158112578,
    "input_throughput": 6233.9811746875275,
    "output_throughput": 5520.238344519137,
    "total_throughput": 11754.219519206665,
    "itl": 155.00192407017522,
    "ttft": 1785477.9154724658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9150284897815308,
    "arrivals": 319202,
    "finished_requests": 90533,
    "scheduler_time": 164.54608811939468
}
#Debug simulation 
Total elapsed time: 70.7863228470087. Arrivals time: 0.4287448641844094 Scheduler time: 70.20802994491532 Scheduler overhead time: 0.05633153300732374 Adapter cache time: 0.01789897447451949 Engine time: 0.05426177801564336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 70.03717880835757,
    "estimated_duration": 3600.0620578463436,
    "input_throughput": 6233.711708132408,
    "output_throughput": 5518.123488094575,
    "total_throughput": 11751.835196226983,
    "itl": 154.98742669584124,
    "ttft": 1786534.7257847528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0696887785382594,
    "arrivals": 319202,
    "finished_requests": 90547,
    "scheduler_time": 164.53508543987522
}
#Debug simulation 
Total elapsed time: 70.03734262939543. Arrivals time: 0.42358957696706057 Scheduler time: 69.46342300763354 Scheduler overhead time: 0.057163882069289684 Adapter cache time: 0.01852975133806467 Engine time: 0.05336661683395505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 69.95709428796545,
    "estimated_duration": 3600.034585706649,
    "input_throughput": 6233.518169269224,
    "output_throughput": 5517.39949356657,
    "total_throughput": 11750.917662835793,
    "itl": 154.98352650148607,
    "ttft": 1786580.6435731119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8897117863781447,
    "arrivals": 319202,
    "finished_requests": 90547,
    "scheduler_time": 164.53863613928345
}
#Debug simulation 
Total elapsed time: 69.95727070979774. Arrivals time: 0.4043889446184039 Scheduler time: 69.40563186304644 Scheduler overhead time: 0.05525169428437948 Adapter cache time: 0.017809048295021057 Engine time: 0.0529463617131114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 70.16698927571997,
    "estimated_duration": 3600.003860245986,
    "input_throughput": 6232.959427567608,
    "output_throughput": 5519.55019254959,
    "total_throughput": 11752.509620117198,
    "itl": 154.98264259458756,
    "ttft": 1786363.7428342837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0919617846235607,
    "arrivals": 319202,
    "finished_requests": 90559,
    "scheduler_time": 164.53335286851222
}
#Debug simulation 
Total elapsed time: 70.16715108975768. Arrivals time: 0.42836005007848144 Scheduler time: 69.59007160551846 Scheduler overhead time: 0.05596841871738434 Adapter cache time: 0.01825442537665367 Engine time: 0.053758625872433186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 66.1844712048769,
    "estimated_duration": 3600.0013151025278,
    "input_throughput": 6238.323554434702,
    "output_throughput": 5519.0068727611415,
    "total_throughput": 11757.330427195842,
    "itl": 155.08552684189115,
    "ttft": 1777026.3144537332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1913092246558916,
    "arrivals": 315552,
    "finished_requests": 90742,
    "scheduler_time": 164.30353369035748
}
#Debug simulation 
Total elapsed time: 66.18463930301368. Arrivals time: 0.4141435562632978 Scheduler time: 65.62478304095566 Scheduler overhead time: 0.05453864624723792 Adapter cache time: 0.0182284377515316 Engine time: 0.05238522915169597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.20832221396267,
    "estimated_duration": 3600.02409727923,
    "input_throughput": 6238.779906216263,
    "output_throughput": 5517.815009908602,
    "total_throughput": 11756.594916124865,
    "itl": 155.08032696286892,
    "ttft": 1777324.603942345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3932742412202117,
    "arrivals": 315552,
    "finished_requests": 90758,
    "scheduler_time": 164.3349719673447
}
#Debug simulation 
Total elapsed time: 68.20855832379311. Arrivals time: 0.43782820040360093 Scheduler time: 67.62308770790696 Scheduler overhead time: 0.05534319533035159 Adapter cache time: 0.019146446604281664 Engine time: 0.05252607772126794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.23529519373551,
    "estimated_duration": 3600.028412489916,
    "input_throughput": 6238.77242803925,
    "output_throughput": 5517.808395923498,
    "total_throughput": 11756.580823962748,
    "itl": 155.0804166828672,
    "ttft": 1777325.8184136965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.397845117338,
    "arrivals": 315552,
    "finished_requests": 90758,
    "scheduler_time": 164.33499477773665
}
#Debug simulation 
Total elapsed time: 68.23546495195478. Arrivals time: 0.4196964828297496 Scheduler time: 67.6692669778131 Scheduler overhead time: 0.05462828930467367 Adapter cache time: 0.018856846261769533 Engine time: 0.052461409009993076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 67.00754325604066,
    "estimated_duration": 3600.1164739352494,
    "input_throughput": 6236.297398305732,
    "output_throughput": 5518.346737899824,
    "total_throughput": 11754.644136205556,
    "itl": 155.08862520274533,
    "ttft": 1776553.4994709403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 715,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.236357432599162,
    "arrivals": 315552,
    "finished_requests": 90757,
    "scheduler_time": 164.3033598232888
}
#Debug simulation 
Total elapsed time: 67.00771538494155. Arrivals time: 0.43576257722452283 Scheduler time: 66.42460900964215 Scheduler overhead time: 0.05499350372701883 Adapter cache time: 0.018657699692994356 Engine time: 0.05298521742224693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 68.25245138909668,
    "estimated_duration": 3600.029092171709,
    "input_throughput": 6239.022637022818,
    "output_throughput": 5517.737076957086,
    "total_throughput": 11756.759713979905,
    "itl": 155.08498282665582,
    "ttft": 1777403.7497040208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4214759870991127,
    "arrivals": 315552,
    "finished_requests": 90755,
    "scheduler_time": 164.3350062299679
}
#Debug simulation 
Total elapsed time: 68.25261245574802. Arrivals time: 0.4324125126004219 Scheduler time: 67.67224617674947 Scheduler overhead time: 0.05498262867331505 Adapter cache time: 0.01910535804927349 Engine time: 0.05260846810415387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 66.21431799372658,
    "estimated_duration": 3600.1543833928613,
    "input_throughput": 6238.493022300243,
    "output_throughput": 5519.274143258786,
    "total_throughput": 11757.76716555903,
    "itl": 155.07823521784258,
    "ttft": 1777038.6827253576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.143866061444821,
    "arrivals": 315552,
    "finished_requests": 90751,
    "scheduler_time": 164.3115972576362
}
#Debug simulation 
Total elapsed time: 66.2144851447083. Arrivals time: 0.42255228152498603 Scheduler time: 65.64558931812644 Scheduler overhead time: 0.054547739680856466 Adapter cache time: 0.01869708066806197 Engine time: 0.052220399025827646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.05795423034579,
    "estimated_duration": 3600.082795717998,
    "input_throughput": 6238.744849622436,
    "output_throughput": 5517.810874690792,
    "total_throughput": 11756.555724313228,
    "itl": 155.08247748901826,
    "ttft": 1777370.5825950608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4524114185571766,
    "arrivals": 315552,
    "finished_requests": 90759,
    "scheduler_time": 164.33593570014892
}
#Debug simulation 
Total elapsed time: 68.05812445329502. Arrivals time: 0.4278152515180409 Scheduler time: 67.48400274198502 Scheduler overhead time: 0.05433070845901966 Adapter cache time: 0.01890221470966935 Engine time: 0.05251353373751044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 64.21838685311377,
    "estimated_duration": 3600.0863698556277,
    "input_throughput": 6293.369289611956,
    "output_throughput": 5517.554569335674,
    "total_throughput": 11810.923858947632,
    "itl": 154.4626373519862,
    "ttft": 1777793.039100294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.120918006545436,
    "arrivals": 314288,
    "finished_requests": 91228,
    "scheduler_time": 164.45990904976105
}
#Debug simulation 
Total elapsed time: 64.2185527603142. Arrivals time: 0.4194297497160733 Scheduler time: 63.65333918808028 Scheduler overhead time: 0.05469711031764746 Adapter cache time: 0.01794513175264001 Engine time: 0.05229704175144434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.650645460002124,
    "estimated_duration": 3600.08006395239,
    "input_throughput": 6289.9665001171115,
    "output_throughput": 5517.833394569389,
    "total_throughput": 11807.799894686501,
    "itl": 154.52228560307623,
    "ttft": 1777988.612681709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.276513450532226,
    "arrivals": 314288,
    "finished_requests": 91218,
    "scheduler_time": 164.43485395734268
}
#Debug simulation 
Total elapsed time: 63.650811690371484. Arrivals time: 0.41650842735543847 Scheduler time: 63.088633221108466 Scheduler overhead time: 0.05428421078249812 Adapter cache time: 0.01839418802410364 Engine time: 0.05192383658140898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.59036795096472,
    "estimated_duration": 3600.08405528502,
    "input_throughput": 6289.959526572008,
    "output_throughput": 5517.827277070982,
    "total_throughput": 11807.78680364299,
    "itl": 154.52239893999143,
    "ttft": 1777990.1529811833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.280176207516344,
    "arrivals": 314288,
    "finished_requests": 91218,
    "scheduler_time": 164.434904057082
}
#Debug simulation 
Total elapsed time: 63.590538520831615. Arrivals time: 0.41064820159226656 Scheduler time: 63.03509666305035 Scheduler overhead time: 0.05466943373903632 Adapter cache time: 0.01786943105980754 Engine time: 0.051880036015063524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 64.34611382894218,
    "estimated_duration": 3600.060020152504,
    "input_throughput": 6296.158917661548,
    "output_throughput": 5517.268014647877,
    "total_throughput": 11813.426932309425,
    "itl": 154.43779223078943,
    "ttft": 1777442.2550835123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1591546033159674,
    "arrivals": 314288,
    "finished_requests": 91275,
    "scheduler_time": 164.465422673413
}
#Debug simulation 
Total elapsed time: 64.34634674573317. Arrivals time: 0.4163810913451016 Scheduler time: 63.78399102669209 Scheduler overhead time: 0.05483919009566307 Adapter cache time: 0.017901135608553886 Engine time: 0.0526279266923666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 63.752899060957134,
    "estimated_duration": 3600.1345941832888,
    "input_throughput": 6290.439539841002,
    "output_throughput": 5517.914255788135,
    "total_throughput": 11808.353795629137,
    "itl": 154.51164126740017,
    "ttft": 1778330.3707093017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3164041400887103,
    "arrivals": 314288,
    "finished_requests": 91211,
    "scheduler_time": 164.43875221353943
}
#Debug simulation 
Total elapsed time: 63.753058513160795. Arrivals time: 0.4144593542441726 Scheduler time: 63.19312851782888 Scheduler overhead time: 0.054391130805015564 Adapter cache time: 0.01800601789727807 Engine time: 0.05209877761080861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.22218818264082,
    "estimated_duration": 3600.1337660910963,
    "input_throughput": 6291.687051560198,
    "output_throughput": 5515.233680208088,
    "total_throughput": 11806.920731768285,
    "itl": 154.49182364569327,
    "ttft": 1777780.3855886133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1199456590856043,
    "arrivals": 314288,
    "finished_requests": 91200,
    "scheduler_time": 164.45048491368698
}
#Debug simulation 
Total elapsed time: 63.22235526656732. Arrivals time: 0.3971353452652693 Scheduler time: 62.68062549177557 Scheduler overhead time: 0.05378024373203516 Adapter cache time: 0.017922637052834034 Engine time: 0.05212259339168668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.893125836737454,
    "estimated_duration": 3600.166654421484,
    "input_throughput": 6290.383522159223,
    "output_throughput": 5517.865117605833,
    "total_throughput": 11808.248639765055,
    "itl": 154.5121959309262,
    "ttft": 1778341.163814803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.345956279896206,
    "arrivals": 314288,
    "finished_requests": 91211,
    "scheduler_time": 164.43904414914533
}
#Debug simulation 
Total elapsed time: 63.89329282799736. Arrivals time: 0.4055306245572865 Scheduler time: 63.343002951238304 Scheduler overhead time: 0.054568419232964516 Adapter cache time: 0.01761522237211466 Engine time: 0.05166718130931258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 67.02410999499261,
    "estimated_duration": 3600.0842453301193,
    "input_throughput": 6198.3807820457805,
    "output_throughput": 5525.6323586882845,
    "total_throughput": 11724.013140734065,
    "itl": 155.5251370681959,
    "ttft": 1761326.6568556887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3412731241086018,
    "arrivals": 311871,
    "finished_requests": 90770,
    "scheduler_time": 163.88304271983552
}
#Debug simulation 
Total elapsed time: 67.02427753712982. Arrivals time: 0.4162797825410962 Scheduler time: 66.45941417105496 Scheduler overhead time: 0.05592841934412718 Adapter cache time: 0.018601268995553255 Engine time: 0.053262114990502596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 66.31378721212968,
    "estimated_duration": 3600.145224802276,
    "input_throughput": 6199.667404035297,
    "output_throughput": 5526.245403362213,
    "total_throughput": 11725.912807397512,
    "itl": 155.51402261744005,
    "ttft": 1761491.115897724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4065901114209614,
    "arrivals": 311871,
    "finished_requests": 90742,
    "scheduler_time": 163.88601706915415
}
#Debug simulation 
Total elapsed time: 66.31395781226456. Arrivals time: 0.4145874544046819 Scheduler time: 65.75011356174946 Scheduler overhead time: 0.05581722501665354 Adapter cache time: 0.01863581594079733 Engine time: 0.054117074236273766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 66.66840631421655,
    "estimated_duration": 3600.151258798842,
    "input_throughput": 6199.657013146378,
    "output_throughput": 5526.236141155326,
    "total_throughput": 11725.893154301704,
    "itl": 155.5142475515139,
    "ttft": 1761493.6711904379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.411713721603152,
    "arrivals": 311871,
    "finished_requests": 90742,
    "scheduler_time": 163.8860920279032
}
#Debug simulation 
Total elapsed time: 66.6685706791468. Arrivals time: 0.4149455474689603 Scheduler time: 66.10385078191757 Scheduler overhead time: 0.056499586906284094 Adapter cache time: 0.01823347434401512 Engine time: 0.05428010085597634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 64.3711853120476,
    "estimated_duration": 3600.0298963642736,
    "input_throughput": 6193.8696738377685,
    "output_throughput": 5523.533851783302,
    "total_throughput": 11717.403525621072,
    "itl": 155.49811313668633,
    "ttft": 1764977.0553135714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.189593584649248,
    "arrivals": 311871,
    "finished_requests": 90763,
    "scheduler_time": 163.88745288330225
}
#Debug simulation 
Total elapsed time: 64.37135381205007. Arrivals time: 0.4176786099560559 Scheduler time: 63.80685304058716 Scheduler overhead time: 0.055574795696884394 Adapter cache time: 0.01768928160890937 Engine time: 0.05308207543566823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 66.58619856415316,
    "estimated_duration": 3600.149692667298,
    "input_throughput": 6199.9238657943015,
    "output_throughput": 5525.660791415986,
    "total_throughput": 11725.584657210287,
    "itl": 155.4863758190837,
    "ttft": 1761674.1729756375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.443786649331456,
    "arrivals": 311871,
    "finished_requests": 90755,
    "scheduler_time": 163.88580454606173
}
#Debug simulation 
Total elapsed time: 66.58636827999726. Arrivals time: 0.4146087463013828 Scheduler time: 66.02318253880367 Scheduler overhead time: 0.055589857045561075 Adapter cache time: 0.01841809321194887 Engine time: 0.053659189492464066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 66.90899120317772,
    "estimated_duration": 3600.0300391257165,
    "input_throughput": 6198.474112015805,
    "output_throughput": 5525.715558982125,
    "total_throughput": 11724.18967099793,
    "itl": 155.52371684966846,
    "ttft": 1761306.5508773872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.28738847560012,
    "arrivals": 311871,
    "finished_requests": 90770,
    "scheduler_time": 163.8827062571295
}
#Debug simulation 
Total elapsed time: 66.90923807024956. Arrivals time: 0.41171255335211754 Scheduler time: 66.34879487194121 Scheduler overhead time: 0.05575716122984886 Adapter cache time: 0.018118536565452814 Engine time: 0.053752567153424025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 66.73614907730371,
    "estimated_duration": 3600.1037651871798,
    "input_throughput": 6198.324952680857,
    "output_throughput": 5525.396571164042,
    "total_throughput": 11723.721523844899,
    "itl": 155.5342099080164,
    "ttft": 1761353.3425895565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.557940554656101,
    "arrivals": 311871,
    "finished_requests": 90767,
    "scheduler_time": 163.874873701028
}
#Debug simulation 
Total elapsed time: 66.73631915729493. Arrivals time: 0.4153423300012946 Scheduler time: 66.17151019815356 Scheduler overhead time: 0.05606807628646493 Adapter cache time: 0.01880793087184429 Engine time: 0.05389072047546506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 93.24327932996675,
    "estimated_duration": 3600.084518807433,
    "input_throughput": 6167.725753104103,
    "output_throughput": 5454.419999701774,
    "total_throughput": 11622.145752805878,
    "itl": 148.51373861991033,
    "ttft": 1557237.6554600245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.508820457758864,
    "arrivals": 211085,
    "finished_requests": 89638,
    "scheduler_time": 161.5158605770493
}
#Debug simulation 
Total elapsed time: 93.24344922229648. Arrivals time: 0.44669807329773903 Scheduler time: 92.63162752427161 Scheduler overhead time: 0.06386112421751022 Adapter cache time: 0.017598171718418598 Engine time: 0.061008498538285494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 92.8433498442173,
    "estimated_duration": 3600.0353393885366,
    "input_throughput": 6177.859355063313,
    "output_throughput": 5451.446763667981,
    "total_throughput": 11629.306118731294,
    "itl": 149.4698534902526,
    "ttft": 1567502.0279343873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6302701978548488,
    "arrivals": 211085,
    "finished_requests": 89819,
    "scheduler_time": 161.14708735644356
}
#Debug simulation 
Total elapsed time: 92.84351536491886. Arrivals time: 0.4456691602244973 Scheduler time: 92.2302043675445 Scheduler overhead time: 0.06527488213032484 Adapter cache time: 0.017878816928714514 Engine time: 0.06169656338170171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 92.3154988558963,
    "estimated_duration": 3600.037910270553,
    "input_throughput": 6177.854943291018,
    "output_throughput": 5451.442870646075,
    "total_throughput": 11629.297813937093,
    "itl": 149.46989440764216,
    "ttft": 1567503.1586826846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6333883450739184,
    "arrivals": 211085,
    "finished_requests": 89819,
    "scheduler_time": 161.14709704294845
}
#Debug simulation 
Total elapsed time: 92.31566520780325. Arrivals time: 0.44551173970103264 Scheduler time: 91.70346952183172 Scheduler overhead time: 0.06527470191940665 Adapter cache time: 0.01783115928992629 Engine time: 0.060456328094005585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 93.9521246519871,
    "estimated_duration": 3600.031158310042,
    "input_throughput": 6177.255979761937,
    "output_throughput": 5449.611444254725,
    "total_throughput": 11626.867424016662,
    "itl": 148.35801025430692,
    "ttft": 1558615.117828239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5337686580000398,
    "arrivals": 211085,
    "finished_requests": 89742,
    "scheduler_time": 161.52177291891036
}
#Debug simulation 
Total elapsed time: 93.95228370232508. Arrivals time: 0.4370277412235737 Scheduler time: 93.3483125353232 Scheduler overhead time: 0.06471465388312936 Adapter cache time: 0.0180047620087862 Engine time: 0.06117685232311487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 92.39564885664731,
    "estimated_duration": 3600.0585743009806,
    "input_throughput": 6177.81948292839,
    "output_throughput": 5451.411579827043,
    "total_throughput": 11629.231062755433,
    "itl": 149.47036734399316,
    "ttft": 1567512.1688255058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6532574433274616,
    "arrivals": 211085,
    "finished_requests": 89819,
    "scheduler_time": 161.14769087848128
}
#Debug simulation 
Total elapsed time: 92.3958221678622. Arrivals time: 0.44237534422427416 Scheduler time: 91.78769521508366 Scheduler overhead time: 0.06454458646476269 Adapter cache time: 0.017589326947927475 Engine time: 0.06104023056104779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 92.38482619682327,
    "estimated_duration": 3600.130815148006,
    "input_throughput": 6177.918009650332,
    "output_throughput": 5451.541348836553,
    "total_throughput": 11629.459358486885,
    "itl": 149.46145115626516,
    "ttft": 1567479.4630077789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4950251474510716,
    "arrivals": 211085,
    "finished_requests": 89821,
    "scheduler_time": 161.1585717368752
}
#Debug simulation 
Total elapsed time: 92.38499446166679. Arrivals time: 0.4396622246131301 Scheduler time: 91.7805486023426 Scheduler overhead time: 0.06450618850067258 Adapter cache time: 0.01733775483444333 Engine time: 0.060262929648160934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 92.25294549018145,
    "estimated_duration": 3600.0850933968763,
    "input_throughput": 6177.773975618689,
    "output_throughput": 5451.371423413319,
    "total_throughput": 11629.145399032008,
    "itl": 149.4695637927685,
    "ttft": 1567521.6639880852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6750128483772262,
    "arrivals": 211085,
    "finished_requests": 89819,
    "scheduler_time": 161.14871740171705
}
#Debug simulation 
Total elapsed time: 92.25311827240512. Arrivals time: 0.44142183428630233 Scheduler time: 91.64552308246493 Scheduler overhead time: 0.06506636133417487 Adapter cache time: 0.017605917993932962 Engine time: 0.060671912506222725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 94.77632959885523,
    "estimated_duration": 3600.000350120639,
    "input_throughput": 6211.919395855226,
    "output_throughput": 5480.4061336657505,
    "total_throughput": 11692.325529520976,
    "itl": 151.1103032714601,
    "ttft": 1523698.730972597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4935180190391997,
    "arrivals": 201527,
    "finished_requests": 90219,
    "scheduler_time": 159.82262168542707
}
#Debug simulation 
Total elapsed time: 94.77649753121659. Arrivals time: 0.4434486827813089 Scheduler time: 94.16991895297542 Scheduler overhead time: 0.06305763637647033 Adapter cache time: 0.01738783437758684 Engine time: 0.06016600225120783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.5112821245566,
    "estimated_duration": 3600.0454326058552,
    "input_throughput": 6207.623880964144,
    "output_throughput": 5472.665934034901,
    "total_throughput": 11680.289814999045,
    "itl": 150.17280023016247,
    "ttft": 1542590.450728714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8076681311987404,
    "arrivals": 201527,
    "finished_requests": 90038,
    "scheduler_time": 160.11865746676025
}
#Debug simulation 
Total elapsed time: 88.51144997961819. Arrivals time: 0.43666658736765385 Scheduler time: 87.91006368398666 Scheduler overhead time: 0.06415567407384515 Adapter cache time: 0.01832699030637741 Engine time: 0.059575160034000874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.50037902407348,
    "estimated_duration": 3600.064460548913,
    "input_throughput": 6197.152924477998,
    "output_throughput": 5467.972925406608,
    "total_throughput": 11665.125849884605,
    "itl": 150.3033736374094,
    "ttft": 1540469.4471473813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6732830462046069,
    "arrivals": 201527,
    "finished_requests": 89985,
    "scheduler_time": 159.97598275176787
}
#Debug simulation 
Total elapsed time: 88.50062637403607. Arrivals time: 0.4428641088306904 Scheduler time: 87.89344605896622 Scheduler overhead time: 0.06361307948827744 Adapter cache time: 0.017845625523477793 Engine time: 0.06033065915107727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 93.3291557370685,
    "estimated_duration": 3600.1625030588625,
    "input_throughput": 6216.4757787973895,
    "output_throughput": 5485.693766106396,
    "total_throughput": 11702.169544903785,
    "itl": 151.5533991191066,
    "ttft": 1528382.1478307329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4996523188007957,
    "arrivals": 201527,
    "finished_requests": 90223,
    "scheduler_time": 159.46501358067306
}
#Debug simulation 
Total elapsed time: 93.3293340029195. Arrivals time: 0.44263104628771544 Scheduler time: 92.7227353178896 Scheduler overhead time: 0.06401645578444004 Adapter cache time: 0.017109562177211046 Engine time: 0.06036737095564604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 88.2602830817923,
    "estimated_duration": 3600.056582922615,
    "input_throughput": 6190.762141273565,
    "output_throughput": 5464.785774013734,
    "total_throughput": 11655.5479152873,
    "itl": 150.05615116204496,
    "ttft": 1544340.2839917236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.676837067808961,
    "arrivals": 201527,
    "finished_requests": 89863,
    "scheduler_time": 160.1005684668686
}
#Debug simulation 
Total elapsed time: 88.26046265289187. Arrivals time: 0.4416443845257163 Scheduler time: 87.65562317986041 Scheduler overhead time: 0.06348054530099034 Adapter cache time: 0.017789548728615046 Engine time: 0.05950675532221794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 93.1386680570431,
    "estimated_duration": 3600.1188528652665,
    "input_throughput": 6216.551151412105,
    "output_throughput": 5485.760278242435,
    "total_throughput": 11702.311429654541,
    "itl": 151.54892541267117,
    "ttft": 1528368.1712897262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4322340912581282,
    "arrivals": 201527,
    "finished_requests": 90223,
    "scheduler_time": 159.46549596595975
}
#Debug simulation 
Total elapsed time: 93.13884923513979. Arrivals time: 0.446549367159605 Scheduler time: 92.52706947829574 Scheduler overhead time: 0.06486123846843839 Adapter cache time: 0.017115327529609203 Engine time: 0.06054363865405321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.25614664470777,
    "estimated_duration": 3600.0853933259123,
    "input_throughput": 6190.712598461514,
    "output_throughput": 5464.742040972741,
    "total_throughput": 11655.454639434256,
    "itl": 150.0564909599063,
    "ttft": 1544354.647367342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6990954880043845,
    "arrivals": 201527,
    "finished_requests": 89863,
    "scheduler_time": 160.10160511075634
}
#Debug simulation 
Total elapsed time: 88.25632507074624. Arrivals time: 0.44705563550814986 Scheduler time: 87.64542653318495 Scheduler overhead time: 0.06372908782213926 Adapter cache time: 0.018148628529161215 Engine time: 0.05984268197789788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 91.04609312210232,
    "estimated_duration": 3600.0586238259275,
    "input_throughput": 6161.142169520539,
    "output_throughput": 5464.894063056037,
    "total_throughput": 11626.036232576576,
    "itl": 149.94736804194895,
    "ttft": 1528978.8057735541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4170058254408782,
    "arrivals": 196873,
    "finished_requests": 89759,
    "scheduler_time": 159.4921838804418
}
#Debug simulation 
Total elapsed time: 91.04627565480769. Arrivals time: 0.442660559900105 Scheduler time: 90.43790935212746 Scheduler overhead time: 0.06470905942842364 Adapter cache time: 0.01693933317437768 Engine time: 0.06086546927690506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.17814648989588,
    "estimated_duration": 3600.092544374398,
    "input_throughput": 6164.082930222635,
    "output_throughput": 5467.513336777426,
    "total_throughput": 11631.59626700006,
    "itl": 150.1875399556486,
    "ttft": 1526813.9999056065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5247823007754104,
    "arrivals": 196873,
    "finished_requests": 89802,
    "scheduler_time": 159.42838167454113
}
#Debug simulation 
Total elapsed time: 91.17832178296521. Arrivals time: 0.4439930603839457 Scheduler time: 90.56986196897924 Scheduler overhead time: 0.06416485318914056 Adapter cache time: 0.01702673640102148 Engine time: 0.060700864531099796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.4482052908279,
    "estimated_duration": 3600.096305056103,
    "input_throughput": 6164.07649118547,
    "output_throughput": 5467.507625380943,
    "total_throughput": 11631.584116566413,
    "itl": 150.18763497688474,
    "ttft": 1526815.805219871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5279018020443709,
    "arrivals": 196873,
    "finished_requests": 89802,
    "scheduler_time": 159.42846590322915
}
#Debug simulation 
Total elapsed time: 91.44837283389643. Arrivals time: 0.44565201131626964 Scheduler time: 90.83913760120049 Scheduler overhead time: 0.06328771216794848 Adapter cache time: 0.017357105389237404 Engine time: 0.06070670345798135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 94.96924529178068,
    "estimated_duration": 3600.1087764354893,
    "input_throughput": 6161.056895053363,
    "output_throughput": 5469.204744278599,
    "total_throughput": 11630.261639331962,
    "itl": 150.2553666272672,
    "ttft": 1519792.0915634157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4469083702610768,
    "arrivals": 196873,
    "finished_requests": 89798,
    "scheduler_time": 159.39670759345483
}
#Debug simulation 
Total elapsed time: 94.9694265536964. Arrivals time: 0.451544638723135 Scheduler time: 94.35194382723421 Scheduler overhead time: 0.06458205077797174 Adapter cache time: 0.01715408032760024 Engine time: 0.06168660009279847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 92.1966306688264,
    "estimated_duration": 3600.166031592061,
    "input_throughput": 6164.01460523378,
    "output_throughput": 5468.325856986683,
    "total_throughput": 11632.340462220462,
    "itl": 150.10756306767232,
    "ttft": 1526268.2933214484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5263545181602294,
    "arrivals": 196873,
    "finished_requests": 89798,
    "scheduler_time": 159.44796836801174
}
#Debug simulation 
Total elapsed time: 92.19680778402835. Arrivals time: 0.458224905654788 Scheduler time: 91.57224084855989 Scheduler overhead time: 0.06547085754573345 Adapter cache time: 0.017066108994185925 Engine time: 0.060911915730684996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.89493181509897,
    "estimated_duration": 3600.081484255086,
    "input_throughput": 6164.822406677349,
    "output_throughput": 5465.25740765869,
    "total_throughput": 11630.079814336039,
    "itl": 149.99395975840744,
    "ttft": 1528749.1476189995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3873833368345971,
    "arrivals": 196873,
    "finished_requests": 89805,
    "scheduler_time": 159.48975269568334
}
#Debug simulation 
Total elapsed time: 89.89511186629534. Arrivals time: 0.44561664341017604 Scheduler time: 89.28414294263348 Scheduler overhead time: 0.06517231231555343 Adapter cache time: 0.01701639825478196 Engine time: 0.06043389858677983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.57888253685087,
    "estimated_duration": 3600.155214818797,
    "input_throughput": 6163.141219209011,
    "output_throughput": 5467.300109445612,
    "total_throughput": 11630.441328654622,
    "itl": 150.08068784319,
    "ttft": 1526428.4039292354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.545469093695283,
    "arrivals": 196873,
    "finished_requests": 89821,
    "scheduler_time": 159.44126245150952
}
#Debug simulation 
Total elapsed time: 91.57905968697742. Arrivals time: 0.44231961807236075 Scheduler time: 90.97191605577245 Scheduler overhead time: 0.06401518220081925 Adapter cache time: 0.017139133531600237 Engine time: 0.060879320837557316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.02057008398697,
    "estimated_duration": 3600.0395664089315,
    "input_throughput": 6144.598855635822,
    "output_throughput": 5448.023455910021,
    "total_throughput": 11592.622311545843,
    "itl": 149.48142062008938,
    "ttft": 1528547.3435834898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3435541195864895,
    "arrivals": 194481,
    "finished_requests": 89340,
    "scheduler_time": 160.34676831506022
}
#Debug simulation 
Total elapsed time: 87.02075085882097. Arrivals time: 0.4383382727392018 Scheduler time: 86.41892301570624 Scheduler overhead time: 0.06377529446035624 Adapter cache time: 0.016372946556657553 Engine time: 0.060532398987561464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.3430578247644,
    "estimated_duration": 3600.0201079080985,
    "input_throughput": 6145.518451799931,
    "output_throughput": 5443.5026507080465,
    "total_throughput": 11589.021102507977,
    "itl": 149.1359278231822,
    "ttft": 1532262.4744945162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4165830656536909,
    "arrivals": 194481,
    "finished_requests": 89345,
    "scheduler_time": 160.64410014287384
}
#Debug simulation 
Total elapsed time: 84.34332737792283. Arrivals time: 0.43410254968330264 Scheduler time: 83.74776311824098 Scheduler overhead time: 0.06321475515142083 Adapter cache time: 0.01626127678900957 Engine time: 0.05917714349925518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.16747615113854,
    "estimated_duration": 3600.0212651445777,
    "input_throughput": 6145.516476306563,
    "output_throughput": 5443.500900879537,
    "total_throughput": 11589.017377186101,
    "itl": 149.1359608467563,
    "ttft": 1532262.530514393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.419026201274254,
    "arrivals": 194481,
    "finished_requests": 89345,
    "scheduler_time": 160.64406738510806
}
#Debug simulation 
Total elapsed time: 84.16764685884118. Arrivals time: 0.4446604526601732 Scheduler time: 83.56158313248307 Scheduler overhead time: 0.0629161256365478 Adapter cache time: 0.016421561129391193 Engine time: 0.05992707656696439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 87.49829885922372,
    "estimated_duration": 3600.149691747962,
    "input_throughput": 6143.13428430306,
    "output_throughput": 5448.621773967408,
    "total_throughput": 11591.756058270468,
    "itl": 149.50874821079674,
    "ttft": 1527510.8885677988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3675326813198598,
    "arrivals": 194481,
    "finished_requests": 89351,
    "scheduler_time": 160.3507626798003
}
#Debug simulation 
Total elapsed time: 87.49847311386839. Arrivals time: 0.4422108232975006 Scheduler time: 86.8921162080951 Scheduler overhead time: 0.06343103339895606 Adapter cache time: 0.016987559385597706 Engine time: 0.060671677347272635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 86.91987965675071,
    "estimated_duration": 3600.1252689833364,
    "input_throughput": 6144.452580742237,
    "output_throughput": 5447.8937633019295,
    "total_throughput": 11592.346344044166,
    "itl": 149.48536415057697,
    "ttft": 1528576.8616203228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4538270845264243,
    "arrivals": 194481,
    "finished_requests": 89340,
    "scheduler_time": 160.34687262881883
}
#Debug simulation 
Total elapsed time: 86.92006250005215. Arrivals time: 0.4397370992228389 Scheduler time: 86.31818487355486 Scheduler overhead time: 0.06289550242945552 Adapter cache time: 0.016470973379909992 Engine time: 0.05994615517556667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.06093191215768,
    "estimated_duration": 3600.093964098512,
    "input_throughput": 6145.522650417853,
    "output_throughput": 5443.565138974729,
    "total_throughput": 11589.08778939258,
    "itl": 149.13230866374124,
    "ttft": 1532266.7819458318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297681827987535,
    "arrivals": 194481,
    "finished_requests": 89348,
    "scheduler_time": 160.6517668618457
}
#Debug simulation 
Total elapsed time: 84.06109000509605. Arrivals time: 0.4159568934701383 Scheduler time: 83.48256897134706 Scheduler overhead time: 0.06421715673059225 Adapter cache time: 0.01607137732207775 Engine time: 0.059286304749548435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.09261605888605,
    "estimated_duration": 3600.0489566099477,
    "input_throughput": 6143.1711808790715,
    "output_throughput": 5448.543682714484,
    "total_throughput": 11591.714863593555,
    "itl": 149.51225118376234,
    "ttft": 1527516.1863331948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.465677112229169,
    "arrivals": 194481,
    "finished_requests": 89349,
    "scheduler_time": 160.34225867283627
}
#Debug simulation 
Total elapsed time: 87.09277496580034. Arrivals time: 0.4100955268368125 Scheduler time: 86.52082999655977 Scheduler overhead time: 0.06339707877486944 Adapter cache time: 0.015579008962959051 Engine time: 0.0604957640171051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 91.52547163376585,
    "estimated_duration": 3600.088271501944,
    "input_throughput": 6172.738645302409,
    "output_throughput": 5425.821404054273,
    "total_throughput": 11598.560049356684,
    "itl": 147.30100133886185,
    "ttft": 1527296.152225413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.444550215136274,
    "arrivals": 193337,
    "finished_requests": 89365,
    "scheduler_time": 160.2944040917223
}
#Debug simulation 
Total elapsed time: 91.52563235582784. Arrivals time: 0.4188713589683175 Scheduler time: 90.94186380831525 Scheduler overhead time: 0.06447299895808101 Adapter cache time: 0.016273934859782457 Engine time: 0.060754310339689255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.81465619103983,
    "estimated_duration": 3600.154994358135,
    "input_throughput": 6172.624243907586,
    "output_throughput": 5425.720845522258,
    "total_throughput": 11598.345089429844,
    "itl": 147.30470913836515,
    "ttft": 1527317.7300878766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5391940738656615,
    "arrivals": 193337,
    "finished_requests": 89365,
    "scheduler_time": 160.2939684712081
}
#Debug simulation 
Total elapsed time: 90.81481417827308. Arrivals time: 0.40778989251703024 Scheduler time: 90.24277888797224 Scheduler overhead time: 0.06397570203989744 Adapter cache time: 0.016604671720415354 Engine time: 0.060386406257748604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.62982535874471,
    "estimated_duration": 3600.1570753637434,
    "input_throughput": 6172.62067593391,
    "output_throughput": 5425.717709282568,
    "total_throughput": 11598.338385216479,
    "itl": 147.30468418434816,
    "ttft": 1527318.440574353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5420993624068888,
    "arrivals": 193337,
    "finished_requests": 89365,
    "scheduler_time": 160.29397961585218
}
#Debug simulation 
Total elapsed time: 89.62997482297942. Arrivals time: 0.3451991369947791 Scheduler time: 89.13088605785742 Scheduler overhead time: 0.060731344390660524 Adapter cache time: 0.014918314293026924 Engine time: 0.05635191034525633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 84.1600919989869,
    "estimated_duration": 3600.1688147928458,
    "input_throughput": 6169.960672046467,
    "output_throughput": 5422.557108929156,
    "total_throughput": 11592.517780975624,
    "itl": 146.82923346250004,
    "ttft": 1538848.8441388467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4251608275598802,
    "arrivals": 193337,
    "finished_requests": 89372,
    "scheduler_time": 160.52672243719735
}
#Debug simulation 
Total elapsed time: 84.16028853179887. Arrivals time: 0.3504727720282972 Scheduler time: 83.65756116388366 Scheduler overhead time: 0.06004142062738538 Adapter cache time: 0.014906613156199455 Engine time: 0.05584529135376215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 89.84878105297685,
    "estimated_duration": 3600.002573539597,
    "input_throughput": 6172.499476341162,
    "output_throughput": 5425.866398977215,
    "total_throughput": 11598.365875318377,
    "itl": 147.3056496057996,
    "ttft": 1527328.6863741635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5619684606604316,
    "arrivals": 193337,
    "finished_requests": 89360,
    "scheduler_time": 160.2863654762137
}
#Debug simulation 
Total elapsed time: 89.84893288789317. Arrivals time: 0.35696280701085925 Scheduler time: 89.33653586031869 Scheduler overhead time: 0.06070397607982159 Adapter cache time: 0.01562843006104231 Engine time: 0.05717361252754927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.97747018421069,
    "estimated_duration": 3600.00168665265,
    "input_throughput": 6165.428222517819,
    "output_throughput": 5421.729404284926,
    "total_throughput": 11587.157626802746,
    "itl": 146.88764908233816,
    "ttft": 1537783.6984151558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3664529847702827,
    "arrivals": 193337,
    "finished_requests": 89327,
    "scheduler_time": 160.50466429509777
}
#Debug simulation 
Total elapsed time: 84.97762431390584. Arrivals time: 0.3600021074526012 Scheduler time: 84.46524905739352 Scheduler overhead time: 0.060182570945471525 Adapter cache time: 0.014827611856162548 Engine time: 0.055736138951033354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.94870283687487,
    "estimated_duration": 3600.074327315688,
    "input_throughput": 6170.078165181221,
    "output_throughput": 5422.391102284654,
    "total_throughput": 11592.469267465876,
    "itl": 146.8345726770108,
    "ttft": 1538784.1746960233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.527207980602979,
    "arrivals": 193337,
    "finished_requests": 89368,
    "scheduler_time": 160.51856992764593
}
#Debug simulation 
Total elapsed time: 84.94884892180562. Arrivals time: 0.3669856102205813 Scheduler time: 84.4274724079296 Scheduler overhead time: 0.06163269421085715 Adapter cache time: 0.015090878587216139 Engine time: 0.05578819662332535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.35760237416252,
    "estimated_duration": 3600.112485087989,
    "input_throughput": 6104.502037375332,
    "output_throughput": 5446.745089555374,
    "total_throughput": 11551.247126930706,
    "itl": 148.13397839138815,
    "ttft": 1506272.3605356487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5057599700149311,
    "arrivals": 182454,
    "finished_requests": 89239,
    "scheduler_time": 158.39844482780816
}
#Debug simulation 
Total elapsed time: 78.35775059089065. Arrivals time: 0.35343312844634056 Scheduler time: 77.85707810986787 Scheduler overhead time: 0.057647709269076586 Adapter cache time: 0.01474148454144597 Engine time: 0.05354310804978013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.13448461191729,
    "estimated_duration": 3600.0183882814026,
    "input_throughput": 6106.433809215764,
    "output_throughput": 5447.9771725174105,
    "total_throughput": 11554.410981733174,
    "itl": 148.10423827506136,
    "ttft": 1508177.9300560893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6105656317458545,
    "arrivals": 182454,
    "finished_requests": 89265,
    "scheduler_time": 158.42538640618488
}
#Debug simulation 
Total elapsed time: 77.13463662099093. Arrivals time: 0.3612359552644193 Scheduler time: 76.62198478216305 Scheduler overhead time: 0.05943985702469945 Adapter cache time: 0.01583832409232855 Engine time: 0.05453636683523655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.93961250502616,
    "estimated_duration": 3600.0210693734343,
    "input_throughput": 6106.429261489317,
    "output_throughput": 5447.973115172215,
    "total_throughput": 11554.402376661532,
    "itl": 148.1043088643581,
    "ttft": 1508178.9447374213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6130954556167223,
    "arrivals": 182454,
    "finished_requests": 89265,
    "scheduler_time": 158.42539843638824
}
#Debug simulation 
Total elapsed time: 76.93976256204769. Arrivals time: 0.3528928719460964 Scheduler time: 76.43789826706052 Scheduler overhead time: 0.05803138390183449 Adapter cache time: 0.015579193364828825 Engine time: 0.05415713461115956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.2247781069018,
    "estimated_duration": 3600.017346546725,
    "input_throughput": 6107.61890386203,
    "output_throughput": 5448.336802825299,
    "total_throughput": 11555.955706687328,
    "itl": 148.19818062484313,
    "ttft": 1506189.7903062252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5252071024337732,
    "arrivals": 182454,
    "finished_requests": 89341,
    "scheduler_time": 158.328475382873
}
#Debug simulation 
Total elapsed time: 78.22492294991389. Arrivals time: 0.35862692492082715 Scheduler time: 77.7182409260422 Scheduler overhead time: 0.05801584990695119 Adapter cache time: 0.014885359909385443 Engine time: 0.0539693608880043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.75043403403834,
    "estimated_duration": 3600.1228503536054,
    "input_throughput": 6106.692164085634,
    "output_throughput": 5447.961587775698,
    "total_throughput": 11554.653751861333,
    "itl": 148.1016369467405,
    "ttft": 1508174.469386807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6335933228023396,
    "arrivals": 182454,
    "finished_requests": 89263,
    "scheduler_time": 158.43156810104986
}
#Debug simulation 
Total elapsed time: 76.75056833028793. Arrivals time: 0.35498833283782005 Scheduler time: 76.24754632730037 Scheduler overhead time: 0.05799501994624734 Adapter cache time: 0.01514514209702611 Engine time: 0.05373380472883582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.58486028201878,
    "estimated_duration": 3600.145391668162,
    "input_throughput": 6108.38330332271,
    "output_throughput": 5452.821723653724,
    "total_throughput": 11561.205026976435,
    "itl": 148.68841764537925,
    "ttft": 1504340.3636840745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.471104745091855,
    "arrivals": 182454,
    "finished_requests": 89365,
    "scheduler_time": 158.0476016832428
}
#Debug simulation 
Total elapsed time: 76.58503222092986. Arrivals time: 0.35918587911874056 Scheduler time: 76.07838046457618 Scheduler overhead time: 0.057610309682786465 Adapter cache time: 0.014964362140744925 Engine time: 0.053618515376001596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.90190101228654,
    "estimated_duration": 3600.143618767323,
    "input_throughput": 6106.656935960665,
    "output_throughput": 5447.930159718333,
    "total_throughput": 11554.587095678999,
    "itl": 148.1016442953111,
    "ttft": 1508182.501004456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6550972202792749,
    "arrivals": 182454,
    "finished_requests": 89263,
    "scheduler_time": 158.43218715973074
}
#Debug simulation 
Total elapsed time: 76.90203604707494. Arrivals time: 0.3580056894570589 Scheduler time: 76.3949034716934 Scheduler overhead time: 0.0588766117580235 Adapter cache time: 0.015272432006895542 Engine time: 0.05373883433640003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.36275974055752,
    "estimated_duration": 3600.1334757876443,
    "input_throughput": 6210.485847363852,
    "output_throughput": 5455.641612205196,
    "total_throughput": 11666.127459569048,
    "itl": 148.81238563691116,
    "ttft": 1485512.9281599014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965785067831325,
    "arrivals": 177727,
    "finished_requests": 89918,
    "scheduler_time": 157.96321489134624
}
#Debug simulation 
Total elapsed time: 75.36288882279769. Arrivals time: 0.35159307392314076 Scheduler time: 74.8658075989224 Scheduler overhead time: 0.05702489800751209 Adapter cache time: 0.014618700370192528 Engine time: 0.05284116882830858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.86344683496282,
    "estimated_duration": 3600.0337718130145,
    "input_throughput": 6197.932967935203,
    "output_throughput": 5437.133160598768,
    "total_throughput": 11635.066128533972,
    "itl": 147.66698991978967,
    "ttft": 1487278.362565615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.623881501946604,
    "arrivals": 177727,
    "finished_requests": 89656,
    "scheduler_time": 158.8484588688267
}
#Debug simulation 
Total elapsed time: 75.86357694631442. Arrivals time: 0.3537281737662852 Scheduler time: 75.362511085812 Scheduler overhead time: 0.05713276797905564 Adapter cache time: 0.015291343908756971 Engine time: 0.053528922609984875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 71.33925898838788,
    "estimated_duration": 3600.08408192219,
    "input_throughput": 6224.668504974196,
    "output_throughput": 5468.342836450866,
    "total_throughput": 11693.011341425063,
    "itl": 149.83415571293133,
    "ttft": 1480796.2841644622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6120920045301415,
    "arrivals": 177727,
    "finished_requests": 90127,
    "scheduler_time": 157.1200542482922
}
#Debug simulation 
Total elapsed time: 71.33939839433879. Arrivals time: 0.3530093696899712 Scheduler time: 70.83982323901728 Scheduler overhead time: 0.057489837519824505 Adapter cache time: 0.014678748790174723 Engine time: 0.053512478712946177 
