INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 7.665474869776517,
    "estimated_duration": 3600.0798567831444,
    "input_throughput": 7673.979772405962,
    "output_throughput": 6806.60095742872,
    "total_throughput": 14480.58072983468,
    "itl": 68.03126080378439,
    "ttft": 19044.670802974673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04987462099388
}
#Debug simulation 
Total elapsed time: 7.665605332702398. Arrivals time: 0.23059153510257602 Scheduler time: 7.2436032416298985 Scheduler overhead time: 0.07297228276729584 Adapter cache time: 0.012002370785921812 Engine time: 0.07331305276602507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.714884567074478,
    "estimated_duration": 3600.0804870154166,
    "input_throughput": 7673.978428994411,
    "output_throughput": 6806.59976586103,
    "total_throughput": 14480.578194855441,
    "itl": 68.03107504307168,
    "ttft": 19044.65875824636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04971557677055
}
#Debug simulation 
Total elapsed time: 7.71497275820002. Arrivals time: 0.23188904440030456 Scheduler time: 7.289872229099274 Scheduler overhead time: 0.07331528374925256 Adapter cache time: 0.012068249750882387 Engine time: 0.0745148784480989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.7135418159887195,
    "estimated_duration": 3600.080557481348,
    "input_throughput": 7673.978278788317,
    "output_throughput": 6806.599632632514,
    "total_throughput": 14480.57791142083,
    "itl": 68.03106343523267,
    "ttft": 19044.647003093105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04971537189587
}
#Debug simulation 
Total elapsed time: 7.713642416056246. Arrivals time: 0.23161894408985972 Scheduler time: 7.287630199454725 Scheduler overhead time: 0.07379127759486437 Adapter cache time: 0.012075880542397499 Engine time: 0.07504054717719555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 7.7074654321186244,
    "estimated_duration": 3600.0798938865346,
    "input_throughput": 7673.979693315865,
    "output_throughput": 6806.600887278063,
    "total_throughput": 14480.580580593927,
    "itl": 68.03112023411015,
    "ttft": 19044.62489564594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04980074910131
}
#Debug simulation 
Total elapsed time: 7.70754289906472. Arrivals time: 0.2300424394197762 Scheduler time: 7.283948861528188 Scheduler overhead time: 0.07337201433256269 Adapter cache time: 0.012169905938208103 Engine time: 0.07472328329458833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 7.7053345227614045,
    "estimated_duration": 3600.0806675485956,
    "input_throughput": 7673.978044167556,
    "output_throughput": 6806.599424530597,
    "total_throughput": 14480.577468698153,
    "itl": 68.03105085628864,
    "ttft": 19044.664864426886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.0496952298055
}
#Debug simulation 
Total elapsed time: 7.705412839073688. Arrivals time: 0.23036329308524728 Scheduler time: 7.282797777093947 Scheduler overhead time: 0.07356175221502781 Adapter cache time: 0.011931956745684147 Engine time: 0.07375305937603116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 7.772724552080035,
    "estimated_duration": 3600.069779101371,
    "input_throughput": 7674.001254191267,
    "output_throughput": 6806.620011158958,
    "total_throughput": 14480.621265350226,
    "itl": 68.03118827183005,
    "ttft": 19044.708223743124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04952643970275
}
#Debug simulation 
Total elapsed time: 7.772815702017397. Arrivals time: 0.23396260291337967 Scheduler time: 7.342918294481933 Scheduler overhead time: 0.07458601845428348 Adapter cache time: 0.012048589996993542 Engine time: 0.07568288408219814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 8640, 8640, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 336960 . Total input tokens: 74978038 . Total output tokens: 67356580
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.768389796372503,
    "estimated_duration": 3600.002107702065,
    "input_throughput": 7674.145506996574,
    "output_throughput": 6806.747959278686,
    "total_throughput": 14480.89346627526,
    "itl": 68.03111501677101,
    "ttft": 19012.712304841716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 112207,
    "finished_requests": 111617,
    "scheduler_time": 90.04763387928892
}
#Debug simulation 
Total elapsed time: 7.7684709103778005. Arrivals time: 0.23260222747921944 Scheduler time: 7.342306193429977 Scheduler overhead time: 0.07353065488860011 Adapter cache time: 0.01209063408896327 Engine time: 0.07442308869212866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 7.263036358170211,
    "estimated_duration": 3600.0135578684094,
    "input_throughput": 7237.013578200619,
    "output_throughput": 6358.376053881712,
    "total_throughput": 13595.389632082331,
    "itl": 58.25924279168582,
    "ttft": 14356.576414238963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 105029,
    "finished_requests": 104610,
    "scheduler_time": 81.81597915339538
}
#Debug simulation 
Total elapsed time: 7.263111928012222. Arrivals time: 0.22378855757415295 Scheduler time: 6.8224446340464056 Scheduler overhead time: 0.08288017148151994 Adapter cache time: 0.013573853764683008 Engine time: 0.08306767093017697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.29164584307,
    "estimated_duration": 3600.0404917651613,
    "input_throughput": 7236.95943409392,
    "output_throughput": 6358.328483348954,
    "total_throughput": 13595.287917442874,
    "itl": 58.2593852647446,
    "ttft": 14390.699607048216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 105029,
    "finished_requests": 104610,
    "scheduler_time": 81.81684878712468
}
#Debug simulation 
Total elapsed time: 7.291733853053302. Arrivals time: 0.22664825432002544 Scheduler time: 6.847226868383586 Scheduler overhead time: 0.08295674109831452 Adapter cache time: 0.013725819531828165 Engine time: 0.08317340770736337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.273662485647947,
    "estimated_duration": 3600.048618799728,
    "input_throughput": 7237.024762372903,
    "output_throughput": 6358.448294409943,
    "total_throughput": 13595.473056782846,
    "itl": 58.25953854372673,
    "ttft": 14390.618265003772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 105029,
    "finished_requests": 104611,
    "scheduler_time": 81.81714426298628
}
#Debug simulation 
Total elapsed time: 7.273742757737637. Arrivals time: 0.22302577691152692 Scheduler time: 6.833125735633075 Scheduler overhead time: 0.08233195543289185 Adapter cache time: 0.013670726213604212 Engine time: 0.08403808111324906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 7.270874516107142,
    "estimated_duration": 3600.028237709326,
    "input_throughput": 7236.984067818749,
    "output_throughput": 6358.350126321484,
    "total_throughput": 13595.334194140232,
    "itl": 58.259375922632294,
    "ttft": 14390.68172114293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 105029,
    "finished_requests": 104610,
    "scheduler_time": 81.8164683702938
}
#Debug simulation 
Total elapsed time: 7.270957780070603. Arrivals time: 0.2237161248922348 Scheduler time: 6.832909832242876 Scheduler overhead time: 0.08171554561704397 Adapter cache time: 0.013462482951581478 Engine time: 0.08232893189415336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 7.328622028697282,
    "estimated_duration": 3600.0486191489636,
    "input_throughput": 7237.02476167085,
    "output_throughput": 6358.448293793119,
    "total_throughput": 13595.473055463968,
    "itl": 58.25952268924862,
    "ttft": 14390.606675211637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 105029,
    "finished_requests": 104611,
    "scheduler_time": 81.81712015803771
}
#Debug simulation 
Total elapsed time: 7.328700773883611. Arrivals time: 0.22447619307786226 Scheduler time: 6.888346842490137 Scheduler overhead time: 0.08217807859182358 Adapter cache time: 0.013594429474323988 Engine time: 0.08294043689966202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 7.263150091283023,
    "estimated_duration": 3600.0139117182644,
    "input_throughput": 7237.012866865533,
    "output_throughput": 6358.375428909004,
    "total_throughput": 13595.388295774537,
    "itl": 58.259332759739934,
    "ttft": 14356.58740839032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 105029,
    "finished_requests": 104610,
    "scheduler_time": 81.81605612767297
}
#Debug simulation 
Total elapsed time: 7.263228502124548. Arrivals time: 0.2239335672929883 Scheduler time: 6.823520577978343 Scheduler overhead time: 0.08181370748206973 Adapter cache time: 0.013550193049013615 Engine time: 0.08326075319200754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 4320, 4320, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 315360 . Total input tokens: 70236227 . Total output tokens: 63011505
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 7.28403951600194,
    "estimated_duration": 3600.0489481119307,
    "input_throughput": 7237.024100370636,
    "output_throughput": 6358.447712774902,
    "total_throughput": 13595.47181314554,
    "itl": 58.25956179644221,
    "ttft": 14390.614211258542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 105029,
    "finished_requests": 104611,
    "scheduler_time": 81.81710455245448
}
#Debug simulation 
Total elapsed time: 7.28411944815889. Arrivals time: 0.22596412943676114 Scheduler time: 6.840029101353139 Scheduler overhead time: 0.08296052366495132 Adapter cache time: 0.013446509838104248 Engine time: 0.08425403758883476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.9214949063025415,
    "estimated_duration": 3600.0351641203456,
    "input_throughput": 6862.081028043585,
    "output_throughput": 6051.456168296398,
    "total_throughput": 12913.537196339983,
    "itl": 51.63800345814578,
    "ttft": 13943.096741443824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.8674902922937
}
#Debug simulation 
Total elapsed time: 6.921600520145148. Arrivals time: 0.21661397349089384 Scheduler time: 6.466539112385362 Scheduler overhead time: 0.08981022890657187 Adapter cache time: 0.016226802952587605 Engine time: 0.09151386516168714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.926177662797272,
    "estimated_duration": 3600.034929780256,
    "input_throughput": 6862.081474722775,
    "output_throughput": 6051.456562208904,
    "total_throughput": 12913.538036931679,
    "itl": 51.637978510615916,
    "ttft": 13943.107060701253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.86748620651052
}
#Debug simulation 
Total elapsed time: 6.926265516784042. Arrivals time: 0.21795175084844232 Scheduler time: 6.47193654673174 Scheduler overhead time: 0.08959091268479824 Adapter cache time: 0.01614742586389184 Engine time: 0.09004571242257953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.939497516024858,
    "estimated_duration": 3600.0349301199726,
    "input_throughput": 6862.081474075236,
    "output_throughput": 6051.4565616378595,
    "total_throughput": 12913.538035713094,
    "itl": 51.637993412835925,
    "ttft": 13943.127104968948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.86744175459702
}
#Debug simulation 
Total elapsed time: 6.939569973852485. Arrivals time: 0.21787319285795093 Scheduler time: 6.486696392297745 Scheduler overhead time: 0.08868361078202724 Adapter cache time: 0.016074802726507187 Engine time: 0.08989953203126788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.9871436092071235,
    "estimated_duration": 3600.0351623452875,
    "input_throughput": 6862.08103142705,
    "output_throughput": 6051.456171280171,
    "total_throughput": 12913.53720270722,
    "itl": 51.637978795742235,
    "ttft": 13943.126414687997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.86747411306126
}
#Debug simulation 
Total elapsed time: 6.987231732811779. Arrivals time: 0.2218411946669221 Scheduler time: 6.526527343317866 Scheduler overhead time: 0.09001784166321158 Adapter cache time: 0.016229561530053616 Engine time: 0.09150632889941335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.9699526177719235,
    "estimated_duration": 3600.0349293272584,
    "input_throughput": 6862.08147558624,
    "output_throughput": 6051.4565629703675,
    "total_throughput": 12913.538038556608,
    "itl": 51.637959271495845,
    "ttft": 13943.154659695765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.867417362824
}
#Debug simulation 
Total elapsed time: 6.970059301704168. Arrivals time: 0.21853695949539542 Scheduler time: 6.514409332536161 Scheduler overhead time: 0.0896379416808486 Adapter cache time: 0.0161991436034441 Engine time: 0.0905092447064817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.929381567053497,
    "estimated_duration": 3600.028086249784,
    "input_throughput": 6862.094241529748,
    "output_throughput": 6051.401955225873,
    "total_throughput": 12913.496196755621,
    "itl": 51.637904164702555,
    "ttft": 13979.168941377327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 99759,
    "finished_requests": 99374,
    "scheduler_time": 75.86744526673164
}
#Debug simulation 
Total elapsed time: 6.9294570330530405. Arrivals time: 0.2172072366811335 Scheduler time: 6.478621124755591 Scheduler overhead time: 0.08852002024650574 Adapter cache time: 0.01609189435839653 Engine time: 0.08869172353297472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [5 5 6]
Adapter prompts. [17280, 1080, 1080, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 299160 . Total input tokens: 66623162 . Total output tokens: 59796328
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.947640219237655,
    "estimated_duration": 3600.034831325273,
    "input_throughput": 6862.081662389324,
    "output_throughput": 6051.456727706206,
    "total_throughput": 12913.538390095531,
    "itl": 51.6378813952511,
    "ttft": 13943.208674144013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 99759,
    "finished_requests": 99375,
    "scheduler_time": 75.86746647416922
}
#Debug simulation 
Total elapsed time: 6.9477202403359115. Arrivals time: 0.22180752456188202 Scheduler time: 6.489853959064931 Scheduler overhead time: 0.08916356088593602 Adapter cache time: 0.016226632986217737 Engine time: 0.09021482151001692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.962175338063389,
    "estimated_duration": 3600.037029164525,
    "input_throughput": 6764.346256085994,
    "output_throughput": 6029.36576045091,
    "total_throughput": 12793.712016536903,
    "itl": 49.89235540629578,
    "ttft": 10720.56441141365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.04148633432511
}
#Debug simulation 
Total elapsed time: 6.962277099955827. Arrivals time: 0.21648952411487699 Scheduler time: 6.501035431865603 Scheduler overhead time: 0.09232569113373756 Adapter cache time: 0.01665913686156273 Engine time: 0.09332448057830334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.920538324862719,
    "estimated_duration": 3600.0049872364907,
    "input_throughput": 6764.406462307014,
    "output_throughput": 6029.419424960952,
    "total_throughput": 12793.825887267967,
    "itl": 49.892453024691825,
    "ttft": 10684.106834390828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.04099489029382
}
#Debug simulation 
Total elapsed time: 6.920614471659064. Arrivals time: 0.21615832298994064 Scheduler time: 6.463869019877166 Scheduler overhead time: 0.09117879625409842 Adapter cache time: 0.016457581892609596 Engine time: 0.0913792047649622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.932860545348376,
    "estimated_duration": 3600.0050120521287,
    "input_throughput": 6764.406415678452,
    "output_throughput": 6029.419383398818,
    "total_throughput": 12793.825799077269,
    "itl": 49.892437328946,
    "ttft": 10684.131069899533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.0409910913351
}
#Debug simulation 
Total elapsed time: 6.932932644151151. Arrivals time: 0.21591265639290214 Scheduler time: 6.475889377295971 Scheduler overhead time: 0.09112407686188817 Adapter cache time: 0.016507679596543312 Engine time: 0.09190875524654984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.923810981679708,
    "estimated_duration": 3600.0475624162295,
    "input_throughput": 6764.326464524773,
    "output_throughput": 6029.348119343099,
    "total_throughput": 12793.67458386787,
    "itl": 49.89236957037206,
    "ttft": 10720.542868682649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.04180117375417
}
#Debug simulation 
Total elapsed time: 6.923888256773353. Arrivals time: 0.21676398161798716 Scheduler time: 6.465558172669262 Scheduler overhead time: 0.09182467777282 Adapter cache time: 0.01665640017017722 Engine time: 0.09137890534475446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.951558988075703,
    "estimated_duration": 3600.005011682401,
    "input_throughput": 6764.40641637317,
    "output_throughput": 6029.4193840180515,
    "total_throughput": 12793.825800391221,
    "itl": 49.89244699670673,
    "ttft": 10684.094662774096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.0410073115422
}
#Debug simulation 
Total elapsed time: 6.951659821905196. Arrivals time: 0.21748980693519115 Scheduler time: 6.486235253978521 Scheduler overhead time: 0.09328065905719995 Adapter cache time: 0.016704472713172436 Engine time: 0.09543401841074228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.942519000265747,
    "estimated_duration": 3600.028207719856,
    "input_throughput": 6764.362831318958,
    "output_throughput": 6029.380534700826,
    "total_throughput": 12793.743366019784,
    "itl": 49.89220202605762,
    "ttft": 10720.578210056561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.04127567650792
}
#Debug simulation 
Total elapsed time: 6.942594466265291. Arrivals time: 0.21568866586312652 Scheduler time: 6.48410235112533 Scheduler overhead time: 0.09157486911863089 Adapter cache time: 0.016608681995421648 Engine time: 0.09300664626061916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [5 5 6]
Adapter prompts. [17280, 540, 540, 17280, 34560, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 296460 . Total input tokens: 66027949 . Total output tokens: 59262692
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.9447479587979615,
    "estimated_duration": 3600.0065655963726,
    "input_throughput": 6764.403496571372,
    "output_throughput": 6029.416781467514,
    "total_throughput": 12793.820278038886,
    "itl": 49.892452349036816,
    "ttft": 10684.089433070916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 98818,
    "finished_requests": 98526,
    "scheduler_time": 75.04101135635048
}
#Debug simulation 
Total elapsed time: 6.944825571961701. Arrivals time: 0.21728268405422568 Scheduler time: 6.482956853695214 Scheduler overhead time: 0.09220711281523108 Adapter cache time: 0.01663210429251194 Engine time: 0.09363178070634604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.858068513683975,
    "estimated_duration": 3600.036675833611,
    "input_throughput": 6773.290162204726,
    "output_throughput": 5984.602919360862,
    "total_throughput": 12757.893081565588,
    "itl": 48.31067916717291,
    "ttft": 12081.733559856906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02721047700324
}
#Debug simulation 
Total elapsed time: 6.858143563847989. Arrivals time: 0.21744298841804266 Scheduler time: 6.394132017623633 Scheduler overhead time: 0.09388156374916434 Adapter cache time: 0.016360036097466946 Engine time: 0.09366648178547621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.909126822836697,
    "estimated_duration": 3600.0366815641933,
    "input_throughput": 6773.29015142292,
    "output_throughput": 5984.602909834498,
    "total_throughput": 12757.893061257417,
    "itl": 48.310627842251904,
    "ttft": 12081.762203909857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02714600592398
}
#Debug simulation 
Total elapsed time: 6.909231396857649. Arrivals time: 0.21618501842021942 Scheduler time: 6.445305274799466 Scheduler overhead time: 0.09421306475996971 Adapter cache time: 0.016379820182919502 Engine time: 0.0941229984164238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.924664592836052,
    "estimated_duration": 3600.0366182607277,
    "input_throughput": 6773.290270525247,
    "output_throughput": 5984.603015068456,
    "total_throughput": 12757.893285593704,
    "itl": 48.31062497057192,
    "ttft": 12081.74850250471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02713779338313
}
#Debug simulation 
Total elapsed time: 6.924740764778107. Arrivals time: 0.21640191739425063 Scheduler time: 6.459455025848001 Scheduler overhead time: 0.09390455111861229 Adapter cache time: 0.016485646832734346 Engine time: 0.09555402677506208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.871620059944689,
    "estimated_duration": 3600.0365931741267,
    "input_throughput": 6773.2903177244425,
    "output_throughput": 5984.60305677174,
    "total_throughput": 12757.893374496183,
    "itl": 48.31064584120638,
    "ttft": 12081.73967085216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02716173443214
}
#Debug simulation 
Total elapsed time: 6.871699918061495. Arrivals time: 0.21563214110210538 Scheduler time: 6.409015418030322 Scheduler overhead time: 0.093494588509202 Adapter cache time: 0.016433581709861755 Engine time: 0.09449452627450228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.910876650363207,
    "estimated_duration": 3600.0366182779358,
    "input_throughput": 6773.290270492871,
    "output_throughput": 5984.60301503985,
    "total_throughput": 12757.89328553272,
    "itl": 48.31061174449828,
    "ttft": 12081.747883981068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02713411734942
}
#Debug simulation 
Total elapsed time: 6.910954844206572. Arrivals time: 0.2199169178493321 Scheduler time: 6.445996979717165 Scheduler overhead time: 0.09314462170004845 Adapter cache time: 0.016257308423519135 Engine time: 0.09311465127393603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.903560997918248,
    "estimated_duration": 3600.0248536942095,
    "input_throughput": 6773.31240504575,
    "output_throughput": 5984.622572227953,
    "total_throughput": 12757.934977273702,
    "itl": 48.310648069272624,
    "ttft": 12081.727953594589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02677772351839
}
#Debug simulation 
Total elapsed time: 6.903664778918028. Arrivals time: 0.21581685915589333 Scheduler time: 6.441561140585691 Scheduler overhead time: 0.09359173011034727 Adapter cache time: 0.016454375814646482 Engine time: 0.09345403779298067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [5 5 6]
Adapter prompts. [17280, 270, 270, 17280, 34560, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 295110 . Total input tokens: 65723209 . Total output tokens: 58992592
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.905121472198516,
    "estimated_duration": 3600.0376467587266,
    "input_throughput": 6773.288335457847,
    "output_throughput": 5984.6013053218285,
    "total_throughput": 12757.889640779676,
    "itl": 48.31065302772569,
    "ttft": 12081.70471639528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 98387,
    "finished_requests": 98059,
    "scheduler_time": 74.02720692389434
}
#Debug simulation 
Total elapsed time: 6.905198003165424. Arrivals time: 0.21667307103052735 Scheduler time: 6.4393929350189865 Scheduler overhead time: 0.09383621392771602 Adapter cache time: 0.016398486215621233 Engine time: 0.09624716825783253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.905158368870616,
    "estimated_duration": 3600.0303062663706,
    "input_throughput": 6750.048730895874,
    "output_throughput": 5980.8374286521575,
    "total_throughput": 12730.886159548032,
    "itl": 47.6194184084542,
    "ttft": 10053.301961911999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.7207330945457
}
#Debug simulation 
Total elapsed time: 6.905237417668104. Arrivals time: 0.2162266978994012 Scheduler time: 6.437210915610194 Scheduler overhead time: 0.09483034722507 Adapter cache time: 0.016268442384898663 Engine time: 0.0971304178237915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.868393528275192,
    "estimated_duration": 3600.0414086920186,
    "input_throughput": 6750.027913936943,
    "output_throughput": 5980.818983919076,
    "total_throughput": 12730.84689785602,
    "itl": 47.6196713325632,
    "ttft": 10053.254554868208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72101169460149
}
#Debug simulation 
Total elapsed time: 6.86846624314785. Arrivals time: 0.21480660745874047 Scheduler time: 6.404923642985523 Scheduler overhead time: 0.09454065654426813 Adapter cache time: 0.015995498280972242 Engine time: 0.09500964870676398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.829886506777257,
    "estimated_duration": 3600.0417859373965,
    "input_throughput": 6750.027206607145,
    "output_throughput": 5980.818357194041,
    "total_throughput": 12730.845563801186,
    "itl": 47.61965355088614,
    "ttft": 10053.23318940903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72102387000072
}
#Debug simulation 
Total elapsed time: 6.8299636649899185. Arrivals time: 0.21342687867581844 Scheduler time: 6.368071623612195 Scheduler overhead time: 0.09429428121075034 Adapter cache time: 0.016112687066197395 Engine time: 0.09482131386175752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.855209827888757,
    "estimated_duration": 3600.0410534331304,
    "input_throughput": 6750.028580042517,
    "output_throughput": 5980.819574117652,
    "total_throughput": 12730.848154160169,
    "itl": 47.61965388229531,
    "ttft": 10053.323326401096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72106783021518
}
#Debug simulation 
Total elapsed time: 6.855288226623088. Arrivals time: 0.21394318621605635 Scheduler time: 6.391110051423311 Scheduler overhead time: 0.09485616581514478 Adapter cache time: 0.016203715465962887 Engine time: 0.09590296167880297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.842666058801115,
    "estimated_duration": 3600.042808860604,
    "input_throughput": 6750.025288641207,
    "output_throughput": 5980.81665779261,
    "total_throughput": 12730.841946433817,
    "itl": 47.61966617590853,
    "ttft": 10053.28201375895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72105618749103
}
#Debug simulation 
Total elapsed time: 6.842744507826865. Arrivals time: 0.2151138400658965 Scheduler time: 6.376636676955968 Scheduler overhead time: 0.09516327129676938 Adapter cache time: 0.016171238850802183 Engine time: 0.09662411641329527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.882963635027409,
    "estimated_duration": 3600.030278981715,
    "input_throughput": 6750.048782054542,
    "output_throughput": 5980.837473980968,
    "total_throughput": 12730.88625603551,
    "itl": 47.61943905137753,
    "ttft": 10053.30886996281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72077730060964
}
#Debug simulation 
Total elapsed time: 6.883067714050412. Arrivals time: 0.21508924011141062 Scheduler time: 6.41052347002551 Scheduler overhead time: 0.09932135418057442 Adapter cache time: 0.016283612698316574 Engine time: 0.09793114569038153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [5 5 6]
Adapter prompts. [17280, 135, 135, 17280, 34560, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294435 . Total input tokens: 65549014 . Total output tokens: 58858268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.840938125737011,
    "estimated_duration": 3600.0429776633296,
    "input_throughput": 6750.024972138689,
    "output_throughput": 5980.8163773575825,
    "total_throughput": 12730.841349496272,
    "itl": 47.619638112436746,
    "ttft": 10053.301205414391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 98173,
    "finished_requests": 97901,
    "scheduler_time": 73.72104409404177
}
#Debug simulation 
Total elapsed time: 6.841022215783596. Arrivals time: 0.21437902003526688 Scheduler time: 6.378701616078615 Scheduler overhead time: 0.09408949688076973 Adapter cache time: 0.016178053338080645 Engine time: 0.09459167346358299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.861324220895767,
    "estimated_duration": 3600.0187922201385,
    "input_throughput": 6749.528933712902,
    "output_throughput": 5949.658664640174,
    "total_throughput": 12699.187598353075,
    "itl": 46.84372808693745,
    "ttft": 11198.041044683456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.0743781642302
}
#Debug simulation 
Total elapsed time: 6.861404015216976. Arrivals time: 0.21632967051118612 Scheduler time: 6.390012104529887 Scheduler overhead time: 0.09656453039497137 Adapter cache time: 0.016163780353963375 Engine time: 0.0983308176510036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.861583204008639,
    "estimated_duration": 3600.0275005225058,
    "input_throughput": 6749.512606910181,
    "output_throughput": 5949.64427268716,
    "total_throughput": 12699.156879597342,
    "itl": 46.84380044476088,
    "ttft": 11198.023120526956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.07453215376056
}
#Debug simulation 
Total elapsed time: 6.861665280070156. Arrivals time: 0.2176436041481793 Scheduler time: 6.392010726965964 Scheduler overhead time: 0.09593905787914991 Adapter cache time: 0.016103883739560843 Engine time: 0.0961876125074923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.835395434871316,
    "estimated_duration": 3600.027469436952,
    "input_throughput": 6749.512665190941,
    "output_throughput": 5949.64432406121,
    "total_throughput": 12699.156989252151,
    "itl": 46.8437805098998,
    "ttft": 11198.01984720305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.07452798602775
}
#Debug simulation 
Total elapsed time: 6.835497693158686. Arrivals time: 0.21588954282924533 Scheduler time: 6.368134086485952 Scheduler overhead time: 0.09613882657140493 Adapter cache time: 0.01599180744960904 Engine time: 0.09555932926014066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.863879537209868,
    "estimated_duration": 3600.02219356125,
    "input_throughput": 6749.522556682703,
    "output_throughput": 5949.653043336324,
    "total_throughput": 12699.175600019027,
    "itl": 46.843708291274275,
    "ttft": 11198.057277155789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.07441060464423
}
#Debug simulation 
Total elapsed time: 6.863960843067616. Arrivals time: 0.21674801083281636 Scheduler time: 6.393964894115925 Scheduler overhead time: 0.09663208574056625 Adapter cache time: 0.016134648118168116 Engine time: 0.09640735015273094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.846773990895599,
    "estimated_duration": 3600.029149164551,
    "input_throughput": 6749.509515954578,
    "output_throughput": 5949.641548033193,
    "total_throughput": 12699.15106398777,
    "itl": 46.843810814466046,
    "ttft": 11197.995104990641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.07456835215821
}
#Debug simulation 
Total elapsed time: 6.846847916953266. Arrivals time: 0.21611990546807647 Scheduler time: 6.37944115139544 Scheduler overhead time: 0.09515480790287256 Adapter cache time: 0.01589877950027585 Engine time: 0.09657147899270058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.880319288000464,
    "estimated_duration": 3600.018406545834,
    "input_throughput": 6749.5296567980595,
    "output_throughput": 5949.659302034267,
    "total_throughput": 12699.188958832327,
    "itl": 46.843822609067345,
    "ttft": 11198.022550522297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.07441023587025
}
#Debug simulation 
Total elapsed time: 6.880394196603447. Arrivals time: 0.21688585076481104 Scheduler time: 6.411403525620699 Scheduler overhead time: 0.09538779919967055 Adapter cache time: 0.01603798009455204 Engine time: 0.09719852078706026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [5 5 6]
Adapter prompts. [17280, 66, 66, 17280, 34560, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 294090 . Total input tokens: 65477184 . Total output tokens: 58785869
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.839346112683415,
    "estimated_duration": 3600.030485516739,
    "input_throughput": 6749.507010497514,
    "output_throughput": 5949.639339491757,
    "total_throughput": 12699.14634998927,
    "itl": 46.84378805508957,
    "ttft": 11198.017659751575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 98091,
    "finished_requests": 97788,
    "scheduler_time": 73.074592416132
}
#Debug simulation 
Total elapsed time: 6.8394567226059735. Arrivals time: 0.21515523036941886 Scheduler time: 6.37368191126734 Scheduler overhead time: 0.0955103999003768 Adapter cache time: 0.015988664701581 Engine time: 0.09560855478048325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.94859133195132,
    "estimated_duration": 3600.0116026015803,
    "input_throughput": 6682.8334615960885,
    "output_throughput": 5999.599274733326,
    "total_throughput": 12682.432736329414,
    "itl": 47.27432715194363,
    "ttft": 12307.054431099754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 98030,
    "finished_requests": 97697,
    "scheduler_time": 73.93743435654693
}
#Debug simulation 
Total elapsed time: 6.948673136997968. Arrivals time: 0.21704298118129373 Scheduler time: 6.479129469953477 Scheduler overhead time: 0.0958049506880343 Adapter cache time: 0.015842368360608816 Engine time: 0.0973016326315701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.94084622617811,
    "estimated_duration": 3600.017261090637,
    "input_throughput": 6682.835735268517,
    "output_throughput": 5999.641233235801,
    "total_throughput": 12682.476968504317,
    "itl": 47.27442378644232,
    "ttft": 12270.299458517762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 98030,
    "finished_requests": 97698,
    "scheduler_time": 73.93749960614922
}
#Debug simulation 
Total elapsed time: 6.940930601209402. Arrivals time: 0.21747618727385998 Scheduler time: 6.469851306639612 Scheduler overhead time: 0.09659639978781343 Adapter cache time: 0.015805849339812994 Engine time: 0.09727285569533706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.911306103225797,
    "estimated_duration": 3600.017611304497,
    "input_throughput": 6682.835085154558,
    "output_throughput": 5999.640649583791,
    "total_throughput": 12682.47573473835,
    "itl": 47.274428988282594,
    "ttft": 12270.314248044431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 98030,
    "finished_requests": 97698,
    "scheduler_time": 73.93751169959847
}
#Debug simulation 
Total elapsed time: 6.911408638115972. Arrivals time: 0.21622765390202403 Scheduler time: 6.4417737810872495 Scheduler overhead time: 0.09609041921794415 Adapter cache time: 0.015930422116070986 Engine time: 0.0978416339494288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.940865232143551,
    "estimated_duration": 3600.0139381557706,
    "input_throughput": 6682.841903752376,
    "output_throughput": 5999.646771107982,
    "total_throughput": 12682.488674860359,
    "itl": 47.27438554060812,
    "ttft": 12270.299764953781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 98030,
    "finished_requests": 97698,
    "scheduler_time": 73.93746700183564
}
#Debug simulation 
Total elapsed time: 6.940976639278233. Arrivals time: 0.21736522438004613 Scheduler time: 6.473615692462772 Scheduler overhead time: 0.0953086051158607 Adapter cache time: 0.01578262960538268 Engine time: 0.09538801247254014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.933752132114023,
    "estimated_duration": 3600.017635254721,
    "input_throughput": 6682.835040694944,
    "output_throughput": 5999.640609669337,
    "total_throughput": 12682.475650364282,
    "itl": 47.274434294136206,
    "ttft": 12270.33084196359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 98030,
    "finished_requests": 97698,
    "scheduler_time": 73.93748751270003
}
#Debug simulation 
Total elapsed time: 6.933841859921813. Arrivals time: 0.2178341643884778 Scheduler time: 6.461998856626451 Scheduler overhead time: 0.09641822101548314 Adapter cache time: 0.01603640429675579 Engine time: 0.09769247099757195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.921180327422917,
    "estimated_duration": 3600.0107514812084,
    "input_throughput": 6682.835041562397,
    "output_throughput": 5999.600693168302,
    "total_throughput": 12682.4357347307,
    "itl": 47.274338617613694,
    "ttft": 12307.029546181095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 98030,
    "finished_requests": 97697,
    "scheduler_time": 73.93743427459718
}
#Debug simulation 
Total elapsed time: 6.9212827743031085. Arrivals time: 0.21667890343815088 Scheduler time: 6.452746049966663 Scheduler overhead time: 0.09579263627529144 Adapter cache time: 0.015877241268754005 Engine time: 0.09667089628055692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [17280, 33, 33, 17280, 34560, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 34560]
Prompts retrieved: 293925 . Total input tokens: 65437245 . Total output tokens: 58752019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.909766727127135,
    "estimated_duration": 3600.0181687055965,
    "input_throughput": 6682.834050432108,
    "output_throughput": 5999.639720642286,
    "total_throughput": 12682.473771074394,
    "itl": 47.2744171171686,
    "ttft": 12270.339162627459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 98030,
    "finished_requests": 97698,
    "scheduler_time": 73.93747550120064
}
#Debug simulation 
Total elapsed time: 6.909856844227761. Arrivals time: 0.21650735847651958 Scheduler time: 6.441756861284375 Scheduler overhead time: 0.09554293891415 Adapter cache time: 0.015753539744764566 Engine time: 0.09694661991670728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.418879130855203,
    "estimated_duration": 3600.003273254013,
    "input_throughput": 6205.558246564324,
    "output_throughput": 5567.214660303409,
    "total_throughput": 11772.772906867733,
    "itl": 46.705569707176956,
    "ttft": 9786.906437080179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38890327721361
}
#Debug simulation 
Total elapsed time: 6.418967711739242. Arrivals time: 0.20286222314462066 Scheduler time: 5.966166172642261 Scheduler overhead time: 0.09474890865385532 Adapter cache time: 0.015727918595075607 Engine time: 0.09602467669174075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.386308286804706,
    "estimated_duration": 3600.0148831683678,
    "input_throughput": 6205.538233869348,
    "output_throughput": 5567.196706242801,
    "total_throughput": 11772.73494011215,
    "itl": 46.70554565168324,
    "ttft": 9787.053489179594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38918195921909
}
#Debug simulation 
Total elapsed time: 6.386389149818569. Arrivals time: 0.20271424017846584 Scheduler time: 5.935606445651501 Scheduler overhead time: 0.09571494488045573 Adapter cache time: 0.015593934804201126 Engine time: 0.0937871839851141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.416912167798728,
    "estimated_duration": 3600.0149019079063,
    "input_throughput": 6205.538201567003,
    "output_throughput": 5567.196677263283,
    "total_throughput": 11772.734878830286,
    "itl": 46.70553897963637,
    "ttft": 9787.042841935034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38916602583653
}
#Debug simulation 
Total elapsed time: 6.4169899257831275. Arrivals time: 0.20334876235574484 Scheduler time: 5.962678491137922 Scheduler overhead time: 0.09499467024579644 Adapter cache time: 0.01583421090617776 Engine time: 0.0966401738114655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 6.438031448982656,
    "estimated_duration": 3600.0088822922935,
    "input_throughput": 6205.548577917692,
    "output_throughput": 5567.205986235881,
    "total_throughput": 11772.754564153573,
    "itl": 46.70554010242927,
    "ttft": 9787.000371269163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38902470340426
}
#Debug simulation 
Total elapsed time: 6.438112400006503. Arrivals time: 0.204494237434119 Scheduler time: 5.981146402191371 Scheduler overhead time: 0.09526374470442533 Adapter cache time: 0.01581437513232231 Engine time: 0.09769143490120769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 6.379924629814923,
    "estimated_duration": 3600.0149003779866,
    "input_throughput": 6205.538204204207,
    "output_throughput": 5567.196679629208,
    "total_throughput": 11772.734883833415,
    "itl": 46.70554998756301,
    "ttft": 9787.052752105516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38914167503843
}
#Debug simulation 
Total elapsed time: 6.380001947749406. Arrivals time: 0.20342534920200706 Scheduler time: 5.926620745100081 Scheduler overhead time: 0.09517008950933814 Adapter cache time: 0.015754491090774536 Engine time: 0.0947054959833622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.426067434251308,
    "estimated_duration": 3600.0019799287516,
    "input_throughput": 6205.560475953443,
    "output_throughput": 5567.216660363241,
    "total_throughput": 11772.777136316685,
    "itl": 46.70553700432038,
    "ttft": 9786.903862892868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38892750508684
}
#Debug simulation 
Total elapsed time: 6.426177586428821. Arrivals time: 0.20447607524693012 Scheduler time: 5.97154772374779 Scheduler overhead time: 0.09463072568178177 Adapter cache time: 0.015867536421865225 Engine time: 0.09613689174875617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 272160 . Total input tokens: 60581643 . Total output tokens: 54459194
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.419103816151619,
    "estimated_duration": 3600.0196142018167,
    "input_throughput": 6205.530078744627,
    "output_throughput": 5567.189390006598,
    "total_throughput": 11772.719468751224,
    "itl": 46.70561736275684,
    "ttft": 9826.540716933228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 90838,
    "finished_requests": 90592,
    "scheduler_time": 67.38925881057254
}
#Debug simulation 
Total elapsed time: 6.41918035922572. Arrivals time: 0.20264822524040937 Scheduler time: 5.962442465592176 Scheduler overhead time: 0.09772834414616227 Adapter cache time: 0.015860962215811014 Engine time: 0.09667460341006517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 6.021584903821349,
    "estimated_duration": 3600.0060055560193,
    "input_throughput": 5885.728236924821,
    "output_throughput": 5216.532686616868,
    "total_throughput": 11102.26092354169,
    "itl": 41.475602951266985,
    "ttft": 9407.904452032622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.575237918393306
}
#Debug simulation 
Total elapsed time: 6.021661920938641. Arrivals time: 0.19450541585683823 Scheduler time: 5.567228265572339 Scheduler overhead time: 0.09885827684774995 Adapter cache time: 0.017848397605121136 Engine time: 0.09767274465411901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.016709638759494,
    "estimated_duration": 3600.0194323606183,
    "input_throughput": 5885.706285231381,
    "output_throughput": 5216.513230787147,
    "total_throughput": 11102.219516018527,
    "itl": 41.475754351714514,
    "ttft": 9407.866124123819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57551263754079
}
#Debug simulation 
Total elapsed time: 6.016792302019894. Arrivals time: 0.19500867277383804 Scheduler time: 5.56168253114447 Scheduler overhead time: 0.09961822675541043 Adapter cache time: 0.01793043315410614 Engine time: 0.09705180069431663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.993754331953824,
    "estimated_duration": 3600.0193576607658,
    "input_throughput": 5885.706407358889,
    "output_throughput": 5216.513339029001,
    "total_throughput": 11102.21974638789,
    "itl": 41.475754453537306,
    "ttft": 9407.8589380219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57552481293983
}
#Debug simulation 
Total elapsed time: 5.993862377014011. Arrivals time: 0.19456046679988503 Scheduler time: 5.537286007776856 Scheduler overhead time: 0.09896986372768879 Adapter cache time: 0.018005835823714733 Engine time: 0.0995146194472909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.947539155837148,
    "estimated_duration": 3600.0125917875644,
    "input_throughput": 5885.717468971102,
    "output_throughput": 5216.523142957989,
    "total_throughput": 11102.24061192909,
    "itl": 41.47566708056677,
    "ttft": 9407.839172592463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57535105009368
}
#Debug simulation 
Total elapsed time: 5.947621875908226. Arrivals time: 0.1931183892302215 Scheduler time: 5.495902804192156 Scheduler overhead time: 0.09819587180390954 Adapter cache time: 0.01785616623237729 Engine time: 0.0973121584393084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.981055472046137,
    "estimated_duration": 3600.0195037059702,
    "input_throughput": 5885.706168588184,
    "output_throughput": 5216.513127406048,
    "total_throughput": 11102.219295994231,
    "itl": 41.4757604433149,
    "ttft": 9407.88759549959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57548436485959
}
#Debug simulation 
Total elapsed time: 5.981131333857775. Arrivals time: 0.19376093242317438 Scheduler time: 5.530318171251565 Scheduler overhead time: 0.09765638271346688 Adapter cache time: 0.017829755321145058 Engine time: 0.09648113511502743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.960370414890349,
    "estimated_duration": 3600.0060525654962,
    "input_throughput": 5885.728160068005,
    "output_throughput": 5216.532618498518,
    "total_throughput": 11102.260778566522,
    "itl": 41.47559693110709,
    "ttft": 9407.895481337335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57523295764946
}
#Debug simulation 
Total elapsed time: 5.960457809269428. Arrivals time: 0.19501445582136512 Scheduler time: 5.506591083016247 Scheduler overhead time: 0.09772496251389384 Adapter cache time: 0.017838811967521906 Engine time: 0.09842349123209715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 255960 . Total input tokens: 56967853 . Total output tokens: 51214622
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 6.012810069601983,
    "estimated_duration": 3600.0235897745897,
    "input_throughput": 5885.699488243269,
    "output_throughput": 5216.507206603014,
    "total_throughput": 11102.206694846283,
    "itl": 41.47570843798469,
    "ttft": 9407.89032345484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 85575,
    "finished_requests": 85353,
    "scheduler_time": 60.57556955167783
}
#Debug simulation 
Total elapsed time: 6.012886436656117. Arrivals time: 0.19325226871296763 Scheduler time: 5.559578608721495 Scheduler overhead time: 0.09801428811624646 Adapter cache time: 0.01785576855763793 Engine time: 0.09884954942390323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.912482985761017,
    "estimated_duration": 3599.9534268240927,
    "input_throughput": 5794.711910593651,
    "output_throughput": 5147.278812533772,
    "total_throughput": 10941.990723127423,
    "itl": 40.057395726421284,
    "ttft": 9336.883138089617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96480256936432
}
#Debug simulation 
Total elapsed time: 5.912561633158475. Arrivals time: 0.19276214949786663 Scheduler time: 5.453274945728481 Scheduler overhead time: 0.10056278528645635 Adapter cache time: 0.017942895647138357 Engine time: 0.10145411919802427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.923419889993966,
    "estimated_duration": 3599.959778403969,
    "input_throughput": 5794.701686708435,
    "output_throughput": 5147.269730945495,
    "total_throughput": 10941.97141765393,
    "itl": 40.05737212040344,
    "ttft": 9336.864130322912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.964822998279566
}
#Debug simulation 
Total elapsed time: 5.923499871976674. Arrivals time: 0.19313226407393813 Scheduler time: 5.468191867228597 Scheduler overhead time: 0.09967630496248603 Adapter cache time: 0.017796387895941734 Engine time: 0.09835787350311875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.893516402691603,
    "estimated_duration": 3599.959785007382,
    "input_throughput": 5794.701676079202,
    "output_throughput": 5147.269721503848,
    "total_throughput": 10941.971397583051,
    "itl": 40.05736818889879,
    "ttft": 9336.862788955927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96481895347153
}
#Debug simulation 
Total elapsed time: 5.89358779694885. Arrivals time: 0.19184810109436512 Scheduler time: 5.438921742141247 Scheduler overhead time: 0.09944140911102295 Adapter cache time: 0.01764294086024165 Engine time: 0.09977421956136823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.894573776051402,
    "estimated_duration": 3599.9534474590614,
    "input_throughput": 5794.711877378305,
    "output_throughput": 5147.278783029519,
    "total_throughput": 10941.990660407824,
    "itl": 40.05735027288945,
    "ttft": 9336.883725537868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96475006880957
}
#Debug simulation 
Total elapsed time: 5.8946758708916605. Arrivals time: 0.19177901512011886 Scheduler time: 5.439339601434767 Scheduler overhead time: 0.099800955504179 Adapter cache time: 0.01780011784285307 Engine time: 0.09994784882292151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.891640279907733,
    "estimated_duration": 3599.959780895669,
    "input_throughput": 5794.7016826976505,
    "output_throughput": 5147.269727382829,
    "total_throughput": 10941.97141008048,
    "itl": 40.057333932299855,
    "ttft": 9336.824661659386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96480297911393
}
#Debug simulation 
Total elapsed time: 5.891717548947781. Arrivals time: 0.19150469079613686 Scheduler time: 5.438128175213933 Scheduler overhead time: 0.0992680205963552 Adapter cache time: 0.017644502222537994 Engine time: 0.0992579534649849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.898095210082829,
    "estimated_duration": 3599.987691485159,
    "input_throughput": 5794.6567565607465,
    "output_throughput": 5147.2298207651775,
    "total_throughput": 10941.886577325924,
    "itl": 40.05727127562627,
    "ttft": 9336.87060381069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96525182988171
}
#Debug simulation 
Total elapsed time: 5.898174833972007. Arrivals time: 0.19480536878108978 Scheduler time: 5.441176327411085 Scheduler overhead time: 0.10022714734077454 Adapter cache time: 0.017728252336382866 Engine time: 0.09791745152324438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 34560, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 253260 . Total input tokens: 56386204 . Total output tokens: 50675276
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.874842816032469,
    "estimated_duration": 3599.9602429967063,
    "input_throughput": 5794.7009388734205,
    "output_throughput": 5147.269066664788,
    "total_throughput": 10941.970005538209,
    "itl": 40.057291273707165,
    "ttft": 9336.82964282514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 84654,
    "finished_requests": 84436,
    "scheduler_time": 58.96483137472025
}
#Debug simulation 
Total elapsed time: 5.874945764429867. Arrivals time: 0.19232818996533751 Scheduler time: 5.421058858279139 Scheduler overhead time: 0.09935830440372229 Adapter cache time: 0.01769257290288806 Engine time: 0.0983513854444027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.960824786685407,
    "estimated_duration": 3599.940543773702,
    "input_throughput": 5769.481953229065,
    "output_throughput": 5176.383824513355,
    "total_throughput": 10945.86577774242,
    "itl": 39.72580919749531,
    "ttft": 9258.821844914755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.24383031602006
}
#Debug simulation 
Total elapsed time: 5.960902297869325. Arrivals time: 0.19812328508123755 Scheduler time: 5.496300016995519 Scheduler overhead time: 0.10198199143633246 Adapter cache time: 0.017294475808739662 Engine time: 0.10045630484819412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.927944694645703,
    "estimated_duration": 3599.946632972142,
    "input_throughput": 5769.4721943286995,
    "output_throughput": 5176.375068820139,
    "total_throughput": 10945.847263148838,
    "itl": 39.72590154873444,
    "ttft": 9258.763023529074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.243890865215675
}
#Debug simulation 
Total elapsed time: 5.928018940612674. Arrivals time: 0.19187181070446968 Scheduler time: 5.470306646544486 Scheduler overhead time: 0.10134733375161886 Adapter cache time: 0.01718338066712022 Engine time: 0.1005399995483458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.944160284008831,
    "estimated_duration": 3599.946293714542,
    "input_throughput": 5769.472738041614,
    "output_throughput": 5176.3755566398,
    "total_throughput": 10945.848294681415,
    "itl": 39.72588287206602,
    "ttft": 9258.762514194923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.24387464500856
}
#Debug simulation 
Total elapsed time: 5.944254391826689. Arrivals time: 0.1931762802414596 Scheduler time: 5.484871627762914 Scheduler overhead time: 0.10180542524904013 Adapter cache time: 0.01748364744707942 Engine time: 0.10018253652378917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.931485914159566,
    "estimated_duration": 3599.941836262438,
    "input_throughput": 5769.479881809366,
    "output_throughput": 5176.381966033943,
    "total_throughput": 10945.861847843309,
    "itl": 39.72577281495883,
    "ttft": 9258.782925182744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.24379407664705
}
#Debug simulation 
Total elapsed time: 5.931564166210592. Arrivals time: 0.19078740384429693 Scheduler time: 5.477915805298835 Scheduler overhead time: 0.1001962055452168 Adapter cache time: 0.017127249855548143 Engine time: 0.09933382598683238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.9439819301478565,
    "estimated_duration": 3599.949366271205,
    "input_throughput": 5769.467813796827,
    "output_throughput": 5176.371138603437,
    "total_throughput": 10945.838952400265,
    "itl": 39.72595564544288,
    "ttft": 9258.675139805291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.24397588813431
}
#Debug simulation 
Total elapsed time: 5.944059261120856. Arrivals time: 0.19132767152041197 Scheduler time: 5.488640606403351 Scheduler overhead time: 0.10028854804113507 Adapter cache time: 0.017231786623597145 Engine time: 0.10039523197337985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.915635315235704,
    "estimated_duration": 3599.9388810560577,
    "input_throughput": 5769.4846180019285,
    "output_throughput": 5176.3862153497,
    "total_throughput": 10945.87083335163,
    "itl": 39.72577949986023,
    "ttft": 9258.835240888247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.2437938307979
}
#Debug simulation 
Total elapsed time: 5.915726168081164. Arrivals time: 0.19281831802800298 Scheduler time: 5.458718623500317 Scheduler overhead time: 0.10052725812420249 Adapter cache time: 0.01715668011456728 Engine time: 0.10033282171934843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 34560, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251910 . Total input tokens: 56075991 . Total output tokens: 50400323
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.944264816585928,
    "estimated_duration": 3599.9114848567665,
    "input_throughput": 5769.528525178832,
    "output_throughput": 5176.425608903947,
    "total_throughput": 10945.95413408278,
    "itl": 39.725933725660596,
    "ttft": 9258.692464147407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 84194,
    "finished_requests": 83979,
    "scheduler_time": 59.24340886297163
}
#Debug simulation 
Total elapsed time: 5.944350572768599. Arrivals time: 0.19233682937920094 Scheduler time: 5.486579157412052 Scheduler overhead time: 0.10124771436676383 Adapter cache time: 0.017315458972007036 Engine time: 0.1004008799791336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.871076988987625,
    "estimated_duration": 3600.0215655363654,
    "input_throughput": 5800.264142831305,
    "output_throughput": 5119.039612545856,
    "total_throughput": 10919.303755377161,
    "itl": 38.841548959363394,
    "ttft": 8723.442040499924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.085983713809114
}
#Debug simulation 
Total elapsed time: 5.871164623182267. Arrivals time: 0.1907113054767251 Scheduler time: 5.4105574931018054 Scheduler overhead time: 0.10306094354018569 Adapter cache time: 0.016960008535534143 Engine time: 0.10269319731742144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.863894251175225,
    "estimated_duration": 3600.027686474895,
    "input_throughput": 5800.254280945963,
    "output_throughput": 5119.030908910904,
    "total_throughput": 10919.285189856868,
    "itl": 38.841590514737526,
    "ttft": 8723.473944396383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.08608091212693
}
#Debug simulation 
Total elapsed time: 5.863973590079695. Arrivals time: 0.18954567424952984 Scheduler time: 5.4084886405617 Scheduler overhead time: 0.10138772940263152 Adapter cache time: 0.016830851323902607 Engine time: 0.10114610427990556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.845248351804912,
    "estimated_duration": 3600.029273732834,
    "input_throughput": 5800.251723605742,
    "output_throughput": 5119.02865192302,
    "total_throughput": 10919.280375528762,
    "itl": 38.8416432466515,
    "ttft": 8723.478562391509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.08612924494865
}
#Debug simulation 
Total elapsed time: 5.845350151881576. Arrivals time: 0.18972376687452197 Scheduler time: 5.38999074138701 Scheduler overhead time: 0.10144675150513649 Adapter cache time: 0.016772810835391283 Engine time: 0.10066914837807417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.872129471972585,
    "estimated_duration": 3600.023871972518,
    "input_throughput": 5800.260426761804,
    "output_throughput": 5119.036332918151,
    "total_throughput": 10919.296759679955,
    "itl": 38.84158300176132,
    "ttft": 8723.48581426671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.086011740640885
}
#Debug simulation 
Total elapsed time: 5.872220626100898. Arrivals time: 0.19048013538122177 Scheduler time: 5.415301153901964 Scheduler overhead time: 0.10162690421566367 Adapter cache time: 0.017015842720866203 Engine time: 0.10089298523962498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.819019420072436,
    "estimated_duration": 3600.029788695458,
    "input_throughput": 5800.250893914595,
    "output_throughput": 5119.027919676739,
    "total_throughput": 10919.278813591332,
    "itl": 38.84164597257087,
    "ttft": 8723.50759613996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.08611711052483
}
#Debug simulation 
Total elapsed time: 5.819095269776881. Arrivals time: 0.1883984487503767 Scheduler time: 5.365347366780043 Scheduler overhead time: 0.10125045012682676 Adapter cache time: 0.01676897332072258 Engine time: 0.10063283191993833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.8696753131225705,
    "estimated_duration": 3600.0215283381813,
    "input_throughput": 5800.264202764084,
    "output_throughput": 5119.0396654397,
    "total_throughput": 10919.303868203784,
    "itl": 38.84151719740884,
    "ttft": 8723.430042380454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.08601603129868
}
#Debug simulation 
Total elapsed time: 5.869768276344985. Arrivals time: 0.19175664195790887 Scheduler time: 5.409458375070244 Scheduler overhead time: 0.10299950139597058 Adapter cache time: 0.016882482916116714 Engine time: 0.10140112088993192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 34560, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 251235 . Total input tokens: 55916619 . Total output tokens: 50269637
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.845665192697197,
    "estimated_duration": 3600.033684714137,
    "input_throughput": 5800.244616782822,
    "output_throughput": 5119.022379776244,
    "total_throughput": 10919.266996559065,
    "itl": 38.84168197170584,
    "ttft": 8723.441249565085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 83981,
    "finished_requests": 83779,
    "scheduler_time": 58.086226074492096
}
#Debug simulation 
Total elapsed time: 5.845741618890315. Arrivals time: 0.1906075468286872 Scheduler time: 5.387755993753672 Scheduler overhead time: 0.10174382291734219 Adapter cache time: 0.016871264670044184 Engine time: 0.1019298555329442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.918072693049908,
    "estimated_duration": 3600.0049003500794,
    "input_throughput": 5724.950818260223,
    "output_throughput": 5157.149924488877,
    "total_throughput": 10882.1007427491,
    "itl": 39.028739593003586,
    "ttft": 10239.574341748548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72661146273759
}
#Debug simulation 
Total elapsed time: 5.918149774894118. Arrivals time: 0.19024868542328477 Scheduler time: 5.461893191095442 Scheduler overhead time: 0.10155479982495308 Adapter cache time: 0.016593536362051964 Engine time: 0.10122166899964213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.851815894711763,
    "estimated_duration": 3600.009220475263,
    "input_throughput": 5724.943948137762,
    "output_throughput": 5157.143735745488,
    "total_throughput": 10882.08768388325,
    "itl": 39.02865999099939,
    "ttft": 10239.601882484716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.726675810892345
}
#Debug simulation 
Total elapsed time: 5.851892039645463. Arrivals time: 0.1903949026018381 Scheduler time: 5.397328894585371 Scheduler overhead time: 0.10232723783701658 Adapter cache time: 0.016260415315628052 Engine time: 0.09906357806175947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.8833379009738564,
    "estimated_duration": 3600.009191921619,
    "input_throughput": 5724.9439935454275,
    "output_throughput": 5157.143776649619,
    "total_throughput": 10882.087770195047,
    "itl": 39.028652769269826,
    "ttft": 10239.587095725876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72667172510941
}
#Debug simulation 
Total elapsed time: 5.883427701890469. Arrivals time: 0.19037305051460862 Scheduler time: 5.431500010192394 Scheduler overhead time: 0.10047157015651464 Adapter cache time: 0.016403345856815577 Engine time: 0.09872808074578643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.863012687768787,
    "estimated_duration": 3600.0071789021154,
    "input_throughput": 5724.947194767909,
    "output_throughput": 5157.146660374703,
    "total_throughput": 10882.093855142612,
    "itl": 39.02867166248481,
    "ttft": 10239.53817266931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72664753821103
}
#Debug simulation 
Total elapsed time: 5.863118523731828. Arrivals time: 0.18928650440648198 Scheduler time: 5.412493030074984 Scheduler overhead time: 0.10063975863158703 Adapter cache time: 0.0162487905472517 Engine time: 0.0981767107732594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.910086501855403,
    "estimated_duration": 3600.009637055087,
    "input_throughput": 5724.943285668385,
    "output_throughput": 5157.143138979855,
    "total_throughput": 10882.08642464824,
    "itl": 39.028677978811714,
    "ttft": 10239.574336631662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72667585186734
}
#Debug simulation 
Total elapsed time: 5.910182950086892. Arrivals time: 0.18938969215378165 Scheduler time: 5.4545812900178134 Scheduler overhead time: 0.10121315252035856 Adapter cache time: 0.016232303343713284 Engine time: 0.10240170080214739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.860648036934435,
    "estimated_duration": 3600.0019063472,
    "input_throughput": 5724.9555795130445,
    "output_throughput": 5157.154213520418,
    "total_throughput": 10882.109793033464,
    "itl": 39.028745927366046,
    "ttft": 10239.564707078609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72654678678375
}
#Debug simulation 
Total elapsed time: 5.86072661774233. Arrivals time: 0.18910900503396988 Scheduler time: 5.408450785558671 Scheduler overhead time: 0.10066339606419206 Adapter cache time: 0.01624628994613886 Engine time: 0.10014302656054497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 34560, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250890 . Total input tokens: 55837478 . Total output tokens: 50199525
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.881427872925997,
    "estimated_duration": 3600.0100168935733,
    "input_throughput": 5724.942681627346,
    "output_throughput": 5157.142594847634,
    "total_throughput": 10882.08527647498,
    "itl": 39.02867702133588,
    "ttft": 10239.594466148257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 83852,
    "finished_requests": 83615,
    "scheduler_time": 58.72665967263536
}
#Debug simulation 
Total elapsed time: 5.881508263759315. Arrivals time: 0.1890755034983158 Scheduler time: 5.429548599757254 Scheduler overhead time: 0.10144503880292177 Adapter cache time: 0.016458801925182343 Engine time: 0.0985384932719171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.823828472755849,
    "estimated_duration": 3600.035452778205,
    "input_throughput": 5775.3939572886065,
    "output_throughput": 5114.341022889458,
    "total_throughput": 10889.734980178066,
    "itl": 38.51842495542334,
    "ttft": 9987.529925438514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 83799,
    "finished_requests": 83568,
    "scheduler_time": 57.90686198398706
}
#Debug simulation 
Total elapsed time: 5.823904024902731. Arrivals time: 0.18792366422712803 Scheduler time: 5.370394601020962 Scheduler overhead time: 0.10264157736673951 Adapter cache time: 0.016119354870170355 Engine time: 0.10001290123909712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.846998422872275,
    "estimated_duration": 3600.000756266835,
    "input_throughput": 5775.390175628875,
    "output_throughput": 5114.286147843056,
    "total_throughput": 10889.676323471931,
    "itl": 38.518457219795835,
    "ttft": 9987.62680778446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 83799,
    "finished_requests": 83567,
    "scheduler_time": 57.9063517500371
}
#Debug simulation 
Total elapsed time: 5.847075060941279. Arrivals time: 0.18853552779182792 Scheduler time: 5.392413515597582 Scheduler overhead time: 0.10142017574980855 Adapter cache time: 0.01686779223382473 Engine time: 0.10138952685520053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.8244917858392,
    "estimated_duration": 3600.0014212217934,
    "input_throughput": 5775.389108858648,
    "output_throughput": 5114.285203185114,
    "total_throughput": 10889.674312043762,
    "itl": 38.51848704015236,
    "ttft": 9987.62367504435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 83799,
    "finished_requests": 83567,
    "scheduler_time": 57.90637601888531
}
#Debug simulation 
Total elapsed time: 5.824563066009432. Arrivals time: 0.18842103192582726 Scheduler time: 5.370560723822564 Scheduler overhead time: 0.10209409845992923 Adapter cache time: 0.016219105571508408 Engine time: 0.10063431458547711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.849903841037303,
    "estimated_duration": 3600.03863027054,
    "input_throughput": 5775.388859768298,
    "output_throughput": 5114.336508832508,
    "total_throughput": 10889.725368600806,
    "itl": 38.518395022441695,
    "ttft": 9987.466397535778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 83799,
    "finished_requests": 83568,
    "scheduler_time": 57.90691060363343
}
#Debug simulation 
Total elapsed time: 5.849995241034776. Arrivals time: 0.191433884203434 Scheduler time: 5.3947602193802595 Scheduler overhead time: 0.10152774723246694 Adapter cache time: 0.01626563724130392 Engine time: 0.09942897316068411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.814988672267646,
    "estimated_duration": 3600.002259831775,
    "input_throughput": 5775.387763498672,
    "output_throughput": 5114.284011827356,
    "total_throughput": 10889.67177532603,
    "itl": 38.51849036981655,
    "ttft": 9987.629649406541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 83799,
    "finished_requests": 83567,
    "scheduler_time": 57.90638414947605
}
#Debug simulation 
Total elapsed time: 5.815088412258774. Arrivals time: 0.18884096154943109 Scheduler time: 5.3614919343963265 Scheduler overhead time: 0.10133568476885557 Adapter cache time: 0.01619029277935624 Engine time: 0.1007771729491651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.863319368567318,
    "estimated_duration": 3600.033852370943,
    "input_throughput": 5775.396524759583,
    "output_throughput": 5114.343296487111,
    "total_throughput": 10889.739821246694,
    "itl": 38.51844955890126,
    "ttft": 9944.665366482293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 83799,
    "finished_requests": 83568,
    "scheduler_time": 57.90683371130532
}
#Debug simulation 
Total elapsed time: 5.8633974408730865. Arrivals time: 0.19009639462456107 Scheduler time: 5.405877336394042 Scheduler overhead time: 0.1013928996399045 Adapter cache time: 0.01634086761623621 Engine time: 0.10318108275532722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 34560, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 34560]
Prompts retrieved: 250725 . Total input tokens: 55803005 . Total output tokens: 50167739
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.802191709168255,
    "estimated_duration": 3600.0022890348696,
    "input_throughput": 5775.387716648926,
    "output_throughput": 5114.283970340461,
    "total_throughput": 10889.671686989386,
    "itl": 38.51843631312883,
    "ttft": 9987.60946962158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 83799,
    "finished_requests": 83567,
    "scheduler_time": 57.90635175003673
}
#Debug simulation 
Total elapsed time: 5.802287673112005. Arrivals time: 0.1892368495464325 Scheduler time: 5.349736954085529 Scheduler overhead time: 0.10093304142355919 Adapter cache time: 0.016152976546436548 Engine time: 0.0997844785451889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.545677605085075,
    "estimated_duration": 3599.962094074105,
    "input_throughput": 5358.620867634863,
    "output_throughput": 4823.395509797988,
    "total_throughput": 10182.01637743285,
    "itl": 38.074499559057195,
    "ttft": 8011.005628672115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.378431626746845
}
#Debug simulation 
Total elapsed time: 5.545755449682474. Arrivals time: 0.18005111161619425 Scheduler time: 5.099432119168341 Scheduler overhead time: 0.10136246448382735 Adapter cache time: 0.01879513869062066 Engine time: 0.09951513819396496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.529185040853918,
    "estimated_duration": 3599.9654715269057,
    "input_throughput": 5358.615840228573,
    "output_throughput": 4823.3909845349535,
    "total_throughput": 10182.006824763526,
    "itl": 38.074456517320144,
    "ttft": 8010.995387906409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.37842370103109
}
#Debug simulation 
Total elapsed time: 5.529259189032018. Arrivals time: 0.180312461219728 Scheduler time: 5.081500798929483 Scheduler overhead time: 0.10124372038990259 Adapter cache time: 0.01873536454513669 Engine time: 0.10011064633727074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.542197124101222,
    "estimated_duration": 3599.9668925059245,
    "input_throughput": 5358.613725075599,
    "output_throughput": 4823.389080645948,
    "total_throughput": 10182.002805721546,
    "itl": 38.074495411980614,
    "ttft": 8011.02487655019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.37845610046989
}
#Debug simulation 
Total elapsed time: 5.542271338868886. Arrivals time: 0.1816688454709947 Scheduler time: 5.0921311979182065 Scheduler overhead time: 0.10181844141334295 Adapter cache time: 0.018701606895774603 Engine time: 0.1013719323091209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.5041353311389685,
    "estimated_duration": 3599.963231416984,
    "input_throughput": 5358.619174676104,
    "output_throughput": 4823.393985933942,
    "total_throughput": 10182.013160610046,
    "itl": 38.07447537677296,
    "ttft": 8011.036927768073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.37843154479745
}
#Debug simulation 
Total elapsed time: 5.504220366012305. Arrivals time: 0.18026465876027942 Scheduler time: 5.056850424967706 Scheduler overhead time: 0.10154618369415402 Adapter cache time: 0.018686124589294195 Engine time: 0.10036859847605228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.5637139501050115,
    "estimated_duration": 3599.9718943875328,
    "input_throughput": 5358.606279697628,
    "output_throughput": 4823.38237892109,
    "total_throughput": 10181.988658618719,
    "itl": 38.074586398953805,
    "ttft": 8011.08923775182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.37856939607032
}
#Debug simulation 
Total elapsed time: 5.5637983889319. Arrivals time: 0.18078646948561072 Scheduler time: 5.1163576492108405 Scheduler overhead time: 0.10168348718434572 Adapter cache time: 0.018748729955404997 Engine time: 0.09960351418703794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.51549366582185,
    "estimated_duration": 3599.951187247722,
    "input_throughput": 5358.63710272929,
    "output_throughput": 4823.410123312079,
    "total_throughput": 10182.04722604137,
    "itl": 38.07441680716961,
    "ttft": 8011.06420132855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 78358,
    "finished_requests": 78185,
    "scheduler_time": 53.37823755791075
}
#Debug simulation 
Total elapsed time: 5.515569475013763. Arrivals time: 0.17910904670134187 Scheduler time: 5.069730831775814 Scheduler overhead time: 0.10154767101630569 Adapter cache time: 0.018746862187981606 Engine time: 0.09942589048296213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 234360 . Total input tokens: 52144814 . Total output tokens: 46922137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.569027834106237,
    "estimated_duration": 3599.972843857167,
    "input_throughput": 5358.615144255068,
    "output_throughput": 4823.381662344823,
    "total_throughput": 10181.996806599891,
    "itl": 38.074383207440704,
    "ttft": 7965.110722687145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 78358,
    "finished_requests": 78186,
    "scheduler_time": 53.37858140756977
}
#Debug simulation 
Total elapsed time: 5.569114308804274. Arrivals time: 0.18516994267702103 Scheduler time: 5.115548137109727 Scheduler overhead time: 0.10169688798487186 Adapter cache time: 0.018798830453306437 Engine time: 0.10116013325750828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.394858095794916,
    "estimated_duration": 3600.0260163510525,
    "input_throughput": 5343.465272925451,
    "output_throughput": 4719.252561741291,
    "total_throughput": 10062.717834666742,
    "itl": 36.468343788938576,
    "ttft": 8938.17270709477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 77453,
    "finished_requests": 77260,
    "scheduler_time": 51.13897733858273
}
#Debug simulation 
Total elapsed time: 5.394965311978012. Arrivals time: 0.17522186506539583 Scheduler time: 4.9459113413468 Scheduler overhead time: 0.10423001367598772 Adapter cache time: 0.018902013078331947 Engine time: 0.10264536505565047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.438555333763361,
    "estimated_duration": 3600.037349448098,
    "input_throughput": 5343.4487292052845,
    "output_throughput": 4719.311871196169,
    "total_throughput": 10062.760600401452,
    "itl": 36.4684659909189,
    "ttft": 8938.030417069565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 77453,
    "finished_requests": 77261,
    "scheduler_time": 51.13921581835754
}
#Debug simulation 
Total elapsed time: 5.438676473684609. Arrivals time: 0.17902218829840422 Scheduler time: 4.98127023736015 Scheduler overhead time: 0.10517294565215707 Adapter cache time: 0.018623434007167816 Engine time: 0.10600377386435866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.431762696243823,
    "estimated_duration": 3600.0373438017173,
    "input_throughput": 5343.448737586072,
    "output_throughput": 4719.311878598045,
    "total_throughput": 10062.760616184118,
    "itl": 36.46846115883863,
    "ttft": 8938.025251778776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 77453,
    "finished_requests": 77261,
    "scheduler_time": 51.139211773549505
}
#Debug simulation 
Total elapsed time: 5.431874504312873. Arrivals time: 0.17677485290914774 Scheduler time: 4.975194986909628 Scheduler overhead time: 0.10715873772278428 Adapter cache time: 0.02006270457059145 Engine time: 0.10408858675509691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.4398659551516175,
    "estimated_duration": 3600.034340249497,
    "input_throughput": 5343.453195690024,
    "output_throughput": 4719.315815977063,
    "total_throughput": 10062.769011667086,
    "itl": 36.468489460936546,
    "ttft": 8891.618430842957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 77453,
    "finished_requests": 77261,
    "scheduler_time": 51.13915939591955
}
#Debug simulation 
Total elapsed time: 5.439961058087647. Arrivals time: 0.17677765479311347 Scheduler time: 4.98962974967435 Scheduler overhead time: 0.10478136502206326 Adapter cache time: 0.01860320521518588 Engine time: 0.10207861475646496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.427889895159751,
    "estimated_duration": 3600.0371609887084,
    "input_throughput": 5343.449008931032,
    "output_throughput": 4719.312118248795,
    "total_throughput": 10062.761127179827,
    "itl": 36.46847066062853,
    "ttft": 8938.033374987894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 77453,
    "finished_requests": 77261,
    "scheduler_time": 51.139215818357535
}
#Debug simulation 
Total elapsed time: 5.4279642309993505. Arrivals time: 0.18111803056672215 Scheduler time: 4.970751047134399 Scheduler overhead time: 0.10436459118500352 Adapter cache time: 0.018605991266667843 Engine time: 0.1050270814448595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.440294434782118,
    "estimated_duration": 3600.024026824268,
    "input_throughput": 5343.46822595221,
    "output_throughput": 4719.255169801489,
    "total_throughput": 10062.7233957537,
    "itl": 36.46834495687654,
    "ttft": 8938.14053385702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 77453,
    "finished_requests": 77260,
    "scheduler_time": 51.13897337572461
}
#Debug simulation 
Total elapsed time: 5.440365357790142. Arrivals time: 0.1741045443341136 Scheduler time: 4.992812337353826 Scheduler overhead time: 0.10440946510061622 Adapter cache time: 0.018680252134799957 Engine time: 0.10235511558130383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 34560, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 231660 . Total input tokens: 51559505 . Total output tokens: 46383203
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.432458265684545,
    "estimated_duration": 3600.03757470256,
    "input_throughput": 5343.4483948655325,
    "output_throughput": 4719.3115759086795,
    "total_throughput": 10062.759970774212,
    "itl": 36.46847129464106,
    "ttft": 8938.061286897431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 77453,
    "finished_requests": 77261,
    "scheduler_time": 51.13920364295845
}
#Debug simulation 
Total elapsed time: 5.432533364742994. Arrivals time: 0.17575669242069125 Scheduler time: 4.9831923064775765 Scheduler overhead time: 0.10413916129618883 Adapter cache time: 0.01863563060760498 Engine time: 0.1026599439792335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.445755597669631,
    "estimated_duration": 3599.933235157803,
    "input_throughput": 5271.11081246711,
    "output_throughput": 4753.378432933605,
    "total_throughput": 10024.489245400715,
    "itl": 36.29904731877522,
    "ttft": 8659.815581461258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.545875278947605
}
#Debug simulation 
Total elapsed time: 5.445839039981365. Arrivals time: 0.17668229341506958 Scheduler time: 4.994965541642159 Scheduler overhead time: 0.10512241581454873 Adapter cache time: 0.0180366737768054 Engine time: 0.10252445377409458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.468634378165007,
    "estimated_duration": 3599.940173307039,
    "input_throughput": 5271.100653477878,
    "output_throughput": 4753.369271767764,
    "total_throughput": 10024.469925245643,
    "itl": 36.29904935444356,
    "ttft": 8659.786877668113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.54598127794257
}
#Debug simulation 
Total elapsed time: 5.46870901202783. Arrivals time: 0.17677036253735423 Scheduler time: 5.018649318255484 Scheduler overhead time: 0.1049079648219049 Adapter cache time: 0.017992074601352215 Engine time: 0.10202991543337703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.46361395297572,
    "estimated_duration": 3599.939211670015,
    "input_throughput": 5271.1020615254165,
    "output_throughput": 4753.370541515838,
    "total_throughput": 10024.472603041255,
    "itl": 36.29900596666974,
    "ttft": 8659.76633180318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.54595296428637
}
#Debug simulation 
Total elapsed time: 5.463694107718766. Arrivals time: 0.17900868970900774 Scheduler time: 5.009164270479232 Scheduler overhead time: 0.10530765121802688 Adapter cache time: 0.01816018857061863 Engine time: 0.10377908311784267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.473637220915407,
    "estimated_duration": 3599.9401618878305,
    "input_throughput": 5271.1006701981,
    "output_throughput": 4753.369286845714,
    "total_throughput": 10024.469957043813,
    "itl": 36.299044797203564,
    "ttft": 8659.86256759111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.546016888203845
}
#Debug simulation 
Total elapsed time: 5.473724101670086. Arrivals time: 0.1806799010373652 Scheduler time: 5.015797763131559 Scheduler overhead time: 0.10598341561853886 Adapter cache time: 0.018190303817391396 Engine time: 0.10417287843301892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.445606756024063,
    "estimated_duration": 3599.9395579888023,
    "input_throughput": 5271.10155443866,
    "output_throughput": 4753.3700842355165,
    "total_throughput": 10024.471638674177,
    "itl": 36.29901880120602,
    "ttft": 8659.777218417184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.54595300526128
}
#Debug simulation 
Total elapsed time: 5.445713659282774. Arrivals time: 0.1778884967789054 Scheduler time: 4.9918026006780565 Scheduler overhead time: 0.10511216940358281 Adapter cache time: 0.018297075293958187 Engine time: 0.1043839231133461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.434907441958785,
    "estimated_duration": 3599.9331600187616,
    "input_throughput": 5271.110922487545,
    "output_throughput": 4753.378532147753,
    "total_throughput": 10024.489454635299,
    "itl": 36.29911733819462,
    "ttft": 8659.90336237381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.545915727027904
}
#Debug simulation 
Total elapsed time: 5.434980811085552. Arrivals time: 0.1755970031954348 Scheduler time: 4.986073945183307 Scheduler overhead time: 0.10469346540048718 Adapter cache time: 0.018140220548957586 Engine time: 0.10230441531166434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 34560, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 230310 . Total input tokens: 51254613 . Total output tokens: 46107791
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.476549953222275,
    "estimated_duration": 3599.9401227472076,
    "input_throughput": 5271.100727508543,
    "output_throughput": 4753.369338527083,
    "total_throughput": 10024.470066035627,
    "itl": 36.29900399713813,
    "ttft": 8659.778929537673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 77024,
    "finished_requests": 76840,
    "scheduler_time": 51.545953046236285
}
#Debug simulation 
Total elapsed time: 5.476633188314736. Arrivals time: 0.18036319129168987 Scheduler time: 5.019000864587724 Scheduler overhead time: 0.10593093372881413 Adapter cache time: 0.018355848733335733 Engine time: 0.10449315793812275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.420640960801393,
    "estimated_duration": 3600.0178083257983,
    "input_throughput": 5252.937070551458,
    "output_throughput": 4722.460250247026,
    "total_throughput": 9975.397320798484,
    "itl": 35.783848394755935,
    "ttft": 11172.76200808288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.87521441830802
}
#Debug simulation 
Total elapsed time: 5.420715724118054. Arrivals time: 0.1793268732726574 Scheduler time: 4.960865800734609 Scheduler overhead time: 0.10841448279097676 Adapter cache time: 0.018038392532616854 Engine time: 0.10475757904350758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.419393284711987,
    "estimated_duration": 3600.0280250676915,
    "input_throughput": 5252.922162916891,
    "output_throughput": 4722.446848085392,
    "total_throughput": 9975.369011002284,
    "itl": 35.78390600370915,
    "ttft": 11172.74295663904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.875424584426526
}
#Debug simulation 
Total elapsed time: 5.419473842717707. Arrivals time: 0.17795939277857542 Scheduler time: 4.964346246328205 Scheduler overhead time: 0.10583250457420945 Adapter cache time: 0.017882059328258038 Engine time: 0.10479002399370074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.409297965001315,
    "estimated_duration": 3600.027583308548,
    "input_throughput": 5252.922807502618,
    "output_throughput": 4722.447427576529,
    "total_throughput": 9975.370235079146,
    "itl": 35.78387788722722,
    "ttft": 11172.767711949557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.87542854728454
}
#Debug simulation 
Total elapsed time: 5.4093974232673645. Arrivals time: 0.17715701647102833 Scheduler time: 4.955274229403585 Scheduler overhead time: 0.1059967502951622 Adapter cache time: 0.01796930469572544 Engine time: 0.10378310177475214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.437093027867377,
    "estimated_duration": 3600.0236099545136,
    "input_throughput": 5252.928605165158,
    "output_throughput": 4722.452639752218,
    "total_throughput": 9975.381244917375,
    "itl": 35.78385673125659,
    "ttft": 11172.809474800642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.875307325968336
}
#Debug simulation 
Total elapsed time: 5.437165008857846. Arrivals time: 0.17839606292545795 Scheduler time: 4.979081845376641 Scheduler overhead time: 0.1069948198273778 Adapter cache time: 0.018168787006288767 Engine time: 0.10549826035276055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.408041018992662,
    "estimated_duration": 3600.028401188283,
    "input_throughput": 5252.921614106723,
    "output_throughput": 4722.446354697757,
    "total_throughput": 9975.36796880448,
    "itl": 35.783942649612996,
    "ttft": 11172.751290015662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.87546515543162
}
#Debug simulation 
Total elapsed time: 5.408143395092338. Arrivals time: 0.17987467255443335 Scheduler time: 4.9502743990160525 Scheduler overhead time: 0.10595522401854396 Adapter cache time: 0.01811081636697054 Engine time: 0.10506613412871957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.407635896932334,
    "estimated_duration": 3600.016644088374,
    "input_throughput": 5252.938769339695,
    "output_throughput": 4722.461777480231,
    "total_throughput": 9975.400546819925,
    "itl": 35.78391749909486,
    "ttft": 11172.805877683228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.875214336358006
}
#Debug simulation 
Total elapsed time: 5.407714850734919. Arrivals time: 0.17798943724483252 Scheduler time: 4.953846739605069 Scheduler overhead time: 0.10576452175155282 Adapter cache time: 0.01787850260734558 Engine time: 0.10342036234214902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 34560, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229635 . Total input tokens: 51104710 . Total output tokens: 45977611
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.402820778079331,
    "estimated_duration": 3600.0293977024185,
    "input_throughput": 5252.920160060085,
    "output_throughput": 4722.445047490502,
    "total_throughput": 9975.365207550587,
    "itl": 35.78388269545991,
    "ttft": 11172.72945792856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 76770,
    "finished_requests": 76533,
    "scheduler_time": 50.87548863126869
}
#Debug simulation 
Total elapsed time: 5.402892678976059. Arrivals time: 0.17819397617131472 Scheduler time: 4.947314601857215 Scheduler overhead time: 0.1059989188797772 Adapter cache time: 0.017933279741555452 Engine time: 0.10456119198352098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.419546147342771,
    "estimated_duration": 3599.964149249945,
    "input_throughput": 5247.822538437266,
    "output_throughput": 4705.649916966394,
    "total_throughput": 9953.47245540366,
    "itl": 35.526941824358126,
    "ttft": 7619.391539706898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.4471060958889
}
#Debug simulation 
Total elapsed time: 5.419616078026593. Arrivals time: 0.17652986384928226 Scheduler time: 4.963745624758303 Scheduler overhead time: 0.10668508941307664 Adapter cache time: 0.0177199924364686 Engine time: 0.10566382063552737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.393777587916702,
    "estimated_duration": 3599.9735650317357,
    "input_throughput": 5247.808812683173,
    "output_throughput": 4705.637609272462,
    "total_throughput": 9953.446421955634,
    "itl": 35.52698648033278,
    "ttft": 7619.34884891473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.447259798594985
}
#Debug simulation 
Total elapsed time: 5.393850137013942. Arrivals time: 0.17546401545405388 Scheduler time: 4.939010220114142 Scheduler overhead time: 0.10692502558231354 Adapter cache time: 0.017742160242050886 Engine time: 0.105451924726367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.409505132120103,
    "estimated_duration": 3599.9735348857616,
    "input_throughput": 5247.808856628026,
    "output_throughput": 4705.637648677204,
    "total_throughput": 9953.44650530523,
    "itl": 35.52697872253867,
    "ttft": 7619.343377702866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.447255753787
}
#Debug simulation 
Total elapsed time: 5.40957596199587. Arrivals time: 0.17624413594603539 Scheduler time: 4.956252520438284 Scheduler overhead time: 0.10704218270257115 Adapter cache time: 0.017585654743015766 Engine time: 0.10310835530981421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.395489656366408,
    "estimated_duration": 3599.972987277148,
    "input_throughput": 5247.809654896608,
    "output_throughput": 4705.638364473606,
    "total_throughput": 9953.448019370213,
    "itl": 35.52706662241589,
    "ttft": 7619.3206667088625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.447251790928654
}
#Debug simulation 
Total elapsed time: 5.395563357044011. Arrivals time: 0.17541120294481516 Scheduler time: 4.940814852248877 Scheduler overhead time: 0.1063935561105609 Adapter cache time: 0.017636741511523724 Engine time: 0.10616064164787531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.393556812312454,
    "estimated_duration": 3599.975297610764,
    "input_throughput": 5247.806287042649,
    "output_throughput": 4705.635344565523,
    "total_throughput": 9953.441631608173,
    "itl": 35.526972106756084,
    "ttft": 7619.359423734213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.44728486045439
}
#Debug simulation 
Total elapsed time: 5.393628623336554. Arrivals time: 0.17459361208602786 Scheduler time: 4.940543771255761 Scheduler overhead time: 0.10623157769441605 Adapter cache time: 0.01778556127101183 Engine time: 0.10554668493568897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.385400803294033,
    "estimated_duration": 3599.962556278748,
    "input_throughput": 5247.824860580906,
    "output_throughput": 4705.651999200491,
    "total_throughput": 9953.476859781396,
    "itl": 35.52692261692388,
    "ttft": 7619.393204607878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.447057558192384
}
#Debug simulation 
Total elapsed time: 5.385487038176507. Arrivals time: 0.1774764396250248 Scheduler time: 4.929630719590932 Scheduler overhead time: 0.10632931301370263 Adapter cache time: 0.017634558957070112 Engine time: 0.10508065856993198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 34560, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229290 . Total input tokens: 51030869 . Total output tokens: 45906495
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.401889119762927,
    "estimated_duration": 3599.973560467681,
    "input_throughput": 5247.8088193363565,
    "output_throughput": 4705.63761523828,
    "total_throughput": 9953.446434574636,
    "itl": 35.52696626237133,
    "ttft": 7619.340348084545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 76660,
    "finished_requests": 76499,
    "scheduler_time": 50.44723223697486
}
#Debug simulation 
Total elapsed time: 5.401987741701305. Arrivals time: 0.17657744698226452 Scheduler time: 4.946226771920919 Scheduler overhead time: 0.1064864001236856 Adapter cache time: 0.01761722331866622 Engine time: 0.10577758261933923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.387038125190884,
    "estimated_duration": 3600.0057367459526,
    "input_throughput": 5304.124603217959,
    "output_throughput": 4693.015021490297,
    "total_throughput": 9997.139624708256,
    "itl": 35.3429040088365,
    "ttft": 8611.94395485213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.220348616255194
}
#Debug simulation 
Total elapsed time: 5.387112178839743. Arrivals time: 0.1762598124332726 Scheduler time: 4.933012507855892 Scheduler overhead time: 0.10676238872110844 Adapter cache time: 0.017608475871384144 Engine time: 0.10402433201670647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.378511203918606,
    "estimated_duration": 3600.0090929783264,
    "input_throughput": 5304.119658265252,
    "output_throughput": 4693.01064626553,
    "total_throughput": 9997.130304530781,
    "itl": 35.34284054546361,
    "ttft": 8611.947671679183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.2203971949262
}
#Debug simulation 
Total elapsed time: 5.378587396815419. Arrivals time: 0.17661985335871577 Scheduler time: 4.922496117185801 Scheduler overhead time: 0.10723615204915404 Adapter cache time: 0.017695334274321795 Engine time: 0.10511328000575304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.380959417205304,
    "estimated_duration": 3600.0093995644465,
    "input_throughput": 5304.11920655269,
    "output_throughput": 4693.010246596594,
    "total_throughput": 9997.129453149284,
    "itl": 35.342829661475065,
    "ttft": 8611.939895988782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.2204093293503
}
#Debug simulation 
Total elapsed time: 5.381033067125827. Arrivals time: 0.1747349831275642 Scheduler time: 4.926470010075718 Scheduler overhead time: 0.10708126937970519 Adapter cache time: 0.017605590634047985 Engine time: 0.10561127914115787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.377866133116186,
    "estimated_duration": 3600.0093959415613,
    "input_throughput": 5304.119211890515,
    "output_throughput": 4693.010251319426,
    "total_throughput": 9997.12946320994,
    "itl": 35.34289076933438,
    "ttft": 8611.931003621752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.22042951241568
}
#Debug simulation 
Total elapsed time: 5.377948942128569. Arrivals time: 0.1760211200453341 Scheduler time: 4.923501745797694 Scheduler overhead time: 0.10683818021789193 Adapter cache time: 0.01758577488362789 Engine time: 0.10466608591377735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.365974250249565,
    "estimated_duration": 3600.009427872651,
    "input_throughput": 5304.119164844441,
    "output_throughput": 4693.01020969372,
    "total_throughput": 9997.12937453816,
    "itl": 35.34282817173374,
    "ttft": 8611.954236211244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.22039719492617
}
#Debug simulation 
Total elapsed time: 5.366048471070826. Arrivals time: 0.17729923222213984 Scheduler time: 4.911212724167854 Scheduler overhead time: 0.10701128095388412 Adapter cache time: 0.01757361926138401 Engine time: 0.10350478906184435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.396872760728002,
    "estimated_duration": 3600.001300375849,
    "input_throughput": 5304.131139621101,
    "output_throughput": 4693.020804808079,
    "total_throughput": 9997.15194442918,
    "itl": 35.342864075764986,
    "ttft": 8611.967623145458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.22023523870524
}
#Debug simulation 
Total elapsed time: 5.396947230678052. Arrivals time: 0.1760921636596322 Scheduler time: 4.942638804204762 Scheduler overhead time: 0.1069523231126368 Adapter cache time: 0.017614697106182575 Engine time: 0.10429850267246366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 34560, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 34560]
Prompts retrieved: 229125 . Total input tokens: 50989765 . Total output tokens: 45878187
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.386441893875599,
    "estimated_duration": 3600.0090790797067,
    "input_throughput": 5304.119678742962,
    "output_throughput": 4693.010664383921,
    "total_throughput": 9997.130343126883,
    "itl": 35.34277990458392,
    "ttft": 8611.95571861469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 76601,
    "finished_requests": 76418,
    "scheduler_time": 50.2203689222448
}
#Debug simulation 
Total elapsed time: 5.386514344718307. Arrivals time: 0.17368366848677397 Scheduler time: 4.9326311480253935 Scheduler overhead time: 0.10625320672988892 Adapter cache time: 0.017586491536349058 Engine time: 0.10731683066114783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.104384587146342,
    "estimated_duration": 3600.0258865506144,
    "input_throughput": 4940.107532682309,
    "output_throughput": 4401.365295509585,
    "total_throughput": 9341.472828191894,
    "itl": 33.29399163549731,
    "ttft": 8344.621297725718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.78076010499622
}
#Debug simulation 
Total elapsed time: 5.104470991995186. Arrivals time: 0.17250854661688209 Scheduler time: 4.6358871278353035 Scheduler overhead time: 0.11207904480397701 Adapter cache time: 0.021507376804947853 Engine time: 0.11058011837303638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.085579487960786,
    "estimated_duration": 3600.025966038276,
    "input_throughput": 4940.107423605987,
    "output_throughput": 4401.3651983285545,
    "total_throughput": 9341.472621934541,
    "itl": 33.29400421628562,
    "ttft": 8344.684135530219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.78073583614812
}
#Debug simulation 
Total elapsed time: 5.0856862142682076. Arrivals time: 0.16971068130806088 Scheduler time: 4.622268188279122 Scheduler overhead time: 0.11183493910357356 Adapter cache time: 0.021372793707996607 Engine time: 0.10857698461040854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.080541979987174,
    "estimated_duration": 3600.0260015545323,
    "input_throughput": 4940.107374869082,
    "output_throughput": 4401.365154906641,
    "total_throughput": 9341.472529775723,
    "itl": 33.293991578985064,
    "ttft": 8344.69322186391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.7807398809561
}
#Debug simulation 
Total elapsed time: 5.080614085774869. Arrivals time: 0.16841714596375823 Scheduler time: 4.616486515384167 Scheduler overhead time: 0.1125549552962184 Adapter cache time: 0.021268397569656372 Engine time: 0.10986896371468902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.094789641909301,
    "estimated_duration": 3600.0258662054525,
    "input_throughput": 4940.1075606008,
    "output_throughput": 4401.365320383431,
    "total_throughput": 9341.47288098423,
    "itl": 33.293998452703605,
    "ttft": 8344.6426640359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.78073992193093
}
#Debug simulation 
Total elapsed time: 5.094883949961513. Arrivals time: 0.16822550725191832 Scheduler time: 4.632185933180153 Scheduler overhead time: 0.11153604229912162 Adapter cache time: 0.021436782553792 Engine time: 0.10980852227658033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.109823120757937,
    "estimated_duration": 3600.026004130698,
    "input_throughput": 4940.107371333959,
    "output_throughput": 4401.365151757041,
    "total_throughput": 9341.472523090999,
    "itl": 33.2940022608814,
    "ttft": 8344.678644024983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.78073583614807
}
#Debug simulation 
Total elapsed time: 5.109897132962942. Arrivals time: 0.16833912255242467 Scheduler time: 4.646262545604259 Scheduler overhead time: 0.11195289762690663 Adapter cache time: 0.021342262160032988 Engine time: 0.11017821868881583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.1060539642348886,
    "estimated_duration": 3600.025976847922,
    "input_throughput": 4940.107408772535,
    "output_throughput": 4401.365185112761,
    "total_throughput": 9341.472593885295,
    "itl": 33.29404169930029,
    "ttft": 8344.654705252311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.780768153637474
}
#Debug simulation 
Total elapsed time: 5.106128088198602. Arrivals time: 0.16873051412403584 Scheduler time: 4.642491577658802 Scheduler overhead time: 0.11210016487166286 Adapter cache time: 0.02135560568422079 Engine time: 0.10953485639765859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 34560, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 215460 . Total input tokens: 47938488 . Total output tokens: 43151762
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.092543120030314,
    "estimated_duration": 3600.0257368619796,
    "input_throughput": 4940.107738091384,
    "output_throughput": 4401.365478517821,
    "total_throughput": 9341.473216609205,
    "itl": 33.29399813889141,
    "ttft": 8344.670354460048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 72090,
    "finished_requests": 71924,
    "scheduler_time": 44.78072770555704
}
#Debug simulation 
Total elapsed time: 5.0926169799640775. Arrivals time: 0.16774414852261543 Scheduler time: 4.631236605811864 Scheduler overhead time: 0.11164166266098619 Adapter cache time: 0.021431160625070333 Engine time: 0.10853444878011942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.03591410536319,
    "estimated_duration": 3599.9418153716,
    "input_throughput": 4959.625992776498,
    "output_throughput": 4357.10125453261,
    "total_throughput": 9316.727247309107,
    "itl": 32.51969258161141,
    "ttft": 8642.316818770185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74328828332316
}
#Debug simulation 
Total elapsed time: 5.035986123140901. Arrivals time: 0.16768384771421552 Scheduler time: 4.568068147171289 Scheduler overhead time: 0.11479084705933928 Adapter cache time: 0.020995623897761106 Engine time: 0.11168339941650629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.028212091885507,
    "estimated_duration": 3599.952012866557,
    "input_throughput": 4959.611943766714,
    "output_throughput": 4357.088912279738,
    "total_throughput": 9316.700856046451,
    "itl": 32.519718912694366,
    "ttft": 8642.393677427388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74346225104382
}
#Debug simulation 
Total elapsed time: 5.028286607936025. Arrivals time: 0.1671033245511353 Scheduler time: 4.562680139672011 Scheduler overhead time: 0.11373882414773107 Adapter cache time: 0.020850264467298985 Engine time: 0.1114003723487258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.060035719070584,
    "estimated_duration": 3599.9519100295415,
    "input_throughput": 4959.612085444076,
    "output_throughput": 4357.089036745295,
    "total_throughput": 9316.701122189372,
    "itl": 32.519699295801566,
    "ttft": 8642.404050603907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74346629585183
}
#Debug simulation 
Total elapsed time: 5.060122047085315. Arrivals time: 0.16885047545656562 Scheduler time: 4.5941005647182465 Scheduler overhead time: 0.11302299797534943 Adapter cache time: 0.02118621952831745 Engine time: 0.11052999552339315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.054853485897183,
    "estimated_duration": 3599.944214260997,
    "input_throughput": 4959.622687838005,
    "output_throughput": 4357.098351097618,
    "total_throughput": 9316.721038935622,
    "itl": 32.51966480726115,
    "ttft": 8642.362214709123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.743328731403636
}
#Debug simulation 
Total elapsed time: 5.054928339086473. Arrivals time: 0.16637285146862268 Scheduler time: 4.589650533162057 Scheduler overhead time: 0.11411071801558137 Adapter cache time: 0.02110337419435382 Engine time: 0.11116716545075178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.023331208154559,
    "estimated_duration": 3599.9520182814163,
    "input_throughput": 4959.6119363067255,
    "output_throughput": 4357.088905726033,
    "total_throughput": 9316.700842032758,
    "itl": 32.51969019365374,
    "ttft": 8642.40287867383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74346625487696
}
#Debug simulation 
Total elapsed time: 5.023426259867847. Arrivals time: 0.1654841103591025 Scheduler time: 4.561529801692814 Scheduler overhead time: 0.11271749902516603 Adapter cache time: 0.02093206439167261 Engine time: 0.11039792327210307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.0653529423289,
    "estimated_duration": 3599.9415996565576,
    "input_throughput": 4959.6262899663,
    "output_throughput": 4357.101515618035,
    "total_throughput": 9316.727805584334,
    "itl": 32.519692661282264,
    "ttft": 8642.327258472922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74328832429808
}
#Debug simulation 
Total elapsed time: 5.065432707313448. Arrivals time: 0.1677255122922361 Scheduler time: 4.598601789679378 Scheduler overhead time: 0.11461099609732628 Adapter cache time: 0.02093031071126461 Engine time: 0.11121215019375086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 34560, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 214110 . Total input tokens: 47634743 . Total output tokens: 42896942
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0492207440547645,
    "estimated_duration": 3599.952062009414,
    "input_throughput": 4959.611876063173,
    "output_throughput": 4357.088852801225,
    "total_throughput": 9316.700728864398,
    "itl": 32.51967023354902,
    "ttft": 8642.400705480466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 71677,
    "finished_requests": 71506,
    "scheduler_time": 43.74347029968499
}
#Debug simulation 
Total elapsed time: 5.04931235127151. Arrivals time: 0.16798240970820189 Scheduler time: 4.583081874065101 Scheduler overhead time: 0.11409593606367707 Adapter cache time: 0.021005737129598856 Engine time: 0.1103725922293961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.0403592409566045,
    "estimated_duration": 3600.0087344711565,
    "input_throughput": 4948.999103641688,
    "output_throughput": 4360.346087411907,
    "total_throughput": 9309.345191053595,
    "itl": 32.35227379421716,
    "ttft": 8214.780475218204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 71461,
    "finished_requests": 71298,
    "scheduler_time": 43.67430621207389
}
#Debug simulation 
Total elapsed time: 5.040432317182422. Arrivals time: 0.16545425076037645 Scheduler time: 4.577326791826636 Scheduler overhead time: 0.11328793410211802 Adapter cache time: 0.02065699128434062 Engine time: 0.11116198124364018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.052233656868339,
    "estimated_duration": 3600.0137638806823,
    "input_throughput": 4948.99246740505,
    "output_throughput": 4360.3405513313655,
    "total_throughput": 9309.333018736415,
    "itl": 32.35207296261337,
    "ttft": 8164.336604482749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 71461,
    "finished_requests": 71299,
    "scheduler_time": 43.67436704809402
}
#Debug simulation 
Total elapsed time: 5.052302406169474. Arrivals time: 0.16826551454141736 Scheduler time: 4.58139559533447 Scheduler overhead time: 0.11629188200458884 Adapter cache time: 0.020678738597780466 Engine time: 0.11271361773833632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0659652426838875,
    "estimated_duration": 3600.013552517486,
    "input_throughput": 4948.992757969197,
    "output_throughput": 4360.340807334712,
    "total_throughput": 9309.333565303908,
    "itl": 32.35207388071792,
    "ttft": 8164.332600140757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 71461,
    "finished_requests": 71299,
    "scheduler_time": 43.67435491366997
}
#Debug simulation 
Total elapsed time: 5.066039390861988. Arrivals time: 0.16780086560174823 Scheduler time: 4.600259055849165 Scheduler overhead time: 0.11371029587462544 Adapter cache time: 0.02054588170722127 Engine time: 0.11102656600996852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.0367212430574,
    "estimated_duration": 3600.0139194458357,
    "input_throughput": 4948.99225354733,
    "output_throughput": 4360.340362910692,
    "total_throughput": 9309.332616458021,
    "itl": 32.35207555178632,
    "ttft": 8164.317467728214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 71461,
    "finished_requests": 71299,
    "scheduler_time": 43.674387190184305
}
#Debug simulation 
Total elapsed time: 5.036811381112784. Arrivals time: 0.16604036558419466 Scheduler time: 4.573136671911925 Scheduler overhead time: 0.11344228405505419 Adapter cache time: 0.020502798724919558 Engine time: 0.11102843331173062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.063674779143184,
    "estimated_duration": 3600.013760810465,
    "input_throughput": 4948.992471625724,
    "output_throughput": 4360.3405550500165,
    "total_throughput": 9309.33302667574,
    "itl": 32.35205868968739,
    "ttft": 8164.341291499822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 71461,
    "finished_requests": 71299,
    "scheduler_time": 43.67435895847795
}
#Debug simulation 
Total elapsed time: 5.063746015075594. Arrivals time: 0.1721706767566502 Scheduler time: 4.590687721036375 Scheduler overhead time: 0.1152156749740243 Adapter cache time: 0.020718012470752 Engine time: 0.11241233814507723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.052412771154195,
    "estimated_duration": 3600.0027920670195,
    "input_throughput": 4949.007272788893,
    "output_throughput": 4360.353284889277,
    "total_throughput": 9309.36055767817,
    "itl": 32.3521559603214,
    "ttft": 8214.691335421654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 71461,
    "finished_requests": 71298,
    "scheduler_time": 43.674180782050136
}
#Debug simulation 
Total elapsed time: 5.052517157047987. Arrivals time: 0.16496362630277872 Scheduler time: 4.589699980802834 Scheduler overhead time: 0.11311295721679926 Adapter cache time: 0.020679144654423 Engine time: 0.11161045078188181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 34560, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213435 . Total input tokens: 47489888 . Total output tokens: 42761831
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.092869365122169,
    "estimated_duration": 3600.013940177285,
    "input_throughput": 4948.9922250475,
    "output_throughput": 4360.3403378007415,
    "total_throughput": 9309.332562848242,
    "itl": 32.35206792160674,
    "ttft": 8164.351590999461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 71461,
    "finished_requests": 71299,
    "scheduler_time": 43.67435082788686
}
#Debug simulation 
Total elapsed time: 5.092944433912635. Arrivals time: 0.16699078539386392 Scheduler time: 4.62507593119517 Scheduler overhead time: 0.11496320413425565 Adapter cache time: 0.020722981076687574 Engine time: 0.11214791052043438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.020095606800169,
    "estimated_duration": 3599.9767576748395,
    "input_throughput": 4903.045821718129,
    "output_throughput": 4344.492771142679,
    "total_throughput": 9247.538592860808,
    "itl": 32.130636048129595,
    "ttft": 7821.394046519667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.27536075124016
}
#Debug simulation 
Total elapsed time: 5.0201673321425915. Arrivals time: 0.16628839587792754 Scheduler time: 4.555817863438278 Scheduler overhead time: 0.11396674159914255 Adapter cache time: 0.020184898283332586 Engine time: 0.11103013763204217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0034183082170784,
    "estimated_duration": 3599.951699794008,
    "input_throughput": 4903.079949936549,
    "output_throughput": 4344.523011487887,
    "total_throughput": 9247.602961424436,
    "itl": 32.130743040387365,
    "ttft": 7821.4528960166945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.275097004732054
}
#Debug simulation 
Total elapsed time: 5.003490169066936. Arrivals time: 0.1622033161111176 Scheduler time: 4.54397229058668 Scheduler overhead time: 0.11315963650122285 Adapter cache time: 0.02031191298738122 Engine time: 0.11142049310728908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.025943946093321,
    "estimated_duration": 3599.95103651514,
    "input_throughput": 4903.0808533125355,
    "output_throughput": 4344.523811951636,
    "total_throughput": 9247.604665264173,
    "itl": 32.130737752345176,
    "ttft": 7821.448350141889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.27508891511593
}
#Debug simulation 
Total elapsed time: 5.026048535015434. Arrivals time: 0.16667950339615345 Scheduler time: 4.560767830349505 Scheduler overhead time: 0.11369274742901325 Adapter cache time: 0.020186169538646936 Engine time: 0.11208920134231448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.052265098784119,
    "estimated_duration": 3599.9450736391636,
    "input_throughput": 4903.088974676177,
    "output_throughput": 4344.531008132727,
    "total_throughput": 9247.619982808903,
    "itl": 32.13067754493206,
    "ttft": 7821.3943317308085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.274979705298556
}
#Debug simulation 
Total elapsed time: 5.052352061960846. Arrivals time: 0.16624994575977325 Scheduler time: 4.585617476142943 Scheduler overhead time: 0.11476598726585507 Adapter cache time: 0.02047634357586503 Engine time: 0.1123673552647233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.009488936979324,
    "estimated_duration": 3599.9510358336047,
    "input_throughput": 4903.080854240777,
    "output_throughput": 4344.523812774132,
    "total_throughput": 9247.60466701491,
    "itl": 32.13072441488847,
    "ttft": 7821.451747419039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.27507678069186
}
#Debug simulation 
Total elapsed time: 5.009561453014612. Arrivals time: 0.16497907787561417 Scheduler time: 4.546898630447686 Scheduler overhead time: 0.11418485315516591 Adapter cache time: 0.0204818700440228 Engine time: 0.11030390439555049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.043469645082951,
    "estimated_duration": 3599.9767960304,
    "input_throughput": 4903.045769479162,
    "output_throughput": 4344.492724854755,
    "total_throughput": 9247.538494333916,
    "itl": 32.130644942765386,
    "ttft": 7821.413258411495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.275372051678254
}
#Debug simulation 
Total elapsed time: 5.043541818857193. Arrivals time: 0.17856283904984593 Scheduler time: 4.565925391856581 Scheduler overhead time: 0.11373340152204037 Adapter cache time: 0.02015897771343589 Engine time: 0.11231596022844315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 34560, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 213090 . Total input tokens: 47410052 . Total output tokens: 42695379
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.026316428091377,
    "estimated_duration": 3599.9518344053636,
    "input_throughput": 4903.079766597919,
    "output_throughput": 4344.522849035121,
    "total_throughput": 9247.602615633039,
    "itl": 32.13072894705472,
    "ttft": 7821.45514015111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 71367,
    "finished_requests": 71213,
    "scheduler_time": 43.275088915116
}
#Debug simulation 
Total elapsed time: 5.026389771141112. Arrivals time: 0.16402914887294173 Scheduler time: 4.560469278134406 Scheduler overhead time: 0.11406977754086256 Adapter cache time: 0.020124643109738827 Engine time: 0.11461579892784357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.029813594184816,
    "estimated_duration": 3599.9701312784355,
    "input_throughput": 4887.411661316134,
    "output_throughput": 4351.979441128384,
    "total_throughput": 9239.391102444519,
    "itl": 32.20897611861094,
    "ttft": 9648.055768773478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 71288,
    "finished_requests": 71098,
    "scheduler_time": 43.4421385716235
}
#Debug simulation 
Total elapsed time: 5.029890511184931. Arrivals time: 0.16679511684924364 Scheduler time: 4.565452678594738 Scheduler overhead time: 0.11414170591160655 Adapter cache time: 0.019899875856935978 Engine time: 0.11089961836114526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0230443137697875,
    "estimated_duration": 3599.9977507675253,
    "input_throughput": 4887.37444245592,
    "output_throughput": 4351.991885733744,
    "total_throughput": 9239.366328189664,
    "itl": 32.20936098417182,
    "ttft": 9597.551196185022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 71288,
    "finished_requests": 71099,
    "scheduler_time": 43.442656552902605
}
#Debug simulation 
Total elapsed time: 5.023118583951145. Arrivals time: 0.16428212355822325 Scheduler time: 4.56320199277252 Scheduler overhead time: 0.11341452784836292 Adapter cache time: 0.019868293311446905 Engine time: 0.1097638146020472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.042226977646351,
    "estimated_duration": 3599.9962816824223,
    "input_throughput": 4887.376436893809,
    "output_throughput": 4351.993661692925,
    "total_throughput": 9239.370098586734,
    "itl": 32.20935768495094,
    "ttft": 9597.56811921533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 71288,
    "finished_requests": 71099,
    "scheduler_time": 43.44263228405433
}
#Debug simulation 
Total elapsed time: 5.042298926971853. Arrivals time: 0.1626488408073783 Scheduler time: 4.581043058075011 Scheduler overhead time: 0.11321526952087879 Adapter cache time: 0.019996084738522768 Engine time: 0.11270282417535782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.011795136611909,
    "estimated_duration": 3599.9882152769014,
    "input_throughput": 4887.387387918623,
    "output_throughput": 4352.003413098652,
    "total_throughput": 9239.390801017274,
    "itl": 32.20934772421251,
    "ttft": 9597.571109357643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 71288,
    "finished_requests": 71099,
    "scheduler_time": 43.44251498462088
}
#Debug simulation 
Total elapsed time: 5.011872222647071. Arrivals time: 0.16297064069658518 Scheduler time: 4.551707550883293 Scheduler overhead time: 0.11284786835312843 Adapter cache time: 0.0199782932177186 Engine time: 0.11202777503058314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.033677724190056,
    "estimated_duration": 3599.9989110494867,
    "input_throughput": 4887.372867251998,
    "output_throughput": 4351.990483083964,
    "total_throughput": 9239.363350335962,
    "itl": 32.20938511476272,
    "ttft": 9597.590504375175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 71288,
    "finished_requests": 71099,
    "scheduler_time": 43.44267681791767
}
#Debug simulation 
Total elapsed time: 5.033777162898332. Arrivals time: 0.16445938870310783 Scheduler time: 4.570124518126249 Scheduler overhead time: 0.11384392809122801 Adapter cache time: 0.020004774443805218 Engine time: 0.11269213305786252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.042566086165607,
    "estimated_duration": 3599.9701559274454,
    "input_throughput": 4887.411627852007,
    "output_throughput": 4351.979411330363,
    "total_throughput": 9239.39103918237,
    "itl": 32.208992639988026,
    "ttft": 9648.057616658947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 71288,
    "finished_requests": 71098,
    "scheduler_time": 43.44213861259844
}
#Debug simulation 
Total elapsed time: 5.042641948442906. Arrivals time: 0.16519318940117955 Scheduler time: 4.579771775752306 Scheduler overhead time: 0.11433057300746441 Adapter cache time: 0.01992703787982464 Engine time: 0.11052283132448792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 34560, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 34560]
Prompts retrieved: 212925 . Total input tokens: 47366437 . Total output tokens: 42665628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0396135142073035,
    "estimated_duration": 3599.999245910389,
    "input_throughput": 4887.3724126435445,
    "output_throughput": 4351.99007827514,
    "total_throughput": 9239.362490918686,
    "itl": 32.209394186415715,
    "ttft": 9597.586941402817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 71288,
    "finished_requests": 71099,
    "scheduler_time": 43.44267677694274
}
#Debug simulation 
Total elapsed time: 5.039689382072538. Arrivals time: 0.1680384986102581 Scheduler time: 4.574111044406891 Scheduler overhead time: 0.11381246009841561 Adapter cache time: 0.01988167269155383 Engine time: 0.11125627718865871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.018442595843226,
    "estimated_duration": 3600.022598122263,
    "input_throughput": 4910.760285010743,
    "output_throughput": 4330.956424588112,
    "total_throughput": 9241.716709598855,
    "itl": 31.921870715760697,
    "ttft": 7278.621388023512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95359715119946
}
#Debug simulation 
Total elapsed time: 5.018539372831583. Arrivals time: 0.16582300560548902 Scheduler time: 4.55149422865361 Scheduler overhead time: 0.1149859200231731 Adapter cache time: 0.020461290143430233 Engine time: 0.11259333835914731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0439864178188145,
    "estimated_duration": 3600.0303301943513,
    "input_throughput": 4910.749737779456,
    "output_throughput": 4330.94712264779,
    "total_throughput": 9241.696860427246,
    "itl": 31.92197928642032,
    "ttft": 7278.509742398949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95369839432554
}
#Debug simulation 
Total elapsed time: 5.044058740139008. Arrivals time: 0.16445928066968918 Scheduler time: 4.578331176191568 Scheduler overhead time: 0.11419988051056862 Adapter cache time: 0.02072613127529621 Engine time: 0.11318226624280214 
