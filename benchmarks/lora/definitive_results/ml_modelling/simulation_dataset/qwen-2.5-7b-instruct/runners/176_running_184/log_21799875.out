INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.656794962938875,
    "estimated_duration": 3599.8730044764575,
    "input_throughput": 1091.0240431026532,
    "output_throughput": 973.6976820130276,
    "total_throughput": 2064.721725115681,
    "itl": 24.037442818410113,
    "ttft": 6379.754411647916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.068633060113676,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002575337226659734
}
#Debug simulation 
Total elapsed time: 1.65691934293136. Arrivals time: 0.0536229545250535 Scheduler time: 1.1637896639294922 Scheduler overhead time: 0.13235350558534265 Adapter cache time: 0.11262804875150323 Engine time: 0.13086567912250757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6092461519874632,
    "estimated_duration": 3599.8646097407786,
    "input_throughput": 1091.0265873256876,
    "output_throughput": 973.6999526358309,
    "total_throughput": 2064.7265399615185,
    "itl": 24.074878715486808,
    "ttft": 6380.000674627826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.205392501353074,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00026324650272527544
}
#Debug simulation 
Total elapsed time: 1.6093287649564445. Arrivals time: 0.05054829688742757 Scheduler time: 1.1273936498910189 Scheduler overhead time: 0.13076445274055004 Adapter cache time: 0.11251983838155866 Engine time: 0.1254597851075232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.4701931891031563,
    "estimated_duration": 3599.6381944112763,
    "input_throughput": 917.7122315039439,
    "output_throughput": 812.8469701601614,
    "total_throughput": 1730.5592016641053,
    "itl": 22.51512246405945,
    "ttft": 5135.219655480188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.526026768933132,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4703008239157498. Arrivals time: 0.04667567042633891 Scheduler time: 0.9806511383503675 Scheduler overhead time: 0.14344126684591174 Adapter cache time: 0.09865337517112494 Engine time: 0.13306354079395533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.44611790869385,
    "estimated_duration": 3599.6549752381547,
    "input_throughput": 917.7079533244554,
    "output_throughput": 812.8431808402464,
    "total_throughput": 1730.5511341647018,
    "itl": 22.530500115507465,
    "ttft": 5135.247419532451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.317006035026623,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4462159047834575. Arrivals time: 0.045675158966332674 Scheduler time: 0.9699611822143197 Scheduler overhead time: 0.1359575423412025 Adapter cache time: 0.09710677852854133 Engine time: 0.13160283816978335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.462913149036467,
    "estimated_duration": 3599.6454336290626,
    "input_throughput": 917.7103859003056,
    "output_throughput": 812.8453354502011,
    "total_throughput": 1730.5557213505067,
    "itl": 22.53321668808995,
    "ttft": 5135.3766907782065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.385764325690555,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4630045876838267. Arrivals time: 0.04528860608115792 Scheduler time: 0.9804071467369795 Scheduler overhead time: 0.14055417524650693 Adapter cache time: 0.09697082731872797 Engine time: 0.1332904938608408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.4662750880233943,
    "estimated_duration": 3599.637094933743,
    "input_throughput": 917.7125118110844,
    "output_throughput": 812.8472184371288,
    "total_throughput": 1730.5597302482133,
    "itl": 22.520074766146294,
    "ttft": 5135.281695288729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.14201578225894,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4663726650178432. Arrivals time: 0.04629285214468837 Scheduler time: 0.981499785091728 Scheduler overhead time: 0.13906741980463266 Adapter cache time: 0.09820427978411317 Engine time: 0.13471216801553965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4985262197442353,
    "estimated_duration": 3599.6372251776093,
    "input_throughput": 917.7124786059534,
    "output_throughput": 812.8471890262861,
    "total_throughput": 1730.5596676322393,
    "itl": 22.533072845020357,
    "ttft": 5135.427981306856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.755451285968814,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4986304300837219. Arrivals time: 0.04679923364892602 Scheduler time: 1.0130970827303827 Scheduler overhead time: 0.13679281575605273 Adapter cache time: 0.10085589764639735 Engine time: 0.13479429902508855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.5102973952889442,
    "estimated_duration": 3599.6527855791037,
    "input_throughput": 917.7085115637207,
    "output_throughput": 812.8436752905542,
    "total_throughput": 1730.5521868542749,
    "itl": 22.509874095011124,
    "ttft": 5135.172233127094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.883542201463683,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5103978901170194. Arrivals time: 0.046581809874624014 Scheduler time: 1.0177556606940925 Scheduler overhead time: 0.13655696203932166 Adapter cache time: 0.0998044996522367 Engine time: 0.14051810558885336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4855584050528705,
    "estimated_duration": 3599.6440827959295,
    "input_throughput": 917.7107302881304,
    "output_throughput": 812.8456404854729,
    "total_throughput": 1730.5563707736032,
    "itl": 22.535385410288136,
    "ttft": 5135.464308091592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.136137169224472,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4856380629353225. Arrivals time: 0.046082515735179186 Scheduler time: 0.9997713575139642 Scheduler overhead time: 0.13913625059649348 Adapter cache time: 0.09956945944577456 Engine time: 0.13429465284571052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.1187302339822054,
    "estimated_duration": 3599.92930136093,
    "input_throughput": 582.6528313228403,
    "output_throughput": 507.4971887112705,
    "total_throughput": 1090.1500200341106,
    "itl": 20.15319015473664,
    "ttft": 5506.086633166289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.4340971739723,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1188053181394935. Arrivals time: 0.03492910694330931 Scheduler time: 0.6521980068646371 Scheduler overhead time: 0.14534711418673396 Adapter cache time: 0.07144325645640492 Engine time: 0.14304646756500006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1312437350861728,
    "estimated_duration": 3599.925968900434,
    "input_throughput": 582.6533706860272,
    "output_throughput": 507.4976585026906,
    "total_throughput": 1090.1510291887178,
    "itl": 20.163622877215374,
    "ttft": 5506.1773809921515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.747995078171908,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1313460650853813. Arrivals time: 0.035653423983603716 Scheduler time: 0.6563432067632675 Scheduler overhead time: 0.1460147900506854 Adapter cache time: 0.077002570964396 Engine time: 0.14459773804992437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1195960328914225,
    "estimated_duration": 3599.9436162900074,
    "input_throughput": 582.6505144437871,
    "output_throughput": 507.49517068347956,
    "total_throughput": 1090.1456851272667,
    "itl": 20.162438221548495,
    "ttft": 5506.064520515749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.780564177501454,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1196776451542974. Arrivals time: 0.035060465801507235 Scheduler time: 0.6536300582811236 Scheduler overhead time: 0.1457852264866233 Adapter cache time: 0.071865598205477 Engine time: 0.1418563835322857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.131911105941981,
    "estimated_duration": 3599.9398660300067,
    "input_throughput": 582.6511214236257,
    "output_throughput": 507.495699369766,
    "total_throughput": 1090.1468207933917,
    "itl": 20.155597670515583,
    "ttft": 5506.1027702157635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.875235477984056,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1320008300244808. Arrivals time: 0.034872904885560274 Scheduler time: 0.6609162292443216 Scheduler overhead time: 0.14774092473089695 Adapter cache time: 0.07234210427850485 Engine time: 0.14361318666487932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.129806529264897,
    "estimated_duration": 3599.9270199427924,
    "input_throughput": 582.6532005733084,
    "output_throughput": 507.49751033259355,
    "total_throughput": 1090.1507109059019,
    "itl": 20.164016544419127,
    "ttft": 5506.323367553821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.049174265283042,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1298892758786678. Arrivals time: 0.03499391861259937 Scheduler time: 0.6596092372201383 Scheduler overhead time: 0.1458888710476458 Adapter cache time: 0.0727073815651238 Engine time: 0.14471528632566333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.1273716408759356,
    "estimated_duration": 3599.938317537557,
    "input_throughput": 582.6513720476038,
    "output_throughput": 507.4959176660782,
    "total_throughput": 1090.147289713682,
    "itl": 20.152025388081096,
    "ttft": 5505.9143908618325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.989809422924566,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1274513858370483. Arrivals time: 0.035711224656552076 Scheduler time: 0.6560190650634468 Scheduler overhead time: 0.14562066923826933 Adapter cache time: 0.07215889170765877 Engine time: 0.14607390202581882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1339991693384945,
    "estimated_duration": 3599.9347934849425,
    "input_throughput": 582.6519424174046,
    "output_throughput": 507.49641446460873,
    "total_throughput": 1090.1483568820133,
    "itl": 20.167016454400237,
    "ttft": 5506.270518937578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.31817620031372,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1340715000405908. Arrivals time: 0.035412255208939314 Scheduler time: 0.6636023153550923 Scheduler overhead time: 0.14600355410948396 Adapter cache time: 0.0724062598310411 Engine time: 0.14502499159425497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 54.84874472906813,
    "estimated_duration": 3600.0367438418175,
    "input_throughput": 5323.999826609037,
    "output_throughput": 4697.511498716821,
    "total_throughput": 10021.511325325859,
    "itl": 182.1700078033121,
    "ttft": 2179654.0508939237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9587121561169945,
    "arrivals": 2153264,
    "finished_requests": 77537,
    "scheduler_time": 132.00549657599456
}
#Debug simulation 
Total elapsed time: 54.84894154686481. Arrivals time: 0.8679372007027268 Scheduler time: 53.84530115080997 Scheduler overhead time: 0.051823952700942755 Adapter cache time: 0.018498999997973442 Engine time: 0.04695192724466324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 53.68449587095529,
    "estimated_duration": 3600.0664709699677,
    "input_throughput": 5318.069028553699,
    "output_throughput": 4696.673557653611,
    "total_throughput": 10014.74258620731,
    "itl": 182.34716852989922,
    "ttft": 2179633.0253197975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0663548470102304,
    "arrivals": 2153264,
    "finished_requests": 77476,
    "scheduler_time": 131.9542494805271
}
#Debug simulation 
Total elapsed time: 53.6846869578585. Arrivals time: 0.4279776928015053 Scheduler time: 53.12037215568125 Scheduler overhead time: 0.051371846348047256 Adapter cache time: 0.018444090150296688 Engine time: 0.048328624572604895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 52.933979601133615,
    "estimated_duration": 3600.166809490759,
    "input_throughput": 5295.440741729591,
    "output_throughput": 4680.59867547736,
    "total_throughput": 9976.03941720695,
    "itl": 180.7401452398023,
    "ttft": 2180758.030547479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0249076201021787,
    "arrivals": 2153264,
    "finished_requests": 77079,
    "scheduler_time": 132.27925774259054
}
#Debug simulation 
Total elapsed time: 52.9341603172943. Arrivals time: 0.44023984856903553 Scheduler time: 52.359648775309324 Scheduler overhead time: 0.05058777425438166 Adapter cache time: 0.017550735268741846 Engine time: 0.047796775586903095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 54.852614908944815,
    "estimated_duration": 3600.078984262901,
    "input_throughput": 5323.937359092211,
    "output_throughput": 4697.45638190838,
    "total_throughput": 10021.393741000591,
    "itl": 182.17177864838598,
    "ttft": 2179673.7186918007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0006629915651724,
    "arrivals": 2153264,
    "finished_requests": 77537,
    "scheduler_time": 132.00578616157415
}
#Debug simulation 
Total elapsed time: 54.85277895303443. Arrivals time: 0.4377761618234217 Scheduler time: 54.27913931570947 Scheduler overhead time: 0.051524731796234846 Adapter cache time: 0.01857476821169257 Engine time: 0.04741349769756198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 52.96340059535578,
    "estimated_duration": 3600.193705715026,
    "input_throughput": 5295.401180702206,
    "output_throughput": 4680.563707794516,
    "total_throughput": 9975.964888496721,
    "itl": 180.7413454264508,
    "ttft": 2180769.6349069034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.051693176608537,
    "arrivals": 2153264,
    "finished_requests": 77079,
    "scheduler_time": 132.27936841036905
}
#Debug simulation 
Total elapsed time: 52.96358184237033. Arrivals time: 0.44893132988363504 Scheduler time: 52.3790083732456 Scheduler overhead time: 0.05093737365677953 Adapter cache time: 0.01778780110180378 Engine time: 0.04868179140612483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 55.05161801120266,
    "estimated_duration": 3600.189773699882,
    "input_throughput": 5323.828799253119,
    "output_throughput": 4697.391544063024,
    "total_throughput": 10021.220343316143,
    "itl": 182.16823556028544,
    "ttft": 2179686.5549863433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9136321887373613,
    "arrivals": 2153264,
    "finished_requests": 77538,
    "scheduler_time": 132.01261744065562
}
#Debug simulation 
Total elapsed time: 55.051819113083184. Arrivals time: 0.4535684110596776 Scheduler time: 54.46163715189323 Scheduler overhead time: 0.05129823787137866 Adapter cache time: 0.018783955834805965 Engine time: 0.04808416962623596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 52.99991724360734,
    "estimated_duration": 3600.019449171182,
    "input_throughput": 5295.287225292305,
    "output_throughput": 4680.679434629008,
    "total_throughput": 9975.966659921312,
    "itl": 180.74307794721446,
    "ttft": 2180758.7986064274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0774727028235778,
    "arrivals": 2153264,
    "finished_requests": 77076,
    "scheduler_time": 132.27214038021816
}
#Debug simulation 
Total elapsed time: 53.000107186846435. Arrivals time: 0.43091542460024357 Scheduler time: 52.43390518706292 Scheduler overhead time: 0.05137427989393473 Adapter cache time: 0.01783052971586585 Engine time: 0.047867980785667896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 68.23662808025256,
    "estimated_duration": 3600.0668361967146,
    "input_throughput": 5303.952084448644,
    "output_throughput": 4683.173054034587,
    "total_throughput": 9987.12513848323,
    "itl": 181.53678534414465,
    "ttft": 2177581.230727381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5271833842224611,
    "arrivals": 2000260,
    "finished_requests": 77468,
    "scheduler_time": 131.94328393958497
}
#Debug simulation 
Total elapsed time: 68.23681392893195. Arrivals time: 0.4625625927001238 Scheduler time: 67.63909958256409 Scheduler overhead time: 0.05273231491446495 Adapter cache time: 0.01582622667774558 Engine time: 0.04850254952907562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 57.8128359769471,
    "estimated_duration": 3600.0135281333887,
    "input_throughput": 5312.162537876835,
    "output_throughput": 4686.25794546595,
    "total_throughput": 9998.420483342785,
    "itl": 181.8932305049899,
    "ttft": 2176855.3793421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6778512364416442,
    "arrivals": 2000260,
    "finished_requests": 77516,
    "scheduler_time": 131.84253896670847
}
#Debug simulation 
Total elapsed time: 57.81302713369951. Arrivals time: 0.44148355070501566 Scheduler time: 57.23690309608355 Scheduler overhead time: 0.05189884686842561 Adapter cache time: 0.015962208155542612 Engine time: 0.048400551080703735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 56.66568507393822,
    "estimated_duration": 3600.006102662632,
    "input_throughput": 5291.482141074908,
    "output_throughput": 4673.009856165936,
    "total_throughput": 9964.491997240844,
    "itl": 179.7756946099575,
    "ttft": 2177461.1223204527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.670914022345106,
    "arrivals": 2000260,
    "finished_requests": 77241,
    "scheduler_time": 132.3896317583941
}
#Debug simulation 
Total elapsed time: 56.66587530774996. Arrivals time: 0.4618064663372934 Scheduler time: 56.06842962792143 Scheduler overhead time: 0.05243516340851784 Adapter cache time: 0.016130951698869467 Engine time: 0.0483765909448266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 57.730185439344496,
    "estimated_duration": 3600.1515541429944,
    "input_throughput": 5312.266084462836,
    "output_throughput": 4686.430764444942,
    "total_throughput": 9998.696848907779,
    "itl": 181.89184167295133,
    "ttft": 2176926.307125571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6087986276252135,
    "arrivals": 2000260,
    "finished_requests": 77521,
    "scheduler_time": 131.84969859933145
}
#Debug simulation 
Total elapsed time: 57.73037744406611. Arrivals time: 0.4487312869168818 Scheduler time: 57.14826576784253 Scheduler overhead time: 0.05162728624418378 Adapter cache time: 0.015686060301959515 Engine time: 0.048037104308605194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 56.85917211836204,
    "estimated_duration": 3600.027488470299,
    "input_throughput": 5291.450707253999,
    "output_throughput": 4672.982096352899,
    "total_throughput": 9964.432803606898,
    "itl": 179.77659819365763,
    "ttft": 2177470.0067796228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6921664122492124,
    "arrivals": 2000260,
    "finished_requests": 77241,
    "scheduler_time": 132.38976517618016
}
#Debug simulation 
Total elapsed time: 56.859376025386155. Arrivals time: 0.46044285083189607 Scheduler time: 56.26424776669592 Scheduler overhead time: 0.05178451770916581 Adapter cache time: 0.016205447260290384 Engine time: 0.04839711496606469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 68.3303684941493,
    "estimated_duration": 3600.0314702435176,
    "input_throughput": 5304.004189360151,
    "output_throughput": 4683.219060543255,
    "total_throughput": 9987.223249903405,
    "itl": 181.53529838520106,
    "ttft": 2177567.1764942408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4920350971561696,
    "arrivals": 2000260,
    "finished_requests": 77468,
    "scheduler_time": 131.94306627338398
}
#Debug simulation 
Total elapsed time: 68.33055676799268. Arrivals time: 0.4727306105196476 Scheduler time: 67.72286581154913 Scheduler overhead time: 0.05243623303249478 Adapter cache time: 0.015721299219876528 Engine time: 0.04856988228857517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 56.784629901871085,
    "estimated_duration": 3600.049488369471,
    "input_throughput": 5291.418371203506,
    "output_throughput": 4672.953539763529,
    "total_throughput": 9964.371910967035,
    "itl": 179.77755677882845,
    "ttft": 2177479.068167665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7140475710853915,
    "arrivals": 2000260,
    "finished_requests": 77241,
    "scheduler_time": 132.38988391654198
}
#Debug simulation 
Total elapsed time: 56.784827628172934. Arrivals time: 0.45271758595481515 Scheduler time: 56.19395626941696 Scheduler overhead time: 0.05159715563058853 Adapter cache time: 0.016403242014348507 Engine time: 0.04801631160080433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 55.829710287973285,
    "estimated_duration": 3600.0226295093526,
    "input_throughput": 5304.522767014565,
    "output_throughput": 4675.808941316064,
    "total_throughput": 9980.331708330628,
    "itl": 180.94217923128045,
    "ttft": 2172970.4474497605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4782155803195354,
    "arrivals": 1885868,
    "finished_requests": 77244,
    "scheduler_time": 132.4817499552426
}
#Debug simulation 
Total elapsed time: 55.82989511685446. Arrivals time: 0.9368517873808742 Scheduler time: 54.761857233475894 Scheduler overhead time: 0.050308417063206434 Adapter cache time: 0.015876816119998693 Engine time: 0.046908642165362835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 55.36481499671936,
    "estimated_duration": 3600.12027501082,
    "input_throughput": 5304.378893269783,
    "output_throughput": 4675.682120078449,
    "total_throughput": 9980.061013348231,
    "itl": 180.94602386200077,
    "ttft": 2173012.098979608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.575353389657108,
    "arrivals": 1885868,
    "finished_requests": 77244,
    "scheduler_time": 132.48225764734593
}
#Debug simulation 
Total elapsed time: 55.36500983592123. Arrivals time: 0.43423008639365435 Scheduler time: 54.79989412194118 Scheduler overhead time: 0.050448513589799404 Adapter cache time: 0.01572358049452305 Engine time: 0.046754361130297184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 55.81607879791409,
    "estimated_duration": 3600.0455217790413,
    "input_throughput": 5292.460299386574,
    "output_throughput": 4671.743981639647,
    "total_throughput": 9964.204281026221,
    "itl": 179.95814254328903,
    "ttft": 2173319.3035119856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5735462933778857,
    "arrivals": 1885868,
    "finished_requests": 77155,
    "scheduler_time": 132.60380329374766
}
#Debug simulation 
Total elapsed time: 55.81626682402566. Arrivals time: 0.5805460340343416 Scheduler time: 55.09939478524029 Scheduler overhead time: 0.05420083599165082 Adapter cache time: 0.01534015266224742 Engine time: 0.04840429872274399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 55.207079587038606,
    "estimated_duration": 3600.0537025707367,
    "input_throughput": 5304.4769822082335,
    "output_throughput": 4675.768583113032,
    "total_throughput": 9980.245565321266,
    "itl": 180.94346669804105,
    "ttft": 2172983.429753952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.509160948069761,
    "arrivals": 1885868,
    "finished_requests": 77244,
    "scheduler_time": 132.4818776488332
}
#Debug simulation 
Total elapsed time: 55.20728698419407. Arrivals time: 0.4200418875552714 Scheduler time: 54.653729010373354 Scheduler overhead time: 0.05129146110266447 Adapter cache time: 0.015382867306470871 Engine time: 0.048393597826361656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 56.09024625085294,
    "estimated_duration": 3600.06589010803,
    "input_throughput": 5292.430355886697,
    "output_throughput": 4671.717550007206,
    "total_throughput": 9964.147905893904,
    "itl": 179.95896266549465,
    "ttft": 2173328.3545258883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5937926529906732,
    "arrivals": 1885868,
    "finished_requests": 77155,
    "scheduler_time": 132.60392526314283
}
#Debug simulation 
Total elapsed time: 56.09043140895665. Arrivals time: 0.9154742988757789 Scheduler time: 55.04191928682849 Scheduler overhead time: 0.05098873330280185 Adapter cache time: 0.015669788233935833 Engine time: 0.0479890089482069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 55.27364306803793,
    "estimated_duration": 3600.19248683843,
    "input_throughput": 5304.536651808488,
    "output_throughput": 4675.736661731293,
    "total_throughput": 9980.273313539781,
    "itl": 180.9413479239869,
    "ttft": 2173034.2931913887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4441942924377364,
    "arrivals": 1885868,
    "finished_requests": 77246,
    "scheduler_time": 132.48901700305737
}
#Debug simulation 
Total elapsed time: 55.273836807813495. Arrivals time: 0.4285098039545119 Scheduler time: 54.71476321434602 Scheduler overhead time: 0.04999153595417738 Adapter cache time: 0.015470185782760382 Engine time: 0.04732373496517539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 55.82485539279878,
    "estimated_duration": 3600.0854895304255,
    "input_throughput": 5292.401543077016,
    "output_throughput": 4671.692116454075,
    "total_throughput": 9964.093659531092,
    "itl": 179.9597837626073,
    "ttft": 2173336.994610624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.613284489884972,
    "arrivals": 1885868,
    "finished_requests": 77155,
    "scheduler_time": 132.60403284866226
}
#Debug simulation 
Total elapsed time: 55.8250519935973. Arrivals time: 0.5661105723120272 Scheduler time: 55.125788120087236 Scheduler overhead time: 0.05106028448790312 Adapter cache time: 0.015225072856992483 Engine time: 0.04864495899528265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.59545107977465,
    "estimated_duration": 3600.156608471606,
    "input_throughput": 5347.133498220936,
    "output_throughput": 4692.457255955852,
    "total_throughput": 10039.590754176788,
    "itl": 182.0450985333044,
    "ttft": 2171484.835006739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4812760680634682,
    "arrivals": 1866718,
    "finished_requests": 77466,
    "scheduler_time": 131.84987703762036
}
#Debug simulation 
Total elapsed time: 63.59564055176452. Arrivals time: 0.557498964946717 Scheduler time: 62.90708153927699 Scheduler overhead time: 0.05091620096936822 Adapter cache time: 0.014285960234701633 Engine time: 0.047643781173974276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 65.38176192715764,
    "estimated_duration": 3600.0400695584035,
    "input_throughput": 5323.210194810613,
    "output_throughput": 4681.996498463294,
    "total_throughput": 10005.206693273907,
    "itl": 181.24916596259555,
    "ttft": 2168753.8205048195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5162207452091445,
    "arrivals": 1866718,
    "finished_requests": 77204,
    "scheduler_time": 132.22228318036898
}
#Debug simulation 
Total elapsed time: 65.38195924414322. Arrivals time: 0.9164915471337736 Scheduler time: 64.33435161225498 Scheduler overhead time: 0.05070148082450032 Adapter cache time: 0.01455526752397418 Engine time: 0.04787580529227853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.177012495696545,
    "estimated_duration": 3600.1663586131012,
    "input_throughput": 5325.660286261369,
    "output_throughput": 4678.380197544105,
    "total_throughput": 10004.040483805475,
    "itl": 180.0479544867516,
    "ttft": 2171809.3593559605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5390558435581716,
    "arrivals": 1866718,
    "finished_requests": 77192,
    "scheduler_time": 132.42405097690667
}
#Debug simulation 
Total elapsed time: 63.177201923914254. Arrivals time: 0.4325409787707031 Scheduler time: 62.614113273099065 Scheduler overhead time: 0.050912912003695965 Adapter cache time: 0.01457921415567398 Engine time: 0.047118634916841984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 63.39549485500902,
    "estimated_duration": 3600.187680372993,
    "input_throughput": 5347.087349069972,
    "output_throughput": 4692.416757075776,
    "total_throughput": 10039.504106145749,
    "itl": 182.04644241255784,
    "ttft": 2171496.606921912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5121509983646633,
    "arrivals": 1866718,
    "finished_requests": 77466,
    "scheduler_time": 131.85007400865322
}
#Debug simulation 
Total elapsed time: 63.39568870095536. Arrivals time: 0.5653546433895826 Scheduler time: 62.69906857330352 Scheduler overhead time: 0.05096298921853304 Adapter cache time: 0.014186620246618986 Engine time: 0.048124589025974274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 63.086646103765815,
    "estimated_duration": 3600.186478223225,
    "input_throughput": 5325.630523856211,
    "output_throughput": 4678.354052457967,
    "total_throughput": 10003.984576314177,
    "itl": 180.04878742411674,
    "ttft": 2171817.005339338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5590506955981294,
    "arrivals": 1866718,
    "finished_requests": 77192,
    "scheduler_time": 132.42417573501243
}
#Debug simulation 
Total elapsed time: 63.086838375777006. Arrivals time: 0.5663120849058032 Scheduler time: 62.38699180772528 Scheduler overhead time: 0.051389312371611595 Adapter cache time: 0.014743493404239416 Engine time: 0.04882943816483021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.93752383394167,
    "estimated_duration": 3600.1222773575564,
    "input_throughput": 5347.184489002866,
    "output_throughput": 4692.5020036818505,
    "total_throughput": 10039.686492684717,
    "itl": 182.04365876707095,
    "ttft": 2171471.9589965036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4471843427326385,
    "arrivals": 1866718,
    "finished_requests": 77466,
    "scheduler_time": 131.84963764883153
}
#Debug simulation 
Total elapsed time: 63.937704166863114. Arrivals time: 0.9225469245575368 Scheduler time: 62.885581999551505 Scheduler overhead time: 0.0501710744574666 Adapter cache time: 0.014258446171879768 Engine time: 0.046980518847703934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 64.50136236613616,
    "estimated_duration": 3600.004937674184,
    "input_throughput": 5325.737973122527,
    "output_throughput": 4678.482194216458,
    "total_throughput": 10004.220167338986,
    "itl": 180.05243459768917,
    "ttft": 2171679.2580270823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5784167787060137,
    "arrivals": 1866718,
    "finished_requests": 77188,
    "scheduler_time": 132.4169039969426
}
#Debug simulation 
Total elapsed time: 64.5015478162095. Arrivals time: 0.42563968850299716 Scheduler time: 63.94377348339185 Scheduler overhead time: 0.05130760697647929 Adapter cache time: 0.014790148939937353 Engine time: 0.04752433253452182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 53.71185823529959,
    "estimated_duration": 3600.1061729708767,
    "input_throughput": 5311.0175315250835,
    "output_throughput": 4691.022205621106,
    "total_throughput": 10002.03973714619,
    "itl": 182.14447377601695,
    "ttft": 2171293.2699117786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3894614357454824,
    "arrivals": 1857211,
    "finished_requests": 77510,
    "scheduler_time": 131.96650564973973
}
#Debug simulation 
Total elapsed time: 53.712046790868044. Arrivals time: 0.41347686061635613 Scheduler time: 53.16977958008647 Scheduler overhead time: 0.049822136759757996 Adapter cache time: 0.013892566319555044 Engine time: 0.04729730961844325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 53.90306991385296,
    "estimated_duration": 3600.199476718811,
    "input_throughput": 5310.8798897515535,
    "output_throughput": 4690.900631814916,
    "total_throughput": 10001.780521566468,
    "itl": 182.14835322460263,
    "ttft": 2171333.8431519126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4821044060098991,
    "arrivals": 1857211,
    "finished_requests": 77510,
    "scheduler_time": 131.96716642737755
}
#Debug simulation 
Total elapsed time: 53.90328804962337. Arrivals time: 0.4280015495605767 Scheduler time: 53.34556238818914 Scheduler overhead time: 0.0502668940462172 Adapter cache time: 0.014289045240730047 Engine time: 0.04729606118053198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 53.481350286863744,
    "estimated_duration": 3600.138104239576,
    "input_throughput": 5292.862787002672,
    "output_throughput": 4678.1897006024465,
    "total_throughput": 9971.052487605119,
    "itl": 180.77597869844084,
    "ttft": 2173327.882956525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.491379575859764,
    "arrivals": 1857211,
    "finished_requests": 77304,
    "scheduler_time": 132.1905675679892
}
#Debug simulation 
Total elapsed time: 53.48154440103099. Arrivals time: 0.42687544180080295 Scheduler time: 52.927896599285305 Scheduler overhead time: 0.04853702522814274 Adapter cache time: 0.014714332297444344 Engine time: 0.04573891684412956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 54.08248574798927,
    "estimated_duration": 3600.1361348799737,
    "input_throughput": 5310.973330911959,
    "output_throughput": 4690.983164880525,
    "total_throughput": 10001.956495792485,
    "itl": 182.1457588896964,
    "ttft": 2171306.91780069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4191807269700762,
    "arrivals": 1857211,
    "finished_requests": 77510,
    "scheduler_time": 131.96674826756188
}
#Debug simulation 
Total elapsed time: 54.082683332730085. Arrivals time: 0.42609994299709797 Scheduler time: 53.52821410307661 Scheduler overhead time: 0.04970340896397829 Adapter cache time: 0.014279689639806747 Engine time: 0.046138595789670944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 53.19725334085524,
    "estimated_duration": 3600.157729347465,
    "input_throughput": 5292.83393465479,
    "output_throughput": 4678.164198948212,
    "total_throughput": 9970.998133603003,
    "itl": 180.77679709983036,
    "ttft": 2173336.1908994867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.510871412754063,
    "arrivals": 1857211,
    "finished_requests": 77304,
    "scheduler_time": 132.190700839001
}
#Debug simulation 
Total elapsed time: 53.197448573075235. Arrivals time: 0.4213872030377388 Scheduler time: 52.64920008601621 Scheduler overhead time: 0.04877104749903083 Adapter cache time: 0.014427004847675562 Engine time: 0.0463397903367877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 54.113031276036054,
    "estimated_duration": 3600.0739731802983,
    "input_throughput": 5311.065034341289,
    "output_throughput": 4691.064163073576,
    "total_throughput": 10002.129197414864,
    "itl": 182.1431302883431,
    "ttft": 2171279.3712386508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3574828338855764,
    "arrivals": 1857211,
    "finished_requests": 77510,
    "scheduler_time": 131.96628446095693
}
#Debug simulation 
Total elapsed time: 54.11322885239497. Arrivals time: 0.5593032040633261 Scheduler time: 53.42399588646367 Scheduler overhead time: 0.050118188839405775 Adapter cache time: 0.01432199077680707 Engine time: 0.04747797967866063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 53.06211740197614,
    "estimated_duration": 3600.17697954238,
    "input_throughput": 5292.805633800284,
    "output_throughput": 4678.139184741081,
    "total_throughput": 9970.944818541366,
    "itl": 180.7775909133568,
    "ttft": 2173344.5788408536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5299859882891178,
    "arrivals": 1857211,
    "finished_requests": 77304,
    "scheduler_time": 132.19083645840067
}
#Debug simulation 
Total elapsed time: 53.06231026304886. Arrivals time: 0.4213127736002207 Scheduler time: 52.513803821988404 Scheduler overhead time: 0.04851488443091512 Adapter cache time: 0.014596723020076752 Engine time: 0.046430012211203575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 67.56011126562953,
    "estimated_duration": 3600.0680132417283,
    "input_throughput": 5361.510373971919,
    "output_throughput": 4684.514830822342,
    "total_throughput": 10046.025204794261,
    "itl": 180.69282763314234,
    "ttft": 2169255.1451541404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.331312168610758,
    "arrivals": 1852456,
    "finished_requests": 77659,
    "scheduler_time": 132.2666354994134
}
#Debug simulation 
Total elapsed time: 67.56030427385122. Arrivals time: 0.4285524799488485 Scheduler time: 67.00056898780167 Scheduler overhead time: 0.05111523624509573 Adapter cache time: 0.014016871806234121 Engine time: 0.04806316876783967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 66.80431266408414,
    "estimated_duration": 3600.1573450459036,
    "input_throughput": 5363.884172055202,
    "output_throughput": 4685.378827459255,
    "total_throughput": 10049.262999514456,
    "itl": 180.7467702452794,
    "ttft": 2170020.632066992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3645264246850344,
    "arrivals": 1852456,
    "finished_requests": 77665,
    "scheduler_time": 132.30485980873402
}
#Debug simulation 
Total elapsed time: 66.80449562333524. Arrivals time: 0.9134076284244657 Scheduler time: 65.75936709949747 Scheduler overhead time: 0.051244213711470366 Adapter cache time: 0.013433623593300581 Engine time: 0.04863857012242079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 57.73418538272381,
    "estimated_duration": 3600.012188935824,
    "input_throughput": 5356.812973930678,
    "output_throughput": 4683.220532368189,
    "total_throughput": 10040.033506298867,
    "itl": 180.00102278589424,
    "ttft": 2171350.5165948854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3845357514545402,
    "arrivals": 1852456,
    "finished_requests": 77590,
    "scheduler_time": 132.36313641930852
}
#Debug simulation 
Total elapsed time: 57.73438002076. Arrivals time: 0.439249403309077 Scheduler time: 57.16636315314099 Scheduler overhead time: 0.04997713165357709 Adapter cache time: 0.013604045379906893 Engine time: 0.04705591732636094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 67.8561996826902,
    "estimated_duration": 3600.09767012785,
    "input_throughput": 5361.466206919474,
    "output_throughput": 4684.476240724071,
    "total_throughput": 10045.942447643545,
    "itl": 180.693893174951,
    "ttft": 2169266.6884100367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3607353900931756,
    "arrivals": 1852456,
    "finished_requests": 77659,
    "scheduler_time": 132.2668691640068
}
#Debug simulation 
Total elapsed time: 67.85640316689387. Arrivals time: 0.9221242498606443 Scheduler time: 66.80380567582324 Scheduler overhead time: 0.050809722393751144 Adapter cache time: 0.014070073142647743 Engine time: 0.047557707875967026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 57.411931827664375,
    "estimated_duration": 3600.030029860056,
    "input_throughput": 5356.786426792571,
    "output_throughput": 4683.197323399934,
    "total_throughput": 10039.983750192505,
    "itl": 180.00177366531636,
    "ttft": 2171357.5758603937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4022670353390327,
    "arrivals": 1852456,
    "finished_requests": 77590,
    "scheduler_time": 132.36324605966735
}
#Debug simulation 
Total elapsed time: 57.4121370408684. Arrivals time: 0.42286980105564 Scheduler time: 56.860962512437254 Scheduler overhead time: 0.04990590177476406 Adapter cache time: 0.013363046571612358 Engine time: 0.04684416111558676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 68.13394235493615,
    "estimated_duration": 3600.0371714304256,
    "input_throughput": 5361.556306467439,
    "output_throughput": 4684.554963441973,
    "total_throughput": 10046.111269909412,
    "itl": 180.69158249440454,
    "ttft": 2169243.6719016493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3006718782824371,
    "arrivals": 1852456,
    "finished_requests": 77659,
    "scheduler_time": 132.26643397837907
}
#Debug simulation 
Total elapsed time: 68.13412594981492. Arrivals time: 0.9362794510088861 Scheduler time: 67.06763650197536 Scheduler overhead time: 0.05043839057907462 Adapter cache time: 0.014134598430246115 Engine time: 0.04735477175563574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 57.66235072677955,
    "estimated_duration": 3600.048644974752,
    "input_throughput": 5356.758727946369,
    "output_throughput": 4683.173107545118,
    "total_throughput": 10039.931835491487,
    "itl": 180.00251804133026,
    "ttft": 2171365.01103778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.420752841942013,
    "arrivals": 1852456,
    "finished_requests": 77590,
    "scheduler_time": 132.3633753677746
}
#Debug simulation 
Total elapsed time: 57.66257041692734. Arrivals time: 0.43515603011474013 Scheduler time: 57.09857218014076 Scheduler overhead time: 0.050120145082473755 Adapter cache time: 0.01349921291694045 Engine time: 0.046923698391765356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 65.0252247271128,
    "estimated_duration": 3600.0959162481895,
    "input_throughput": 5300.9865414609,
    "output_throughput": 4695.302678939701,
    "total_throughput": 9996.2892204006,
    "itl": 181.73245778384907,
    "ttft": 2170474.093635758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2150136343413094,
    "arrivals": 1850068,
    "finished_requests": 77467,
    "scheduler_time": 132.1045538753779
}
#Debug simulation 
Total elapsed time: 65.0254163169302. Arrivals time: 0.4499176605604589 Scheduler time: 64.44625143473968 Scheduler overhead time: 0.04999887431040406 Adapter cache time: 0.013149129692465067 Engine time: 0.04754091380164027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.44136594701558,
    "estimated_duration": 3600.044883850935,
    "input_throughput": 5285.808542377032,
    "output_throughput": 4686.582680033776,
    "total_throughput": 9972.391222410808,
    "itl": 181.95421308614664,
    "ttft": 2168355.6510747983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2659657018980996,
    "arrivals": 1850068,
    "finished_requests": 77306,
    "scheduler_time": 131.94866175195884
}
#Debug simulation 
Total elapsed time: 68.44155083270743. Arrivals time: 0.4432631963863969 Scheduler time: 67.86570315808058 Scheduler overhead time: 0.05184923531487584 Adapter cache time: 0.013797438237816095 Engine time: 0.04871821030974388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 71.63158058095723,
    "estimated_duration": 3600.0376205410157,
    "input_throughput": 5301.818761863837,
    "output_throughput": 4690.222375360209,
    "total_throughput": 9992.041137224047,
    "itl": 180.39286655675153,
    "ttft": 2169205.527090797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2959530401416197,
    "arrivals": 1850068,
    "finished_requests": 77412,
    "scheduler_time": 132.32374859527755
}
#Debug simulation 
Total elapsed time: 71.63178366981447. Arrivals time: 0.4457334172911942 Scheduler time: 71.05207642400637 Scheduler overhead time: 0.052702441811561584 Adapter cache time: 0.01314104301854968 Engine time: 0.04952172329649329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 65.2945677624084,
    "estimated_duration": 3600.1249812883643,
    "input_throughput": 5300.943744783675,
    "output_throughput": 4695.264772155435,
    "total_throughput": 9996.20851693911,
    "itl": 181.7335918499937,
    "ttft": 2170485.361207335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2438447163393722,
    "arrivals": 1850068,
    "finished_requests": 77467,
    "scheduler_time": 132.10478783351977
}
#Debug simulation 
Total elapsed time: 65.29477527318522. Arrivals time: 0.42941576009616256 Scheduler time: 64.73562836134806 Scheduler overhead time: 0.05024807853624225 Adapter cache time: 0.013092528097331524 Engine time: 0.04812914924696088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 70.05681008985266,
    "estimated_duration": 3600.0539647488495,
    "input_throughput": 5301.794691661393,
    "output_throughput": 4690.201081799047,
    "total_throughput": 9991.99577346044,
    "itl": 180.39353837208083,
    "ttft": 2169212.767850597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3121752785891345,
    "arrivals": 1850068,
    "finished_requests": 77412,
    "scheduler_time": 132.3238705646727
}
#Debug simulation 
Total elapsed time: 70.05700938310474. Arrivals time: 0.4639692441560328 Scheduler time: 69.45866611646488 Scheduler overhead time: 0.05296240374445915 Adapter cache time: 0.013089158106595278 Engine time: 0.04943903023377061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 65.23314525280148,
    "estimated_duration": 3600.0677375567066,
    "input_throughput": 5301.028033698046,
    "output_throughput": 4695.339430327523,
    "total_throughput": 9996.367464025569,
    "itl": 181.73128660964736,
    "ttft": 2170463.1260992074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1870499670761585,
    "arrivals": 1850068,
    "finished_requests": 77467,
    "scheduler_time": 132.10433885111325
}
#Debug simulation 
Total elapsed time: 65.23332690587267. Arrivals time: 0.573005944956094 Scheduler time: 64.53103866335005 Scheduler overhead time: 0.05077431909739971 Adapter cache time: 0.012964251451194286 Engine time: 0.047654472291469574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 67.608889777679,
    "estimated_duration": 3600.0717080999507,
    "input_throughput": 5301.768561180583,
    "output_throughput": 4690.177965624904,
    "total_throughput": 9991.946526805486,
    "itl": 180.39424935741258,
    "ttft": 2169220.5999132334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3297808086872118,
    "arrivals": 1850068,
    "finished_requests": 77412,
    "scheduler_time": 132.324008385686
}
#Debug simulation 
Total elapsed time: 67.60909459600225. Arrivals time: 0.5717034037224948 Scheduler time: 66.90347216650844 Scheduler overhead time: 0.052350969053804874 Adapter cache time: 0.01324907410889864 Engine time: 0.04953240184113383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 50.18122065020725,
    "estimated_duration": 3600.1581612321374,
    "input_throughput": 5290.942827212022,
    "output_throughput": 4702.387017965348,
    "total_throughput": 9993.32984517737,
    "itl": 183.1949630650816,
    "ttft": 2174561.509701335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1323804652551221,
    "arrivals": 1848950,
    "finished_requests": 77313,
    "scheduler_time": 131.51109482410772
}
#Debug simulation 
Total elapsed time: 50.181412731297314. Arrivals time: 0.4088862407952547 Scheduler time: 49.64700372284278 Scheduler overhead time: 0.04886334203183651 Adapter cache time: 0.012816112022846937 Engine time: 0.04596777679398656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 50.27885243110359,
    "estimated_duration": 3600.036310222819,
    "input_throughput": 5290.941356872336,
    "output_throughput": 4702.439237050975,
    "total_throughput": 9993.380593923312,
    "itl": 183.197744677392,
    "ttft": 2174565.027318082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2088760340423377,
    "arrivals": 1848950,
    "finished_requests": 77311,
    "scheduler_time": 131.50439869003768
}
#Debug simulation 
Total elapsed time: 50.27904706541449. Arrivals time: 0.4236002410762012 Scheduler time: 49.7285603559576 Scheduler overhead time: 0.04971952270716429 Adapter cache time: 0.012914380058646202 Engine time: 0.046334374230355024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 47.86475662421435,
    "estimated_duration": 3600.1326502185098,
    "input_throughput": 5280.860136874701,
    "output_throughput": 4687.407559545273,
    "total_throughput": 9968.267696419975,
    "itl": 181.13807280648865,
    "ttft": 2174871.557326325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2668751330301238,
    "arrivals": 1848950,
    "finished_requests": 77022,
    "scheduler_time": 132.01319963504233
}
#Debug simulation 
Total elapsed time: 47.864954872988164. Arrivals time: 0.43373942375183105 Scheduler time: 47.30282367113978 Scheduler overhead time: 0.049763045739382505 Adapter cache time: 0.013838497921824455 Engine time: 0.04661290114745498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 50.21059527527541,
    "estimated_duration": 3600.1846294252387,
    "input_throughput": 5290.903928735735,
    "output_throughput": 4702.3524464918155,
    "total_throughput": 9993.25637522755,
    "itl": 183.19598943507395,
    "ttft": 2174575.5245212535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1586188098741705,
    "arrivals": 1848950,
    "finished_requests": 77313,
    "scheduler_time": 131.5113246725708
}
#Debug simulation 
Total elapsed time: 50.2107820501551. Arrivals time: 0.40931748785078526 Scheduler time: 49.676066854503006 Scheduler overhead time: 0.04893025429919362 Adapter cache time: 0.012939807493239641 Engine time: 0.04604907613247633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 47.84960832213983,
    "estimated_duration": 3600.1491250236763,
    "input_throughput": 5280.8359708918915,
    "output_throughput": 4687.386109287631,
    "total_throughput": 9968.222080179523,
    "itl": 181.1387299544731,
    "ttft": 2174880.10105581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2832231252640536,
    "arrivals": 1848950,
    "finished_requests": 77022,
    "scheduler_time": 132.01332644798748
}
#Debug simulation 
Total elapsed time: 47.849810409825295. Arrivals time: 0.42214932991191745 Scheduler time: 47.299391952808946 Scheduler overhead time: 0.04929305939003825 Adapter cache time: 0.013490025419741869 Engine time: 0.047151817474514246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 50.47280647791922,
    "estimated_duration": 3600.131884792083,
    "input_throughput": 5290.981444447857,
    "output_throughput": 4702.421339483154,
    "total_throughput": 9993.402783931011,
    "itl": 183.19391857737878,
    "ttft": 2174547.704337055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1063186091138026,
    "arrivals": 1848950,
    "finished_requests": 77313,
    "scheduler_time": 131.51088024016582
}
#Debug simulation 
Total elapsed time: 50.473001058679074. Arrivals time: 0.566218972671777 Scheduler time: 49.781902275048196 Scheduler overhead time: 0.048515068367123604 Adapter cache time: 0.012798908166587353 Engine time: 0.045977027621120214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 47.95282681891695,
    "estimated_duration": 3600.1660997617305,
    "input_throughput": 5280.811071816452,
    "output_throughput": 4687.364008320854,
    "total_throughput": 9968.175080137305,
    "itl": 181.1393845213317,
    "ttft": 2174888.996855302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3000741326436425,
    "arrivals": 1848950,
    "finished_requests": 77022,
    "scheduler_time": 132.01345017867354
}
#Debug simulation 
Total elapsed time: 47.953024917282164. Arrivals time: 0.41642773849889636 Scheduler time: 47.4088625786826 Scheduler overhead time: 0.04983564605936408 Adapter cache time: 0.013319452293217182 Engine time: 0.046576584689319134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.91752017987892,
    "estimated_duration": 3600.1560223876872,
    "input_throughput": 5328.88682620935,
    "output_throughput": 4686.944369930124,
    "total_throughput": 10015.831196139474,
    "itl": 181.63378759469973,
    "ttft": 2168933.0058400733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7383570385538285,
    "arrivals": 1692537,
    "finished_requests": 77253,
    "scheduler_time": 131.93197335294792
}
#Debug simulation 
Total elapsed time: 46.91770508000627. Arrivals time: 0.4315661326982081 Scheduler time: 46.356449463404715 Scheduler overhead time: 0.0485665095038712 Adapter cache time: 0.017121193930506706 Engine time: 0.0463056480512023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 48.30575799755752,
    "estimated_duration": 3600.0347209038896,
    "input_throughput": 5327.8208370124385,
    "output_throughput": 4685.95008321598,
    "total_throughput": 10013.770920228419,
    "itl": 181.6529777965479,
    "ttft": 2168934.6479028184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8260170282865928,
    "arrivals": 1692537,
    "finished_requests": 77241,
    "scheduler_time": 131.89247807319293
}
#Debug simulation 
Total elapsed time: 48.30594488978386. Arrivals time: 0.4391555027104914 Scheduler time: 47.73602168913931 Scheduler overhead time: 0.04911888297647238 Adapter cache time: 0.016995910555124283 Engine time: 0.04689757153391838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 46.64789618598297,
    "estimated_duration": 3600.077343258509,
    "input_throughput": 5317.370482566716,
    "output_throughput": 4677.3970096872035,
    "total_throughput": 9994.767492253919,
    "itl": 179.92359493016562,
    "ttft": 2169937.9150819387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8419924072735125,
    "arrivals": 1692537,
    "finished_requests": 77096,
    "scheduler_time": 132.350519590445
}
#Debug simulation 
Total elapsed time: 46.648075675126165. Arrivals time: 0.4113087016157806 Scheduler time: 46.10633336612955 Scheduler overhead time: 0.04928646236658096 Adapter cache time: 0.01652998011559248 Engine time: 0.04662034334614873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 46.9926891210489,
    "estimated_duration": 3600.196329034673,
    "input_throughput": 5328.827165696283,
    "output_throughput": 4686.891896399546,
    "total_throughput": 10015.719062095828,
    "itl": 181.63545352215175,
    "ttft": 2168950.263711167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.778433249918735,
    "arrivals": 1692537,
    "finished_requests": 77253,
    "scheduler_time": 131.93220378850796
}
#Debug simulation 
Total elapsed time: 46.99286035494879. Arrivals time: 0.42556189745664597 Scheduler time: 46.43793846713379 Scheduler overhead time: 0.049019360449165106 Adapter cache time: 0.016827079001814127 Engine time: 0.0457605249248445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 46.691928416956216,
    "estimated_duration": 3600.100830627309,
    "input_throughput": 5317.335791582367,
    "output_throughput": 4677.366493945073,
    "total_throughput": 9994.70228552744,
    "itl": 179.924622156329,
    "ttft": 2169947.4368220745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8653826115466696,
    "arrivals": 1692537,
    "finished_requests": 77096,
    "scheduler_time": 132.35061675499327
}
#Debug simulation 
Total elapsed time: 46.69210894498974. Arrivals time: 0.4239021623507142 Scheduler time: 46.1381197469309 Scheduler overhead time: 0.04881154699251056 Adapter cache time: 0.016764215659350157 Engine time: 0.04655059706419706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.87554386397824,
    "estimated_duration": 3600.115825458593,
    "input_throughput": 5328.946325652226,
    "output_throughput": 4686.996701793775,
    "total_throughput": 10015.943027446001,
    "itl": 181.6320556120736,
    "ttft": 2168916.2031816416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6983485675044123,
    "arrivals": 1692537,
    "finished_requests": 77253,
    "scheduler_time": 131.93178489482108
}
#Debug simulation 
Total elapsed time: 46.87573548499495. Arrivals time: 0.4043822642415762 Scheduler time: 46.34210372297093 Scheduler overhead time: 0.04892459884285927 Adapter cache time: 0.016731102019548416 Engine time: 0.04595019109547138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 46.63187552802265,
    "estimated_duration": 3600.125488088258,
    "input_throughput": 5317.299372851946,
    "output_throughput": 4677.334458400187,
    "total_throughput": 9994.633831252133,
    "itl": 179.92564777804398,
    "ttft": 2169957.8873030837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8899045998975588,
    "arrivals": 1692537,
    "finished_requests": 77096,
    "scheduler_time": 132.3507522276187
}
#Debug simulation 
Total elapsed time: 46.63204290205613. Arrivals time: 0.4205633248202503 Scheduler time: 46.08233623439446 Scheduler overhead time: 0.04841222194954753 Adapter cache time: 0.016825251281261444 Engine time: 0.046089508570730686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 93.16286447178572,
    "estimated_duration": 3600.1289073460607,
    "input_throughput": 5303.431207988323,
    "output_throughput": 4689.207090766334,
    "total_throughput": 9992.638298754657,
    "itl": 182.0746219115015,
    "ttft": 2157000.423778927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9426302251312869,
    "arrivals": 1577546,
    "finished_requests": 77477,
    "scheduler_time": 131.75669006972782
}
#Debug simulation 
Total elapsed time: 93.1630685357377. Arrivals time: 0.6796894231811166 Scheduler time: 92.33599588135257 Scheduler overhead time: 0.059375477489084005 Adapter cache time: 0.014076062012463808 Engine time: 0.05378161417320371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 64.08690904127434,
    "estimated_duration": 3600.1141613478217,
    "input_throughput": 5330.133195780639,
    "output_throughput": 4697.843524403166,
    "total_throughput": 10027.976720183806,
    "itl": 182.62411498939477,
    "ttft": 2165454.1578847636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7880934481555653,
    "arrivals": 1577546,
    "finished_requests": 77704,
    "scheduler_time": 131.4997665677773
}
#Debug simulation 
Total elapsed time: 64.08711602538824. Arrivals time: 0.6398114636540413 Scheduler time: 63.3045440451242 Scheduler overhead time: 0.05474236002191901 Adapter cache time: 0.01770036481320858 Engine time: 0.05130213359370828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 93.49805100727826,
    "estimated_duration": 3600.0264312007284,
    "input_throughput": 5294.113908392391,
    "output_throughput": 4681.597294378384,
    "total_throughput": 9975.711202770775,
    "itl": 180.3612918398607,
    "ttft": 2157381.9648586344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.049477761778986,
    "arrivals": 1577546,
    "finished_requests": 77370,
    "scheduler_time": 132.12524412423994
}
#Debug simulation 
Total elapsed time: 93.49824989307672. Arrivals time: 0.4747147732414305 Scheduler time: 92.87584330141544 Scheduler overhead time: 0.059229944832623005 Adapter cache time: 0.01470300741493702 Engine time: 0.054233663249760866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 64.28031932376325,
    "estimated_duration": 3600.0374152683457,
    "input_throughput": 5330.246824273534,
    "output_throughput": 4697.943673660216,
    "total_throughput": 10028.190497933749,
    "itl": 182.62062861531555,
    "ttft": 2165432.5583435306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7116861236072058,
    "arrivals": 1577546,
    "finished_requests": 77704,
    "scheduler_time": 131.49942781282658
}
#Debug simulation 
Total elapsed time: 64.28053096681833. Arrivals time: 0.6483407528139651 Scheduler time: 63.48881336208433 Scheduler overhead time: 0.05525856791064143 Adapter cache time: 0.017445261124521494 Engine time: 0.051511527970433235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 93.62277901312336,
    "estimated_duration": 3600.040490704907,
    "input_throughput": 5294.093232898099,
    "output_throughput": 4681.579010990491,
    "total_throughput": 9975.67224388859,
    "itl": 180.36185623295273,
    "ttft": 2157386.999876522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0634364320710352,
    "arrivals": 1577546,
    "finished_requests": 77370,
    "scheduler_time": 132.12534495814424
}
#Debug simulation 
Total elapsed time: 93.62297307094559. Arrivals time: 0.663589971140027 Scheduler time: 92.81174603430554 Scheduler overhead time: 0.059171032160520554 Adapter cache time: 0.014446040149778128 Engine time: 0.054381432477384806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 93.03526084497571,
    "estimated_duration": 3600.1070204843104,
    "input_throughput": 5303.463450214732,
    "output_throughput": 4689.235598815325,
    "total_throughput": 9992.699049030058,
    "itl": 182.07379216415015,
    "ttft": 2156991.742486645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 1577546,
    "finished_requests": 77477,
    "scheduler_time": 131.75649794224495
}
#Debug simulation 
Total elapsed time: 93.03545849910006. Arrivals time: 0.684023754671216 Scheduler time: 92.20522874919698 Scheduler overhead time: 0.05864869710057974 Adapter cache time: 0.013691427651792765 Engine time: 0.05416586808860302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 93.23139870166779,
    "estimated_duration": 3600.0536984067853,
    "input_throughput": 5294.073810186386,
    "output_throughput": 4681.561835441158,
    "total_throughput": 9975.635645627544,
    "itl": 180.36232828568257,
    "ttft": 2157392.0790996333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0765148258581805,
    "arrivals": 1577546,
    "finished_requests": 77370,
    "scheduler_time": 132.12547426625153
}
#Debug simulation 
Total elapsed time: 93.23160593770444. Arrivals time: 0.6881225425750017 Scheduler time: 92.39542519161478 Scheduler overhead time: 0.05896625109016895 Adapter cache time: 0.014292820822447538 Engine time: 0.0547380312345922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.15227383514866,
    "estimated_duration": 3600.005379361497,
    "input_throughput": 5357.089217300147,
    "output_throughput": 4696.566870963613,
    "total_throughput": 10053.656088263759,
    "itl": 182.20895089059846,
    "ttft": 2160352.064746378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1935902201337794,
    "arrivals": 1558275,
    "finished_requests": 77859,
    "scheduler_time": 131.58010414496258
}
#Debug simulation 
Total elapsed time: 79.15247990516946. Arrivals time: 0.4684843150898814 Scheduler time: 78.54059481015429 Scheduler overhead time: 0.056831339839845896 Adapter cache time: 0.0153076546266675 Engine time: 0.05234217178076506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.89937761984766,
    "estimated_duration": 3600.0753704900967,
    "input_throughput": 5355.9736993437045,
    "output_throughput": 4695.993072416844,
    "total_throughput": 10051.96677176055,
    "itl": 182.21769232185633,
    "ttft": 2160454.243984061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2748059697169876,
    "arrivals": 1558275,
    "finished_requests": 77855,
    "scheduler_time": 131.57831385352495
}
#Debug simulation 
Total elapsed time: 78.8995649968274. Arrivals time: 0.48066242039203644 Scheduler time: 78.27519845869392 Scheduler overhead time: 0.05712851230055094 Adapter cache time: 0.01515967445448041 Engine time: 0.052339133340865374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 41.165528825018555,
    "estimated_duration": 3600.0069883361857,
    "input_throughput": 5333.1827027573145,
    "output_throughput": 4679.954248585104,
    "total_throughput": 10013.13695134242,
    "itl": 180.22997200090057,
    "ttft": 2159791.1801938517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8068274624645821,
    "arrivals": 1558275,
    "finished_requests": 77590,
    "scheduler_time": 132.10853215666887
}
#Debug simulation 
Total elapsed time: 41.165729022119194. Arrivals time: 0.4253038172610104 Scheduler time: 40.610926817171276 Scheduler overhead time: 0.048958905041217804 Adapter cache time: 0.01655494049191475 Engine time: 0.046165520790964365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.55202749790624,
    "estimated_duration": 3600.0332597841416,
    "input_throughput": 5357.04772937469,
    "output_throughput": 4696.530498447058,
    "total_throughput": 10053.578227821748,
    "itl": 182.21007195822853,
    "ttft": 2160362.955979066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2212799830012955,
    "arrivals": 1558275,
    "finished_requests": 77859,
    "scheduler_time": 131.58029480470304
}
#Debug simulation 
Total elapsed time: 78.5522339087911. Arrivals time: 0.4892556485719979 Scheduler time: 77.9187952876091 Scheduler overhead time: 0.05641179997473955 Adapter cache time: 0.015230235178023577 Engine time: 0.052759552374482155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 41.270200414117426,
    "estimated_duration": 3600.0304856856565,
    "input_throughput": 5333.147893147158,
    "output_throughput": 4679.923702588085,
    "total_throughput": 10013.071595735244,
    "itl": 180.2310008005856,
    "ttft": 2159803.959880406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8302176667377392,
    "arrivals": 1558275,
    "finished_requests": 77590,
    "scheduler_time": 132.10863930186557
}
#Debug simulation 
Total elapsed time: 41.27039611618966. Arrivals time: 0.5459034652449191 Scheduler time: 40.59364159964025 Scheduler overhead time: 0.04942409507930279 Adapter cache time: 0.016853339970111847 Engine time: 0.04663102515041828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.29235199699178,
    "estimated_duration": 3600.178061550154,
    "input_throughput": 5357.195302638871,
    "output_throughput": 4696.609365126661,
    "total_throughput": 10053.804667765531,
    "itl": 182.2074472200975,
    "ttft": 2160403.024715026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.166119615011844,
    "arrivals": 1558275,
    "finished_requests": 77863,
    "scheduler_time": 131.5872835279686
}
#Debug simulation 
Total elapsed time: 79.29255403298885. Arrivals time: 0.4677029810845852 Scheduler time: 78.68218124378473 Scheduler overhead time: 0.05596779054030776 Adapter cache time: 0.015135462861508131 Engine time: 0.05225431779399514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 40.806257363874465,
    "estimated_duration": 3600.0545038099544,
    "input_throughput": 5333.112312516681,
    "output_throughput": 4679.8924800082395,
    "total_throughput": 10013.00479252492,
    "itl": 180.23200773970746,
    "ttft": 2159817.180666148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.854110886156555,
    "arrivals": 1558275,
    "finished_requests": 77590,
    "scheduler_time": 132.10876420674558
}
#Debug simulation 
Total elapsed time: 40.806464163120836. Arrivals time: 0.4228377719409764 Scheduler time: 40.25302062090486 Scheduler overhead time: 0.04988100798800588 Adapter cache time: 0.01645196322351694 Engine time: 0.046274293679744005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 40.797408980783075,
    "estimated_duration": 3600.080374386387,
    "input_throughput": 5328.71575215033,
    "output_throughput": 4685.712607978985,
    "total_throughput": 10014.428360129315,
    "itl": 181.86308068985122,
    "ttft": 2162863.601996096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6496028939797756,
    "arrivals": 1548789,
    "finished_requests": 77544,
    "scheduler_time": 131.7805389912653
}
#Debug simulation 
Total elapsed time: 40.797551803756505. Arrivals time: 0.4013682813383639 Scheduler time: 40.27048985287547 Scheduler overhead time: 0.04725460195913911 Adapter cache time: 0.016078247223049402 Engine time: 0.0449466765858233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 40.57374455919489,
    "estimated_duration": 3600.1895886563657,
    "input_throughput": 5328.554101829851,
    "output_throughput": 4685.570463608749,
    "total_throughput": 10014.1245654386,
    "itl": 181.86773895766845,
    "ttft": 2162908.150547997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7583228282723629,
    "arrivals": 1548789,
    "finished_requests": 77544,
    "scheduler_time": 131.7810333269126
}
#Debug simulation 
Total elapsed time: 40.57388719310984. Arrivals time: 0.40060707507655025 Scheduler time: 40.04727838328108 Scheduler overhead time: 0.047113907523453236 Adapter cache time: 0.016221366357058287 Engine time: 0.045299523044377565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 45.83133159019053,
    "estimated_duration": 3600.065281501834,
    "input_throughput": 5316.815808410848,
    "output_throughput": 4676.812969618208,
    "total_throughput": 9993.628778029055,
    "itl": 180.24453942648702,
    "ttft": 2164423.432111322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7358313692547487,
    "arrivals": 1548789,
    "finished_requests": 77410,
    "scheduler_time": 132.18363261564284
}
#Debug simulation 
Total elapsed time: 45.8315262561664. Arrivals time: 0.42158355144783854 Scheduler time: 45.27724556531757 Scheduler overhead time: 0.0503674834035337 Adapter cache time: 0.01649521989747882 Engine time: 0.04734377283602953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 40.737724270205945,
    "estimated_duration": 3600.114873958314,
    "input_throughput": 5328.664687554115,
    "output_throughput": 4685.667705223154,
    "total_throughput": 10014.332392777269,
    "itl": 181.86459661471025,
    "ttft": 2162877.6241510706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6839584803162062,
    "arrivals": 1548789,
    "finished_requests": 77544,
    "scheduler_time": 131.78068297679675
}
#Debug simulation 
Total elapsed time: 40.737907622009516. Arrivals time: 0.5180032290518284 Scheduler time: 40.09374013543129 Scheduler overhead time: 0.047331375535577536 Adapter cache time: 0.01607077056542039 Engine time: 0.0452036140486598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 45.748152827844024,
    "estimated_duration": 3600.088020805986,
    "input_throughput": 5316.782225706455,
    "output_throughput": 4676.783429375868,
    "total_throughput": 9993.565655082324,
    "itl": 180.2455075806572,
    "ttft": 2164432.108005557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7584670508094173,
    "arrivals": 1548789,
    "finished_requests": 77410,
    "scheduler_time": 132.18373623825772
}
#Debug simulation 
Total elapsed time: 45.74831569986418. Arrivals time: 0.4119884795509279 Scheduler time: 45.20546408323571 Scheduler overhead time: 0.049590913113206625 Adapter cache time: 0.0159483440220356 Engine time: 0.0473498972132802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 40.80384902423248,
    "estimated_duration": 3600.0422261610556,
    "input_throughput": 5328.772218446132,
    "output_throughput": 4685.762260624476,
    "total_throughput": 10014.534479070608,
    "itl": 181.86146103658157,
    "ttft": 2162847.9855828364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6116371089522523,
    "arrivals": 1548789,
    "finished_requests": 77544,
    "scheduler_time": 131.7803565508824
}
#Debug simulation 
Total elapsed time: 40.80404399801046. Arrivals time: 0.4202060173265636 Scheduler time: 40.259174935054034 Scheduler overhead time: 0.04635124187916517 Adapter cache time: 0.016024392563849688 Engine time: 0.044801974669098854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 45.711285723838955,
    "estimated_duration": 3600.1101237089447,
    "input_throughput": 5316.7495832823215,
    "output_throughput": 4676.754716229118,
    "total_throughput": 9993.50429951144,
    "itl": 180.2464397778183,
    "ttft": 2164440.627490698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7804739634320113,
    "arrivals": 1548789,
    "finished_requests": 77410,
    "scheduler_time": 132.18383222861203
}
#Debug simulation 
Total elapsed time: 45.71147345425561. Arrivals time: 0.4241744102910161 Scheduler time: 45.15599501831457 Scheduler overhead time: 0.04957990860566497 Adapter cache time: 0.016011621337383986 Engine time: 0.04756435425952077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 44.48417920200154,
    "estimated_duration": 3600.151049367633,
    "input_throughput": 5314.788945691847,
    "output_throughput": 4688.966870699814,
    "total_throughput": 10003.755816391662,
    "itl": 182.08205366138014,
    "ttft": 2160204.9484767285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5363648474542597,
    "arrivals": 1544103,
    "finished_requests": 77426,
    "scheduler_time": 131.72736512235986
}
#Debug simulation 
Total elapsed time: 44.484358462970704. Arrivals time: 0.40412831166759133 Scheduler time: 43.951998573262244 Scheduler overhead time: 0.0487002725712955 Adapter cache time: 0.015100699849426746 Engine time: 0.04634087113663554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 44.32109021069482,
    "estimated_duration": 3600.050135695712,
    "input_throughput": 5314.24876845578,
    "output_throughput": 4688.432206163762,
    "total_throughput": 10002.680974619543,
    "itl": 182.08558064976356,
    "ttft": 2160195.8236034475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.636250298444652,
    "arrivals": 1544103,
    "finished_requests": 77418,
    "scheduler_time": 131.72053163514408
}
#Debug simulation 
Total elapsed time: 44.321256486698985. Arrivals time: 0.4127192464657128 Scheduler time: 43.78159865131602 Scheduler overhead time: 0.04803646448999643 Adapter cache time: 0.014482804574072361 Engine time: 0.046043445356190205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.10953115718439,
    "estimated_duration": 3600.1264858432814,
    "input_throughput": 5321.5702490831845,
    "output_throughput": 4684.192921085634,
    "total_throughput": 10005.763170168819,
    "itl": 180.58409523941705,
    "ttft": 2144139.186698936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6095994326658571,
    "arrivals": 1544103,
    "finished_requests": 77391,
    "scheduler_time": 132.028162922881
}
#Debug simulation 
Total elapsed time: 105.10974252223969. Arrivals time: 0.4934564307332039 Scheduler time: 104.46758272917941 Scheduler overhead time: 0.060429373756051064 Adapter cache time: 0.012507428880780935 Engine time: 0.055525357369333506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 44.322732113767415,
    "estimated_duration": 3600.184494646339,
    "input_throughput": 5314.739571945081,
    "output_throughput": 4688.923310764464,
    "total_throughput": 10003.662882709545,
    "itl": 182.083498090055,
    "ttft": 2160218.5837930054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5696492615388644,
    "arrivals": 1544103,
    "finished_requests": 77426,
    "scheduler_time": 131.72752598692918
}
#Debug simulation 
Total elapsed time: 44.32289217878133. Arrivals time: 0.41130662290379405 Scheduler time: 43.78426998062059 Scheduler overhead time: 0.04821010306477547 Adapter cache time: 0.014728920068591833 Engine time: 0.04650647705420852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 110.1771363420412,
    "estimated_duration": 3600.1345386673506,
    "input_throughput": 5321.558345731093,
    "output_throughput": 4684.182443426787,
    "total_throughput": 10005.74078915788,
    "itl": 180.58432941675184,
    "ttft": 2144144.445153231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6175219212099927,
    "arrivals": 1544103,
    "finished_requests": 77391,
    "scheduler_time": 132.02829325840796
}
#Debug simulation 
Total elapsed time: 110.1773458798416. Arrivals time: 0.49740723753347993 Scheduler time: 109.52867779880762 Scheduler overhead time: 0.062409769743680954 Adapter cache time: 0.01260053412988782 Engine time: 0.05588995898142457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 44.261115735862404,
    "estimated_duration": 3600.1154825230606,
    "input_throughput": 5314.841452416502,
    "output_throughput": 4689.013194701559,
    "total_throughput": 10003.854647118062,
    "itl": 182.08055620889408,
    "ttft": 2160190.3737252383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5010052480408758,
    "arrivals": 1544103,
    "finished_requests": 77426,
    "scheduler_time": 131.72715787713005
}
#Debug simulation 
Total elapsed time: 44.261297846678644. Arrivals time: 0.39683874510228634 Scheduler time: 43.73623966705054 Scheduler overhead time: 0.0489388694986701 Adapter cache time: 0.014959995169192553 Engine time: 0.04621541639789939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.11454091407359,
    "estimated_duration": 3600.142948351159,
    "input_throughput": 5321.545914940512,
    "output_throughput": 4684.171501502032,
    "total_throughput": 10005.717416442543,
    "itl": 180.5846025146004,
    "ttft": 2144149.7160332305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6258216711133731,
    "arrivals": 1544103,
    "finished_requests": 77391,
    "scheduler_time": 132.02840319231527
}
#Debug simulation 
Total elapsed time: 105.1147570698522. Arrivals time: 0.4866210320033133 Scheduler time: 104.47793327504769 Scheduler overhead time: 0.06123613379895687 Adapter cache time: 0.012805332895368338 Engine time: 0.05560793308541179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 40.34037129813805,
    "estimated_duration": 3600.046539822886,
    "input_throughput": 5303.515882030604,
    "output_throughput": 4696.741226248663,
    "total_throughput": 10000.257108279267,
    "itl": 182.78676114060474,
    "ttft": 2153671.7763991468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3190702176350266,
    "arrivals": 1541713,
    "finished_requests": 77597,
    "scheduler_time": 131.4487547946874
}
#Debug simulation 
Total elapsed time: 40.34057345194742. Arrivals time: 0.4081413606181741 Scheduler time: 39.81056230561808 Scheduler overhead time: 0.04643071396276355 Adapter cache time: 0.014046899508684874 Engine time: 0.0441743703559041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.3742643147707,
    "estimated_duration": 3600.065591910762,
    "input_throughput": 5303.861697104686,
    "output_throughput": 4695.1683430380635,
    "total_throughput": 9999.03004014275,
    "itl": 182.84992407439464,
    "ttft": 2142469.972728441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8732462550792882,
    "arrivals": 1541713,
    "finished_requests": 77508,
    "scheduler_time": 131.4737261592326
}
#Debug simulation 
Total elapsed time: 103.3744600857608. Arrivals time: 0.486446110997349 Scheduler time: 102.74001811305061 Scheduler overhead time: 0.05990049475803971 Adapter cache time: 0.013216819614171982 Engine time: 0.0549934022128582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 70.2303018658422,
    "estimated_duration": 3600.199397558721,
    "input_throughput": 5308.400421643114,
    "output_throughput": 4689.708301003796,
    "total_throughput": 9998.10872264691,
    "itl": 181.1294957571383,
    "ttft": 2156065.368978061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9186313254758762,
    "arrivals": 1541713,
    "finished_requests": 77553,
    "scheduler_time": 131.8587559365262
}
#Debug simulation 
Total elapsed time: 70.23050967371091. Arrivals time: 0.43188442941755056 Scheduler time: 69.66090645687655 Scheduler overhead time: 0.055084540974348783 Adapter cache time: 0.01266058487817645 Engine time: 0.0513740642927587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 40.424058477859944,
    "estimated_duration": 3600.0780786416585,
    "input_throughput": 5303.469420086556,
    "output_throughput": 4696.70008001041,
    "total_throughput": 10000.169500096967,
    "itl": 182.7880830918036,
    "ttft": 2153689.431312857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3504095701873289,
    "arrivals": 1541713,
    "finished_requests": 77597,
    "scheduler_time": 131.44895426088237
}
#Debug simulation 
Total elapsed time: 40.424238599836826. Arrivals time: 0.4959320784546435 Scheduler time: 39.806343152187765 Scheduler overhead time: 0.046483243349939585 Adapter cache time: 0.013946892227977514 Engine time: 0.04424713784828782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 70.39251479087397,
    "estimated_duration": 3600.0070173213285,
    "input_throughput": 5308.442152487684,
    "output_throughput": 4689.58363657909,
    "total_throughput": 9998.025789066774,
    "itl": 181.1288933027053,
    "ttft": 2155970.4107109844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9300749200396287,
    "arrivals": 1541713,
    "finished_requests": 77549,
    "scheduler_time": 131.85137830283642
}
#Debug simulation 
Total elapsed time: 70.39273385191336. Arrivals time: 0.4352213265374303 Scheduler time: 69.81937004998326 Scheduler overhead time: 0.05524080200120807 Adapter cache time: 0.012693169061094522 Engine time: 0.05127545911818743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 40.45488716894761,
    "estimated_duration": 3600.016002069863,
    "input_throughput": 5303.560870013454,
    "output_throughput": 4696.781067161453,
    "total_throughput": 10000.341937174908,
    "itl": 182.78550418973342,
    "ttft": 2153654.611423299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2887116771028289,
    "arrivals": 1541713,
    "finished_requests": 77597,
    "scheduler_time": 131.4485755821593
}
#Debug simulation 
Total elapsed time: 40.45507459389046. Arrivals time: 0.3867148160934448 Scheduler time: 39.945865055546165 Scheduler overhead time: 0.04627561895176768 Adapter cache time: 0.0140662738122046 Engine time: 0.044695476070046425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 69.70932533917949,
    "estimated_duration": 3600.0193338854083,
    "input_throughput": 5308.423990983017,
    "output_throughput": 4689.567592343766,
    "total_throughput": 9997.991583326782,
    "itl": 181.12933829926678,
    "ttft": 2155976.1501693884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9422730373218703,
    "arrivals": 1541713,
    "finished_requests": 77549,
    "scheduler_time": 131.85149674964978
}
#Debug simulation 
Total elapsed time: 69.7095387452282. Arrivals time: 0.44819875294342637 Scheduler time: 69.12259500846267 Scheduler overhead time: 0.05554326483979821 Adapter cache time: 0.012859008740633726 Engine time: 0.051389563363045454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 56.56234513921663,
    "estimated_duration": 3600.1557211948952,
    "input_throughput": 5331.182728293152,
    "output_throughput": 4703.232668608049,
    "total_throughput": 10034.4153969012,
    "itl": 181.83002242265937,
    "ttft": 2158831.8301493097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3374331440986238,
    "arrivals": 1540502,
    "finished_requests": 77527,
    "scheduler_time": 132.03848944965813
}
#Debug simulation 
Total elapsed time: 56.562524097040296. Arrivals time: 0.8693531434983015 Scheduler time: 55.55902538076043 Scheduler overhead time: 0.05193249927833676 Adapter cache time: 0.014921968802809715 Engine time: 0.04846200067549944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 56.15626463666558,
    "estimated_duration": 3600.042348684597,
    "input_throughput": 5331.157564580489,
    "output_throughput": 4703.198562702075,
    "total_throughput": 10034.356127282565,
    "itl": 181.8338789961608,
    "ttft": 2158803.1650397773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4263704071752783,
    "arrivals": 1540502,
    "finished_requests": 77523,
    "scheduler_time": 132.03163364949725
}
#Debug simulation 
Total elapsed time: 56.15644717076793. Arrivals time: 0.4289736393839121 Scheduler time: 55.59381893603131 Scheduler overhead time: 0.051575851161032915 Adapter cache time: 0.015072809997946024 Engine time: 0.04839359410107136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 34.47501778509468,
    "estimated_duration": 3600.146570946858,
    "input_throughput": 5310.901271158894,
    "output_throughput": 4682.4982449440495,
    "total_throughput": 9993.399516102943,
    "itl": 180.69188807880286,
    "ttft": 2161335.8980703778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3889365516789338,
    "arrivals": 1540502,
    "finished_requests": 77322,
    "scheduler_time": 132.03248973459304
}
#Debug simulation 
Total elapsed time: 34.47521006083116. Arrivals time: 0.5325696016661823 Scheduler time: 33.819989420473576 Scheduler overhead time: 0.04663324123248458 Adapter cache time: 0.01394228683784604 Engine time: 0.044854598585516214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 55.488683021161705,
    "estimated_duration": 3600.186900942241,
    "input_throughput": 5331.136557098406,
    "output_throughput": 4703.191935832126,
    "total_throughput": 10034.328492930532,
    "itl": 181.83122626224463,
    "ttft": 2158844.561137907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3683498719567406,
    "arrivals": 1540502,
    "finished_requests": 77527,
    "scheduler_time": 132.03875246909993
}
#Debug simulation 
Total elapsed time: 55.48887111293152. Arrivals time: 0.440703134983778 Scheduler time: 54.91310455882922 Scheduler overhead time: 0.052388808224350214 Adapter cache time: 0.014950588811188936 Engine time: 0.04896207991987467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 34.72163652069867,
    "estimated_duration": 3600.1628966611474,
    "input_throughput": 5310.877187732876,
    "output_throughput": 4682.47701114694,
    "total_throughput": 9993.354198879817,
    "itl": 180.69254949776317,
    "ttft": 2161344.6124479803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4051587901264488,
    "arrivals": 1540502,
    "finished_requests": 77322,
    "scheduler_time": 132.0325932104337
}
#Debug simulation 
Total elapsed time: 34.72175330482423. Arrivals time: 0.3853672267869115 Scheduler time: 34.21521705202758 Scheduler overhead time: 0.04596212226897478 Adapter cache time: 0.013751986902207136 Engine time: 0.04415511852130294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 56.1052645011805,
    "estimated_duration": 3600.12473865547,
    "input_throughput": 5331.228608253167,
    "output_throughput": 4703.2731444532365,
    "total_throughput": 10034.501752706405,
    "itl": 181.82877988268461,
    "ttft": 2158820.420896849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3066519788722413,
    "arrivals": 1540502,
    "finished_requests": 77527,
    "scheduler_time": 132.03828807539801
}
#Debug simulation 
Total elapsed time: 56.105441282037646. Arrivals time: 0.4329029740765691 Scheduler time: 55.53842590888962 Scheduler overhead time: 0.05214494513347745 Adapter cache time: 0.015184267424046993 Engine time: 0.04809211753308773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 34.378942620009184,
    "estimated_duration": 3600.1824070233356,
    "input_throughput": 5310.848406652988,
    "output_throughput": 4682.451635537569,
    "total_throughput": 9993.300042190556,
    "itl": 180.69332814230685,
    "ttft": 2161354.934041711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4245248732343327,
    "arrivals": 1540502,
    "finished_requests": 77322,
    "scheduler_time": 132.03273748951366
}
#Debug simulation 
Total elapsed time: 34.37919513974339. Arrivals time: 0.5246073557063937 Scheduler time: 33.73216866515577 Scheduler overhead time: 0.046875239349901676 Adapter cache time: 0.013570836745202541 Engine time: 0.044453686103224754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.33922519301996,
    "estimated_duration": 3600.1336497917036,
    "input_throughput": 5305.486922993849,
    "output_throughput": 4699.9388483755265,
    "total_throughput": 10005.425771369375,
    "itl": 183.25959008670043,
    "ttft": 2148704.8813526714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8385736418375734,
    "arrivals": 1423678,
    "finished_requests": 77329,
    "scheduler_time": 131.32982995486188
}
#Debug simulation 
Total elapsed time: 81.33941838238388. Arrivals time: 0.4735319893807173 Scheduler time: 80.72256186278537 Scheduler overhead time: 0.057509861420840025 Adapter cache time: 0.012957769446074963 Engine time: 0.0529926186427474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.67041494278237,
    "estimated_duration": 3600.0234828466987,
    "input_throughput": 5303.92595797773,
    "output_throughput": 4699.408790139946,
    "total_throughput": 10003.334748117677,
    "itl": 183.27053622502012,
    "ttft": 2148705.6682272423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8758277100557503,
    "arrivals": 1423678,
    "finished_requests": 77309,
    "scheduler_time": 131.32428276444105
}
#Debug simulation 
Total elapsed time: 81.67061249772087. Arrivals time: 0.4815398622304201 Scheduler time: 81.04511159472167 Scheduler overhead time: 0.05850417772307992 Adapter cache time: 0.012685146182775497 Engine time: 0.05339236091822386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.81091216299683,
    "estimated_duration": 3600.049822723255,
    "input_throughput": 5291.34899182876,
    "output_throughput": 4686.783747686217,
    "total_throughput": 9978.132739514976,
    "itl": 181.3125509897249,
    "ttft": 2149889.5625254298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8838119195587977,
    "arrivals": 1423678,
    "finished_requests": 77115,
    "scheduler_time": 131.81982513705086
}
#Debug simulation 
Total elapsed time: 80.8110970929265. Arrivals time: 0.4764742814004421 Scheduler time: 80.19150428380817 Scheduler overhead time: 0.058158790692687035 Adapter cache time: 0.01280938321724534 Engine time: 0.052891114726662636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 81.69128327723593,
    "estimated_duration": 3600.15217363071,
    "input_throughput": 5305.459624707312,
    "output_throughput": 4699.914665811466,
    "total_throughput": 10005.374290518777,
    "itl": 183.26019888396547,
    "ttft": 2148713.229452293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8568645500997106,
    "arrivals": 1423678,
    "finished_requests": 77329,
    "scheduler_time": 131.33006288558403
}
#Debug simulation 
Total elapsed time: 81.6914810850285. Arrivals time: 0.474540276452899 Scheduler time: 81.07311722403392 Scheduler overhead time: 0.05817408440634608 Adapter cache time: 0.012898406013846397 Engine time: 0.05299920774996281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 81.30175553867593,
    "estimated_duration": 3600.0607423456822,
    "input_throughput": 5291.332942229251,
    "output_throughput": 4686.7695318402675,
    "total_throughput": 9978.10247406952,
    "itl": 181.31293917591987,
    "ttft": 2149893.7641036017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8946267451904758,
    "arrivals": 1423678,
    "finished_requests": 77115,
    "scheduler_time": 131.8199299338597
}
#Debug simulation 
Total elapsed time: 81.30194684909657. Arrivals time: 0.9019441031850874 Scheduler time: 80.25675300508738 Scheduler overhead time: 0.05761007871478796 Adapter cache time: 0.01277740253135562 Engine time: 0.05288677103817463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.66736996266991,
    "estimated_duration": 3600.114148556438,
    "input_throughput": 5305.51566195723,
    "output_throughput": 4699.964307183062,
    "total_throughput": 10005.479969140293,
    "itl": 183.25890391355793,
    "ttft": 2148697.043108763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8192737808031972,
    "arrivals": 1423678,
    "finished_requests": 77329,
    "scheduler_time": 131.32962858060176
}
#Debug simulation 
Total elapsed time: 81.66756628174335. Arrivals time: 0.47236836794763803 Scheduler time: 81.05341112148017 Scheduler overhead time: 0.057246745098382235 Adapter cache time: 0.012852403800934553 Engine time: 0.0524740656837821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.69882954098284,
    "estimated_duration": 3600.072071226255,
    "input_throughput": 5291.31629120733,
    "output_throughput": 4686.75478328767,
    "total_throughput": 9978.071074495001,
    "itl": 181.31332673253846,
    "ttft": 2149898.7366696093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9058188321813985,
    "arrivals": 1423678,
    "finished_requests": 77115,
    "scheduler_time": 131.8200667274533
}
#Debug simulation 
Total elapsed time: 80.69901246484369. Arrivals time: 0.459987910464406 Scheduler time: 80.09438976366073 Scheduler overhead time: 0.05809531873092055 Adapter cache time: 0.012794177513569593 Engine time: 0.05415257718414068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 65.62484948895872,
    "estimated_duration": 3600.078702074418,
    "input_throughput": 5310.53668048527,
    "output_throughput": 4700.734178463575,
    "total_throughput": 10011.270858948845,
    "itl": 183.36916110194858,
    "ttft": 2152867.9887795486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8477551050693717,
    "arrivals": 1404624,
    "finished_requests": 77310,
    "scheduler_time": 131.34314110661492
}
#Debug simulation 
Total elapsed time: 65.62503890274093. Arrivals time: 0.44544880697503686 Scheduler time: 65.04021083796397 Scheduler overhead time: 0.056167254224419594 Adapter cache time: 0.01282804599031806 Engine time: 0.051558589562773705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.46622710628435,
    "estimated_duration": 3600.032302275741,
    "input_throughput": 5304.536847607797,
    "output_throughput": 4697.840346962701,
    "total_throughput": 10002.377194570498,
    "itl": 183.33701015757353,
    "ttft": 2137114.4010298173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44382901408476755,
    "arrivals": 1404624,
    "finished_requests": 77260,
    "scheduler_time": 131.33660007191585
}
#Debug simulation 
Total elapsed time: 90.46644619712606. Arrivals time: 0.883063712157309 Scheduler time: 89.43822998553514 Scheduler overhead time: 0.059708571527153254 Adapter cache time: 0.010723373387008905 Engine time: 0.05482157599180937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.0467002778314,
    "estimated_duration": 3600.042928255803,
    "input_throughput": 5306.811718841399,
    "output_throughput": 4688.600479599792,
    "total_throughput": 9995.412198441192,
    "itl": 181.3352511029121,
    "ttft": 2140162.1233767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.454075889475645,
    "arrivals": 1404624,
    "finished_requests": 77217,
    "scheduler_time": 131.8497940398591
}
#Debug simulation 
Total elapsed time: 84.04690648755059. Arrivals time: 0.4608375574462116 Scheduler time: 83.44095914345235 Scheduler overhead time: 0.05964781017974019 Adapter cache time: 0.010838981252163649 Engine time: 0.05405628914013505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 90.60991050861776,
    "estimated_duration": 3600.0143713188645,
    "input_throughput": 5304.563268452731,
    "output_throughput": 4697.8637459728125,
    "total_throughput": 10002.427014425544,
    "itl": 183.33661277771157,
    "ttft": 2137101.2984314277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42625941539183276,
    "arrivals": 1404624,
    "finished_requests": 77260,
    "scheduler_time": 131.3362387137319
}
#Debug simulation 
Total elapsed time: 90.61013552360237. Arrivals time: 0.46918842010200024 Scheduler time: 89.99481652677059 Scheduler overhead time: 0.06038451613858342 Adapter cache time: 0.01079587871208787 Engine time: 0.05504314927384257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.00265918578953,
    "estimated_duration": 3600.048447217043,
    "input_throughput": 5306.803583370831,
    "output_throughput": 4688.59329186199,
    "total_throughput": 9995.396875232822,
    "itl": 181.33537170770808,
    "ttft": 2140166.159096515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4594833022914833,
    "arrivals": 1404624,
    "finished_requests": 77217,
    "scheduler_time": 131.84990558828306
}
#Debug simulation 
Total elapsed time: 84.00286785978824. Arrivals time: 0.47189044626429677 Scheduler time: 83.38390468945727 Scheduler overhead time: 0.06090200133621693 Adapter cache time: 0.010939270723611116 Engine time: 0.05511779710650444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 65.53927865903825,
    "estimated_duration": 3600.058988352611,
    "input_throughput": 5310.565760687318,
    "output_throughput": 4700.759919421204,
    "total_throughput": 10011.325680108523,
    "itl": 183.36844071313925,
    "ttft": 2152859.957308367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8282439316879038,
    "arrivals": 1404624,
    "finished_requests": 77310,
    "scheduler_time": 131.34293855816085
}
#Debug simulation 
Total elapsed time: 65.53948727203533. Arrivals time: 0.541552388574928 Scheduler time: 64.85957108996809 Scheduler overhead time: 0.055377548560500145 Adapter cache time: 0.012666920199990273 Engine time: 0.05160433333367109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.67146541597322,
    "estimated_duration": 3600.0547287735844,
    "input_throughput": 5306.794323793054,
    "output_throughput": 4688.58511096862,
    "total_throughput": 9995.379434761673,
    "itl": 181.33551207703647,
    "ttft": 2140170.731057453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4656452378258106,
    "arrivals": 1404624,
    "finished_requests": 77217,
    "scheduler_time": 131.85002520929035
}
#Debug simulation 
Total elapsed time: 83.67167072184384. Arrivals time: 0.4738977919332683 Scheduler time: 83.05244355881587 Scheduler overhead time: 0.05912597943097353 Adapter cache time: 0.011019446421414614 Engine time: 0.05494140554219484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.670092293061316,
    "estimated_duration": 3600.1744650584833,
    "input_throughput": 5370.200579900489,
    "output_throughput": 4693.3411599889005,
    "total_throughput": 10063.54173988939,
    "itl": 181.99326329794775,
    "ttft": 2148613.561841425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8691785192769009,
    "arrivals": 1395198,
    "finished_requests": 78056,
    "scheduler_time": 131.57765664555205
}
#Debug simulation 
Total elapsed time: 63.67029345408082. Arrivals time: 0.44729459565132856 Scheduler time: 63.08582146698609 Scheduler overhead time: 0.05401616171002388 Adapter cache time: 0.012819116469472647 Engine time: 0.05136295175179839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.3805979588069,
    "estimated_duration": 3600.0262970044623,
    "input_throughput": 5370.318826861624,
    "output_throughput": 4693.279883554988,
    "total_throughput": 10063.598710416612,
    "itl": 181.9946677437933,
    "ttft": 2148615.1239061668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9268073942558892,
    "arrivals": 1395198,
    "finished_requests": 78053,
    "scheduler_time": 131.5706211064732
}
#Debug simulation 
Total elapsed time: 63.3807927290909. Arrivals time: 0.45543658500537276 Scheduler time: 62.78732100920752 Scheduler overhead time: 0.054878865368664265 Adapter cache time: 0.012729723006486893 Engine time: 0.05136263323947787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 62.042253114748746,
    "estimated_duration": 3600.1046454928023,
    "input_throughput": 5347.330396104312,
    "output_throughput": 4686.110172136587,
    "total_throughput": 10033.440568240898,
    "itl": 180.4941686473475,
    "ttft": 2143966.618069577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.012963826991623,
    "arrivals": 1395198,
    "finished_requests": 77773,
    "scheduler_time": 131.9951864970118
}
#Debug simulation 
Total elapsed time: 62.04243519715965. Arrivals time: 0.4411210175603628 Scheduler time: 61.46218839241192 Scheduler overhead time: 0.05584682431071997 Adapter cache time: 0.013227976858615875 Engine time: 0.05141480779275298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 63.40477397385985,
    "estimated_duration": 3600.1917884502354,
    "input_throughput": 5370.174739585889,
    "output_throughput": 4693.318576584371,
    "total_throughput": 10063.493316170261,
    "itl": 181.99389384667998,
    "ttft": 2148620.3128246497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8863564577302923,
    "arrivals": 1395198,
    "finished_requests": 78056,
    "scheduler_time": 131.57780209882594
}
#Debug simulation 
Total elapsed time: 63.404961480759084. Arrivals time: 0.4423029497265816 Scheduler time: 62.8228814965114 Scheduler overhead time: 0.05570013402029872 Adapter cache time: 0.012705464847385883 Engine time: 0.05201892973855138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 61.72896021883935,
    "estimated_duration": 3600.1180891441813,
    "input_throughput": 5347.310427968858,
    "output_throughput": 4686.092673146299,
    "total_throughput": 10033.403101115156,
    "itl": 180.49468814119385,
    "ttft": 2143971.564866208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0262937283515985,
    "arrivals": 1395198,
    "finished_requests": 77773,
    "scheduler_time": 131.99530024704939
}
#Debug simulation 
Total elapsed time: 61.72915104590356. Arrivals time: 0.4454723666422069 Scheduler time: 61.14461612375453 Scheduler overhead time: 0.05533177359029651 Adapter cache time: 0.013783528935164213 Engine time: 0.051100997254252434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.612738308962435,
    "estimated_duration": 3600.154272951961,
    "input_throughput": 5370.230699627015,
    "output_throughput": 4693.367483428804,
    "total_throughput": 10063.59818305582,
    "itl": 181.9925472428332,
    "ttft": 2148605.585045103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.849174283752219,
    "arrivals": 1395198,
    "finished_requests": 78056,
    "scheduler_time": 131.5774687745222
}
#Debug simulation 
Total elapsed time: 63.61292207427323. Arrivals time: 0.43792880792170763 Scheduler time: 63.037498036399484 Scheduler overhead time: 0.05486321868374944 Adapter cache time: 0.012711639050394297 Engine time: 0.051321092527359724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 61.87911800900474,
    "estimated_duration": 3600.1307685857423,
    "input_throughput": 5347.291595066823,
    "output_throughput": 4686.076169012971,
    "total_throughput": 10033.367764079794,
    "itl": 180.49516674809536,
    "ttft": 2143976.4357916336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0388691069930844,
    "arrivals": 1395198,
    "finished_requests": 77773,
    "scheduler_time": 131.995404309987
}
#Debug simulation 
Total elapsed time: 61.87929662084207. Arrivals time: 0.43628839822486043 Scheduler time: 61.30362758459523 Scheduler overhead time: 0.05521891778334975 Adapter cache time: 0.013704146724194288 Engine time: 0.05156693747267127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 44.27539233490825,
    "estimated_duration": 3600.1553314583152,
    "input_throughput": 5326.887935202429,
    "output_throughput": 4685.795041284131,
    "total_throughput": 10012.68297648656,
    "itl": 181.55171582392975,
    "ttft": 2154935.707520907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4567921661120053,
    "arrivals": 1390337,
    "finished_requests": 77447,
    "scheduler_time": 131.8461889091301
}
#Debug simulation 
Total elapsed time: 44.27556954883039. Arrivals time: 0.41429145028814673 Scheduler time: 43.73109603533521 Scheduler overhead time: 0.049900739919394255 Adapter cache time: 0.01513804355636239 Engine time: 0.047011610586196184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 43.614682035986334,
    "estimated_duration": 3600.1942194305097,
    "input_throughput": 5334.072227647124,
    "output_throughput": 4685.3072284162035,
    "total_throughput": 10019.379456063329,
    "itl": 181.58977303359183,
    "ttft": 2155070.2781442064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5633931884775,
    "arrivals": 1390337,
    "finished_requests": 77500,
    "scheduler_time": 131.81911836496712
}
#Debug simulation 
Total elapsed time: 43.61483095912263. Arrivals time: 0.4014232996851206 Scheduler time: 43.08275228831917 Scheduler overhead time: 0.04983496945351362 Adapter cache time: 0.015408180188387632 Engine time: 0.04740324383601546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 43.06676029134542,
    "estimated_duration": 3600.0521010854495,
    "input_throughput": 5324.376276171297,
    "output_throughput": 4678.844229760272,
    "total_throughput": 10003.22050593157,
    "itl": 180.3525684603839,
    "ttft": 2156760.12797304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5704944831319247,
    "arrivals": 1390337,
    "finished_requests": 77385,
    "scheduler_time": 132.10219499161954
}
#Debug simulation 
Total elapsed time: 43.0669089499861. Arrivals time: 0.40377767803147435 Scheduler time: 42.53313839389011 Scheduler overhead time: 0.049967051949352026 Adapter cache time: 0.015158968046307564 Engine time: 0.04703572578728199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 43.79694218095392,
    "estimated_duration": 3600.0272794775424,
    "input_throughput": 5327.482963624482,
    "output_throughput": 4685.208386100847,
    "total_throughput": 10012.69134972533,
    "itl": 181.5289757266244,
    "ttft": 2154813.1688406817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5005993925034955,
    "arrivals": 1390337,
    "finished_requests": 77440,
    "scheduler_time": 131.83968618326088
}
#Debug simulation 
Total elapsed time: 43.79713786812499. Arrivals time: 0.4115495556034148 Scheduler time: 43.25517152203247 Scheduler overhead time: 0.050079668406397104 Adapter cache time: 0.015289062168449163 Engine time: 0.047137226443737745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 43.05551938107237,
    "estimated_duration": 3600.0728388967455,
    "input_throughput": 5324.345605705608,
    "output_throughput": 4678.8172778087255,
    "total_throughput": 10003.162883514333,
    "itl": 180.35341977466794,
    "ttft": 2156767.2874001297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.591118104103957,
    "arrivals": 1390337,
    "finished_requests": 77385,
    "scheduler_time": 132.10230918197988
}
#Debug simulation 
Total elapsed time: 43.055699774995446. Arrivals time: 0.40393345849588513 Scheduler time: 42.52282149763778 Scheduler overhead time: 0.04957254137843847 Adapter cache time: 0.014898308087140322 Engine time: 0.046518833842128515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 43.956752746831626,
    "estimated_duration": 3600.1216119858104,
    "input_throughput": 5326.937827920127,
    "output_throughput": 4685.838929395169,
    "total_throughput": 10012.776757315296,
    "itl": 181.5503830791612,
    "ttft": 2154923.8077035137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.423263940373422,
    "arrivals": 1390337,
    "finished_requests": 77447,
    "scheduler_time": 131.8459976622927
}
#Debug simulation 
Total elapsed time: 43.95690922997892. Arrivals time: 0.395221708342433 Scheduler time: 43.43060270138085 Scheduler overhead time: 0.05040518008172512 Adapter cache time: 0.015473229344934225 Engine time: 0.047161271795630455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 42.9988847640343,
    "estimated_duration": 3600.0932170595934,
    "input_throughput": 5324.315467491048,
    "output_throughput": 4678.790793577714,
    "total_throughput": 10003.106261068762,
    "itl": 180.35422617069847,
    "ttft": 2156774.3725149557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6113644637167441,
    "arrivals": 1390337,
    "finished_requests": 77385,
    "scheduler_time": 132.10244098524925
}
#Debug simulation 
Total elapsed time: 42.99904260691255. Arrivals time: 0.4006729070097208 Scheduler time: 42.467318563722074 Scheduler overhead time: 0.04979560011997819 Adapter cache time: 0.0166396819986403 Engine time: 0.0469873184338212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 58.78124332195148,
    "estimated_duration": 3600.0765009316306,
    "input_throughput": 5330.233120055696,
    "output_throughput": 4711.59876619581,
    "total_throughput": 10041.831886251506,
    "itl": 182.36020214470818,
    "ttft": 2143239.6778597445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0375053451932035,
    "arrivals": 1387991,
    "finished_requests": 77628,
    "scheduler_time": 131.68637951573498
}
#Debug simulation 
Total elapsed time: 58.78142872918397. Arrivals time: 0.4276078836992383 Scheduler time: 58.216569452080876 Scheduler overhead time: 0.053751814644783735 Adapter cache time: 0.01366131380200386 Engine time: 0.05108976364135742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 59.16588153876364,
    "estimated_duration": 3600.0157590241038,
    "input_throughput": 5330.241111278291,
    "output_throughput": 4711.6654857639005,
    "total_throughput": 10041.90659704219,
    "itl": 182.36340664588639,
    "ttft": 2143198.404979038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.108421163850004,
    "arrivals": 1387991,
    "finished_requests": 77627,
    "scheduler_time": 131.6812161247227
}
#Debug simulation 
Total elapsed time: 59.16606248309836. Arrivals time: 0.5143521847203374 Scheduler time: 58.50235178600997 Scheduler overhead time: 0.053385911509394646 Adapter cache time: 0.013293077237904072 Engine time: 0.06349603552371264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 57.97729666810483,
    "estimated_duration": 3600.0945797092318,
    "input_throughput": 5319.14831013874,
    "output_throughput": 4697.934908522879,
    "total_throughput": 10017.083218661619,
    "itl": 180.78730819856978,
    "ttft": 2144330.6726088584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0846344151906728,
    "arrivals": 1387991,
    "finished_requests": 77467,
    "scheduler_time": 132.03533775832548
}
#Debug simulation 
Total elapsed time: 57.977475587278605. Arrivals time: 0.41916660126298666 Scheduler time: 57.4215601105243 Scheduler overhead time: 0.05382959917187691 Adapter cache time: 0.013556899968534708 Engine time: 0.050568193197250366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 59.03999035805464,
    "estimated_duration": 3600.096939242185,
    "input_throughput": 5330.202859492808,
    "output_throughput": 4711.572017716418,
    "total_throughput": 10041.774877209225,
    "itl": 182.3608953621914,
    "ttft": 2143248.070875625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0577553443633974,
    "arrivals": 1387991,
    "finished_requests": 77628,
    "scheduler_time": 131.68656782708754
}
#Debug simulation 
Total elapsed time: 59.04016718501225. Arrivals time: 0.4171237670816481 Scheduler time: 58.48524563247338 Scheduler overhead time: 0.05467554274946451 Adapter cache time: 0.013519445899873972 Engine time: 0.05072864284738898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 58.03292932594195,
    "estimated_duration": 3600.1100498050664,
    "input_throughput": 5319.125453133544,
    "output_throughput": 4697.91472094465,
    "total_throughput": 10017.040174078194,
    "itl": 180.78786838390272,
    "ttft": 2144336.5928927856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.099976377133285,
    "arrivals": 1387991,
    "finished_requests": 77467,
    "scheduler_time": 132.0354658922388
}
#Debug simulation 
Total elapsed time: 58.0331084090285. Arrivals time: 0.5293282805941999 Scheduler time: 57.366355835460126 Scheduler overhead time: 0.05400186078622937 Adapter cache time: 0.013313153758645058 Engine time: 0.05092715471982956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 59.13681235490367,
    "estimated_duration": 3600.0524153912206,
    "input_throughput": 5330.268781076814,
    "output_throughput": 4711.630288348652,
    "total_throughput": 10041.899069425466,
    "itl": 182.35936229551973,
    "ttft": 2143230.3638046784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0136270499718385,
    "arrivals": 1387991,
    "finished_requests": 77628,
    "scheduler_time": 131.68617227050515
}
#Debug simulation 
Total elapsed time: 59.137075788807124. Arrivals time: 0.4216994899325073 Scheduler time: 58.579140490852296 Scheduler overhead time: 0.05412774905562401 Adapter cache time: 0.013549880590289831 Engine time: 0.050052125472575426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 58.10101465880871,
    "estimated_duration": 3600.123626989267,
    "input_throughput": 5319.105393059628,
    "output_throughput": 4697.89700364932,
    "total_throughput": 10017.00239670895,
    "itl": 180.78833096492778,
    "ttft": 2144342.0417638957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1134320322796745,
    "arrivals": 1387991,
    "finished_requests": 77467,
    "scheduler_time": 132.03558742131125
}
#Debug simulation 
Total elapsed time: 58.10118963383138. Arrivals time: 0.4001649748533964 Scheduler time: 57.56405240157619 Scheduler overhead time: 0.05409461399540305 Adapter cache time: 0.013402842916548252 Engine time: 0.05052175745368004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.14860779466107,
    "estimated_duration": 3600.1466366587056,
    "input_throughput": 5290.969208320549,
    "output_throughput": 4702.938993538859,
    "total_throughput": 9993.908201859407,
    "itl": 183.52856206439435,
    "ttft": 2136465.6105272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45601267384597977,
    "arrivals": 1386791,
    "finished_requests": 77493,
    "scheduler_time": 131.25092487579627
}
#Debug simulation 
Total elapsed time: 82.14883379172534. Arrivals time: 0.4311245200224221 Scheduler time: 81.57364459428936 Scheduler overhead time: 0.05935270246118307 Adapter cache time: 0.011113413609564304 Engine time: 0.05416726507246494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.46970254089683,
    "estimated_duration": 3600.174684788756,
    "input_throughput": 5290.9279876006,
    "output_throughput": 4702.902354026596,
    "total_throughput": 9993.830341627197,
    "itl": 183.5292583516703,
    "ttft": 2136486.078446037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48351685855537657,
    "arrivals": 1386791,
    "finished_requests": 77493,
    "scheduler_time": 131.2514688211374
}
#Debug simulation 
Total elapsed time: 81.46990365674719. Arrivals time: 0.4347551055252552 Scheduler time: 80.89025755925104 Scheduler overhead time: 0.05956302024424076 Adapter cache time: 0.010936986654996872 Engine time: 0.054883381351828575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.57780053373426,
    "estimated_duration": 3600.1840233914054,
    "input_throughput": 5276.472779329025,
    "output_throughput": 4690.591617061925,
    "total_throughput": 9967.06439639095,
    "itl": 181.68336984688915,
    "ttft": 2137604.078323987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48484832545742546,
    "arrivals": 1386791,
    "finished_requests": 77290,
    "scheduler_time": 131.71265201931362
}
#Debug simulation 
Total elapsed time: 80.57801445573568. Arrivals time: 0.4344025463797152 Scheduler time: 79.99632998509333 Scheduler overhead time: 0.0604939260520041 Adapter cache time: 0.011028393171727657 Engine time: 0.055333107709884644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 81.71966124791652,
    "estimated_duration": 3600.1555331830227,
    "input_throughput": 5290.956133542032,
    "output_throughput": 4702.927371871202,
    "total_throughput": 9993.883505413234,
    "itl": 183.5287333752429,
    "ttft": 2136472.1877888246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4647214739071208,
    "arrivals": 1386791,
    "finished_requests": 77493,
    "scheduler_time": 131.2511126000519
}
#Debug simulation 
Total elapsed time: 81.71988876862451. Arrivals time: 0.52993423352018 Scheduler time: 81.04354100162163 Scheduler overhead time: 0.05952971754595637 Adapter cache time: 0.011477685067802668 Engine time: 0.05496174190193415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 80.86024028481916,
    "estimated_duration": 3600.189917412391,
    "input_throughput": 5276.464140995491,
    "output_throughput": 4690.583937898864,
    "total_throughput": 9967.048078894355,
    "itl": 181.6835275778215,
    "ttft": 2137608.35117735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4906329996325083,
    "arrivals": 1386791,
    "finished_requests": 77290,
    "scheduler_time": 131.71276136612397
}
#Debug simulation 
Total elapsed time: 80.86045344080776. Arrivals time: 0.5235535278916359 Scheduler time: 80.19097904721275 Scheduler overhead time: 0.05999097740277648 Adapter cache time: 0.011019933503121138 Engine time: 0.055129371117800474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.3779395497404,
    "estimated_duration": 3600.1359365819585,
    "input_throughput": 5290.984933775808,
    "output_throughput": 4702.9529712911035,
    "total_throughput": 9993.93790506691,
    "itl": 183.52829750626452,
    "ttft": 2136457.810645355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4455174939404247,
    "arrivals": 1386791,
    "finished_requests": 77493,
    "scheduler_time": 131.25071997895435
}
#Debug simulation 
Total elapsed time: 82.37815116299316. Arrivals time: 0.8663987568579614 Scheduler time: 81.3672039611265 Scheduler overhead time: 0.059660824947059155 Adapter cache time: 0.010986243840306997 Engine time: 0.05436155153438449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.80086825508624,
    "estimated_duration": 3600.0001644334643,
    "input_throughput": 5276.534203433667,
    "output_throughput": 4690.803119076387,
    "total_throughput": 9967.337322510053,
    "itl": 181.68337478782863,
    "ttft": 2137575.5078054355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.496543427594006,
    "arrivals": 1386791,
    "finished_requests": 77288,
    "scheduler_time": 131.70560635742314
}
#Debug simulation 
Total elapsed time: 80.80107388086617. Arrivals time: 0.5316260494291782 Scheduler time: 80.12289525475353 Scheduler overhead time: 0.05982194701209664 Adapter cache time: 0.011070206295698881 Engine time: 0.055759016424417496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 39.26826595701277,
    "estimated_duration": 3600.001957971079,
    "input_throughput": 5292.209899446131,
    "output_throughput": 4694.029947006978,
    "total_throughput": 9986.239846453109,
    "itl": 182.99344864784987,
    "ttft": 2148708.724052757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4751550925756025,
    "arrivals": 1289387,
    "finished_requests": 77131,
    "scheduler_time": 131.33607568362058
}
#Debug simulation 
Total elapsed time: 39.26838585501537. Arrivals time: 0.38822960015386343 Scheduler time: 38.74940579943359 Scheduler overhead time: 0.05073833931237459 Adapter cache time: 0.015322723891586065 Engine time: 0.0468302215449512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 38.67882451089099,
    "estimated_duration": 3600.110492618115,
    "input_throughput": 5299.912055233677,
    "output_throughput": 4697.458045989448,
    "total_throughput": 9997.370101223125,
    "itl": 183.36576793840456,
    "ttft": 2149555.0644883187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5851407311786954,
    "arrivals": 1289387,
    "finished_requests": 77202,
    "scheduler_time": 131.20870137961205
}
#Debug simulation 
Total elapsed time: 38.6789387781173. Arrivals time: 0.3935520015656948 Scheduler time: 38.154625304508954 Scheduler overhead time: 0.050720002967864275 Adapter cache time: 0.015132449567317963 Engine time: 0.04677641578018665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 23.36940704798326,
    "estimated_duration": 3600.0449367125366,
    "input_throughput": 5285.742076702155,
    "output_throughput": 4687.978427128068,
    "total_throughput": 9973.720503830222,
    "itl": 181.19110234551627,
    "ttft": 2152083.432521743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5224892593361528,
    "arrivals": 1289387,
    "finished_requests": 76971,
    "scheduler_time": 131.77182452140153
}
#Debug simulation 
Total elapsed time: 23.36954779876396. Arrivals time: 0.3459443533793092 Scheduler time: 22.90819493867457 Scheduler overhead time: 0.04328740108758211 Adapter cache time: 0.013772135134786367 Engine time: 0.0415304796770215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 38.538829759228975,
    "estimated_duration": 3600.0481751218417,
    "input_throughput": 5300.003797686468,
    "output_throughput": 4697.539359852495,
    "total_throughput": 9997.543157538963,
    "itl": 183.3631479919341,
    "ttft": 2149540.5661374438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.522625647457312,
    "arrivals": 1289387,
    "finished_requests": 77202,
    "scheduler_time": 131.20837624386064
}
#Debug simulation 
Total elapsed time: 38.539007196202874. Arrivals time: 0.38152700290083885 Scheduler time: 38.026301237754524 Scheduler overhead time: 0.05063261557370424 Adapter cache time: 0.015332895331084728 Engine time: 0.04698817431926727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 23.439282364677638,
    "estimated_duration": 3600.0644072988907,
    "input_throughput": 5285.713489297624,
    "output_throughput": 4687.953072668129,
    "total_throughput": 9973.666561965752,
    "itl": 181.19194483959532,
    "ttft": 2152091.299396965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5418553424440367,
    "arrivals": 1289387,
    "finished_requests": 76971,
    "scheduler_time": 131.7719290246619
}
#Debug simulation 
Total elapsed time: 23.439415260683745. Arrivals time: 0.3409497970715165 Scheduler time: 22.98347166646272 Scheduler overhead time: 0.04324967972934246 Adapter cache time: 0.013756824657320976 Engine time: 0.04137750202789903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 39.38381664408371,
    "estimated_duration": 3600.1686966355874,
    "input_throughput": 5292.063401863553,
    "output_throughput": 4694.009760096127,
    "total_throughput": 9986.07316195968,
    "itl": 182.99248533478965,
    "ttft": 2148737.0850949534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4412042421428344,
    "arrivals": 1289387,
    "finished_requests": 77133,
    "scheduler_time": 131.3432956752537
}
#Debug simulation 
Total elapsed time: 39.38395318062976. Arrivals time: 0.38319511618465185 Scheduler time: 38.87015732424334 Scheduler overhead time: 0.04995661415159702 Adapter cache time: 0.01556819910183549 Engine time: 0.04734174208715558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 23.439446504227817,
    "estimated_duration": 3600.0840247745223,
    "input_throughput": 5285.684686537783,
    "output_throughput": 4687.927527207375,
    "total_throughput": 9973.612213745158,
    "itl": 181.19277623020199,
    "ttft": 2152099.710393156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5613471793383353,
    "arrivals": 1289387,
    "finished_requests": 76971,
    "scheduler_time": 131.77205466341312
}
#Debug simulation 
Total elapsed time: 23.439583064988256. Arrivals time: 0.35048780404031277 Scheduler time: 22.973863667342812 Scheduler overhead time: 0.043372557032853365 Adapter cache time: 0.013749126344919205 Engine time: 0.041375300381332636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 35.67821380728856,
    "estimated_duration": 3600.0832640252947,
    "input_throughput": 5290.968181303199,
    "output_throughput": 4698.8571539552995,
    "total_throughput": 9989.825335258498,
    "itl": 183.4404200220047,
    "ttft": 2147005.6581952055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.77202240373709,
    "arrivals": 1279697,
    "finished_requests": 77823,
    "scheduler_time": 131.15907827723208
}
#Debug simulation 
Total elapsed time: 35.67835804307833. Arrivals time: 0.466156636364758 Scheduler time: 35.08390043536201 Scheduler overhead time: 0.04848818853497505 Adapter cache time: 0.01635684771463275 Engine time: 0.04573802649974823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 35.264615521766245,
    "estimated_duration": 3600.1480726425775,
    "input_throughput": 5287.910556975032,
    "output_throughput": 4699.162272951206,
    "total_throughput": 9987.07282992624,
    "itl": 183.50580265966312,
    "ttft": 2146978.332993804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8642193206702413,
    "arrivals": 1279697,
    "finished_requests": 77810,
    "scheduler_time": 131.14146162327867
}
#Debug simulation 
Total elapsed time: 35.26475443178788. Arrivals time: 0.3739234348759055 Scheduler time: 34.761826841160655 Scheduler overhead time: 0.049429554026573896 Adapter cache time: 0.01586260786280036 Engine time: 0.046109570655971766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 34.5909577277489,
    "estimated_duration": 3600.07885966878,
    "input_throughput": 5274.893062133408,
    "output_throughput": 4689.368943866194,
    "total_throughput": 9964.262005999602,
    "itl": 181.75662924117657,
    "ttft": 2148136.0809866707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9099532730318725,
    "arrivals": 1279697,
    "finished_requests": 77617,
    "scheduler_time": 131.58157747977592
}
#Debug simulation 
Total elapsed time: 34.591078826691955. Arrivals time: 0.38231069641187787 Scheduler time: 34.07921066414565 Scheduler overhead time: 0.04899428831413388 Adapter cache time: 0.016843341756612062 Engine time: 0.045980580151081085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 35.38286226661876,
    "estimated_duration": 3600.009369613495,
    "input_throughput": 5289.3784557134,
    "output_throughput": 4700.446377398386,
    "total_throughput": 9989.824833111787,
    "itl": 183.4998935005444,
    "ttft": 2146992.6528284866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8057522978912937,
    "arrivals": 1279697,
    "finished_requests": 77823,
    "scheduler_time": 131.14171847887357
}
#Debug simulation 
Total elapsed time: 35.38299371488392. Arrivals time: 0.48552351305261254 Scheduler time: 34.76813163794577 Scheduler overhead time: 0.04856419423595071 Adapter cache time: 0.01712767966091633 Engine time: 0.04593376163393259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 34.6870623389259,
    "estimated_duration": 3600.1033601130016,
    "input_throughput": 5274.857163935408,
    "output_throughput": 4689.337030442953,
    "total_throughput": 9964.19419437836,
    "itl": 181.75772218418413,
    "ttft": 2148141.9344633296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9343495075963475,
    "arrivals": 1279697,
    "finished_requests": 77617,
    "scheduler_time": 131.5816816894878
}
#Debug simulation 
Total elapsed time: 34.68726629205048. Arrivals time: 0.3979063108563423 Scheduler time: 34.15874482085928 Scheduler overhead time: 0.04905902501195669 Adapter cache time: 0.016599048394709826 Engine time: 0.046904182992875576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 35.6398764019832,
    "estimated_duration": 3600.0422994762184,
    "input_throughput": 5291.028386741829,
    "output_throughput": 4698.910621817195,
    "total_throughput": 9989.939008559024,
    "itl": 183.4386078062064,
    "ttft": 2146995.3882649066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731239120748335,
    "arrivals": 1279697,
    "finished_requests": 77823,
    "scheduler_time": 131.1588970110431
}
#Debug simulation 
Total elapsed time: 35.640064008999616. Arrivals time: 0.36771276872605085 Scheduler time: 35.14368765195832 Scheduler overhead time: 0.04889193503186107 Adapter cache time: 0.016283645294606686 Engine time: 0.04561902070418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 34.72449281299487,
    "estimated_duration": 3600.128510608428,
    "input_throughput": 5274.820313786702,
    "output_throughput": 4689.304270737518,
    "total_throughput": 9964.12458452422,
    "itl": 181.7588175728985,
    "ttft": 2148148.463064626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9593745110928966,
    "arrivals": 1279697,
    "finished_requests": 77617,
    "scheduler_time": 131.58180718146477
}
#Debug simulation 
Total elapsed time: 34.72462174901739. Arrivals time: 0.47207743115723133 Scheduler time: 34.12235767580569 Scheduler overhead time: 0.04899387340992689 Adapter cache time: 0.016829331871122122 Engine time: 0.04652701551094651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 46.12731091165915,
    "estimated_duration": 3600.138945871942,
    "input_throughput": 5335.683785767773,
    "output_throughput": 4693.594678998551,
    "total_throughput": 10029.278464766323,
    "itl": 182.4965521207993,
    "ttft": 2144166.3148781448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8202107153739769,
    "arrivals": 1274994,
    "finished_requests": 77562,
    "scheduler_time": 131.39906210565348
}
#Debug simulation 
Total elapsed time: 46.12748843384907. Arrivals time: 0.41496176132932305 Scheduler time: 45.57958043040708 Scheduler overhead time: 0.05312726320698857 Adapter cache time: 0.011707747355103493 Engine time: 0.049514477141201496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 46.03598144603893,
    "estimated_duration": 3600.1978122830646,
    "input_throughput": 5335.596542629553,
    "output_throughput": 4693.5179345838205,
    "total_throughput": 10029.114477213374,
    "itl": 182.49857038249513,
    "ttft": 2144185.6312905247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8765150176268115,
    "arrivals": 1274994,
    "finished_requests": 77562,
    "scheduler_time": 131.39963976449283
}
#Debug simulation 
Total elapsed time: 46.036130914930254. Arrivals time: 0.48808041028678417 Scheduler time: 45.41470643132925 Scheduler overhead time: 0.05382696073502302 Adapter cache time: 0.0115860546939075 Engine time: 0.04938777256757021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 45.329774304293096,
    "estimated_duration": 3600.0505330564033,
    "input_throughput": 5325.439135912159,
    "output_throughput": 4685.2600665246655,
    "total_throughput": 10010.699202436825,
    "itl": 180.8095806448114,
    "ttft": 2145153.532894088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8743358241207941,
    "arrivals": 1274994,
    "finished_requests": 77414,
    "scheduler_time": 131.82865449420055
}
#Debug simulation 
Total elapsed time: 45.32996189733967. Arrivals time: 0.41620724042877555 Scheduler time: 44.781238328665495 Scheduler overhead time: 0.052737892139703035 Adapter cache time: 0.011878127697855234 Engine time: 0.04918034002184868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 45.8417498790659,
    "estimated_duration": 3600.1598663201107,
    "input_throughput": 5335.652780229066,
    "output_throughput": 4693.567404625231,
    "total_throughput": 10029.220184854297,
    "itl": 182.49722668671788,
    "ttft": 2144172.782147277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8389242483302977,
    "arrivals": 1274994,
    "finished_requests": 77562,
    "scheduler_time": 131.399284570827
}
#Debug simulation 
Total elapsed time: 45.84190990589559. Arrivals time: 0.4891830747947097 Scheduler time: 45.218022239394486 Scheduler overhead time: 0.0539350057952106 Adapter cache time: 0.011678935028612614 Engine time: 0.050067363772541285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 45.69919717917219,
    "estimated_duration": 3600.0622146870323,
    "input_throughput": 5325.421855707204,
    "output_throughput": 4685.244863599206,
    "total_throughput": 10010.66671930641,
    "itl": 180.80999338737658,
    "ttft": 2145157.4822190227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8859051724709615,
    "arrivals": 1274994,
    "finished_requests": 77414,
    "scheduler_time": 131.82876677649574
}
#Debug simulation 
Total elapsed time: 45.69936326891184. Arrivals time: 0.41171826981008053 Scheduler time: 45.15624624257907 Scheduler overhead time: 0.05276883253827691 Adapter cache time: 0.011113828048110008 Engine time: 0.049217511899769306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 45.79748753923923,
    "estimated_duration": 3600.1198822323454,
    "input_throughput": 5335.7120397026465,
    "output_throughput": 4693.619532892393,
    "total_throughput": 10029.33157259504,
    "itl": 182.4958941153832,
    "ttft": 2144159.6243765657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8013334790337842,
    "arrivals": 1274994,
    "finished_requests": 77562,
    "scheduler_time": 131.39887570236607
}
#Debug simulation 
Total elapsed time: 45.79765736917034. Arrivals time: 0.4919300335459411 Scheduler time: 45.17446402879432 Scheduler overhead time: 0.05217216536402702 Adapter cache time: 0.011118788737803698 Engine time: 0.04939782293513417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_96_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 45.33087864192203,
    "estimated_duration": 3600.0737645461327,
    "input_throughput": 5325.404770537258,
    "output_throughput": 4685.229832263304,
    "total_throughput": 10010.634602800563,
    "itl": 180.8103788191344,
    "ttft": 2145161.517189915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8973487670347139,
    "arrivals": 1274994,
    "finished_requests": 77414,
    "scheduler_time": 131.828873041047
}
#Debug simulation 
Total elapsed time: 45.3310709791258. Arrivals time: 0.4071740750223398 Scheduler time: 44.790418022312224 Scheduler overhead time: 0.053491426166146994 Adapter cache time: 0.011405149009078741 Engine time: 0.05003499612212181 
