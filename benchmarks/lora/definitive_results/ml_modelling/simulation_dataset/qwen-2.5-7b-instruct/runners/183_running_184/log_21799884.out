INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.001265326980501,
    "estimated_duration": 3600.0974043219207,
    "input_throughput": 4810.359291726388,
    "output_throughput": 4261.9663516826295,
    "total_throughput": 9072.325643409016,
    "itl": 201.7809534962425,
    "ttft": 2111288.393430984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5086521974228733,
    "arrivals": 623634,
    "finished_requests": 70358,
    "scheduler_time": 107.60543434253604
}
#Debug simulation 
Total elapsed time: 5.001416942104697. Arrivals time: 0.2418562676757574 Scheduler time: 4.672273913864046 Scheduler overhead time: 0.02719398820772767 Adapter cache time: 0.01876682508736849 Engine time: 0.028301358222961426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.916652773041278,
    "estimated_duration": 3600.137754709594,
    "input_throughput": 4650.470382167508,
    "output_throughput": 4127.932043866687,
    "total_throughput": 8778.402426034196,
    "itl": 170.1858319523144,
    "ttft": 2131596.275929626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7068008940667094,
    "arrivals": 623634,
    "finished_requests": 68059,
    "scheduler_time": 113.9672307518196
}
#Debug simulation 
Total elapsed time: 4.916756830178201. Arrivals time: 0.23602683935314417 Scheduler time: 4.58063883241266 Scheduler overhead time: 0.03182413801550865 Adapter cache time: 0.020388310309499502 Engine time: 0.032674672082066536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.04164415365085,
    "estimated_duration": 3600.1362849672455,
    "input_throughput": 4886.08058351881,
    "output_throughput": 4305.804773204866,
    "total_throughput": 9191.885356723677,
    "itl": 199.37560726489912,
    "ttft": 2108651.404796215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.163764834960496,
    "arrivals": 622407,
    "finished_requests": 71083,
    "scheduler_time": 108.77885611144114
}
#Debug simulation 
Total elapsed time: 5.041741240769625. Arrivals time: 0.24494364159181714 Scheduler time: 4.710122223477811 Scheduler overhead time: 0.027792747598141432 Adapter cache time: 0.017244629561901093 Engine time: 0.028430085629224777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.09305761475116,
    "estimated_duration": 3600.0608767697486,
    "input_throughput": 4885.988765774142,
    "output_throughput": 4305.682467766611,
    "total_throughput": 9191.671233540754,
    "itl": 199.38187758289448,
    "ttft": 2108643.117794317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.303553786252164,
    "arrivals": 622407,
    "finished_requests": 71081,
    "scheduler_time": 108.77256163457072
}
#Debug simulation 
Total elapsed time: 5.093169546686113. Arrivals time: 0.25141635024920106 Scheduler time: 4.755005241371691 Scheduler overhead time: 0.027816916350275278 Adapter cache time: 0.017168450634926558 Engine time: 0.02861909568309784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.009055377915502,
    "estimated_duration": 3600.0581868705935,
    "input_throughput": 4716.112384494161,
    "output_throughput": 4162.696607142,
    "total_throughput": 8878.80899163616,
    "itl": 168.65533503474379,
    "ttft": 2129740.505100118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.230484746247534,
    "arrivals": 622407,
    "finished_requests": 68660,
    "scheduler_time": 115.01011081537293
}
#Debug simulation 
Total elapsed time: 5.009181649889797. Arrivals time: 0.273742753546685 Scheduler time: 4.635575070977211 Scheduler overhead time: 0.03231883654370904 Adapter cache time: 0.019124952144920826 Engine time: 0.03296156972646713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.05216042464599,
    "estimated_duration": 3600.175131881034,
    "input_throughput": 4886.027861319407,
    "output_throughput": 4305.758312346523,
    "total_throughput": 9191.786173665929,
    "itl": 199.3774075431869,
    "ttft": 2108669.3022282463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1997705753682912,
    "arrivals": 622407,
    "finished_requests": 71083,
    "scheduler_time": 108.77902786962807
}
#Debug simulation 
Total elapsed time: 5.052255644928664. Arrivals time: 0.24524766067042947 Scheduler time: 4.720277634449303 Scheduler overhead time: 0.027906093280762434 Adapter cache time: 0.017182162031531334 Engine time: 0.02843769919127226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.254052403382957,
    "estimated_duration": 3600.0961893100975,
    "input_throughput": 4715.388730558657,
    "output_throughput": 4162.270453910166,
    "total_throughput": 8877.659184468823,
    "itl": 168.52863607203318,
    "ttft": 2129817.178990942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.257787903789433,
    "arrivals": 622407,
    "finished_requests": 68652,
    "scheduler_time": 115.04279460513487
}
#Debug simulation 
Total elapsed time: 5.254147567320615. Arrivals time: 0.5547388270497322 Scheduler time: 4.600375969428569 Scheduler overhead time: 0.032289881724864244 Adapter cache time: 0.018692065961658955 Engine time: 0.032721553929150105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.043736499268562,
    "estimated_duration": 3600.005006328033,
    "input_throughput": 4886.172371727301,
    "output_throughput": 4305.851512081908,
    "total_throughput": 9192.023883809208,
    "itl": 199.37314683325647,
    "ttft": 2108606.8316428317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1139655584958,
    "arrivals": 622407,
    "finished_requests": 71082,
    "scheduler_time": 108.77615427990173
}
#Debug simulation 
Total elapsed time: 5.043833916075528. Arrivals time: 0.24736471753567457 Scheduler time: 4.709403727203608 Scheduler overhead time: 0.02784874802455306 Adapter cache time: 0.0173828755505383 Engine time: 0.028737171553075314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.961246181745082,
    "estimated_duration": 3600.0512900955086,
    "input_throughput": 4715.088656292358,
    "output_throughput": 4161.974869975393,
    "total_throughput": 8877.06352626775,
    "itl": 168.4747510243044,
    "ttft": 2129817.1913060476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2805239111557647,
    "arrivals": 622407,
    "finished_requests": 68646,
    "scheduler_time": 115.05393268961458
}
#Debug simulation 
Total elapsed time: 4.961387099698186. Arrivals time: 0.23339165840297937 Scheduler time: 4.628757288213819 Scheduler overhead time: 0.032287444453686476 Adapter cache time: 0.018679532688111067 Engine time: 0.03290940076112747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.1376302586868405,
    "estimated_duration": 3600.1079409365793,
    "input_throughput": 4938.387484952689,
    "output_throughput": 4358.193492364622,
    "total_throughput": 9296.580977317311,
    "itl": 196.7257943404997,
    "ttft": 2099406.5809346316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4476107028802068,
    "arrivals": 619978,
    "finished_requests": 71958,
    "scheduler_time": 110.08453929285575
}
#Debug simulation 
Total elapsed time: 5.137760293669999. Arrivals time: 0.28364875819534063 Scheduler time: 4.771217396948487 Scheduler overhead time: 0.027942436281591654 Adapter cache time: 0.012802576646208763 Engine time: 0.02894243272021413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.139541042968631,
    "estimated_duration": 3600.0330938557595,
    "input_throughput": 4938.326269928536,
    "output_throughput": 4358.093270524977,
    "total_throughput": 9296.419540453513,
    "itl": 196.73080248822745,
    "ttft": 2099419.6612905306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5474958633002893,
    "arrivals": 619978,
    "finished_requests": 71956,
    "scheduler_time": 110.07958977054241
}
#Debug simulation 
Total elapsed time: 5.139639541041106. Arrivals time: 0.24983411561697721 Scheduler time: 4.806706346105784 Scheduler overhead time: 0.028143053874373436 Adapter cache time: 0.013032687362283468 Engine time: 0.02862048940733075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.040685684420168,
    "estimated_duration": 3600.0217582570335,
    "input_throughput": 4755.098482595832,
    "output_throughput": 4204.637365116521,
    "total_throughput": 8959.735847712354,
    "itl": 166.56235190458636,
    "ttft": 2121767.0764595806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.483598009292045,
    "arrivals": 619978,
    "finished_requests": 69288,
    "scheduler_time": 116.1822297409907
}
#Debug simulation 
Total elapsed time: 5.040781471412629. Arrivals time: 0.2464337064884603 Scheduler time: 4.698652902152389 Scheduler overhead time: 0.03266707621514797 Adapter cache time: 0.01422510202974081 Engine time: 0.03334336681291461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.167509566992521,
    "estimated_duration": 3600.15649615092,
    "input_throughput": 4938.321158818511,
    "output_throughput": 4358.206932608371,
    "total_throughput": 9296.528091426882,
    "itl": 196.72757910719656,
    "ttft": 2099413.9176767766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4772174685285375,
    "arrivals": 619978,
    "finished_requests": 71959,
    "scheduler_time": 110.08543727920622
}
#Debug simulation 
Total elapsed time: 5.16760791093111. Arrivals time: 0.2852726331911981 Scheduler time: 4.799120420124382 Scheduler overhead time: 0.027982167433947325 Adapter cache time: 0.01292230375111103 Engine time: 0.028966493904590607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.026755651924759,
    "estimated_duration": 3600.055109745631,
    "input_throughput": 4755.126651716606,
    "output_throughput": 4204.616467959993,
    "total_throughput": 8959.7431196766,
    "itl": 166.56284841381682,
    "ttft": 2121807.512850484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5008408639207522,
    "arrivals": 619978,
    "finished_requests": 69288,
    "scheduler_time": 116.18353659387815
}
#Debug simulation 
Total elapsed time: 5.026849505957216. Arrivals time: 0.2815635446459055 Scheduler time: 4.6496021607890725 Scheduler overhead time: 0.03243726957589388 Adapter cache time: 0.014202799182385206 Engine time: 0.03354558302089572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.163471437059343,
    "estimated_duration": 3600.074477920571,
    "input_throughput": 4938.4333877084455,
    "output_throughput": 4358.234002165043,
    "total_throughput": 9296.66738987349,
    "itl": 196.72426796064929,
    "ttft": 2099391.713097693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4142937894887158,
    "arrivals": 619978,
    "finished_requests": 71958,
    "scheduler_time": 110.08439319018274
}
#Debug simulation 
Total elapsed time: 5.163572826888412. Arrivals time: 0.28648599050939083 Scheduler time: 4.793718075845391 Scheduler overhead time: 0.028467055410146713 Adapter cache time: 0.012919651344418526 Engine time: 0.02864088723435998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.020361427217722,
    "estimated_duration": 3600.1769797958864,
    "input_throughput": 4755.340666883168,
    "output_throughput": 4204.588298005898,
    "total_throughput": 8959.928964889066,
    "itl": 166.5649998268155,
    "ttft": 2121805.3230024865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5192009167373177,
    "arrivals": 619978,
    "finished_requests": 69293,
    "scheduler_time": 116.18580886975207
}
#Debug simulation 
Total elapsed time: 5.020487834233791. Arrivals time: 0.28142627142369747 Scheduler time: 4.643162295222282 Scheduler overhead time: 0.03286676714196801 Adapter cache time: 0.014220787212252617 Engine time: 0.0332400850020349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 19.824414705857635,
    "estimated_duration": 3600.1651504136853,
    "input_throughput": 4652.337129055148,
    "output_throughput": 4078.7212215285995,
    "total_throughput": 8731.058350583748,
    "itl": 209.58930280223154,
    "ttft": 2096408.7757254788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.455290662900163,
    "arrivals": 500641,
    "finished_requests": 67652,
    "scheduler_time": 102.89803227741149
}
#Debug simulation 
Total elapsed time: 19.82451928779483. Arrivals time: 0.3120150971226394 Scheduler time: 19.398429971188307 Scheduler overhead time: 0.036710300017148256 Adapter cache time: 0.027133607305586338 Engine time: 0.03555539296939969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 19.348771238233894,
    "estimated_duration": 3600.0616801876868,
    "input_throughput": 4644.888195117873,
    "output_throughput": 4077.8384661550144,
    "total_throughput": 8722.726661272887,
    "itl": 209.76080333129164,
    "ttft": 2096951.8043969441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7977672226284698,
    "arrivals": 500641,
    "finished_requests": 67570,
    "scheduler_time": 102.86612970149847
}
#Debug simulation 
Total elapsed time: 19.348899754229933. Arrivals time: 0.3164272955618799 Scheduler time: 18.91757154278457 Scheduler overhead time: 0.03668972663581371 Adapter cache time: 0.028026229701936245 Engine time: 0.03580509964376688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.290663559921086,
    "estimated_duration": 3600.0028317036395,
    "input_throughput": 4447.268724070269,
    "output_throughput": 3911.850534110724,
    "total_throughput": 8359.119258180992,
    "itl": 178.52638572182468,
    "ttft": 2125663.9778023236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.26339615473519,
    "arrivals": 500641,
    "finished_requests": 64702,
    "scheduler_time": 107.9565784451613
}
#Debug simulation 
Total elapsed time: 11.290781230200082. Arrivals time: 0.315380516462028 Scheduler time: 10.847032466437668 Scheduler overhead time: 0.035513547249138355 Adapter cache time: 0.0422390541061759 Engine time: 0.03504396555945277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.512072087731212,
    "estimated_duration": 3600.0327835780895,
    "input_throughput": 4646.809072492196,
    "output_throughput": 4075.596774265247,
    "total_throughput": 8722.405846757443,
    "itl": 209.69576646552284,
    "ttft": 2097946.689142434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.875465158491816,
    "arrivals": 500641,
    "finished_requests": 67573,
    "scheduler_time": 102.87374789820984
}
#Debug simulation 
Total elapsed time: 18.51219464978203. Arrivals time: 0.3094734000042081 Scheduler time: 18.08816109923646 Scheduler overhead time: 0.03578206058591604 Adapter cache time: 0.028956693597137928 Engine time: 0.03534587752074003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 13.321878619026393,
    "estimated_duration": 3600.140162585775,
    "input_throughput": 4458.105039019465,
    "output_throughput": 3920.2412580134483,
    "total_throughput": 8378.346297032913,
    "itl": 178.21769946165045,
    "ttft": 2124369.4687917437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.49016656786197,
    "arrivals": 500641,
    "finished_requests": 64863,
    "scheduler_time": 108.19248794556447
}
#Debug simulation 
Total elapsed time: 13.32199535984546. Arrivals time: 0.2925056032836437 Scheduler time: 12.902284645475447 Scheduler overhead time: 0.03670760989189148 Adapter cache time: 0.03879745816811919 Engine time: 0.03601010097190738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 19.2369656059891,
    "estimated_duration": 3600.10801373632,
    "input_throughput": 4650.375748761135,
    "output_throughput": 4077.7148752168555,
    "total_throughput": 8728.09062397799,
    "itl": 209.70894101018123,
    "ttft": 2096732.6453635201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.369786682354669,
    "arrivals": 500641,
    "finished_requests": 67577,
    "scheduler_time": 102.88744487767151
}
#Debug simulation 
Total elapsed time: 19.237087844870985. Arrivals time: 0.3445878871716559 Scheduler time: 18.77979484340176 Scheduler overhead time: 0.036164752673357725 Adapter cache time: 0.026856674812734127 Engine time: 0.03525584889575839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.030994379892945,
    "estimated_duration": 3600.035738368743,
    "input_throughput": 4451.678862294249,
    "output_throughput": 3911.15145050757,
    "total_throughput": 8362.830312801818,
    "itl": 178.6140414546537,
    "ttft": 2125336.2502363995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.646194056793847,
    "arrivals": 500641,
    "finished_requests": 64748,
    "scheduler_time": 107.93863097165747
}
#Debug simulation 
Total elapsed time: 11.03111589513719. Arrivals time: 0.27593644335865974 Scheduler time: 10.626609562896192 Scheduler overhead time: 0.0352327018044889 Adapter cache time: 0.043378757778555155 Engine time: 0.034481116104871035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.89110096776858,
    "estimated_duration": 3600.041843538953,
    "input_throughput": 4590.149703303358,
    "output_throughput": 4082.974487193889,
    "total_throughput": 8673.124190497248,
    "itl": 211.1707633277844,
    "ttft": 2097987.0774189923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.981694554856615,
    "arrivals": 481654,
    "finished_requests": 67013,
    "scheduler_time": 102.6580896613169
}
#Debug simulation 
Total elapsed time: 18.89121596654877. Arrivals time: 0.3191976295784116 Scheduler time: 18.45608020015061 Scheduler overhead time: 0.03598222276195884 Adapter cache time: 0.03015533136203885 Engine time: 0.035277157090604305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 20.005645556841046,
    "estimated_duration": 3600.192276356517,
    "input_throughput": 4587.965234100267,
    "output_throughput": 4082.630835171669,
    "total_throughput": 8670.596069271936,
    "itl": 211.18108692501193,
    "ttft": 2096651.3407370753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.681544910324744,
    "arrivals": 481654,
    "finished_requests": 66963,
    "scheduler_time": 102.66702873442878
}
#Debug simulation 
Total elapsed time: 20.005774036049843. Arrivals time: 0.3139519249089062 Scheduler time: 19.57559722242877 Scheduler overhead time: 0.03761602845042944 Adapter cache time: 0.027441976591944695 Engine time: 0.03637200454249978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.316428964026272,
    "estimated_duration": 3600.0262689349524,
    "input_throughput": 4387.967981320701,
    "output_throughput": 3912.732282413941,
    "total_throughput": 8300.700263734643,
    "itl": 178.50195551359866,
    "ttft": 2127213.623586579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6734068251400664,
    "arrivals": 481654,
    "finished_requests": 64105,
    "scheduler_time": 107.92618834462282
}
#Debug simulation 
Total elapsed time: 12.31657176790759. Arrivals time: 0.28750015841796994 Scheduler time: 11.90438369428739 Scheduler overhead time: 0.0358965452760458 Adapter cache time: 0.03813357697799802 Engine time: 0.03501947782933712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 19.95102778915316,
    "estimated_duration": 3600.0346575555004,
    "input_throughput": 4588.166107049583,
    "output_throughput": 4082.8095832778527,
    "total_throughput": 8670.975690327436,
    "itl": 211.17289742624214,
    "ttft": 2096583.6510781914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.525052903362046,
    "arrivals": 481654,
    "finished_requests": 66963,
    "scheduler_time": 102.66665597348101
}
#Debug simulation 
Total elapsed time: 19.951128751970828. Arrivals time: 0.31426167488098145 Scheduler time: 19.52116412157193 Scheduler overhead time: 0.037358426954597235 Adapter cache time: 0.027054960373789072 Engine time: 0.03675665054470301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 12.349643886089325,
    "estimated_duration": 3600.101032340747,
    "input_throughput": 4387.876856258417,
    "output_throughput": 3912.651026585627,
    "total_throughput": 8300.527882844044,
    "itl": 178.505318247576,
    "ttft": 2127243.540726447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7473500515519795,
    "arrivals": 481654,
    "finished_requests": 64105,
    "scheduler_time": 107.9263447296564
}
#Debug simulation 
Total elapsed time: 12.349794511683285. Arrivals time: 0.285870716907084 Scheduler time: 11.938130188267678 Scheduler overhead time: 0.03630451811477542 Adapter cache time: 0.038500912487506866 Engine time: 0.03519283886998892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.37363385874778,
    "estimated_duration": 3600.09023200912,
    "input_throughput": 4593.343203726153,
    "output_throughput": 4083.8559737418145,
    "total_throughput": 8677.199177467968,
    "itl": 211.10995555602818,
    "ttft": 2098989.77923984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0335778478229285,
    "arrivals": 481654,
    "finished_requests": 67034,
    "scheduler_time": 102.66477695756578
}
#Debug simulation 
Total elapsed time: 18.37376152165234. Arrivals time: 0.3052004976198077 Scheduler time: 17.95269792061299 Scheduler overhead time: 0.03564995154738426 Adapter cache time: 0.030515966936945915 Engine time: 0.035214709118008614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.318738834001124,
    "estimated_duration": 3600.1454470740987,
    "input_throughput": 4394.48050990768,
    "output_throughput": 3917.705605884012,
    "total_throughput": 8312.186115791694,
    "itl": 178.30839669426334,
    "ttft": 2129709.7740786145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1917,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4303082816673545,
    "arrivals": 481654,
    "finished_requests": 64132,
    "scheduler_time": 108.0854557921499
}
#Debug simulation 
Total elapsed time: 11.318855251651257. Arrivals time: 0.2895239181816578 Scheduler time: 10.900412559974939 Scheduler overhead time: 0.035822606179863214 Adapter cache time: 0.04222531011328101 Engine time: 0.035371681209653616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 21.208809552248567,
    "estimated_duration": 3600.0169811567343,
    "input_throughput": 4621.882365303097,
    "output_throughput": 4085.0093421711385,
    "total_throughput": 8706.891707474235,
    "itl": 209.9932902375377,
    "ttft": 2090781.0068675966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9296662632097563,
    "arrivals": 472156,
    "finished_requests": 67559,
    "scheduler_time": 102.78703003807354
}
#Debug simulation 
Total elapsed time: 21.20893385494128. Arrivals time: 0.3566118967719376 Scheduler time: 20.734408903867006 Scheduler overhead time: 0.03701310558244586 Adapter cache time: 0.02865220559760928 Engine time: 0.03729321574792266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 19.950257014948875,
    "estimated_duration": 3600.2080263322746,
    "input_throughput": 4619.060309395912,
    "output_throughput": 4080.6878081894733,
    "total_throughput": 8699.748117585385,
    "itl": 210.1916621385883,
    "ttft": 2091519.2531110784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.403895089395783,
    "arrivals": 472156,
    "finished_requests": 67484,
    "scheduler_time": 102.70572018727671
}
#Debug simulation 
Total elapsed time: 19.950395859777927. Arrivals time: 0.3227425869554281 Scheduler time: 19.509352972730994 Scheduler overhead time: 0.03727302374318242 Adapter cache time: 0.02992222271859646 Engine time: 0.036431082524359226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.08431568928063,
    "estimated_duration": 3600.1547820425703,
    "input_throughput": 4428.883468991768,
    "output_throughput": 3915.1011146257247,
    "total_throughput": 8343.984583617492,
    "itl": 178.92008975567208,
    "ttft": 2118833.527425639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.904672800656369,
    "arrivals": 472156,
    "finished_requests": 64628,
    "scheduler_time": 107.74676654543671
}
#Debug simulation 
Total elapsed time: 11.08441489096731. Arrivals time: 0.2766953790560365 Scheduler time: 10.682601742912084 Scheduler overhead time: 0.035538292955607176 Adapter cache time: 0.039491727482527494 Engine time: 0.03448330191895366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 22.90329414792359,
    "estimated_duration": 3600.1253749769066,
    "input_throughput": 4629.646543936519,
    "output_throughput": 4095.0134966048417,
    "total_throughput": 8724.660040541361,
    "itl": 209.57480101117991,
    "ttft": 2093028.7956117436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9862269024690122,
    "arrivals": 472156,
    "finished_requests": 67680,
    "scheduler_time": 103.04381553978294
}
#Debug simulation 
Total elapsed time: 22.903460558969527. Arrivals time: 0.36709112068638206 Scheduler time: 22.416533437091857 Scheduler overhead time: 0.03816126054152846 Adapter cache time: 0.028763113543391228 Engine time: 0.03776947082951665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.34015812817961,
    "estimated_duration": 3600.026516079484,
    "input_throughput": 4428.67293582123,
    "output_throughput": 3914.8728313668985,
    "total_throughput": 8343.545767188129,
    "itl": 178.92471010346907,
    "ttft": 2118814.3986434406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.980250826291649,
    "arrivals": 472156,
    "finished_requests": 64622,
    "scheduler_time": 107.74072929492968
}
#Debug simulation 
Total elapsed time: 11.340226964093745. Arrivals time: 0.5579260201193392 Scheduler time: 10.657730028033257 Scheduler overhead time: 0.03523378260433674 Adapter cache time: 0.03938884846866131 Engine time: 0.03456135978922248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 21.28844666806981,
    "estimated_duration": 3600.0026730109157,
    "input_throughput": 4617.909904521227,
    "output_throughput": 4084.2944673989737,
    "total_throughput": 8702.204371920201,
    "itl": 210.0715139072071,
    "ttft": 2090603.8767718528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.803343975115469,
    "arrivals": 472156,
    "finished_requests": 67475,
    "scheduler_time": 102.80572578729212
}
#Debug simulation 
Total elapsed time: 21.288604298140854. Arrivals time: 0.35967852594330907 Scheduler time: 20.810308882035315 Scheduler overhead time: 0.03794566635042429 Adapter cache time: 0.028620896860957146 Engine time: 0.037022892851382494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.000322688370943,
    "estimated_duration": 3600.1682983312944,
    "input_throughput": 4424.685092467343,
    "output_throughput": 3917.10215506772,
    "total_throughput": 8341.787247535063,
    "itl": 178.90490468305407,
    "ttft": 2118844.7220054558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.906706716641656,
    "arrivals": 472156,
    "finished_requests": 64635,
    "scheduler_time": 107.77190378124371
}
#Debug simulation 
Total elapsed time: 11.00043865526095. Arrivals time: 0.32975958939641714 Scheduler time: 10.545427755452693 Scheduler overhead time: 0.03531218320131302 Adapter cache time: 0.039878175128251314 Engine time: 0.03459774423390627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.76482013706118,
    "estimated_duration": 3600.1101073312543,
    "input_throughput": 4639.235329494113,
    "output_throughput": 4115.104138018202,
    "total_throughput": 8754.339467512316,
    "itl": 208.84832723908264,
    "ttft": 2088039.1524359342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7062506579026575,
    "arrivals": 467317,
    "finished_requests": 67803,
    "scheduler_time": 103.5626305680389
}
#Debug simulation 
Total elapsed time: 17.764954668004066. Arrivals time: 0.3054690007120371 Scheduler time: 17.347466533072293 Scheduler overhead time: 0.03552986867725849 Adapter cache time: 0.02685473719611764 Engine time: 0.03533781133592129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.02390914876014,
    "estimated_duration": 3600.2221351539697,
    "input_throughput": 4651.896291750272,
    "output_throughput": 4126.03373968332,
    "total_throughput": 8777.930031433592,
    "itl": 208.32209635006143,
    "ttft": 2085572.825521067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8692686635744824,
    "arrivals": 467317,
    "finished_requests": 68025,
    "scheduler_time": 103.83909716574144
}
#Debug simulation 
Total elapsed time: 18.024064189754426. Arrivals time: 0.34281776705756783 Scheduler time: 17.568299257196486 Scheduler overhead time: 0.03593820659443736 Adapter cache time: 0.026510834228247404 Engine time: 0.035929934587329626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.951661886181682,
    "estimated_duration": 3600.169437842754,
    "input_throughput": 4415.992434380083,
    "output_throughput": 3916.944533713339,
    "total_throughput": 8332.936968093421,
    "itl": 177.20658515221683,
    "ttft": 2119725.1500905817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.001703282128962,
    "arrivals": 467317,
    "finished_requests": 64510,
    "scheduler_time": 108.30165777737042
}
#Debug simulation 
Total elapsed time: 9.951760243158787. Arrivals time: 0.2707809014245868 Scheduler time: 9.556548470631242 Scheduler overhead time: 0.03466004366055131 Adapter cache time: 0.039773631375283 Engine time: 0.03457677457481623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 17.531420129351318,
    "estimated_duration": 3600.004593005883,
    "input_throughput": 4635.875474276853,
    "output_throughput": 4108.349202868872,
    "total_throughput": 8744.224677145727,
    "itl": 209.21118867948073,
    "ttft": 2087181.6288524086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.794863683595279,
    "arrivals": 467317,
    "finished_requests": 67734,
    "scheduler_time": 103.36012578144049
}
#Debug simulation 
Total elapsed time: 17.531538726296276. Arrivals time: 0.32199312234297395 Scheduler time: 17.095479119569063 Scheduler overhead time: 0.03583320276811719 Adapter cache time: 0.027824297547340393 Engine time: 0.03597091790288687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.851540480274707,
    "estimated_duration": 3600.0770583512844,
    "input_throughput": 4412.2616662196015,
    "output_throughput": 3915.5584093123944,
    "total_throughput": 8327.820075531996,
    "itl": 177.7219048988486,
    "ttft": 2120735.7500905637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.174142888598033,
    "arrivals": 467317,
    "finished_requests": 64500,
    "scheduler_time": 108.09838766783798
}
#Debug simulation 
Total elapsed time: 9.851641304325312. Arrivals time: 0.2707514585927129 Scheduler time: 9.457015647087246 Scheduler overhead time: 0.03477773489430547 Adapter cache time: 0.03951748600229621 Engine time: 0.034099772572517395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.967842389829457,
    "estimated_duration": 3600.1195284278137,
    "input_throughput": 4663.297667600379,
    "output_throughput": 4131.504213276911,
    "total_throughput": 8794.80188087729,
    "itl": 207.92819100260283,
    "ttft": 2087258.7129967278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6388912088958554,
    "arrivals": 467317,
    "finished_requests": 68125,
    "scheduler_time": 103.9998123267505
}
#Debug simulation 
Total elapsed time: 17.967991824261844. Arrivals time: 0.34650943195447326 Scheduler time: 17.50902065448463 Scheduler overhead time: 0.03616413054987788 Adapter cache time: 0.026255339849740267 Engine time: 0.0355487116612494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.991567045915872,
    "estimated_duration": 3600.186407465206,
    "input_throughput": 4413.707292225416,
    "output_throughput": 3915.652525871674,
    "total_throughput": 8329.35981809709,
    "itl": 177.76580115141618,
    "ttft": 2120436.322264848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.03625047132359,
    "arrivals": 467317,
    "finished_requests": 64479,
    "scheduler_time": 108.10117983126143
}
#Debug simulation 
Total elapsed time: 9.991666446905583. Arrivals time: 0.27183777652680874 Scheduler time: 9.595240867231041 Scheduler overhead time: 0.035029311664402485 Adapter cache time: 0.03952607233077288 Engine time: 0.034492327366024256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.383149762172252,
    "estimated_duration": 3600.2032117605686,
    "input_throughput": 4703.591159710955,
    "output_throughput": 4155.393493103447,
    "total_throughput": 8858.984652814403,
    "itl": 206.55033468075672,
    "ttft": 2079796.677647504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.121697498811481,
    "arrivals": 464889,
    "finished_requests": 68532,
    "scheduler_time": 104.53533512119905
}
#Debug simulation 
Total elapsed time: 17.383367938920856. Arrivals time: 0.33710157638415694 Scheduler time: 16.939332742709666 Scheduler overhead time: 0.03484001103788614 Adapter cache time: 0.02226047683507204 Engine time: 0.035250443033874035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.285224644001573,
    "estimated_duration": 3600.2128088148106,
    "input_throughput": 4709.33217016731,
    "output_throughput": 4160.723767029551,
    "total_throughput": 8870.055937196861,
    "itl": 206.2744656017529,
    "ttft": 2081181.630969626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3289219032949835,
    "arrivals": 464889,
    "finished_requests": 68640,
    "scheduler_time": 104.6679951261193
}
#Debug simulation 
Total elapsed time: 18.28529188130051. Arrivals time: 0.586938327178359 Scheduler time: 17.588981590233743 Scheduler overhead time: 0.035968334414064884 Adapter cache time: 0.02294267574325204 Engine time: 0.03581691952422261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.298553611617535,
    "estimated_duration": 3600.1617835385096,
    "input_throughput": 4439.718812939015,
    "output_throughput": 3929.8108948021572,
    "total_throughput": 8369.529707741172,
    "itl": 177.3282410377718,
    "ttft": 2115498.0545853674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.470100049041154,
    "arrivals": 464889,
    "finished_requests": 64749,
    "scheduler_time": 108.39946646738998
}
#Debug simulation 
Total elapsed time: 10.298686753958464. Arrivals time: 0.2919690920971334 Scheduler time: 9.890261384658515 Scheduler overhead time: 0.03518625907599926 Adapter cache time: 0.0313872410915792 Engine time: 0.0343380831182003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 17.67746706493199,
    "estimated_duration": 3600.1035645370584,
    "input_throughput": 4703.651630137901,
    "output_throughput": 4163.6085549465315,
    "total_throughput": 8867.260185084431,
    "itl": 206.27697422165386,
    "ttft": 2079622.2239583263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3221191325061605,
    "arrivals": 464889,
    "finished_requests": 68620,
    "scheduler_time": 104.74512001776766
}
#Debug simulation 
Total elapsed time: 17.67756839096546. Arrivals time: 0.31577243749052286 Scheduler time: 17.25016289576888 Scheduler overhead time: 0.036367135122418404 Adapter cache time: 0.023704548366367817 Engine time: 0.0364454286172986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.998808845877647,
    "estimated_duration": 3600.0172317670454,
    "input_throughput": 4450.2525873011455,
    "output_throughput": 3937.165321023436,
    "total_throughput": 8387.417908324582,
    "itl": 177.03562379866676,
    "ttft": 2117476.511919038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.217113289926147,
    "arrivals": 464889,
    "finished_requests": 64927,
    "scheduler_time": 108.57907575508669
}
#Debug simulation 
Total elapsed time: 9.998942561913282. Arrivals time: 0.27344538597390056 Scheduler time: 9.606926387641579 Scheduler overhead time: 0.03473957348614931 Adapter cache time: 0.034032913856208324 Engine time: 0.0343894618563354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.44623023690656,
    "estimated_duration": 3600.1312545884484,
    "input_throughput": 4703.685172149594,
    "output_throughput": 4155.47654850995,
    "total_throughput": 8859.161720659544,
    "itl": 206.54669405336,
    "ttft": 2079768.140457893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0498513008001478,
    "arrivals": 464889,
    "finished_requests": 68532,
    "scheduler_time": 104.53513839838813
}
#Debug simulation 
Total elapsed time: 17.446336081717163. Arrivals time: 0.31003974843770266 Scheduler time: 17.026755765080452 Scheduler overhead time: 0.03579739248380065 Adapter cache time: 0.023434410337358713 Engine time: 0.03579986095428467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.006170423235744,
    "estimated_duration": 3600.0846227984853,
    "input_throughput": 4450.169281728236,
    "output_throughput": 3937.0916200803376,
    "total_throughput": 8387.260901808573,
    "itl": 177.03875649394928,
    "ttft": 2117502.0384011026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.284391565658086,
    "arrivals": 464889,
    "finished_requests": 64927,
    "scheduler_time": 108.57918851084418
}
#Debug simulation 
Total elapsed time: 10.006302310153842. Arrivals time: 0.2732606856152415 Scheduler time: 9.614561847876757 Scheduler overhead time: 0.034613586496561766 Adapter cache time: 0.03396292729303241 Engine time: 0.03442233707755804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.979579207021743,
    "estimated_duration": 3600.2244789764677,
    "input_throughput": 4735.838306628948,
    "output_throughput": 4218.312521534096,
    "total_throughput": 8954.150828163043,
    "itl": 204.31523595924327,
    "ttft": 2075803.8141779138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.925826283199778,
    "arrivals": 463720,
    "finished_requests": 69198,
    "scheduler_time": 105.93509161760943
}
#Debug simulation 
Total elapsed time: 18.979679549112916. Arrivals time: 0.3213011580519378 Scheduler time: 18.55045422911644 Scheduler overhead time: 0.03624289250001311 Adapter cache time: 0.021275362465530634 Engine time: 0.03599188383668661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.895543484017253,
    "estimated_duration": 3600.196043784319,
    "input_throughput": 4740.4662947355955,
    "output_throughput": 4224.881871713769,
    "total_throughput": 8965.348166449365,
    "itl": 203.9984998815381,
    "ttft": 2075962.0027927377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0816569102788405,
    "arrivals": 463720,
    "finished_requests": 69315,
    "scheduler_time": 106.10577076501458
}
#Debug simulation 
Total elapsed time: 18.895701892208308. Arrivals time: 0.31282701482996345 Scheduler time: 18.472058108542114 Scheduler overhead time: 0.03730711806565523 Adapter cache time: 0.021486836951225996 Engine time: 0.03706860775128007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.197054557036608,
    "estimated_duration": 3600.1452034981953,
    "input_throughput": 4435.542484365244,
    "output_throughput": 3961.6085446057896,
    "total_throughput": 8397.151028971033,
    "itl": 176.4366368511201,
    "ttft": 2107705.2547703045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.820013511273952,
    "arrivals": 463720,
    "finished_requests": 64881,
    "scheduler_time": 109.11198023526005
}
#Debug simulation 
Total elapsed time: 10.197204832918942. Arrivals time: 0.2755363490432501 Scheduler time: 9.804789918474853 Scheduler overhead time: 0.03519407194107771 Adapter cache time: 0.03164580697193742 Engine time: 0.03452552296221256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.96317988820374,
    "estimated_duration": 3600.0606610951118,
    "input_throughput": 4735.821311081393,
    "output_throughput": 4218.261698784968,
    "total_throughput": 8954.083009866361,
    "itl": 204.3166996200758,
    "ttft": 2075809.9048447353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.992098751056446,
    "arrivals": 463720,
    "finished_requests": 69193,
    "scheduler_time": 105.92854239906377
}
#Debug simulation 
Total elapsed time: 18.96333954203874. Arrivals time: 0.33242819737643003 Scheduler time: 18.52065312769264 Scheduler overhead time: 0.036917423363775015 Adapter cache time: 0.02157562877982855 Engine time: 0.036823661997914314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.270458028186113,
    "estimated_duration": 3600.1281547020494,
    "input_throughput": 4442.376857921495,
    "output_throughput": 3966.6776810010183,
    "total_throughput": 8409.054538922514,
    "itl": 175.59414193575338,
    "ttft": 2111481.1163275293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9166803490370095,
    "arrivals": 463720,
    "finished_requests": 64990,
    "scheduler_time": 109.43182108687903
}
#Debug simulation 
Total elapsed time: 10.270556131377816. Arrivals time: 0.282179303932935 Scheduler time: 9.872066740412265 Scheduler overhead time: 0.03481064923107624 Adapter cache time: 0.03136151563376188 Engine time: 0.03471452044323087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.92855879617855,
    "estimated_duration": 3600.110340043215,
    "input_throughput": 4735.874289840611,
    "output_throughput": 4218.373206810574,
    "total_throughput": 8954.247496651184,
    "itl": 204.30900097377625,
    "ttft": 2075780.5620811223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8584880819264153,
    "arrivals": 463720,
    "finished_requests": 69197,
    "scheduler_time": 105.93478421183303
}
#Debug simulation 
Total elapsed time: 18.92869175830856. Arrivals time: 0.3122017811983824 Scheduler time: 18.508164066821337 Scheduler overhead time: 0.035829280968755484 Adapter cache time: 0.02143661631271243 Engine time: 0.03630373580381274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.78703584568575,
    "estimated_duration": 3600.1089895582427,
    "input_throughput": 4455.510943286263,
    "output_throughput": 3980.419215518911,
    "total_throughput": 8435.930158805173,
    "itl": 175.2645051596872,
    "ttft": 2112373.5313248117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.718112715706222,
    "arrivals": 463720,
    "finished_requests": 65201,
    "scheduler_time": 109.78529555360159
}
#Debug simulation 
Total elapsed time: 10.78715493902564. Arrivals time: 0.2851359657943249 Scheduler time: 10.384397751651704 Scheduler overhead time: 0.03541706735268235 Adapter cache time: 0.031287011690437794 Engine time: 0.03524945955723524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.949716975912452,
    "estimated_duration": 3600.0529979217417,
    "input_throughput": 4659.861121401378,
    "output_throughput": 4079.188558745554,
    "total_throughput": 8739.049680146933,
    "itl": 209.01350248269128,
    "ttft": 2033950.2693389803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.160704347216563,
    "arrivals": 366022,
    "finished_requests": 67457,
    "scheduler_time": 102.27027137639112
}
#Debug simulation 
Total elapsed time: 14.949838710017502. Arrivals time: 0.2927185562439263 Scheduler time: 14.554782651830465 Scheduler overhead time: 0.034418174996972084 Adapter cache time: 0.019148713443428278 Engine time: 0.034402760211378336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.996476780623198,
    "estimated_duration": 3600.1258810654554,
    "input_throughput": 4659.7667843312265,
    "output_throughput": 4079.105977164858,
    "total_throughput": 8738.872761496084,
    "itl": 209.02089885271712,
    "ttft": 2033963.1063568732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3034239031863453,
    "arrivals": 366022,
    "finished_requests": 67457,
    "scheduler_time": 102.269211430803
}
#Debug simulation 
Total elapsed time: 14.996595434844494. Arrivals time: 0.30711409682407975 Scheduler time: 14.587200761772692 Scheduler overhead time: 0.03451730264350772 Adapter cache time: 0.018771061673760414 Engine time: 0.03482191730290651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.477030201815069,
    "estimated_duration": 3600.0260766803403,
    "input_throughput": 4463.318780961914,
    "output_throughput": 3913.542763276768,
    "total_throughput": 8376.861544238682,
    "itl": 177.8226179062188,
    "ttft": 2066183.0062425532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.019174643624512,
    "arrivals": 366022,
    "finished_requests": 64629,
    "scheduler_time": 107.26056903786353
}
#Debug simulation 
Total elapsed time: 9.47715085465461. Arrivals time: 0.25868827011436224 Scheduler time: 9.10090007726103 Scheduler overhead time: 0.033811346627771854 Adapter cache time: 0.034681383054703474 Engine time: 0.03379834070801735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 15.002245772164315,
    "estimated_duration": 3600.1317455612316,
    "input_throughput": 4659.75919372495,
    "output_throughput": 4079.099332435869,
    "total_throughput": 8738.858526160819,
    "itl": 209.01615671652513,
    "ttft": 2034001.0183882036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2069954080344,
    "arrivals": 366022,
    "finished_requests": 67457,
    "scheduler_time": 102.27151660706184
}
#Debug simulation 
Total elapsed time: 15.002345186192542. Arrivals time: 0.30002063512802124 Scheduler time: 14.600987060926855 Scheduler overhead time: 0.035051483660936356 Adapter cache time: 0.018516311421990395 Engine time: 0.0338351153768599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.96098270919174,
    "estimated_duration": 3600.026349282971,
    "input_throughput": 4459.004030122512,
    "output_throughput": 3917.3310503154626,
    "total_throughput": 8376.335080437973,
    "itl": 178.13701999498596,
    "ttft": 2065615.225659626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.569527729395746,
    "arrivals": 366022,
    "finished_requests": 64641,
    "scheduler_time": 107.2211352562398
}
#Debug simulation 
Total elapsed time: 9.961106507107615. Arrivals time: 0.26274564070627093 Scheduler time: 9.581119040958583 Scheduler overhead time: 0.03488127235323191 Adapter cache time: 0.03267335006967187 Engine time: 0.034225864335894585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.99239893304184,
    "estimated_duration": 3600.231172551964,
    "input_throughput": 4659.83715932004,
    "output_throughput": 4079.250552566573,
    "total_throughput": 8739.087711886614,
    "itl": 209.01050101597414,
    "ttft": 2033975.775078772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.110975508200898,
    "arrivals": 366022,
    "finished_requests": 67462,
    "scheduler_time": 102.27661584969336
}
#Debug simulation 
Total elapsed time: 14.992498446721584. Arrivals time: 0.2971570761874318 Scheduler time: 14.593313680496067 Scheduler overhead time: 0.03472189884632826 Adapter cache time: 0.019065693952143192 Engine time: 0.03412343328818679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.000481212045997,
    "estimated_duration": 3600.083655819059,
    "input_throughput": 4458.9330511954095,
    "output_throughput": 3917.2686937997073,
    "total_throughput": 8376.201744995116,
    "itl": 178.13965522712562,
    "ttft": 2065633.784236123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.626745702214538,
    "arrivals": 366022,
    "finished_requests": 64641,
    "scheduler_time": 107.22130058497386
}
#Debug simulation 
Total elapsed time: 10.000653455033898. Arrivals time: 0.2632712656632066 Scheduler time: 9.620211047586054 Scheduler overhead time: 0.034784840885549784 Adapter cache time: 0.03255598386749625 Engine time: 0.03435350535437465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.415357341989875,
    "estimated_duration": 3600.2001266186994,
    "input_throughput": 4637.890509626225,
    "output_throughput": 4082.6685970384456,
    "total_throughput": 8720.55910666467,
    "itl": 209.5577630321277,
    "ttft": 2031567.3756942344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3688175138039975,
    "arrivals": 356416,
    "finished_requests": 67253,
    "scheduler_time": 102.14535329482594
}
#Debug simulation 
Total elapsed time: 12.415454564150423. Arrivals time: 0.28214069502428174 Scheduler time: 12.034837731625885 Scheduler overhead time: 0.032650845125317574 Adapter cache time: 0.019764909520745277 Engine time: 0.032241683918982744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.495316714979708,
    "estimated_duration": 3600.141588391444,
    "input_throughput": 4637.682321672235,
    "output_throughput": 4082.587209178923,
    "total_throughput": 8720.269530851157,
    "itl": 209.56937339421876,
    "ttft": 2031545.7108475326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5263598985248295,
    "arrivals": 356416,
    "finished_requests": 67251,
    "scheduler_time": 102.13946434004752
}
#Debug simulation 
Total elapsed time: 12.495471099857241. Arrivals time: 0.30989919044077396 Scheduler time: 12.085345693863928 Scheduler overhead time: 0.03292158292606473 Adapter cache time: 0.02007510792464018 Engine time: 0.033497266471385956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.59260400896892,
    "estimated_duration": 3600.1737048297714,
    "input_throughput": 4434.73740685935,
    "output_throughput": 3912.35761238526,
    "total_throughput": 8347.09501924461,
    "itl": 177.5757348027598,
    "ttft": 2063529.2249900198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.955145491193918,
    "arrivals": 356416,
    "finished_requests": 64302,
    "scheduler_time": 107.30705522642208
}
#Debug simulation 
Total elapsed time: 8.592703473288566. Arrivals time: 0.2572639393620193 Scheduler time: 8.224252897780389 Scheduler overhead time: 0.03405559482052922 Adapter cache time: 0.028630710672587156 Engine time: 0.033280201721936464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.711806954350322,
    "estimated_duration": 3600.192350696742,
    "input_throughput": 4635.845081102406,
    "output_throughput": 4082.359098717503,
    "total_throughput": 8718.20417981991,
    "itl": 209.56217676291945,
    "ttft": 2031460.6805954087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 753,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3520223203976434,
    "arrivals": 356416,
    "finished_requests": 67254,
    "scheduler_time": 102.14847661042948
}
#Debug simulation 
Total elapsed time: 12.711934049148113. Arrivals time: 0.29857336077839136 Scheduler time: 12.312940954230726 Scheduler overhead time: 0.03361471090465784 Adapter cache time: 0.019802952650934458 Engine time: 0.03308386309072375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.67594749527052,
    "estimated_duration": 3600.12310549889,
    "input_throughput": 4431.707064580801,
    "output_throughput": 3913.1114651280204,
    "total_throughput": 8344.81852970882,
    "itl": 177.6148235281122,
    "ttft": 2063584.772510751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.074645693600177,
    "arrivals": 356416,
    "finished_requests": 64280,
    "scheduler_time": 107.29689277715056
}
#Debug simulation 
Total elapsed time: 8.676071777008474. Arrivals time: 0.2590109468437731 Scheduler time: 8.305122135672718 Scheduler overhead time: 0.033760576974600554 Adapter cache time: 0.029649185948073864 Engine time: 0.033239153213799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.717854208312929,
    "estimated_duration": 3600.194285468403,
    "input_throughput": 4638.033860394156,
    "output_throughput": 4082.94687298731,
    "total_throughput": 8720.980733381468,
    "itl": 209.55684563447838,
    "ttft": 2031518.8314038443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3142989282542388,
    "arrivals": 356416,
    "finished_requests": 67256,
    "scheduler_time": 102.14596171009832
}
#Debug simulation 
Total elapsed time: 12.71796052204445. Arrivals time: 0.28424754086881876 Scheduler time: 12.334151456598192 Scheduler overhead time: 0.03332492662593722 Adapter cache time: 0.020010442938655615 Engine time: 0.03238250873982906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.930948722641915,
    "estimated_duration": 3600.0636851023974,
    "input_throughput": 4433.789620459448,
    "output_throughput": 3910.642486203563,
    "total_throughput": 8344.432106663011,
    "itl": 177.52050232237855,
    "ttft": 2063398.05893341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.044786256738065,
    "arrivals": 356416,
    "finished_requests": 64273,
    "scheduler_time": 107.31340261018217
}
#Debug simulation 
Total elapsed time: 8.931053499691188. Arrivals time: 0.5189153756946325 Scheduler time: 8.300108391791582 Scheduler overhead time: 0.034035416319966316 Adapter cache time: 0.029111251700669527 Engine time: 0.03352125966921449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.459595338907093,
    "estimated_duration": 3600.203418501396,
    "input_throughput": 4632.104651170431,
    "output_throughput": 4081.992679768437,
    "total_throughput": 8714.097330938868,
    "itl": 209.82473961141645,
    "ttft": 2032002.0539039627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 747,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2861843447178103,
    "arrivals": 351637,
    "finished_requests": 67263,
    "scheduler_time": 102.12074474284594
}
#Debug simulation 
Total elapsed time: 11.459664087742567. Arrivals time: 0.27788798324763775 Scheduler time: 11.086215859279037 Scheduler overhead time: 0.03135430859401822 Adapter cache time: 0.019388859160244465 Engine time: 0.031187493819743395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.33803826989606,
    "estimated_duration": 3600.0444938144633,
    "input_throughput": 4633.94883831671,
    "output_throughput": 4081.9314942492897,
    "total_throughput": 8715.880332566,
    "itl": 209.79240633747253,
    "ttft": 2031543.7671718872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.406330345289322,
    "arrivals": 351637,
    "finished_requests": 67275,
    "scheduler_time": 102.11693235802323
}
#Debug simulation 
Total elapsed time: 11.338146158028394. Arrivals time: 0.27030668687075377 Scheduler time: 10.97226324910298 Scheduler overhead time: 0.031761569902300835 Adapter cache time: 0.0190314631909132 Engine time: 0.031041644047945738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.013719007838517,
    "estimated_duration": 3600.1905781749756,
    "input_throughput": 4436.347646933858,
    "output_throughput": 3917.184575031291,
    "total_throughput": 8353.53222196515,
    "itl": 178.6719276022062,
    "ttft": 2063197.3693108154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9196515902876263,
    "arrivals": 351637,
    "finished_requests": 64385,
    "scheduler_time": 107.0808341500546
}
#Debug simulation 
Total elapsed time: 9.013785114046186. Arrivals time: 0.2571467384696007 Scheduler time: 8.646118642296642 Scheduler overhead time: 0.033538435120135546 Adapter cache time: 0.028525991830974817 Engine time: 0.03309338819235563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 11.652797054033726,
    "estimated_duration": 3600.1544547624053,
    "input_throughput": 4632.332087291132,
    "output_throughput": 4080.7299199527147,
    "total_throughput": 8713.062007243847,
    "itl": 209.8496329613783,
    "ttft": 2031708.9224518496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.337480664241574,
    "arrivals": 351637,
    "finished_requests": 67249,
    "scheduler_time": 102.11609446689542
}
#Debug simulation 
Total elapsed time: 11.652919713873416. Arrivals time: 0.5349776521325111 Scheduler time: 11.021481011528522 Scheduler overhead time: 0.03182016499340534 Adapter cache time: 0.019475340843200684 Engine time: 0.031537070870399475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.320197647903115,
    "estimated_duration": 3600.145199593261,
    "input_throughput": 4438.347376046179,
    "output_throughput": 3916.1995470607326,
    "total_throughput": 8354.546923106913,
    "itl": 178.65637085362465,
    "ttft": 2063115.1876766745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9126318410784027,
    "arrivals": 351637,
    "finished_requests": 64390,
    "scheduler_time": 107.08374986333627
}
#Debug simulation 
Total elapsed time: 8.32026195898652. Arrivals time: 0.2539329659193754 Scheduler time: 7.956763187423348 Scheduler overhead time: 0.03335572453215718 Adapter cache time: 0.02816785452887416 Engine time: 0.03284680750221014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.500418794341385,
    "estimated_duration": 3600.146223831507,
    "input_throughput": 4632.178240319299,
    "output_throughput": 4082.0575294187825,
    "total_throughput": 8714.235769738081,
    "itl": 209.82186112826656,
    "ttft": 2031979.5654977586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 747,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.233567570291883,
    "arrivals": 351637,
    "finished_requests": 67263,
    "scheduler_time": 102.12040612060072
}
#Debug simulation 
Total elapsed time: 11.500560332089663. Arrivals time: 0.2870296291075647 Scheduler time: 11.11742111062631 Scheduler overhead time: 0.03217987343668938 Adapter cache time: 0.019105353858321905 Engine time: 0.03104716958478093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.329512774012983,
    "estimated_duration": 3600.0108040728473,
    "input_throughput": 4438.459179601026,
    "output_throughput": 3918.854905668367,
    "total_throughput": 8357.314085269392,
    "itl": 178.66122574849223,
    "ttft": 2064144.2906554744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.778685707114691,
    "arrivals": 351637,
    "finished_requests": 64410,
    "scheduler_time": 107.06894239860226
}
#Debug simulation 
Total elapsed time: 8.329580330755562. Arrivals time: 0.5109633151441813 Scheduler time: 7.710602100938559 Scheduler overhead time: 0.033049257937818766 Adapter cache time: 0.027143743820488453 Engine time: 0.03281580237671733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.055003680288792,
    "estimated_duration": 3600.088283902671,
    "input_throughput": 4627.19708138423,
    "output_throughput": 4081.8993427765863,
    "total_throughput": 8709.096424160816,
    "itl": 209.9830351564904,
    "ttft": 2023636.198430221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.310668246669273,
    "arrivals": 349246,
    "finished_requests": 67432,
    "scheduler_time": 102.08291648307018
}
#Debug simulation 
Total elapsed time: 10.055173113942146. Arrivals time: 0.2819463494233787 Scheduler time: 9.679544415790588 Scheduler overhead time: 0.03069152031093836 Adapter cache time: 0.019124476704746485 Engine time: 0.030340794008225203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.045874015893787,
    "estimated_duration": 3600.009509388032,
    "input_throughput": 4624.345284807304,
    "output_throughput": 4081.140053015451,
    "total_throughput": 8705.485337822754,
    "itl": 210.04158332887488,
    "ttft": 2023586.7148177663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.407147535926203,
    "arrivals": 349246,
    "finished_requests": 67398,
    "scheduler_time": 102.06806206034861
}
#Debug simulation 
Total elapsed time: 10.045968510676175. Arrivals time: 0.2716270047239959 Scheduler time: 9.681127417832613 Scheduler overhead time: 0.031105320900678635 Adapter cache time: 0.018220679368823767 Engine time: 0.030488476622849703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.484991112258285,
    "estimated_duration": 3600.129426199628,
    "input_throughput": 4429.5624162695685,
    "output_throughput": 3918.424125904681,
    "total_throughput": 8347.98654217425,
    "itl": 178.80460373166625,
    "ttft": 2054353.3338040875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.739779896307684,
    "arrivals": 349246,
    "finished_requests": 64643,
    "scheduler_time": 107.02625592958847
}
#Debug simulation 
Total elapsed time: 7.485122335143387. Arrivals time: 0.24661081284284592 Scheduler time: 7.130691307131201 Scheduler overhead time: 0.033261960837990046 Adapter cache time: 0.026949431747198105 Engine time: 0.03247538302093744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.119256789796054,
    "estimated_duration": 3600.1069671909313,
    "input_throughput": 4623.399013331941,
    "output_throughput": 4080.491255920204,
    "total_throughput": 8703.890269252146,
    "itl": 210.0362493476321,
    "ttft": 2023773.7185652177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.251028971821051,
    "arrivals": 349246,
    "finished_requests": 67400,
    "scheduler_time": 102.07585397167445
}
#Debug simulation 
Total elapsed time: 10.119356240611523. Arrivals time: 0.2668921947479248 Scheduler time: 9.759113477077335 Scheduler overhead time: 0.031088885851204395 Adapter cache time: 0.018372550141066313 Engine time: 0.030454767867922783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.611948078963906,
    "estimated_duration": 3600.1426267639554,
    "input_throughput": 4430.665296818484,
    "output_throughput": 3919.5516575085926,
    "total_throughput": 8350.216954327077,
    "itl": 178.7371302433508,
    "ttft": 2054434.4220929483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6955171175673627,
    "arrivals": 349246,
    "finished_requests": 64643,
    "scheduler_time": 107.04107489258632
}
#Debug simulation 
Total elapsed time: 7.612063393928111. Arrivals time: 0.2550214324146509 Scheduler time: 7.247827825136483 Scheduler overhead time: 0.03376096114516258 Adapter cache time: 0.026770022697746754 Engine time: 0.03325499501079321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.031104031950235,
    "estimated_duration": 3600.0766387265794,
    "input_throughput": 4624.463774162566,
    "output_throughput": 4081.4339455832755,
    "total_throughput": 8705.89771974584,
    "itl": 210.03107191382858,
    "ttft": 2023535.3927434986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.203667067342862,
    "arrivals": 349246,
    "finished_requests": 67402,
    "scheduler_time": 102.07466769884995
}
#Debug simulation 
Total elapsed time: 10.031204971950501. Arrivals time: 0.2700714557431638 Scheduler time: 9.667712709400803 Scheduler overhead time: 0.030543489381670952 Adapter cache time: 0.01864022109657526 Engine time: 0.030761212576180696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.566301526967436,
    "estimated_duration": 3600.0179660679714,
    "input_throughput": 4430.520111381814,
    "output_throughput": 3919.2862738434455,
    "total_throughput": 8349.80638522526,
    "itl": 178.59023506886263,
    "ttft": 2054489.0525977672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6720330783352755,
    "arrivals": 349246,
    "finished_requests": 64648,
    "scheduler_time": 107.07048939596929
}
#Debug simulation 
Total elapsed time: 7.56642183708027. Arrivals time: 0.25492042303085327 Scheduler time: 7.204218594357371 Scheduler overhead time: 0.03314803447574377 Adapter cache time: 0.026389051228761673 Engine time: 0.03266290528699756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.127147187944502,
    "estimated_duration": 3600.079758325652,
    "input_throughput": 4592.833245363986,
    "output_throughput": 4086.521962736253,
    "total_throughput": 8679.35520810024,
    "itl": 210.87116553169423,
    "ttft": 2027685.895101873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1025550800818387,
    "arrivals": 348063,
    "finished_requests": 67224,
    "scheduler_time": 102.0218496677333
}
#Debug simulation 
Total elapsed time: 9.127248111180961. Arrivals time: 0.27963023725897074 Scheduler time: 8.757463674992323 Scheduler overhead time: 0.02987445890903473 Adapter cache time: 0.017372602131217718 Engine time: 0.029574439860880375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.189994526095688,
    "estimated_duration": 3600.0339791246884,
    "input_throughput": 4592.607207563069,
    "output_throughput": 4086.459207136963,
    "total_throughput": 8679.066414700032,
    "itl": 210.8770606002892,
    "ttft": 2027737.6105884137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.247430138220086,
    "arrivals": 348063,
    "finished_requests": 67221,
    "scheduler_time": 102.01698672749585
}
#Debug simulation 
Total elapsed time: 9.1901088883169. Arrivals time: 0.2729514939710498 Scheduler time: 8.826800046022981 Scheduler overhead time: 0.030316912569105625 Adapter cache time: 0.017351871822029352 Engine time: 0.029327657539397478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.94369299383834,
    "estimated_duration": 3600.1141823323396,
    "input_throughput": 4396.721658907316,
    "output_throughput": 3917.087704941631,
    "total_throughput": 8313.809363848946,
    "itl": 178.7113879536313,
    "ttft": 2059532.307122407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3942257773130717,
    "arrivals": 348063,
    "finished_requests": 64362,
    "scheduler_time": 107.12029721275128
}
#Debug simulation 
Total elapsed time: 6.94386216904968. Arrivals time: 0.2384485537186265 Scheduler time: 6.60029983939603 Scheduler overhead time: 0.03249585209414363 Adapter cache time: 0.02526245405897498 Engine time: 0.03230964904651046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.199400526937097,
    "estimated_duration": 3600.1545806280874,
    "input_throughput": 4592.8208441303395,
    "output_throughput": 4086.563137917617,
    "total_throughput": 8679.383982047957,
    "itl": 210.87419533656933,
    "ttft": 2027692.915903787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1493672617943798,
    "arrivals": 348063,
    "finished_requests": 67225,
    "scheduler_time": 102.02296830017596
}
#Debug simulation 
Total elapsed time: 9.19949638703838. Arrivals time: 0.2679150318726897 Scheduler time: 8.840244910214096 Scheduler overhead time: 0.030375530943274498 Adapter cache time: 0.017537790350615978 Engine time: 0.02993563562631607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.796673339325935,
    "estimated_duration": 3600.115562442369,
    "input_throughput": 4218.360698870791,
    "output_throughput": 3761.4025897583315,
    "total_throughput": 7979.763288629122,
    "itl": 159.81958009406645,
    "ttft": 2062453.749877328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.103113009538502,
    "arrivals": 348063,
    "finished_requests": 61749,
    "scheduler_time": 112.11136105063528
}
#Debug simulation 
Total elapsed time: 6.796801815275103. Arrivals time: 0.22949887346476316 Scheduler time: 6.455032302066684 Scheduler overhead time: 0.035901632625609636 Adapter cache time: 0.02388262888416648 Engine time: 0.03583392407745123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.146887111943215,
    "estimated_duration": 3600.1423965197714,
    "input_throughput": 4593.076933841549,
    "output_throughput": 4086.838069022806,
    "total_throughput": 8679.915002864356,
    "itl": 210.8680786017496,
    "ttft": 2027671.663248901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0541645525977588,
    "arrivals": 348063,
    "finished_requests": 67227,
    "scheduler_time": 102.02455538020907
}
#Debug simulation 
Total elapsed time: 9.146984254010022. Arrivals time: 0.27847764920443296 Scheduler time: 8.777811134699732 Scheduler overhead time: 0.029949404299259186 Adapter cache time: 0.017348293215036392 Engine time: 0.029991905204951763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.049192389007658,
    "estimated_duration": 3600.18055455694,
    "input_throughput": 4396.290619359734,
    "output_throughput": 3916.624954310187,
    "total_throughput": 8312.915573669921,
    "itl": 178.46053459006583,
    "ttft": 2059586.9802180845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.361403238661628,
    "arrivals": 348063,
    "finished_requests": 64353,
    "scheduler_time": 107.17593007768124
}
#Debug simulation 
Total elapsed time: 7.049309671856463. Arrivals time: 0.2511118403635919 Scheduler time: 6.69317416427657 Scheduler overhead time: 0.03280879929661751 Adapter cache time: 0.024655515793710947 Engine time: 0.03248184686526656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.227659413591027,
    "estimated_duration": 3600.1552191407036,
    "input_throughput": 4629.412618486499,
    "output_throughput": 4080.4765644261133,
    "total_throughput": 8709.889182912613,
    "itl": 210.15211406636612,
    "ttft": 2019555.8702210002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6993501901487464,
    "arrivals": 337149,
    "finished_requests": 67257,
    "scheduler_time": 101.98272528486254
}
#Debug simulation 
Total elapsed time: 9.227785641793162. Arrivals time: 0.26391200674697757 Scheduler time: 8.868610023055226 Scheduler overhead time: 0.030585759319365025 Adapter cache time: 0.02118824888020754 Engine time: 0.03003978542983532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.692436262965202,
    "estimated_duration": 3600.118560546767,
    "input_throughput": 4629.20421083824,
    "output_throughput": 4080.8697694024595,
    "total_throughput": 8710.0739802407,
    "itl": 210.15323277955662,
    "ttft": 2019731.099023435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.888491534823558,
    "arrivals": 337149,
    "finished_requests": 67271,
    "scheduler_time": 101.9783045153777
}
#Debug simulation 
Total elapsed time: 9.692504195030779. Arrivals time: 0.5239808317273855 Scheduler time: 9.072092513553798 Scheduler overhead time: 0.030768047086894512 Adapter cache time: 0.021518248599022627 Engine time: 0.03061649762094021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.326753528788686,
    "estimated_duration": 3600.194001449892,
    "input_throughput": 4438.256103300269,
    "output_throughput": 3918.1391320354187,
    "total_throughput": 8356.395235335687,
    "itl": 178.84993031361986,
    "ttft": 2052275.5933611002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.269252679217549,
    "arrivals": 337149,
    "finished_requests": 64493,
    "scheduler_time": 106.95260781902971
}
#Debug simulation 
Total elapsed time: 7.326883471105248. Arrivals time: 0.24471130967140198 Scheduler time: 6.970440441276878 Scheduler overhead time: 0.03315067896619439 Adapter cache time: 0.030479344073683023 Engine time: 0.03289226721972227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.184908865019679,
    "estimated_duration": 3600.1747310328983,
    "input_throughput": 4629.525299517385,
    "output_throughput": 4081.0188664883835,
    "total_throughput": 8710.54416600577,
    "itl": 210.14541484102676,
    "ttft": 2019684.2975675452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7634613673807777,
    "arrivals": 337149,
    "finished_requests": 67275,
    "scheduler_time": 101.98295504407648
}
#Debug simulation 
Total elapsed time: 9.185007532127202. Arrivals time: 0.26331973262131214 Scheduler time: 8.82587296469137 Scheduler overhead time: 0.03057254897430539 Adapter cache time: 0.021421384066343307 Engine time: 0.030362515710294247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.331660771276802,
    "estimated_duration": 3600.0246391479627,
    "input_throughput": 4434.627426266301,
    "output_throughput": 3916.614304989063,
    "total_throughput": 8351.241731255364,
    "itl": 178.89990329715528,
    "ttft": 2051456.1103140395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.258695269711304,
    "arrivals": 337149,
    "finished_requests": 64455,
    "scheduler_time": 106.93970768390227
}
#Debug simulation 
Total elapsed time: 7.331809740047902. Arrivals time: 0.24662521062418818 Scheduler time: 6.974343869369477 Scheduler overhead time: 0.03308680187910795 Adapter cache time: 0.02990668872371316 Engine time: 0.03262764401733875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.200087829027325,
    "estimated_duration": 3600.087931505284,
    "input_throughput": 4629.4991447698585,
    "output_throughput": 4080.5528307908885,
    "total_throughput": 8710.051975560747,
    "itl": 210.14925965601543,
    "ttft": 2019528.5563087198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6372243601036622,
    "arrivals": 337149,
    "finished_requests": 67257,
    "scheduler_time": 101.98239563025915
}
#Debug simulation 
Total elapsed time: 9.200217006728053. Arrivals time: 0.2615653960965574 Scheduler time: 8.843337559141219 Scheduler overhead time: 0.030465145129710436 Adapter cache time: 0.021405475214123726 Engine time: 0.029970191419124603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.331394205801189,
    "estimated_duration": 3600.129398806575,
    "input_throughput": 4436.4880343730465,
    "output_throughput": 3914.607904002504,
    "total_throughput": 8351.09593837555,
    "itl": 178.7195799922036,
    "ttft": 2051603.6008544457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.280124658681486,
    "arrivals": 337149,
    "finished_requests": 64453,
    "scheduler_time": 106.97375116659961
}
#Debug simulation 
Total elapsed time: 7.33149593276903. Arrivals time: 0.24175248388200998 Scheduler time: 6.97897698963061 Scheduler overhead time: 0.03289388306438923 Adapter cache time: 0.030074000358581543 Engine time: 0.032641717698425055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.113211047835648,
    "estimated_duration": 3600.2234426610607,
    "input_throughput": 4642.258533722193,
    "output_throughput": 4080.6392253090744,
    "total_throughput": 8722.897759031266,
    "itl": 209.6180827031557,
    "ttft": 2018345.5116607004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.668745312709418,
    "arrivals": 332464,
    "finished_requests": 67141,
    "scheduler_time": 102.00454866403899
}
#Debug simulation 
Total elapsed time: 8.113329617772251. Arrivals time: 0.26221130788326263 Scheduler time: 7.758070795796812 Scheduler overhead time: 0.02978575835004449 Adapter cache time: 0.020567476749420166 Engine time: 0.029244459699839354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.140927305445075,
    "estimated_duration": 3600.004613007675,
    "input_throughput": 4642.1368293853275,
    "output_throughput": 4080.4939379583743,
    "total_throughput": 8722.630767343702,
    "itl": 209.62841460312737,
    "ttft": 2018357.0108558093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.845943523123866,
    "arrivals": 332464,
    "finished_requests": 67134,
    "scheduler_time": 101.99378188025607
}
#Debug simulation 
Total elapsed time: 8.14102459140122. Arrivals time: 0.25497426837682724 Scheduler time: 7.792934097815305 Scheduler overhead time: 0.029098185244947672 Adapter cache time: 0.020910860504955053 Engine time: 0.029824580531567335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.678381358738989,
    "estimated_duration": 3600.123230394583,
    "input_throughput": 4439.595251923699,
    "output_throughput": 3906.093236274782,
    "total_throughput": 8345.68848819848,
    "itl": 176.9902244814879,
    "ttft": 2052105.788869551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.422744446042862,
    "arrivals": 332464,
    "finished_requests": 64210,
    "scheduler_time": 107.22317419486141
}
#Debug simulation 
Total elapsed time: 6.6784775741398335. Arrivals time: 0.25450598262250423 Scheduler time: 6.312422295566648 Scheduler overhead time: 0.03281681193038821 Adapter cache time: 0.030819845385849476 Engine time: 0.032682766672223806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.144895067904145,
    "estimated_duration": 3600.0812897709543,
    "input_throughput": 4642.191843691195,
    "output_throughput": 4080.5670254558713,
    "total_throughput": 8722.758869147066,
    "itl": 209.62262563179297,
    "ttft": 2018325.2114180096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7225477369548474,
    "arrivals": 332464,
    "finished_requests": 67136,
    "scheduler_time": 101.99911444563391
}
#Debug simulation 
Total elapsed time: 8.145024938043207. Arrivals time: 0.25807831389829516 Scheduler time: 7.793963317759335 Scheduler overhead time: 0.0292250900529325 Adapter cache time: 0.02099999040365219 Engine time: 0.029387072660028934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.75319126714021,
    "estimated_duration": 3600.146265139281,
    "input_throughput": 4441.807032909909,
    "output_throughput": 3909.0634000825917,
    "total_throughput": 8350.8704329925,
    "itl": 177.40932303224955,
    "ttft": 2051989.572714297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.41030131204052,
    "arrivals": 332464,
    "finished_requests": 64250,
    "scheduler_time": 107.135410053374
}
#Debug simulation 
Total elapsed time: 6.753290717955679. Arrivals time: 0.23825339740142226 Scheduler time: 6.4035763614811 Scheduler overhead time: 0.032981229946017265 Adapter cache time: 0.030386294703930616 Engine time: 0.032815087120980024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.17486543301493,
    "estimated_duration": 3600.1213594975598,
    "input_throughput": 4642.3276692907075,
    "output_throughput": 4080.70993530349,
    "total_throughput": 8723.037604594198,
    "itl": 209.61328925360496,
    "ttft": 2018334.0060293884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6073238571546415,
    "arrivals": 332464,
    "finished_requests": 67140,
    "scheduler_time": 102.00296431225453
}
#Debug simulation 
Total elapsed time: 8.17499714391306. Arrivals time: 0.2566622095182538 Scheduler time: 7.825598979368806 Scheduler overhead time: 0.029316853266209364 Adapter cache time: 0.02086276514455676 Engine time: 0.029261881951242685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.714315610937774,
    "estimated_duration": 3600.1406447752843,
    "input_throughput": 4439.735992869156,
    "output_throughput": 3909.492541749997,
    "total_throughput": 8349.228534619153,
    "itl": 177.40711423628227,
    "ttft": 2052070.6364097337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.370565669611123,
    "arrivals": 332464,
    "finished_requests": 64233,
    "scheduler_time": 107.13899780261717
}
#Debug simulation 
Total elapsed time: 6.714462073054165. Arrivals time: 0.24096827628090978 Scheduler time: 6.362652234267443 Scheduler overhead time: 0.03293183259665966 Adapter cache time: 0.030029746238142252 Engine time: 0.03276396496221423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.286447945982218,
    "estimated_duration": 3600.0502347881034,
    "input_throughput": 4613.15312756393,
    "output_throughput": 4086.3871447799092,
    "total_throughput": 8699.54027234384,
    "itl": 210.50442897113854,
    "ttft": 2012045.4287241884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6381404352700892,
    "arrivals": 329992,
    "finished_requests": 67088,
    "scheduler_time": 101.86850348090293
}
#Debug simulation 
Total elapsed time: 7.286579554900527. Arrivals time: 0.25412515411153436 Scheduler time: 6.9409615765325725 Scheduler overhead time: 0.02884117653593421 Adapter cache time: 0.0200908905826509 Engine time: 0.02932664519175887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.295875117182732,
    "estimated_duration": 3600.022676394146,
    "input_throughput": 4612.157059141296,
    "output_throughput": 4086.4034264181287,
    "total_throughput": 8698.560485559425,
    "itl": 210.5330834843436,
    "ttft": 2011904.1403939954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 857,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7994583874265726,
    "arrivals": 329992,
    "finished_requests": 67077,
    "scheduler_time": 101.86207195316898
}
#Debug simulation 
Total elapsed time: 7.295973435975611. Arrivals time: 0.25005911802873015 Scheduler time: 6.954794425982982 Scheduler overhead time: 0.028880543541163206 Adapter cache time: 0.020210180431604385 Engine time: 0.028811939992010593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.11188468337059,
    "estimated_duration": 3600.1371865996466,
    "input_throughput": 4421.078190921171,
    "output_throughput": 3916.282427369593,
    "total_throughput": 8337.360618290764,
    "itl": 178.67162526493445,
    "ttft": 2043942.5433922347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9514274773559825,
    "arrivals": 329992,
    "finished_requests": 64288,
    "scheduler_time": 106.91435946714196
}
#Debug simulation 
Total elapsed time: 6.112001060973853. Arrivals time: 0.24400678556412458 Scheduler time: 5.761126695666462 Scheduler overhead time: 0.03240704629570246 Adapter cache time: 0.02712528593838215 Engine time: 0.032348751090466976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.35147250816226,
    "estimated_duration": 3600.1568978793757,
    "input_throughput": 4613.108114755407,
    "output_throughput": 4086.336628457939,
    "total_throughput": 8699.444743213346,
    "itl": 210.51181378868986,
    "ttft": 2012067.8702498537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.67008250066775,
    "arrivals": 329992,
    "finished_requests": 67086,
    "scheduler_time": 101.87054300917652
}
#Debug simulation 
Total elapsed time: 7.3515738332644105. Arrivals time: 0.2650146558880806 Scheduler time: 6.995439125690609 Scheduler overhead time: 0.029020826797932386 Adapter cache time: 0.01983794802799821 Engine time: 0.029019718524068594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.313520196359605,
    "estimated_duration": 3600.153131730016,
    "input_throughput": 4421.465259271012,
    "output_throughput": 3916.5336817837897,
    "total_throughput": 8337.9989410548,
    "itl": 178.67326117102806,
    "ttft": 2044010.3306977462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.02309393581003,
    "arrivals": 329992,
    "finished_requests": 64291,
    "scheduler_time": 106.91364226048641
}
#Debug simulation 
Total elapsed time: 6.313631094992161. Arrivals time: 0.2388028483837843 Scheduler time: 5.968586369417608 Scheduler overhead time: 0.03251351974904537 Adapter cache time: 0.026698401663452387 Engine time: 0.03200621297582984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.338565963786095,
    "estimated_duration": 3600.129634286691,
    "input_throughput": 4613.187492425013,
    "output_throughput": 4086.608676499788,
    "total_throughput": 8699.796168924802,
    "itl": 210.50575061366615,
    "ttft": 2012014.216344865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5564930021413064,
    "arrivals": 329992,
    "finished_requests": 67088,
    "scheduler_time": 101.87237522183293
}
#Debug simulation 
Total elapsed time: 7.338673831894994. Arrivals time: 0.2735901949927211 Scheduler time: 6.974369366187602 Scheduler overhead time: 0.02897876314818859 Adapter cache time: 0.019898332189768553 Engine time: 0.02860542433336377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.110327295027673,
    "estimated_duration": 3600.086225948915,
    "input_throughput": 4421.70325956684,
    "output_throughput": 3916.6964664251586,
    "total_throughput": 8338.399725991998,
    "itl": 178.67011815623715,
    "ttft": 2044115.4271172986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0490212893114075,
    "arrivals": 329992,
    "finished_requests": 64297,
    "scheduler_time": 106.91044480175107
}
#Debug simulation 
Total elapsed time: 6.110486830584705. Arrivals time: 0.2498340387828648 Scheduler time: 5.753651523496956 Scheduler overhead time: 0.03242863854393363 Adapter cache time: 0.027246718760579824 Engine time: 0.03231533011421561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.6815397292375565,
    "estimated_duration": 3600.128524654891,
    "input_throughput": 4603.798971757214,
    "output_throughput": 4083.95891960813,
    "total_throughput": 8687.757891365343,
    "itl": 210.3174491616247,
    "ttft": 2007929.0484019131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.687108239173015,
    "arrivals": 328805,
    "finished_requests": 67261,
    "scheduler_time": 101.82152756703685
}
#Debug simulation 
Total elapsed time: 6.681663196068257. Arrivals time: 0.24587029963731766 Scheduler time: 6.345202081371099 Scheduler overhead time: 0.028785424306988716 Adapter cache time: 0.020031266380101442 Engine time: 0.028601628728210926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.720301922876388,
    "estimated_duration": 3600.1761936126386,
    "input_throughput": 4602.249198079869,
    "output_throughput": 4083.8342929118094,
    "total_throughput": 8686.083490991678,
    "itl": 210.36162550474873,
    "ttft": 2007867.8663695985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.860355296214118,
    "arrivals": 328805,
    "finished_requests": 67246,
    "scheduler_time": 101.81521950838615
}
#Debug simulation 
Total elapsed time: 6.720402610022575. Arrivals time: 0.2496960386633873 Scheduler time: 6.380010069347918 Scheduler overhead time: 0.028722595889121294 Adapter cache time: 0.020367827266454697 Engine time: 0.0284445327706635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.718921836931258,
    "estimated_duration": 3600.0871466391823,
    "input_throughput": 4409.388537946686,
    "output_throughput": 3913.852200259581,
    "total_throughput": 8323.240738206267,
    "itl": 178.0153712049177,
    "ttft": 2039106.0463793173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0241180994361,
    "arrivals": 328805,
    "finished_requests": 64364,
    "scheduler_time": 106.99939248177638
}
#Debug simulation 
Total elapsed time: 5.719016945920885. Arrivals time: 0.23872059350833297 Scheduler time: 5.372787434142083 Scheduler overhead time: 0.03239688370376825 Adapter cache time: 0.02792486222460866 Engine time: 0.032168627716600895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.6746359299868345,
    "estimated_duration": 3600.2052237507673,
    "input_throughput": 4603.380076965111,
    "output_throughput": 4084.06634794047,
    "total_throughput": 8687.44642490558,
    "itl": 210.33536699180797,
    "ttft": 2007864.5478647726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.73831517906624,
    "arrivals": 328805,
    "finished_requests": 67256,
    "scheduler_time": 101.8211173893941
}
#Debug simulation 
Total elapsed time: 6.674769123084843. Arrivals time: 0.24902461608871818 Scheduler time: 6.335317393299192 Scheduler overhead time: 0.02855086885392666 Adapter cache time: 0.01995766069740057 Engine time: 0.028711782302707434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.7387493760325015,
    "estimated_duration": 3600.0679091129628,
    "input_throughput": 4409.824592423224,
    "output_throughput": 3914.6383778833856,
    "total_throughput": 8324.46297030661,
    "itl": 178.23201707787308,
    "ttft": 2038920.5834479672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.122553753089155,
    "arrivals": 328805,
    "finished_requests": 64373,
    "scheduler_time": 106.95487690439825
}
#Debug simulation 
Total elapsed time: 5.738846284337342. Arrivals time: 0.23269302677363157 Scheduler time: 5.398687923327088 Scheduler overhead time: 0.03249446302652359 Adapter cache time: 0.02776673436164856 Engine time: 0.03216839535161853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.698274228256196,
    "estimated_duration": 3600.2330945963477,
    "input_throughput": 4603.365272341667,
    "output_throughput": 4084.0372313861335,
    "total_throughput": 8687.4025037278,
    "itl": 210.32694867748592,
    "ttft": 2007894.1779665514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.622274108629152,
    "arrivals": 328805,
    "finished_requests": 67258,
    "scheduler_time": 101.82456202165643
}
#Debug simulation 
Total elapsed time: 6.698376617860049. Arrivals time: 0.2677744454704225 Scheduler time: 6.340249160304666 Scheduler overhead time: 0.02844647504389286 Adapter cache time: 0.020390077959746122 Engine time: 0.02843842888250947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.643792188726366,
    "estimated_duration": 3600.0033992070057,
    "input_throughput": 4410.792501889785,
    "output_throughput": 3914.4507483254424,
    "total_throughput": 8325.243250215228,
    "itl": 178.259411000948,
    "ttft": 2039077.7738339952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.164273452311801,
    "arrivals": 328805,
    "finished_requests": 64386,
    "scheduler_time": 106.9460351405913
}
#Debug simulation 
Total elapsed time: 5.643895673099905. Arrivals time: 0.2341119023039937 Scheduler time: 5.30259814299643 Scheduler overhead time: 0.032281437423080206 Adapter cache time: 0.02810895023867488 Engine time: 0.03196961572393775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.324601911939681,
    "estimated_duration": 3600.1032380793226,
    "input_throughput": 4635.465678729601,
    "output_throughput": 4080.9363033261684,
    "total_throughput": 8716.40198205577,
    "itl": 209.97279077630432,
    "ttft": 2004963.290153938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2624799350323928,
    "arrivals": 322791,
    "finished_requests": 67503,
    "scheduler_time": 101.81238952307783
}
#Debug simulation 
Total elapsed time: 6.32470168126747. Arrivals time: 0.2445431319065392 Scheduler time: 5.986482044216245 Scheduler overhead time: 0.028623381163924932 Adapter cache time: 0.02342065330594778 Engine time: 0.028527371119707823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.34224882395938,
    "estimated_duration": 3600.07978487227,
    "input_throughput": 4634.797559241316,
    "output_throughput": 4080.5223433461224,
    "total_throughput": 8715.319902587438,
    "itl": 209.98395955764798,
    "ttft": 2004997.7915062883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.475323430800351,
    "arrivals": 322791,
    "finished_requests": 67497,
    "scheduler_time": 101.80565433827641
}
#Debug simulation 
Total elapsed time: 6.342400568071753. Arrivals time: 0.2511880681850016 Scheduler time: 5.997388488613069 Scheduler overhead time: 0.02846236852928996 Adapter cache time: 0.02372458018362522 Engine time: 0.028470237273722887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.741020123939961,
    "estimated_duration": 3600.1493283915283,
    "input_throughput": 4442.842099315415,
    "output_throughput": 3919.72407608569,
    "total_throughput": 8362.566175401105,
    "itl": 179.04775342074817,
    "ttft": 2035974.7326432732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0516250256820925,
    "arrivals": 322791,
    "finished_requests": 64721,
    "scheduler_time": 106.7046454109073
}
#Debug simulation 
Total elapsed time: 5.741129429079592. Arrivals time: 0.23313861805945635 Scheduler time: 5.395642418880016 Scheduler overhead time: 0.03246657131239772 Adapter cache time: 0.03286430612206459 Engine time: 0.03197847353294492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.279757195618004,
    "estimated_duration": 3600.1152403108417,
    "input_throughput": 4634.8566326891505,
    "output_throughput": 4080.665484122547,
    "total_throughput": 8715.522116811697,
    "itl": 209.9771572637229,
    "ttft": 2004990.9061001162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.332036357093565,
    "arrivals": 322791,
    "finished_requests": 67499,
    "scheduler_time": 101.8104982781889
}
#Debug simulation 
Total elapsed time: 6.27985033672303. Arrivals time: 0.24115851894021034 Scheduler time: 5.945124721620232 Scheduler overhead time: 0.028536947909742594 Adapter cache time: 0.023438469972461462 Engine time: 0.028531943913549185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.468445033766329,
    "estimated_duration": 3600.029919293642,
    "input_throughput": 4442.334191249688,
    "output_throughput": 3919.426037094858,
    "total_throughput": 8361.760228344547,
    "itl": 179.0241343215788,
    "ttft": 2036010.9579767657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.161127012539609,
    "arrivals": 322791,
    "finished_requests": 64710,
    "scheduler_time": 106.70364716476745
}
#Debug simulation 
Total elapsed time: 5.468549117911607. Arrivals time: 0.23104474786669016 Scheduler time: 5.1242332817055285 Scheduler overhead time: 0.03262909082695842 Adapter cache time: 0.03315350925549865 Engine time: 0.03248165035620332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.588068241253495,
    "estimated_duration": 3600.0517069107173,
    "input_throughput": 4635.046760014169,
    "output_throughput": 4080.83944233314,
    "total_throughput": 8715.886202347308,
    "itl": 209.96866263473018,
    "ttft": 2004983.2034673693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.184403564070741,
    "arrivals": 322791,
    "finished_requests": 67500,
    "scheduler_time": 101.81213554827211
}
#Debug simulation 
Total elapsed time: 6.588133007287979. Arrivals time: 0.25292521761730313 Scheduler time: 6.241362166125327 Scheduler overhead time: 0.02860969305038452 Adapter cache time: 0.023430652916431427 Engine time: 0.02865788759663701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.472084084991366,
    "estimated_duration": 3600.170361524327,
    "input_throughput": 4442.222560053686,
    "output_throughput": 3919.380080120871,
    "total_throughput": 8361.602640174557,
    "itl": 179.04181265380282,
    "ttft": 2035964.161406111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.174892908148412,
    "arrivals": 322791,
    "finished_requests": 64710,
    "scheduler_time": 106.70487366978463
}
#Debug simulation 
Total elapsed time: 5.472182746976614. Arrivals time: 0.22973560448735952 Scheduler time: 5.130605564452708 Scheduler overhead time: 0.032164341770112514 Adapter cache time: 0.03266287408769131 Engine time: 0.032046777196228504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.057874981779605,
    "estimated_duration": 3600.0151169820892,
    "input_throughput": 4645.634381118964,
    "output_throughput": 4079.773423927284,
    "total_throughput": 8725.407805046247,
    "itl": 209.2545731491369,
    "ttft": 2002199.5239445027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2012701801537355,
    "arrivals": 320386,
    "finished_requests": 67519,
    "scheduler_time": 101.80682365791886
}
#Debug simulation 
Total elapsed time: 6.057969090063125. Arrivals time: 0.49881267407909036 Scheduler time: 5.4660189230926335 Scheduler overhead time: 0.028597287368029356 Adapter cache time: 0.022792236413806677 Engine time: 0.02860770234838128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.752368101850152,
    "estimated_duration": 3600.0341367612386,
    "input_throughput": 4645.63789249124,
    "output_throughput": 4079.719925437496,
    "total_throughput": 8725.357817928736,
    "itl": 209.2638195443791,
    "ttft": 2002226.3628318724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.414017926694366,
    "arrivals": 320386,
    "finished_requests": 67518,
    "scheduler_time": 101.80200171788609
}
#Debug simulation 
Total elapsed time: 5.752469121944159. Arrivals time: 0.23624379001557827 Scheduler time: 5.423578627873212 Scheduler overhead time: 0.02875598007813096 Adapter cache time: 0.022492957767099142 Engine time: 0.028316952753812075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.182102495804429,
    "estimated_duration": 3600.1660135920683,
    "input_throughput": 4450.981410163297,
    "output_throughput": 3917.307964898197,
    "total_throughput": 8368.289375061495,
    "itl": 178.26019257838485,
    "ttft": 2034047.6127874085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9096328392624295,
    "arrivals": 320386,
    "finished_requests": 64688,
    "scheduler_time": 106.73897219642336
}
#Debug simulation 
Total elapsed time: 5.182196990121156. Arrivals time: 0.2322364063002169 Scheduler time: 4.838680447544903 Scheduler overhead time: 0.03234266582876444 Adapter cache time: 0.031715054996311665 Engine time: 0.032188431825488806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.784120732918382,
    "estimated_duration": 3600.0871309305708,
    "input_throughput": 4645.615062010159,
    "output_throughput": 4079.8440331646684,
    "total_throughput": 8725.459095174829,
    "itl": 209.2584230445766,
    "ttft": 2002214.0400780775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.264472040145156,
    "arrivals": 320386,
    "finished_requests": 67520,
    "scheduler_time": 101.80732446605809
}
#Debug simulation 
Total elapsed time: 5.784264498855919. Arrivals time: 0.2411574083380401 Scheduler time: 5.449268243275583 Scheduler overhead time: 0.029071776662021875 Adapter cache time: 0.022933575324714184 Engine time: 0.028515785466879606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.181521229445934,
    "estimated_duration": 3600.1295623824853,
    "input_throughput": 4450.896203134369,
    "output_throughput": 3917.295129419482,
    "total_throughput": 8368.19133255385,
    "itl": 178.25496588542873,
    "ttft": 2034087.7788500264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.977313804328397,
    "arrivals": 320386,
    "finished_requests": 64687,
    "scheduler_time": 106.73841595627927
}
#Debug simulation 
Total elapsed time: 5.181625436060131. Arrivals time: 0.2302337298169732 Scheduler time: 4.840204520151019 Scheduler overhead time: 0.03236039448529482 Adapter cache time: 0.03164484724402428 Engine time: 0.03215512586757541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.800805603619665,
    "estimated_duration": 3600.106099266041,
    "input_throughput": 4645.648083374464,
    "output_throughput": 4079.9369782447543,
    "total_throughput": 8725.585061619218,
    "itl": 209.25061852797737,
    "ttft": 2002166.1790694126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1275926084676016,
    "arrivals": 320386,
    "finished_requests": 67522,
    "scheduler_time": 101.81117631422256
}
#Debug simulation 
Total elapsed time: 5.800905047915876. Arrivals time: 0.2573052574880421 Scheduler time: 5.451117882039398 Scheduler overhead time: 0.02827913872897625 Adapter cache time: 0.022969188634306192 Engine time: 0.028176039457321167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.173333805054426,
    "estimated_duration": 3600.110959053263,
    "input_throughput": 4450.754207924107,
    "output_throughput": 3917.038435867656,
    "total_throughput": 8367.792643791763,
    "itl": 178.26038394317655,
    "ttft": 2034027.4809468265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.044225660785988,
    "arrivals": 320386,
    "finished_requests": 64686,
    "scheduler_time": 106.73556304573209
}
#Debug simulation 
Total elapsed time: 5.173449672292918. Arrivals time: 0.23456463171169162 Scheduler time: 4.828357132151723 Scheduler overhead time: 0.03236749954521656 Adapter cache time: 0.0313210254535079 Engine time: 0.03185205813497305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.4780868999660015,
    "estimated_duration": 3600.103245236149,
    "input_throughput": 4627.042299979185,
    "output_throughput": 4081.4379474931343,
    "total_throughput": 8708.48024747232,
    "itl": 210.04686900889487,
    "ttft": 2007663.0091804499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.51650041777882,
    "arrivals": 319202,
    "finished_requests": 67139,
    "scheduler_time": 101.84043328168418
}
#Debug simulation 
Total elapsed time: 5.478186958003789. Arrivals time: 0.23881817189976573 Scheduler time: 5.145982653833926 Scheduler overhead time: 0.028036904986947775 Adapter cache time: 0.0243539921939373 Engine time: 0.027936617378145456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.476286452263594,
    "estimated_duration": 3600.1997738313516,
    "input_throughput": 4626.778525202001,
    "output_throughput": 4081.2632417792875,
    "total_throughput": 8708.041766981289,
    "itl": 210.06133664267716,
    "ttft": 2007725.2885033882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7530463512707577,
    "arrivals": 319202,
    "finished_requests": 67136,
    "scheduler_time": 101.8371291161472
}
#Debug simulation 
Total elapsed time: 5.476381563115865. Arrivals time: 0.23726469930261374 Scheduler time: 5.1451647956855595 Scheduler overhead time: 0.028283081483095884 Adapter cache time: 0.02447572909295559 Engine time: 0.028134687338024378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.943085971754044,
    "estimated_duration": 3600.134564783048,
    "input_throughput": 4431.962948296496,
    "output_throughput": 3916.474994553346,
    "total_throughput": 8348.437942849841,
    "itl": 178.38991751271334,
    "ttft": 2040410.98872419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.180094146728469,
    "arrivals": 319202,
    "finished_requests": 64267,
    "scheduler_time": 106.87029930590987
}
#Debug simulation 
Total elapsed time: 4.943198384717107. Arrivals time: 0.23416223423555493 Scheduler time: 4.597414454910904 Scheduler overhead time: 0.03188401320949197 Adapter cache time: 0.03297461336478591 Engine time: 0.031748313922435045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.419912680052221,
    "estimated_duration": 3600.186238169569,
    "input_throughput": 4626.935635549034,
    "output_throughput": 4081.343860552786,
    "total_throughput": 8708.279496101819,
    "itl": 210.04825977572162,
    "ttft": 2007691.37840626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5904254145314516,
    "arrivals": 319202,
    "finished_requests": 67139,
    "scheduler_time": 101.84094029562593
}
#Debug simulation 
Total elapsed time: 5.420009898021817. Arrivals time: 0.24117009993642569 Scheduler time: 5.085564656183124 Scheduler overhead time: 0.0281992731615901 Adapter cache time: 0.02419631602242589 Engine time: 0.027869489043951035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.919335739687085,
    "estimated_duration": 3600.057335999099,
    "input_throughput": 4432.058023201437,
    "output_throughput": 3916.559011160018,
    "total_throughput": 8348.617034361456,
    "itl": 178.40288949200925,
    "ttft": 2040404.9305284175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.266454082410732,
    "arrivals": 319202,
    "finished_requests": 64267,
    "scheduler_time": 106.86301921634455
}
#Debug simulation 
Total elapsed time: 4.919441691599786. Arrivals time: 0.2341849454678595 Scheduler time: 4.573679190129042 Scheduler overhead time: 0.031969523057341576 Adapter cache time: 0.03304226230829954 Engine time: 0.03169022360816598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.446211535017937,
    "estimated_duration": 3600.1524588622474,
    "input_throughput": 4627.059323277784,
    "output_throughput": 4081.447707535052,
    "total_throughput": 8708.507030812836,
    "itl": 210.0394153819178,
    "ttft": 2007654.2104938768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4265976379578085,
    "arrivals": 319202,
    "finished_requests": 67140,
    "scheduler_time": 101.84407868737244
}
#Debug simulation 
Total elapsed time: 5.44638080522418. Arrivals time: 0.24069896852597594 Scheduler time: 5.111512546893209 Scheduler overhead time: 0.0283752279356122 Adapter cache time: 0.02451908588409424 Engine time: 0.02816353365778923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9543959349393845,
    "estimated_duration": 3600.1800102109364,
    "input_throughput": 4431.907003190418,
    "output_throughput": 3916.425556502627,
    "total_throughput": 8348.332559693044,
    "itl": 178.40009481732608,
    "ttft": 2040431.6482587543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3121101944892954,
    "arrivals": 319202,
    "finished_requests": 64267,
    "scheduler_time": 106.86758914820436
}
#Debug simulation 
Total elapsed time: 4.954496595077217. Arrivals time: 0.22769708838313818 Scheduler time: 4.614591364748776 Scheduler overhead time: 0.03209905792027712 Adapter cache time: 0.03329889755696058 Engine time: 0.03178126644343138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.938175593968481,
    "estimated_duration": 3600.206545062712,
    "input_throughput": 4624.87298758854,
    "output_throughput": 4088.489595183379,
    "total_throughput": 8713.362582771919,
    "itl": 210.05621030716426,
    "ttft": 1997045.0974419347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.397920888031484,
    "arrivals": 315552,
    "finished_requests": 67440,
    "scheduler_time": 101.83866786800434
}
#Debug simulation 
Total elapsed time: 4.938296793028712. Arrivals time: 0.2451192713342607 Scheduler time: 4.596334807109088 Scheduler overhead time: 0.027458710130304098 Adapter cache time: 0.028584551997482777 Engine time: 0.02788593666628003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.935325901955366,
    "estimated_duration": 3600.024211688451,
    "input_throughput": 4624.193622351299,
    "output_throughput": 4088.20222714482,
    "total_throughput": 8712.395849496119,
    "itl": 210.07599838840062,
    "ttft": 1997026.8265431288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6922225420246235,
    "arrivals": 315552,
    "finished_requests": 67431,
    "scheduler_time": 101.82568909117143
}
#Debug simulation 
Total elapsed time: 4.935429722070694. Arrivals time: 0.24028989486396313 Scheduler time: 4.598199473228306 Scheduler overhead time: 0.027698480058461428 Adapter cache time: 0.028504760470241308 Engine time: 0.027787734754383564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.807687079999596,
    "estimated_duration": 3600.136791448148,
    "input_throughput": 4494.680601703203,
    "output_throughput": 3980.559581525112,
    "total_throughput": 8475.240183228316,
    "itl": 176.10914462944373,
    "ttft": 2019891.909802411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.788583163097453,
    "arrivals": 315552,
    "finished_requests": 65499,
    "scheduler_time": 108.31504928356982
}
#Debug simulation 
Total elapsed time: 4.807781123090535. Arrivals time: 0.24385520862415433 Scheduler time: 4.454004309140146 Scheduler overhead time: 0.031349267810583115 Adapter cache time: 0.03185661043971777 Engine time: 0.031878999434411526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.920857314951718,
    "estimated_duration": 3600.1542047865237,
    "input_throughput": 4624.759122224121,
    "output_throughput": 4088.4137630634573,
    "total_throughput": 8713.172885287579,
    "itl": 210.06039749602647,
    "ttft": 1997045.6197478003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.492419431307275,
    "arrivals": 315552,
    "finished_requests": 67439,
    "scheduler_time": 101.83479980200751
}
#Debug simulation 
Total elapsed time: 4.920957723166794. Arrivals time: 0.23400654317811131 Scheduler time: 4.59027238143608 Scheduler overhead time: 0.027469472028315067 Adapter cache time: 0.028519803658127785 Engine time: 0.027769096195697784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8268300332129,
    "estimated_duration": 3600.1653350239235,
    "input_throughput": 4494.608578828637,
    "output_throughput": 3980.4794131502777,
    "total_throughput": 8475.087991978915,
    "itl": 176.1187468702696,
    "ttft": 2019929.8746314347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.854629328940025,
    "arrivals": 315552,
    "finished_requests": 65499,
    "scheduler_time": 108.3127988142788
}
#Debug simulation 
Total elapsed time: 4.8269272851757705. Arrivals time: 0.23487945878878236 Scheduler time: 4.4816881264559925 Scheduler overhead time: 0.031620202120393515 Adapter cache time: 0.03172588814049959 Engine time: 0.03210427891463041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.914312690030783,
    "estimated_duration": 3600.083827132724,
    "input_throughput": 4625.030638039681,
    "output_throughput": 4088.6289616548256,
    "total_throughput": 8713.659599694507,
    "itl": 210.05068408216377,
    "ttft": 1997002.3522676288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.296702273774311,
    "arrivals": 315552,
    "finished_requests": 67440,
    "scheduler_time": 101.83788824148566
}
#Debug simulation 
Total elapsed time: 4.914413958787918. Arrivals time: 0.2547307671047747 Scheduler time: 4.563168059568852 Scheduler overhead time: 0.02775364276021719 Adapter cache time: 0.02827049233019352 Engine time: 0.02765525784343481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.81117036100477,
    "estimated_duration": 3600.160447951537,
    "input_throughput": 4494.512740177133,
    "output_throughput": 3980.4670395048192,
    "total_throughput": 8474.979779681953,
    "itl": 176.10622367391088,
    "ttft": 2019925.7698940102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.908526847362487,
    "arrivals": 315552,
    "finished_requests": 65498,
    "scheduler_time": 108.31520066551309
}
#Debug simulation 
Total elapsed time: 4.811265984084457. Arrivals time: 0.2341116825118661 Scheduler time: 4.4676320613361895 Scheduler overhead time: 0.031218653079122305 Adapter cache time: 0.03153523663058877 Engine time: 0.03186047775670886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.931366441771388,
    "estimated_duration": 3600.0581367839695,
    "input_throughput": 4725.402022312072,
    "output_throughput": 4141.406453318804,
    "total_throughput": 8866.808475630876,
    "itl": 206.30803056832016,
    "ttft": 1984244.5594203228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.828670167659972,
    "arrivals": 314288,
    "finished_requests": 68424,
    "scheduler_time": 103.32532529518745
}
#Debug simulation 
Total elapsed time: 4.931536708958447. Arrivals time: 0.23760509304702282 Scheduler time: 4.599574041552842 Scheduler overhead time: 0.027430773712694645 Adapter cache time: 0.025932786986231804 Engine time: 0.027946350164711475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.905465226154774,
    "estimated_duration": 3600.183995268738,
    "input_throughput": 4724.9568417489245,
    "output_throughput": 4141.151402148577,
    "total_throughput": 8866.1082438975,
    "itl": 206.32320226231982,
    "ttft": 1984312.2411519887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.085815963004715,
    "arrivals": 314288,
    "finished_requests": 68422,
    "scheduler_time": 103.3213521978719
}
#Debug simulation 
Total elapsed time: 4.90556202782318. Arrivals time: 0.24572010524570942 Scheduler time: 4.565684410277754 Scheduler overhead time: 0.027373450808227062 Adapter cache time: 0.025871568825095892 Engine time: 0.027957431506365538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.856957133393735,
    "estimated_duration": 3600.0523953201377,
    "input_throughput": 4591.943167685466,
    "output_throughput": 4030.1546774320755,
    "total_throughput": 8622.09784511754,
    "itl": 173.45934428909212,
    "ttft": 2008222.7311817226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.978136360607975,
    "arrivals": 314288,
    "finished_requests": 66488,
    "scheduler_time": 109.78295281153962
}
#Debug simulation 
Total elapsed time: 4.857056131120771. Arrivals time: 0.24204403441399336 Scheduler time: 4.507389035541564 Scheduler overhead time: 0.03176137851551175 Adapter cache time: 0.02836231328547001 Engine time: 0.032363814767450094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.9955339431762695,
    "estimated_duration": 3600.155249714984,
    "input_throughput": 4725.274556242201,
    "output_throughput": 4141.2947403255275,
    "total_throughput": 8866.569296567728,
    "itl": 206.3117098138553,
    "ttft": 1984308.370494339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.912980143304403,
    "arrivals": 314288,
    "finished_requests": 68424,
    "scheduler_time": 103.3262503237173
}
#Debug simulation 
Total elapsed time: 4.995646778959781. Arrivals time: 0.24755586311221123 Scheduler time: 4.65352205792442 Scheduler overhead time: 0.027536123991012573 Adapter cache time: 0.026043022982776165 Engine time: 0.028034596238285303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.840437273960561,
    "estimated_duration": 3600.1381548354243,
    "input_throughput": 4591.834059978097,
    "output_throughput": 4030.135338143228,
    "total_throughput": 8621.969398121324,
    "itl": 173.46325465575515,
    "ttft": 2008286.0000574458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.034585224818437,
    "arrivals": 314288,
    "finished_requests": 66489,
    "scheduler_time": 109.7839840127077
}
#Debug simulation 
Total elapsed time: 4.840536693111062. Arrivals time: 0.2324074348434806 Scheduler time: 4.500616951379925 Scheduler overhead time: 0.03170297062024474 Adapter cache time: 0.028422331903129816 Engine time: 0.032350131776183844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.188323477748781,
    "estimated_duration": 3600.1331982590204,
    "input_throughput": 4725.722095012314,
    "output_throughput": 4141.565930730113,
    "total_throughput": 8867.288025742428,
    "itl": 206.30387136526656,
    "ttft": 1984296.3859173441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7405529189225257,
    "arrivals": 314288,
    "finished_requests": 68427,
    "scheduler_time": 103.32954193463682
}
#Debug simulation 
Total elapsed time: 5.188387507107109. Arrivals time: 0.24186995485797524 Scheduler time: 4.852413759101182 Scheduler overhead time: 0.02726232446730137 Adapter cache time: 0.02592145511880517 Engine time: 0.028008023276925087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.861426929011941,
    "estimated_duration": 3600.0252104109372,
    "input_throughput": 4592.014231509498,
    "output_throughput": 4030.1892770200475,
    "total_throughput": 8622.203508529547,
    "itl": 173.46425253480712,
    "ttft": 2008255.1390211154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.088519013300594,
    "arrivals": 314288,
    "finished_requests": 66488,
    "scheduler_time": 109.779034543042
}
#Debug simulation 
Total elapsed time: 4.861539362929761. Arrivals time: 0.2362111103720963 Scheduler time: 4.517940101213753 Scheduler overhead time: 0.03159551462158561 Adapter cache time: 0.028546039015054703 Engine time: 0.032171789556741714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.282654165290296,
    "estimated_duration": 3600.045146893939,
    "input_throughput": 4797.604556404425,
    "output_throughput": 4260.4329596347325,
    "total_throughput": 9058.037516039158,
    "itl": 202.0391922328289,
    "ttft": 1962753.0346192992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5065394622809762,
    "arrivals": 311871,
    "finished_requests": 70208,
    "scheduler_time": 105.92556578897582
}
#Debug simulation 
Total elapsed time: 5.282717565074563. Arrivals time: 0.49780270690098405 Scheduler time: 4.6970214350149035 Scheduler overhead time: 0.027655336540192366 Adapter cache time: 0.018940790556371212 Engine time: 0.028246105648577213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.018224806059152,
    "estimated_duration": 3600.177944105275,
    "input_throughput": 4797.4275905666045,
    "output_throughput": 4260.275808064753,
    "total_throughput": 9057.703398631356,
    "itl": 202.0496327163531,
    "ttft": 1962799.8047832053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6674496868904742,
    "arrivals": 311871,
    "finished_requests": 70208,
    "scheduler_time": 105.92537739580865
}
#Debug simulation 
Total elapsed time: 5.018327849917114. Arrivals time: 0.24475717218592763 Scheduler time: 4.685386360157281 Scheduler overhead time: 0.027531254570931196 Adapter cache time: 0.019013707991689444 Engine time: 0.02859093528240919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8928011120297015,
    "estimated_duration": 3600.1814301997315,
    "input_throughput": 4640.173647880077,
    "output_throughput": 4130.906258014594,
    "total_throughput": 8771.07990589467,
    "itl": 170.816394590701,
    "ttft": 1988578.4210799937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.613901790007936,
    "arrivals": 311871,
    "finished_requests": 67924,
    "scheduler_time": 111.98165288599176
}
#Debug simulation 
Total elapsed time: 4.892932053189725. Arrivals time: 0.23170173494145274 Scheduler time: 4.5610649469308555 Scheduler overhead time: 0.03188409376889467 Adapter cache time: 0.02038957504555583 Engine time: 0.032720733899623156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.016445480287075,
    "estimated_duration": 3600.005093347316,
    "input_throughput": 4797.657656628681,
    "output_throughput": 4260.437305586968,
    "total_throughput": 9058.09496221565,
    "itl": 202.04425464221615,
    "ttft": 1962767.6270527365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5571289509115505,
    "arrivals": 311871,
    "finished_requests": 70207,
    "scheduler_time": 105.92250791795213
}
#Debug simulation 
Total elapsed time: 5.016547393985093. Arrivals time: 0.2433819375000894 Scheduler time: 4.685225348453969 Scheduler overhead time: 0.027665378991514444 Adapter cache time: 0.018943259958177805 Engine time: 0.028242224361747503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.943780574947596,
    "estimated_duration": 3600.076083377942,
    "input_throughput": 4639.860551037805,
    "output_throughput": 4130.764365970432,
    "total_throughput": 8770.624917008237,
    "itl": 170.81851688959597,
    "ttft": 1988657.5791813917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6467235282622292,
    "arrivals": 311871,
    "finished_requests": 67920,
    "scheduler_time": 111.9765076430002
}
#Debug simulation 
Total elapsed time: 4.943878402002156. Arrivals time: 0.23830011719837785 Scheduler time: 4.604815752711147 Scheduler overhead time: 0.03215618710964918 Adapter cache time: 0.02028389647603035 Engine time: 0.03298691846430302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.095420406199992,
    "estimated_duration": 3600.2117039533396,
    "input_throughput": 4797.7023076262585,
    "output_throughput": 4260.625835740798,
    "total_throughput": 9058.328143367056,
    "itl": 202.03851251253644,
    "ttft": 1962829.3871493854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.451841241819734,
    "arrivals": 311871,
    "finished_requests": 70212,
    "scheduler_time": 105.93191109718407
}
#Debug simulation 
Total elapsed time: 5.095515625085682. Arrivals time: 0.2571883462369442 Scheduler time: 4.7506201937794685 Scheduler overhead time: 0.027538337279111147 Adapter cache time: 0.01876939320936799 Engine time: 0.028302413411438465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.930704404134303,
    "estimated_duration": 3600.127274693288,
    "input_throughput": 4639.794575435692,
    "output_throughput": 4130.705629363322,
    "total_throughput": 8770.500204799015,
    "itl": 170.8115498684284,
    "ttft": 1988633.5990746382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6795452665165254,
    "arrivals": 311871,
    "finished_requests": 67920,
    "scheduler_time": 111.9790193614713
}
#Debug simulation 
Total elapsed time: 4.930832135025412. Arrivals time: 0.23376397415995598 Scheduler time: 4.596321669407189 Scheduler overhead time: 0.032187297474592924 Adapter cache time: 0.020536246709525585 Engine time: 0.03268666099756956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 28.140472087077796,
    "estimated_duration": 3600.026323531635,
    "input_throughput": 4620.1623280585545,
    "output_throughput": 4082.833201503072,
    "total_throughput": 8702.995529561627,
    "itl": 209.68111561243776,
    "ttft": 1859974.804961129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4759345848416476,
    "arrivals": 211085,
    "finished_requests": 67240,
    "scheduler_time": 99.90390273078201
}
#Debug simulation 
Total elapsed time: 28.14059655694291. Arrivals time: 0.3090932024642825 Scheduler time: 27.719714288134128 Scheduler overhead time: 0.038164700381457806 Adapter cache time: 0.0211930638179183 Engine time: 0.03728541359305382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 20.865275844931602,
    "estimated_duration": 3600.099644417524,
    "input_throughput": 4612.568717576903,
    "output_throughput": 4079.113205316845,
    "total_throughput": 8691.681922893747,
    "itl": 209.84712427583713,
    "ttft": 1856683.6123725325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0408731629187304,
    "arrivals": 211085,
    "finished_requests": 67157,
    "scheduler_time": 99.85922437331881
}
#Debug simulation 
Total elapsed time: 20.865433448925614. Arrivals time: 0.32019928423687816 Scheduler time: 20.42693910887465 Scheduler overhead time: 0.04001895571127534 Adapter cache time: 0.024394134525209665 Engine time: 0.03860218729823828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.953655405901372,
    "estimated_duration": 3600.0218924409633,
    "input_throughput": 4422.460883760053,
    "output_throughput": 3916.9706244310696,
    "total_throughput": 8339.431508191123,
    "itl": 178.23516496695376,
    "ttft": 1901202.9381948172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.295739571582473,
    "arrivals": 211085,
    "finished_requests": 64334,
    "scheduler_time": 104.65784070571567
}
#Debug simulation 
Total elapsed time: 11.953755545895547. Arrivals time: 0.2748895026743412 Scheduler time: 11.553968278691173 Scheduler overhead time: 0.036066558212041855 Adapter cache time: 0.037732917349785566 Engine time: 0.03546821093186736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 28.20232545491308,
    "estimated_duration": 3600.1870258479375,
    "input_throughput": 4619.999705732656,
    "output_throughput": 4083.474245768515,
    "total_throughput": 8703.473951501172,
    "itl": 209.8801046659997,
    "ttft": 1859689.6036498495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6129928328119902,
    "arrivals": 211085,
    "finished_requests": 67236,
    "scheduler_time": 99.88078308541154
}
#Debug simulation 
Total elapsed time: 28.20248425612226. Arrivals time: 0.3047672458924353 Scheduler time: 27.784324517007917 Scheduler overhead time: 0.03882173588499427 Adapter cache time: 0.022554253228008747 Engine time: 0.036936874501407146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.529700771905482,
    "estimated_duration": 3600.0916338674638,
    "input_throughput": 4423.847673813494,
    "output_throughput": 3915.1503443422903,
    "total_throughput": 8338.998018155784,
    "itl": 178.27995663337478,
    "ttft": 1901523.1285377606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.861286943945946,
    "arrivals": 211085,
    "finished_requests": 64339,
    "scheduler_time": 104.62540937244208
}
#Debug simulation 
Total elapsed time: 11.529841273091733. Arrivals time: 0.2693274305202067 Scheduler time: 11.133684285450727 Scheduler overhead time: 0.036044411826878786 Adapter cache time: 0.03981389570981264 Engine time: 0.03529664361849427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 27.64333494193852,
    "estimated_duration": 3600.1490418111075,
    "input_throughput": 4623.257761469448,
    "output_throughput": 4082.633476920142,
    "total_throughput": 8705.89123838959,
    "itl": 209.76630202737644,
    "ttft": 1860618.351051419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5535029518464043,
    "arrivals": 211085,
    "finished_requests": 67263,
    "scheduler_time": 99.89368564798427
}
#Debug simulation 
Total elapsed time: 27.643489741254598. Arrivals time: 0.3182606971822679 Scheduler time: 27.212200231384486 Scheduler overhead time: 0.0385170909576118 Adapter cache time: 0.022360941395163536 Engine time: 0.036975749768316746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.341002017725259,
    "estimated_duration": 3600.017519735629,
    "input_throughput": 4427.39900920551,
    "output_throughput": 3913.20706712409,
    "total_throughput": 8340.6060763296,
    "itl": 178.1016233820935,
    "ttft": 1900350.982101785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.004462425634227,
    "arrivals": 211085,
    "finished_requests": 64378,
    "scheduler_time": 104.67076335902394
}
#Debug simulation 
Total elapsed time: 12.341108325868845. Arrivals time: 0.27113416977226734 Scheduler time: 11.945122227072716 Scheduler overhead time: 0.03796711517497897 Adapter cache time: 0.035312512423843145 Engine time: 0.035753718577325344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.371279544197023,
    "estimated_duration": 3600.2028435407838,
    "input_throughput": 4652.420079621621,
    "output_throughput": 4077.4663645236647,
    "total_throughput": 8729.886444145286,
    "itl": 209.17527382050167,
    "ttft": 1838883.7326898312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.081911158140354,
    "arrivals": 201527,
    "finished_requests": 67457,
    "scheduler_time": 99.64123742790376
}
#Debug simulation 
Total elapsed time: 17.371425091288984. Arrivals time: 0.30129058798775077 Scheduler time: 16.961265210062265 Scheduler overhead time: 0.035688302014023066 Adapter cache time: 0.024344140198081732 Engine time: 0.034375089686363935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.54988788207993,
    "estimated_duration": 3600.208793758443,
    "input_throughput": 4648.822320809807,
    "output_throughput": 4077.9782065565014,
    "total_throughput": 8726.800527366308,
    "itl": 209.26773653745417,
    "ttft": 1841167.5426178062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.102048783958897,
    "arrivals": 201527,
    "finished_requests": 67453,
    "scheduler_time": 99.63023256104589
}
#Debug simulation 
Total elapsed time: 18.549989483784884. Arrivals time: 0.29660039534792304 Scheduler time: 18.143614545930177 Scheduler overhead time: 0.03632237296551466 Adapter cache time: 0.023887886200100183 Engine time: 0.03500290773808956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.282877675257623,
    "estimated_duration": 3600.1051794148593,
    "input_throughput": 4458.4516840724145,
    "output_throughput": 3915.1742234072526,
    "total_throughput": 8373.625907479667,
    "itl": 177.9765639432189,
    "ttft": 1882013.0096927092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0624584024957775,
    "arrivals": 201527,
    "finished_requests": 64648,
    "scheduler_time": 104.33149436524937
}
#Debug simulation 
Total elapsed time: 11.283030502963811. Arrivals time: 0.2716127336025238 Scheduler time: 10.890599899925292 Scheduler overhead time: 0.03580112708732486 Adapter cache time: 0.03465034766122699 Engine time: 0.034733754117041826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 17.272266362793744,
    "estimated_duration": 3600.0599766595938,
    "input_throughput": 4647.7039572894055,
    "output_throughput": 4078.4717741352056,
    "total_throughput": 8726.175731424612,
    "itl": 209.3081157537555,
    "ttft": 1839017.690265748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1006,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1424184564384294,
    "arrivals": 201527,
    "finished_requests": 67418,
    "scheduler_time": 99.61958617461029
}
#Debug simulation 
Total elapsed time: 17.27236825088039. Arrivals time: 0.29601761512458324 Scheduler time: 16.866685145534575 Scheduler overhead time: 0.035718112252652645 Adapter cache time: 0.024687713012099266 Engine time: 0.034730763640254736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.407666984014213,
    "estimated_duration": 3600.1803733596403,
    "input_throughput": 4456.913081003876,
    "output_throughput": 3916.5732095921967,
    "total_throughput": 8373.486290596073,
    "itl": 178.03958745388056,
    "ttft": 1881917.14315764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.913513655606613,
    "arrivals": 201527,
    "finished_requests": 64659,
    "scheduler_time": 104.32711506429222
}
#Debug simulation 
Total elapsed time: 11.40778403589502. Arrivals time: 0.2677764561958611 Scheduler time: 11.019626127555966 Scheduler overhead time: 0.035809232387691736 Adapter cache time: 0.03367074020206928 Engine time: 0.035320145543664694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.163893561810255,
    "estimated_duration": 3600.040026210328,
    "input_throughput": 4646.923055911218,
    "output_throughput": 4076.222734514301,
    "total_throughput": 8723.14579042552,
    "itl": 209.25506747246422,
    "ttft": 1840867.7092177023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9422094901836733,
    "arrivals": 201527,
    "finished_requests": 67413,
    "scheduler_time": 99.6273589498257
}
#Debug simulation 
Total elapsed time: 18.164018189068884. Arrivals time: 0.2809599288739264 Scheduler time: 17.77144029457122 Scheduler overhead time: 0.0356042324565351 Adapter cache time: 0.026140372268855572 Engine time: 0.03533011768013239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.13265795307234,
    "estimated_duration": 3600.11999970839,
    "input_throughput": 4455.5628704874525,
    "output_throughput": 3913.1059523407835,
    "total_throughput": 8368.668822828236,
    "itl": 177.9807225853206,
    "ttft": 1881527.3901377446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4396724749728245,
    "arrivals": 201527,
    "finished_requests": 64631,
    "scheduler_time": 104.31996668929779
}
#Debug simulation 
Total elapsed time: 11.132768729235977. Arrivals time: 0.2583461981266737 Scheduler time: 10.751292828470469 Scheduler overhead time: 0.03545797523111105 Adapter cache time: 0.03720201551914215 Engine time: 0.03481699572876096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.588790298905224,
    "estimated_duration": 3600.0477831921667,
    "input_throughput": 4601.543923206237,
    "output_throughput": 4084.322455009795,
    "total_throughput": 8685.866378216033,
    "itl": 209.99454251224634,
    "ttft": 1828135.2577732902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6718058004533507,
    "arrivals": 196873,
    "finished_requests": 67300,
    "scheduler_time": 99.38635691631413
}
#Debug simulation 
Total elapsed time: 17.58891918323934. Arrivals time: 0.28007725067436695 Scheduler time: 17.200612888205796 Scheduler overhead time: 0.03717021457850933 Adapter cache time: 0.021354048047214746 Engine time: 0.035303620621562004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 16.946395993232727,
    "estimated_duration": 3600.001824364255,
    "input_throughput": 4599.822668957762,
    "output_throughput": 4085.896818287749,
    "total_throughput": 8685.719487245511,
    "itl": 210.10930068847512,
    "ttft": 1829130.633309174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9451726073608797,
    "arrivals": 196873,
    "finished_requests": 67228,
    "scheduler_time": 99.38110971308545
}
#Debug simulation 
Total elapsed time: 16.946509902831167. Arrivals time: 0.28739683283492923 Scheduler time: 16.55051623797044 Scheduler overhead time: 0.0359212476760149 Adapter cache time: 0.022984327748417854 Engine time: 0.03543348656967282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.007869315333664,
    "estimated_duration": 3600.084292710411,
    "input_throughput": 4400.579462008269,
    "output_throughput": 3918.4510286506065,
    "total_throughput": 8319.030490658875,
    "itl": 178.05394485934355,
    "ttft": 1876733.3310196965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.982323461342548,
    "arrivals": 196873,
    "finished_requests": 64377,
    "scheduler_time": 104.14353931756871
}
#Debug simulation 
Total elapsed time: 10.007989321369678. Arrivals time: 0.2487721648067236 Scheduler time: 9.63989673089236 Scheduler overhead time: 0.03492219280451536 Adapter cache time: 0.034855240024626255 Engine time: 0.034129837062209845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 16.757270864211023,
    "estimated_duration": 3600.099553014223,
    "input_throughput": 4604.076291757623,
    "output_throughput": 4084.1553916722787,
    "total_throughput": 8688.231683429902,
    "itl": 209.96690746445236,
    "ttft": 1829538.3218523636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 928,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8981624598381748,
    "arrivals": 196873,
    "finished_requests": 67293,
    "scheduler_time": 99.39596277651943
}
#Debug simulation 
Total elapsed time: 16.757369231432676. Arrivals time: 0.28492365777492523 Scheduler time: 16.365983666852117 Scheduler overhead time: 0.03566737473011017 Adapter cache time: 0.022191043943166733 Engine time: 0.03449992137029767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.91513541014865,
    "estimated_duration": 3600.011874268825,
    "input_throughput": 4405.895467559112,
    "output_throughput": 3922.1231743486287,
    "total_throughput": 8328.01864190774,
    "itl": 177.9213893489657,
    "ttft": 1874222.4127726783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.746218726355544,
    "arrivals": 196873,
    "finished_requests": 64476,
    "scheduler_time": 104.26412282456292
}
#Debug simulation 
Total elapsed time: 9.915271217003465. Arrivals time: 0.2486555683426559 Scheduler time: 9.549892106559128 Scheduler overhead time: 0.03461158135905862 Adapter cache time: 0.032542066648602486 Engine time: 0.03417277382686734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 17.00799164408818,
    "estimated_duration": 3600.0787026249486,
    "input_throughput": 4602.938815731312,
    "output_throughput": 4083.4398951559533,
    "total_throughput": 8686.378710887266,
    "itl": 209.95565880942178,
    "ttft": 1829358.388807791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6133039577444457,
    "arrivals": 196873,
    "finished_requests": 67274,
    "scheduler_time": 99.40011933304241
}
#Debug simulation 
Total elapsed time: 17.008093220181763. Arrivals time: 0.2811040095984936 Scheduler time: 16.620035409927368 Scheduler overhead time: 0.03575448878109455 Adapter cache time: 0.02171065052971244 Engine time: 0.03526128362864256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.066593062132597,
    "estimated_duration": 3600.1678146552235,
    "input_throughput": 4399.497972156846,
    "output_throughput": 3917.087404257715,
    "total_throughput": 8316.585376414561,
    "itl": 178.07501300023824,
    "ttft": 1876528.0788692134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.249523854479134,
    "arrivals": 196873,
    "finished_requests": 64358,
    "scheduler_time": 104.1646501361302
}
#Debug simulation 
Total elapsed time: 10.06669858423993. Arrivals time: 0.25132991280406713 Scheduler time: 9.69478834187612 Scheduler overhead time: 0.03519654367119074 Adapter cache time: 0.03553783614188433 Engine time: 0.03437280282378197 
