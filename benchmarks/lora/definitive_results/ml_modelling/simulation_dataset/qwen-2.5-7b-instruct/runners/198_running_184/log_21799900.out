INFO 06-01 00:47:17 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:18 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.909467362333089,
    "estimated_duration": 3600.1950169812703,
    "input_throughput": 3640.0317033348574,
    "output_throughput": 3208.4428608774147,
    "total_throughput": 6848.4745642122725,
    "itl": 265.7704010144273,
    "ttft": 2270726.2783323806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8385736418375734,
    "arrivals": 770785,
    "finished_requests": 53202,
    "scheduler_time": 32.64510277482952
}
#Debug simulation 
Total elapsed time: 3.909579011145979. Arrivals time: 0.285697553306818 Scheduler time: 3.5176876983605325 Scheduler overhead time: 0.020938248373568058 Adapter cache time: 0.05383487418293953 Engine time: 0.021331069990992546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.98078987095505,
    "estimated_duration": 3600.118188054294,
    "input_throughput": 3490.279580735392,
    "output_throughput": 3089.105806831995,
    "total_throughput": 6579.385387567387,
    "itl": 164.11267635775093,
    "ttft": 2303090.979111031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8922824597382032,
    "arrivals": 770785,
    "finished_requests": 51012,
    "scheduler_time": 21.26544351818344
}
#Debug simulation 
Total elapsed time: 3.980917274951935. Arrivals time: 0.27115435851737857 Scheduler time: 3.512002988252789 Scheduler overhead time: 0.03236733051016927 Adapter cache time: 0.11677192524075508 Engine time: 0.03296898491680622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.025440730154514,
    "estimated_duration": 3600.099586009386,
    "input_throughput": 3490.612051076533,
    "output_throughput": 3089.3275961647255,
    "total_throughput": 6579.939647241259,
    "itl": 164.25152879415003,
    "ttft": 2303003.6780667496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8526487138494877,
    "arrivals": 770785,
    "finished_requests": 51016,
    "scheduler_time": 21.294175951188468
}
#Debug simulation 
Total elapsed time: 4.025532094296068. Arrivals time: 0.33200572431087494 Scheduler time: 3.494621817022562 Scheduler overhead time: 0.032375052105635405 Adapter cache time: 0.11754170013591647 Engine time: 0.03340536169707775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.022085802163929,
    "estimated_duration": 3600.063388613461,
    "input_throughput": 3490.647147977002,
    "output_throughput": 3089.35865828838,
    "total_throughput": 6580.005806265382,
    "itl": 164.25009515199918,
    "ttft": 2302982.1632446893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8162837305082951,
    "arrivals": 770785,
    "finished_requests": 51016,
    "scheduler_time": 21.29434353860282
}
#Debug simulation 
Total elapsed time: 4.022193521261215. Arrivals time: 0.29326645750552416 Scheduler time: 3.5295189060270786 Scheduler overhead time: 0.0323640089482069 Adapter cache time: 0.11854389635846019 Engine time: 0.032775923144072294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.194466863293201,
    "estimated_duration": 3600.0649821411844,
    "input_throughput": 3949.0826055990483,
    "output_throughput": 3470.421523494053,
    "total_throughput": 7419.504129093101,
    "itl": 246.0182781895902,
    "ttft": 2230506.2301428937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 673640,
    "finished_requests": 57399,
    "scheduler_time": 35.25705627782864
}
#Debug simulation 
Total elapsed time: 4.194566942285746. Arrivals time: 0.21485194470733404 Scheduler time: 3.829869634937495 Scheduler overhead time: 0.02278528269380331 Adapter cache time: 0.09260075585916638 Engine time: 0.023469979874789715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.283966465853155,
    "estimated_duration": 3600.1215227349044,
    "input_throughput": 3854.066567580612,
    "output_throughput": 3404.7234024168183,
    "total_throughput": 7258.7899699974305,
    "itl": 149.81808680658537,
    "ttft": 2252474.7653554007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 673640,
    "finished_requests": 56045,
    "scheduler_time": 23.56979415041974
}
#Debug simulation 
Total elapsed time: 4.284062378108501. Arrivals time: 0.21525125578045845 Scheduler time: 3.8527750954963267 Scheduler overhead time: 0.03543424839153886 Adapter cache time: 0.1276629576459527 Engine time: 0.03592246025800705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.274212671909481,
    "estimated_duration": 3600.1092333111096,
    "input_throughput": 3854.5269325723316,
    "output_throughput": 3405.2483426245512,
    "total_throughput": 7259.775275196883,
    "itl": 149.93523064192885,
    "ttft": 2252362.748643169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 673640,
    "finished_requests": 56052,
    "scheduler_time": 23.596588119249585
}
#Debug simulation 
Total elapsed time: 4.274298573844135. Arrivals time: 0.24447684502229095 Scheduler time: 3.8148381733335555 Scheduler overhead time: 0.035225287545472383 Adapter cache time: 0.12690111948177218 Engine time: 0.03578325593844056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.254212390165776,
    "estimated_duration": 3600.0083971090025,
    "input_throughput": 3852.53351384893,
    "output_throughput": 3403.5606722027887,
    "total_throughput": 7256.094186051719,
    "itl": 149.37712165875547,
    "ttft": 2252264.396747741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 673640,
    "finished_requests": 56020,
    "scheduler_time": 23.47150972624558
}
#Debug simulation 
Total elapsed time: 4.254305846057832. Arrivals time: 0.20716661866754293 Scheduler time: 3.8288523233495653 Scheduler overhead time: 0.035643729381263256 Adapter cache time: 0.12949754670262337 Engine time: 0.036096463445574045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.3148996769450605,
    "estimated_duration": 3600.2416916089605,
    "input_throughput": 4097.822108550376,
    "output_throughput": 3619.256460023038,
    "total_throughput": 7717.078568573413,
    "itl": 236.7150478620668,
    "ttft": 2205726.167136972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 664253,
    "finished_requests": 60120,
    "scheduler_time": 36.79326998412589
}
#Debug simulation 
Total elapsed time: 4.314990987069905. Arrivals time: 0.22139140125364065 Scheduler time: 3.9545417516492307 Scheduler overhead time: 0.023727974854409695 Adapter cache time: 0.0796534176915884 Engine time: 0.024282874073833227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.345086209941655,
    "estimated_duration": 3600.11186945322,
    "input_throughput": 3951.221660831459,
    "output_throughput": 3508.3109797691577,
    "total_throughput": 7459.532640600616,
    "itl": 145.93631700946156,
    "ttft": 2229723.4930890985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 664253,
    "finished_requests": 58000,
    "scheduler_time": 24.368624229373914
}
#Debug simulation 
Total elapsed time: 4.3451859769411385. Arrivals time: 0.20758440857753158 Scheduler time: 3.9355956790968776 Scheduler overhead time: 0.036358377896249294 Adapter cache time: 0.11133818421512842 Engine time: 0.03677527094259858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.3095431686379015,
    "estimated_duration": 3600.040032459804,
    "input_throughput": 3951.2796723764836,
    "output_throughput": 3507.927658063065,
    "total_throughput": 7459.207330439548,
    "itl": 145.93246987594097,
    "ttft": 2229623.1573791793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 664253,
    "finished_requests": 57997,
    "scheduler_time": 24.36786986410582
}
#Debug simulation 
Total elapsed time: 4.309629229828715. Arrivals time: 0.20450750552117825 Scheduler time: 3.9022303479723632 Scheduler overhead time: 0.03613601438701153 Adapter cache time: 0.1125768143683672 Engine time: 0.03670957637950778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.344159875996411,
    "estimated_duration": 3600.069040248702,
    "input_throughput": 3950.9770065457924,
    "output_throughput": 3507.739118005253,
    "total_throughput": 7458.716124551045,
    "itl": 145.93621715993837,
    "ttft": 2229718.6725590527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 664253,
    "finished_requests": 57995,
    "scheduler_time": 24.368643329942476
}
#Debug simulation 
Total elapsed time: 4.344243511091918. Arrivals time: 0.20847718510776758 Scheduler time: 3.934814932756126 Scheduler overhead time: 0.036139439791440964 Adapter cache time: 0.11015159264206886 Engine time: 0.03722538612782955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.4069461110048,
    "estimated_duration": 3600.1213129298535,
    "input_throughput": 4200.867327910146,
    "output_throughput": 3708.5366962633075,
    "total_throughput": 7909.404024173454,
    "itl": 231.51184019401202,
    "ttft": 2196399.0914009744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9732351025706144,
    "arrivals": 659440,
    "finished_requests": 61106,
    "scheduler_time": 37.69167265037475
}
#Debug simulation 
Total elapsed time: 4.407032169401646. Arrivals time: 0.24948980659246445 Scheduler time: 4.028506796341389 Scheduler overhead time: 0.0240520890802145 Adapter cache time: 0.06886778166517615 Engine time: 0.024601605720818043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.3742955341003835,
    "estimated_duration": 3600.0658601344835,
    "input_throughput": 4015.568203927239,
    "output_throughput": 3561.76817263032,
    "total_throughput": 7577.33637655756,
    "itl": 143.2192229733717,
    "ttft": 2226470.7662837673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0344681509933493,
    "arrivals": 659440,
    "finished_requests": 58428,
    "scheduler_time": 24.601838496128856
}
#Debug simulation 
Total elapsed time: 4.3744068229570985. Arrivals time: 0.20411660755053163 Scheduler time: 3.980407129507512 Scheduler overhead time: 0.036844246089458466 Adapter cache time: 0.09779734490439296 Engine time: 0.03743265150114894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.429933839011937,
    "estimated_duration": 3600.0077899025546,
    "input_throughput": 4015.632977391781,
    "output_throughput": 3561.825626034849,
    "total_throughput": 7577.45860342663,
    "itl": 143.27917855095578,
    "ttft": 2226471.69900973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9915656425571107,
    "arrivals": 659440,
    "finished_requests": 58428,
    "scheduler_time": 24.61435339572263
}
#Debug simulation 
Total elapsed time: 4.430014160927385. Arrivals time: 0.20666542323306203 Scheduler time: 4.033990933559835 Scheduler overhead time: 0.036871806252747774 Adapter cache time: 0.09724765457212925 Engine time: 0.037418453488498926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.448862605728209,
    "estimated_duration": 3600.1224563932856,
    "input_throughput": 4015.695903434204,
    "output_throughput": 3561.761066551679,
    "total_throughput": 7577.456969985883,
    "itl": 143.27791947917765,
    "ttft": 2226489.472127845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.947845943483991,
    "arrivals": 659440,
    "finished_requests": 58429,
    "scheduler_time": 24.615575240399846
}
#Debug simulation 
Total elapsed time: 4.4489568788558245. Arrivals time: 0.2519824169576168 Scheduler time: 4.00549445534125 Scheduler overhead time: 0.037909597624093294 Adapter cache time: 0.09796470170840621 Engine time: 0.037665330339223146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.403916576411575,
    "estimated_duration": 3600.1326841126656,
    "input_throughput": 4221.409412788296,
    "output_throughput": 3711.553204404573,
    "total_throughput": 7932.9626171928685,
    "itl": 230.2473902757034,
    "ttft": 2186787.3783200923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9395697373873542,
    "arrivals": 657053,
    "finished_requests": 61366,
    "scheduler_time": 37.67903621069097
}
#Debug simulation 
Total elapsed time: 4.404025434982032. Arrivals time: 0.21225141501054168 Scheduler time: 4.067225960083306 Scheduler overhead time: 0.024211419746279716 Adapter cache time: 0.06401143921539187 Engine time: 0.024685551412403584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.387044853065163,
    "estimated_duration": 3600.0124330186877,
    "input_throughput": 4031.0116339880624,
    "output_throughput": 3557.758546200419,
    "total_throughput": 7588.770180188481,
    "itl": 142.9088381173977,
    "ttft": 2218774.0076968223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9919201392936575,
    "arrivals": 657053,
    "finished_requests": 58615,
    "scheduler_time": 24.541883516378952
}
#Debug simulation 
Total elapsed time: 4.3871265347115695. Arrivals time: 0.2064097565598786 Scheduler time: 3.9978083493188024 Scheduler overhead time: 0.037015614565461874 Adapter cache time: 0.09046216402202845 Engine time: 0.03760083299130201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.361596207134426,
    "estimated_duration": 3600.0873618025357,
    "input_throughput": 4031.055511034565,
    "output_throughput": 3557.6869983474908,
    "total_throughput": 7588.742509382056,
    "itl": 142.90803655606655,
    "ttft": 2218781.847004279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9502434168127398,
    "arrivals": 657053,
    "finished_requests": 58616,
    "scheduler_time": 24.542661450720217
}
#Debug simulation 
Total elapsed time: 4.361676930915564. Arrivals time: 0.2063247817568481 Scheduler time: 3.9740447234362364 Scheduler overhead time: 0.036922349128872156 Adapter cache time: 0.08903797483071685 Engine time: 0.037560660392045975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.4045953480526805,
    "estimated_duration": 3600.0963505972973,
    "input_throughput": 4030.243245460013,
    "output_throughput": 3557.257571141189,
    "total_throughput": 7587.500816601202,
    "itl": 142.82889625468061,
    "ttft": 2218791.6068528346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089752896502626,
    "arrivals": 657053,
    "finished_requests": 58604,
    "scheduler_time": 24.521134339759115
}
#Debug simulation 
Total elapsed time: 4.404678951948881. Arrivals time: 0.20500373980030417 Scheduler time: 4.0177318304777145 Scheduler overhead time: 0.03700839914381504 Adapter cache time: 0.08969089994207025 Engine time: 0.03744162432849407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.415416607167572,
    "estimated_duration": 3600.104997277505,
    "input_throughput": 4261.695981534552,
    "output_throughput": 3747.8668011637296,
    "total_throughput": 8009.562782698281,
    "itl": 228.65810729358356,
    "ttft": 2186009.914230216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8630575437890354,
    "arrivals": 655825,
    "finished_requests": 61932,
    "scheduler_time": 38.028119127200256
}
#Debug simulation 
Total elapsed time: 4.415501542855054. Arrivals time: 0.21468751039355993 Scheduler time: 4.079988922458142 Scheduler overhead time: 0.02435120288282633 Adapter cache time: 0.05991761991754174 Engine time: 0.024849433451890945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.39315913291648,
    "estimated_duration": 3600.144441122144,
    "input_throughput": 4060.332922487888,
    "output_throughput": 3583.033461840581,
    "total_throughput": 7643.366384328469,
    "itl": 142.4478338900489,
    "ttft": 2218509.8904907308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9132128118025185,
    "arrivals": 655825,
    "finished_requests": 58970,
    "scheduler_time": 24.798105970471735
}
#Debug simulation 
Total elapsed time: 4.393244096077979. Arrivals time: 0.20468114456161857 Scheduler time: 4.01157492492348 Scheduler overhead time: 0.03684741444885731 Adapter cache time: 0.08500049682334065 Engine time: 0.03740329574793577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.4062965186312795,
    "estimated_duration": 3600.116846816264,
    "input_throughput": 4061.2673482889877,
    "output_throughput": 3583.0112045966957,
    "total_throughput": 7644.278552885683,
    "itl": 142.46527970096247,
    "ttft": 2218927.1459394577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.875213447187564,
    "arrivals": 655825,
    "finished_requests": 58980,
    "scheduler_time": 24.813605423271557
}
#Debug simulation 
Total elapsed time: 4.406381232663989. Arrivals time: 0.20648553455248475 Scheduler time: 4.022687333170325 Scheduler overhead time: 0.03715056926012039 Adapter cache time: 0.08455199981108308 Engine time: 0.037555460818111897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.419386296998709,
    "estimated_duration": 3600.0790416727627,
    "input_throughput": 4061.3099964622975,
    "output_throughput": 3583.0488305074573,
    "total_throughput": 7644.358826969755,
    "itl": 142.46400457941175,
    "ttft": 2218904.0865531145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8372140825726103,
    "arrivals": 655825,
    "finished_requests": 58980,
    "scheduler_time": 24.813799644382573
}
#Debug simulation 
Total elapsed time: 4.419472533278167. Arrivals time: 0.2437482620589435 Scheduler time: 3.9986115372739732 Scheduler overhead time: 0.037105102092027664 Adapter cache time: 0.0844786623492837 Engine time: 0.03764580888673663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.609416172839701,
    "estimated_duration": 3600.19176315857,
    "input_throughput": 4413.283248573497,
    "output_throughput": 3879.466405907899,
    "total_throughput": 8292.749654481395,
    "itl": 220.25373501711317,
    "ttft": 2162324.3434598455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 644956,
    "finished_requests": 64157,
    "scheduler_time": 39.334048739982805
}
#Debug simulation 
Total elapsed time: 4.609501602128148. Arrivals time: 0.25590029638260603 Scheduler time: 4.223014842253178 Scheduler overhead time: 0.025201530195772648 Adapter cache time: 0.06753349024802446 Engine time: 0.025700039230287075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.505866392049938,
    "estimated_duration": 3600.0596020730004,
    "input_throughput": 4178.638873461339,
    "output_throughput": 3688.379490260102,
    "total_throughput": 7867.018363721441,
    "itl": 137.28397865537815,
    "ttft": 2196307.1158094085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 644956,
    "finished_requests": 60755,
    "scheduler_time": 25.38572857157249
}
#Debug simulation 
Total elapsed time: 4.505947215016931. Arrivals time: 0.20974161894991994 Scheduler time: 4.111609198153019 Scheduler overhead time: 0.03823342872783542 Adapter cache time: 0.08935307199135423 Engine time: 0.03865589341148734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.488527945242822,
    "estimated_duration": 3600.1296927441804,
    "input_throughput": 4173.585754502897,
    "output_throughput": 3682.432059800252,
    "total_throughput": 7856.017814303148,
    "itl": 136.376141715752,
    "ttft": 2197752.190000108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 644956,
    "finished_requests": 60667,
    "scheduler_time": 25.11362299545029
}
#Debug simulation 
Total elapsed time: 4.4886509431526065. Arrivals time: 0.2092676921747625 Scheduler time: 4.094788147136569 Scheduler overhead time: 0.038376566022634506 Adapter cache time: 0.08901457209140062 Engine time: 0.03873929614201188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.496007762849331,
    "estimated_duration": 3600.08165629861,
    "input_throughput": 4173.69727536916,
    "output_throughput": 3682.4817506029294,
    "total_throughput": 7856.179025972089,
    "itl": 136.37370841566292,
    "ttft": 2197856.639173503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 644956,
    "finished_requests": 60668,
    "scheduler_time": 25.113856429533705
}
#Debug simulation 
Total elapsed time: 4.496091106906533. Arrivals time: 0.2091156397946179 Scheduler time: 4.1011739410459995 Scheduler overhead time: 0.038385908119380474 Adapter cache time: 0.08985825954005122 Engine time: 0.0390926250256598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.686676557175815,
    "estimated_duration": 3600.1013449731345,
    "input_throughput": 4521.929090338284,
    "output_throughput": 3968.4310609613167,
    "total_throughput": 8490.360151299601,
    "itl": 215.51984964730744,
    "ttft": 2153628.080298813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9640536393388162,
    "arrivals": 640132,
    "finished_requests": 65605,
    "scheduler_time": 40.24646012184834
}
#Debug simulation 
Total elapsed time: 4.686766286380589. Arrivals time: 0.22648742515593767 Scheduler time: 4.337751283310354 Scheduler overhead time: 0.02573938760906458 Adapter cache time: 0.05796552076935768 Engine time: 0.02641564281657338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.560745588038117,
    "estimated_duration": 3600.0420169433955,
    "input_throughput": 4252.160649224082,
    "output_throughput": 3745.0526789815485,
    "total_throughput": 7997.213328205629,
    "itl": 135.9805407184646,
    "ttft": 2191504.326831157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.028079455085104,
    "arrivals": 640132,
    "finished_requests": 61690,
    "scheduler_time": 25.87012872488571
}
#Debug simulation 
Total elapsed time: 4.560829563997686. Arrivals time: 0.21410242607817054 Scheduler time: 4.1732397503219545 Scheduler overhead time: 0.03865827573463321 Adapter cache time: 0.07717285305261612 Engine time: 0.03903057146817446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.615113485138863,
    "estimated_duration": 3600.065136044875,
    "input_throughput": 4252.2116743748775,
    "output_throughput": 3745.029184336386,
    "total_throughput": 7997.240858711264,
    "itl": 135.97936476339825,
    "ttft": 2191498.5667464626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9843597560119849,
    "arrivals": 640132,
    "finished_requests": 61691,
    "scheduler_time": 25.87159069770861
}
#Debug simulation 
Total elapsed time: 4.615199411287904. Arrivals time: 0.2568682720884681 Scheduler time: 4.181900205090642 Scheduler overhead time: 0.03947833040729165 Adapter cache time: 0.0769275319762528 Engine time: 0.03941283794119954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.562443810980767,
    "estimated_duration": 3600.056101558424,
    "input_throughput": 4249.235169801351,
    "output_throughput": 3743.0802798230543,
    "total_throughput": 7992.315449624406,
    "itl": 135.69744407390507,
    "ttft": 2191568.490290335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9418658428941866,
    "arrivals": 640132,
    "finished_requests": 61652,
    "scheduler_time": 25.774329641124535
}
#Debug simulation 
Total elapsed time: 4.56254998780787. Arrivals time: 0.21127590676769614 Scheduler time: 4.1772315157577395 Scheduler overhead time: 0.03858597343787551 Adapter cache time: 0.07780573517084122 Engine time: 0.0390051631256938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.749134841840714,
    "estimated_duration": 3600.043396945754,
    "input_throughput": 4548.439058788028,
    "output_throughput": 4019.1279394785643,
    "total_throughput": 8567.566998266593,
    "itl": 213.45551911917258,
    "ttft": 2149562.3865508316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9548721761070179,
    "arrivals": 637737,
    "finished_requests": 66254,
    "scheduler_time": 40.83113104803614
}
#Debug simulation 
Total elapsed time: 4.749221485573798. Arrivals time: 0.222171351313591 Scheduler time: 4.411245140712708 Scheduler overhead time: 0.026062353048473597 Adapter cache time: 0.050645934883505106 Engine time: 0.026565898675471544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.63926055887714,
    "estimated_duration": 3600.0475083704764,
    "input_throughput": 4262.232641186841,
    "output_throughput": 3777.9665319350984,
    "total_throughput": 8040.199173121939,
    "itl": 135.02148665343444,
    "ttft": 2192470.0785963656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0080961767234893,
    "arrivals": 637737,
    "finished_requests": 62034,
    "scheduler_time": 26.117159877961043
}
#Debug simulation 
Total elapsed time: 4.6393419108353555. Arrivals time: 0.25249572191387415 Scheduler time: 4.223037721123546 Scheduler overhead time: 0.03876074589788914 Adapter cache time: 0.06697278283536434 Engine time: 0.03933593910187483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.562683430034667,
    "estimated_duration": 3600.14147571192,
    "input_throughput": 4262.508321833501,
    "output_throughput": 3778.146523341909,
    "total_throughput": 8040.65484517541,
    "itl": 135.09413063405879,
    "ttft": 2192585.8704130687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9656022636056911,
    "arrivals": 637737,
    "finished_requests": 62042,
    "scheduler_time": 26.14113357127392
}
#Debug simulation 
Total elapsed time: 4.562769314739853. Arrivals time: 0.21170858712866902 Scheduler time: 4.186820475850254 Scheduler overhead time: 0.03867200342938304 Adapter cache time: 0.06773679004982114 Engine time: 0.03916663583368063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.584777059964836,
    "estimated_duration": 3600.062824550247,
    "input_throughput": 4261.596463088576,
    "output_throughput": 3777.6512974322914,
    "total_throughput": 8039.247760520867,
    "itl": 134.977921984009,
    "ttft": 2192682.2056358457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9239255411247735,
    "arrivals": 637737,
    "finished_requests": 62028,
    "scheduler_time": 26.10188021008425
}
#Debug simulation 
Total elapsed time: 4.584859350230545. Arrivals time: 0.2125262999907136 Scheduler time: 4.207637322600931 Scheduler overhead time: 0.03899158677086234 Adapter cache time: 0.06738539040088654 Engine time: 0.03951795166358352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.684030285105109,
    "estimated_duration": 3600.10130500834,
    "input_throughput": 4574.686544817062,
    "output_throughput": 4020.4257529821007,
    "total_throughput": 8595.112297799164,
    "itl": 212.79847332068263,
    "ttft": 2142916.2219385183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8906019334844302,
    "arrivals": 636613,
    "finished_requests": 66753,
    "scheduler_time": 40.74773160768026
}
#Debug simulation 
Total elapsed time: 4.6841159160248935. Arrivals time: 0.22519471449777484 Scheduler time: 4.34679488139227 Scheduler overhead time: 0.025849140714854002 Adapter cache time: 0.04727604566141963 Engine time: 0.02646948816254735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.561932875774801,
    "estimated_duration": 3600.1182728376602,
    "input_throughput": 4282.67513218315,
    "output_throughput": 3771.5733125894103,
    "total_throughput": 8054.24844477256,
    "itl": 134.8426523159056,
    "ttft": 2184764.034427615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9391761907539381,
    "arrivals": 636613,
    "finished_requests": 62462,
    "scheduler_time": 26.026348569727435
}
#Debug simulation 
Total elapsed time: 4.562057711649686. Arrivals time: 0.21370266657322645 Scheduler time: 4.187869577668607 Scheduler overhead time: 0.03882997715845704 Adapter cache time: 0.06367137841880322 Engine time: 0.03919294569641352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.8932613879442215,
    "estimated_duration": 3600.0086335388564,
    "input_throughput": 4282.880284329624,
    "output_throughput": 3771.462066371029,
    "total_throughput": 8054.342350700654,
    "itl": 134.8384123158025,
    "ttft": 2184721.6225203057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9007682308205432,
    "arrivals": 636613,
    "finished_requests": 62459,
    "scheduler_time": 26.025390769804105
}
#Debug simulation 
Total elapsed time: 4.893321738112718. Arrivals time: 0.5180954309180379 Scheduler time: 4.214976981282234 Scheduler overhead time: 0.03973749838769436 Adapter cache time: 0.06217880826443434 Engine time: 0.039379145950078964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.607921185903251,
    "estimated_duration": 3600.1476343874915,
    "input_throughput": 4285.102880961342,
    "output_throughput": 3773.628856281995,
    "total_throughput": 8058.731737243337,
    "itl": 135.11711677837621,
    "ttft": 2184798.1738275397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8611344849318278,
    "arrivals": 636613,
    "finished_requests": 62495,
    "scheduler_time": 26.114493354106028
}
#Debug simulation 
Total elapsed time: 4.608012545853853. Arrivals time: 0.22114306595176458 Scheduler time: 4.224969381466508 Scheduler overhead time: 0.038961189333349466 Adapter cache time: 0.06477751489728689 Engine time: 0.03942074393853545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.843329219147563,
    "estimated_duration": 3600.1864356062006,
    "input_throughput": 4717.087101946291,
    "output_throughput": 4149.870643430816,
    "total_throughput": 8866.957745377107,
    "itl": 206.2379984724747,
    "ttft": 2125829.033297212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 630527,
    "finished_requests": 68788,
    "scheduler_time": 42.07947497884257
}
#Debug simulation 
Total elapsed time: 4.843439505901188. Arrivals time: 0.22807852877303958 Scheduler time: 4.5057073859497905 Scheduler overhead time: 0.02683923300355673 Adapter cache time: 0.04276094073429704 Engine time: 0.027128207497298717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.610836362000555,
    "estimated_duration": 3600.0747175562924,
    "input_throughput": 4344.225113920973,
    "output_throughput": 3842.1099797031416,
    "total_throughput": 8186.335093624115,
    "itl": 133.36164391880317,
    "ttft": 2169318.4211880234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0408568469015937,
    "arrivals": 630527,
    "finished_requests": 63397,
    "scheduler_time": 26.753616430393635
}
#Debug simulation 
Total elapsed time: 4.610917172860354. Arrivals time: 0.21252439683303237 Scheduler time: 4.242690994404256 Scheduler overhead time: 0.039250689558684826 Adapter cache time: 0.05777684738859534 Engine time: 0.03972038812935352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.714333912357688,
    "estimated_duration": 3600.0052673854184,
    "input_throughput": 4362.937505201834,
    "output_throughput": 3858.391298990537,
    "total_throughput": 8221.328804192372,
    "itl": 132.91139832688475,
    "ttft": 2168428.9573280113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9975457431469148,
    "arrivals": 630527,
    "finished_requests": 63660,
    "scheduler_time": 26.877163478738666
}
#Debug simulation 
Total elapsed time: 4.714433775283396. Arrivals time: 0.2227982422336936 Scheduler time: 4.333120480645448 Scheduler overhead time: 0.03958390327170491 Adapter cache time: 0.05994248669594526 Engine time: 0.039969771169126034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.67544322879985,
    "estimated_duration": 3600.1061915066525,
    "input_throughput": 4361.689951547915,
    "output_throughput": 3857.40649338686,
    "total_throughput": 8219.096444934776,
    "itl": 132.76854523640353,
    "ttft": 2168385.97073602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 630527,
    "finished_requests": 63644,
    "scheduler_time": 26.828018930654924
}
#Debug simulation 
Total elapsed time: 4.675551414955407. Arrivals time: 0.21452428540214896 Scheduler time: 4.304403352551162 Scheduler overhead time: 0.039654552936553955 Adapter cache time: 0.057732594199478626 Engine time: 0.04004484601318836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.904684606939554,
    "estimated_duration": 3600.194955720142,
    "input_throughput": 4772.067405045134,
    "output_throughput": 4203.375146658683,
    "total_throughput": 8975.442551703816,
    "itl": 203.71559041918587,
    "ttft": 2120670.7885909034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9487512006191524,
    "arrivals": 628242,
    "finished_requests": 69663,
    "scheduler_time": 42.602745797204875
}
#Debug simulation 
Total elapsed time: 4.904769337270409. Arrivals time: 0.23033854831010103 Scheduler time: 4.567562718410045 Scheduler overhead time: 0.027097817044705153 Adapter cache time: 0.03944572480395436 Engine time: 0.027356727048754692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.702037943061441,
    "estimated_duration": 3600.111224949637,
    "input_throughput": 4395.2955926302975,
    "output_throughput": 3883.3252992608795,
    "total_throughput": 8278.620891891176,
    "itl": 130.71455087151963,
    "ttft": 2168128.577623644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0063319123839085,
    "arrivals": 628242,
    "finished_requests": 64148,
    "scheduler_time": 26.810542856099858
}
#Debug simulation 
Total elapsed time: 4.702129966113716. Arrivals time: 0.22795493341982365 Scheduler time: 4.321746130473912 Scheduler overhead time: 0.04006760288029909 Adapter cache time: 0.052758308593183756 Engine time: 0.04030275950208306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.658534723799676,
    "estimated_duration": 3600.0325116473514,
    "input_throughput": 4396.014466202201,
    "output_throughput": 3883.9071466056957,
    "total_throughput": 8279.921612807897,
    "itl": 130.87560273769768,
    "ttft": 2167941.205700858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9638379992661098,
    "arrivals": 628242,
    "finished_requests": 64157,
    "scheduler_time": 26.86900321970512
}
#Debug simulation 
Total elapsed time: 4.658618269953877. Arrivals time: 0.21283759223297238 Scheduler time: 4.293669148348272 Scheduler overhead time: 0.03979006642475724 Adapter cache time: 0.05291871493682265 Engine time: 0.0401528007350862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.679211215116084,
    "estimated_duration": 3600.1273102215328,
    "input_throughput": 4395.898710322598,
    "output_throughput": 3883.8048755391405,
    "total_throughput": 8279.703585861738,
    "itl": 130.8333167290091,
    "ttft": 2167959.7876021285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 628242,
    "finished_requests": 64157,
    "scheduler_time": 26.85561230392182
}
#Debug simulation 
Total elapsed time: 4.679295643232763. Arrivals time: 0.21585637936368585 Scheduler time: 4.310504843946546 Scheduler overhead time: 0.039884398225694895 Adapter cache time: 0.05376538308337331 Engine time: 0.04008146747946739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.257576507050544,
    "estimated_duration": 3600.1664628978992,
    "input_throughput": 4801.812410108623,
    "output_throughput": 4250.236803684695,
    "total_throughput": 9052.049213793318,
    "itl": 202.56057863218592,
    "ttft": 2118535.4559661923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8814204702526319,
    "arrivals": 627073,
    "finished_requests": 69892,
    "scheduler_time": 43.16742480808681
}
#Debug simulation 
Total elapsed time: 5.257667549885809. Arrivals time: 0.5374501873739064 Scheduler time: 4.619200065266341 Scheduler overhead time: 0.027267015539109707 Adapter cache time: 0.032803635112941265 Engine time: 0.027797942515462637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.71188011020422,
    "estimated_duration": 3600.005615995735,
    "input_throughput": 4408.098401149495,
    "output_throughput": 3916.4191681685156,
    "total_throughput": 8324.51756931801,
    "itl": 130.6451058750894,
    "ttft": 2167478.6828299933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9302060398692312,
    "arrivals": 627073,
    "finished_requests": 64145,
    "scheduler_time": 27.168035527927614
}
#Debug simulation 
Total elapsed time: 4.7119638924486935. Arrivals time: 0.21590273594483733 Scheduler time: 4.350310678593814 Scheduler overhead time: 0.04026137990877032 Adapter cache time: 0.045510172843933105 Engine time: 0.04059149278327823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.728678121697158,
    "estimated_duration": 3600.127351519426,
    "input_throughput": 4407.476583655621,
    "output_throughput": 3915.923417000802,
    "total_throughput": 8323.400000656424,
    "itl": 130.5745971233055,
    "ttft": 2167585.9270456727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8913894846173963,
    "arrivals": 627073,
    "finished_requests": 64138,
    "scheduler_time": 27.144665581378337
}
#Debug simulation 
Total elapsed time: 4.728761218022555. Arrivals time: 0.21851969696581364 Scheduler time: 4.365385712124407 Scheduler overhead time: 0.04009503033012152 Adapter cache time: 0.04491485236212611 Engine time: 0.040493734646588564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.702807907015085,
    "estimated_duration": 3600.085848624799,
    "input_throughput": 4407.699334742662,
    "output_throughput": 3916.139667998606,
    "total_throughput": 8323.839002741268,
    "itl": 130.58444662989348,
    "ttft": 2167566.4111786257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8521643340471212,
    "arrivals": 627073,
    "finished_requests": 64140,
    "scheduler_time": 27.14852127398748
}
#Debug simulation 
Total elapsed time: 4.702916828915477. Arrivals time: 0.21874162135645747 Scheduler time: 4.340159935411066 Scheduler overhead time: 0.04012739425525069 Adapter cache time: 0.04428136767819524 Engine time: 0.04029703326523304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.017735437024385,
    "estimated_duration": 3600.1723344638845,
    "input_throughput": 4897.5138859916915,
    "output_throughput": 4340.171399691297,
    "total_throughput": 9237.685285682988,
    "itl": 198.1491227829785,
    "ttft": 2101849.4913571337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9671141270827489,
    "arrivals": 623634,
    "finished_requests": 71654,
    "scheduler_time": 44.109562840727484
}
#Debug simulation 
Total elapsed time: 5.017819473985583. Arrivals time: 0.23333088122308254 Scheduler time: 4.687487607821822 Scheduler overhead time: 0.027744601480662823 Adapter cache time: 0.027679271064698696 Engine time: 0.028249932918697596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.743806519079953,
    "estimated_duration": 3600.026307162288,
    "input_throughput": 4458.810472597023,
    "output_throughput": 3969.557658945126,
    "total_throughput": 8428.36813154215,
    "itl": 128.70521116872237,
    "ttft": 2157696.454877737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0144848726317341,
    "arrivals": 623634,
    "finished_requests": 65270,
    "scheduler_time": 27.513576604599688
}
#Debug simulation 
Total elapsed time: 4.743887948337942. Arrivals time: 0.22145819757133722 Scheduler time: 4.3836797387339175 Scheduler overhead time: 0.040370316710323095 Adapter cache time: 0.03834604611620307 Engine time: 0.040611432399600744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.756313805002719,
    "estimated_duration": 3600.0689287052196,
    "input_throughput": 4459.084622519585,
    "output_throughput": 3969.668159975995,
    "total_throughput": 8428.75278249558,
    "itl": 128.7023135166087,
    "ttft": 2157634.6500699827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9732167454692568,
    "arrivals": 623634,
    "finished_requests": 65275,
    "scheduler_time": 27.514185792580243
}
#Debug simulation 
Total elapsed time: 4.75639975303784. Arrivals time: 0.21558955824002624 Scheduler time: 4.401858076453209 Scheduler overhead time: 0.0405664979480207 Adapter cache time: 0.03817148553207517 Engine time: 0.040657276287674904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.750895883888006,
    "estimated_duration": 3600.100817767497,
    "input_throughput": 4447.501559117186,
    "output_throughput": 3961.1474016561774,
    "total_throughput": 8408.648960773364,
    "itl": 127.85223282610711,
    "ttft": 2156166.284584008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9299056417145779,
    "arrivals": 623634,
    "finished_requests": 65113,
    "scheduler_time": 27.15964792454164
}
#Debug simulation 
Total elapsed time: 4.7509781969711185. Arrivals time: 0.21805942570790648 Scheduler time: 4.392074633855373 Scheduler overhead time: 0.04074983159080148 Adapter cache time: 0.03924647672101855 Engine time: 0.040993673261255026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.092949274927378,
    "estimated_duration": 3600.1225125762567,
    "input_throughput": 4980.498007321689,
    "output_throughput": 4386.1160126743125,
    "total_throughput": 9366.614019996003,
    "itl": 195.65820462896264,
    "ttft": 2099573.44791814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8967229089722957,
    "arrivals": 622407,
    "finished_requests": 72423,
    "scheduler_time": 44.47025861073914
}
#Debug simulation 
Total elapsed time: 5.093033814802766. Arrivals time: 0.23675219109281898 Scheduler time: 4.762224294245243 Scheduler overhead time: 0.02834381442517042 Adapter cache time: 0.02333013480529189 Engine time: 0.02874035481363535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.791178815998137,
    "estimated_duration": 3600.078777471133,
    "input_throughput": 4518.301127684262,
    "output_throughput": 3995.6539534683398,
    "total_throughput": 8513.955081152602,
    "itl": 127.86618896277932,
    "ttft": 2157554.1100725858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9429834316857211,
    "arrivals": 622407,
    "finished_requests": 65746,
    "scheduler_time": 27.68022644300585
}
#Debug simulation 
Total elapsed time: 4.791299743112177. Arrivals time: 0.216209152713418 Scheduler time: 4.440204386133701 Scheduler overhead time: 0.04076628992334008 Adapter cache time: 0.033282001968473196 Engine time: 0.04112132033333182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.8136252840049565,
    "estimated_duration": 3600.115415307369,
    "input_throughput": 4518.863737209114,
    "output_throughput": 3996.4124313419065,
    "total_throughput": 8515.276168551021,
    "itl": 127.9230977819657,
    "ttft": 2157432.902779589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9029410904785649,
    "arrivals": 622407,
    "finished_requests": 65756,
    "scheduler_time": 27.70818159007316
}
#Debug simulation 
Total elapsed time: 4.813708550762385. Arrivals time: 0.25360892014577985 Scheduler time: 4.425538606476039 Scheduler overhead time: 0.040930159855633974 Adapter cache time: 0.033119427505880594 Engine time: 0.04079575231298804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7639607433229685,
    "estimated_duration": 3600.0178116792677,
    "input_throughput": 4519.096252029716,
    "output_throughput": 3996.6585591110006,
    "total_throughput": 8515.754811140718,
    "itl": 127.92199813807825,
    "ttft": 2157336.61664938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8641245352267299,
    "arrivals": 622407,
    "finished_requests": 65757,
    "scheduler_time": 27.706901607691783
}
#Debug simulation 
Total elapsed time: 4.764054498169571. Arrivals time: 0.22402378171682358 Scheduler time: 4.40520085580647 Scheduler overhead time: 0.04073938401415944 Adapter cache time: 0.033232356421649456 Engine time: 0.041110017336905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.110886975191534,
    "estimated_duration": 3600.180586954873,
    "input_throughput": 5030.524875786464,
    "output_throughput": 4443.01573592161,
    "total_throughput": 9473.540611708075,
    "itl": 193.18094075805783,
    "ttft": 2089732.5743171019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8691785192769009,
    "arrivals": 619978,
    "finished_requests": 73319,
    "scheduler_time": 45.030220722476756
}
#Debug simulation 
Total elapsed time: 5.110994471237063. Arrivals time: 0.23775677615776658 Scheduler time: 4.785953877493739 Scheduler overhead time: 0.02822401560842991 Adapter cache time: 0.01666561421006918 Engine time: 0.028818374499678612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.844779648818076,
    "estimated_duration": 3600.006168872425,
    "input_throughput": 4540.714996919019,
    "output_throughput": 4022.2603297747683,
    "total_throughput": 8562.975326693786,
    "itl": 126.38122061809098,
    "ttft": 2149343.516020673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9152557883947204,
    "arrivals": 619978,
    "finished_requests": 66153,
    "scheduler_time": 27.770725944264324
}
#Debug simulation 
Total elapsed time: 4.844863930717111. Arrivals time: 0.21936661005020142 Scheduler time: 4.4956214050762355 Scheduler overhead time: 0.04126453446224332 Adapter cache time: 0.027105456683784723 Engine time: 0.04152395389974117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.839497036766261,
    "estimated_duration": 3600.131522271173,
    "input_throughput": 4543.197630091473,
    "output_throughput": 4024.1046501713813,
    "total_throughput": 8567.302280262855,
    "itl": 126.60762565372916,
    "ttft": 2148926.295936081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8764392331428853,
    "arrivals": 619978,
    "finished_requests": 66191,
    "scheduler_time": 27.865243882920158
}
#Debug simulation 
Total elapsed time: 4.839592801872641. Arrivals time: 0.2275428492575884 Scheduler time: 4.483060647267848 Scheduler overhead time: 0.04101375816389918 Adapter cache time: 0.026818716432899237 Engine time: 0.04132327763363719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.807610113173723,
    "estimated_duration": 3600.1319953697357,
    "input_throughput": 4543.5467424632825,
    "output_throughput": 4024.342723720622,
    "total_throughput": 8567.889466183904,
    "itl": 126.60832637188285,
    "ttft": 2148893.678853941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8372140825726103,
    "arrivals": 619978,
    "finished_requests": 66194,
    "scheduler_time": 27.867080061943124
}
#Debug simulation 
Total elapsed time: 4.8077198402024806. Arrivals time: 0.21677441196516156 Scheduler time: 4.462081522215158 Scheduler overhead time: 0.04114971915259957 Adapter cache time: 0.026467522606253624 Engine time: 0.04133274964988232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.287042330019176,
    "estimated_duration": 3600.2327791198677,
    "input_throughput": 3047.0529749139746,
    "output_throughput": 2656.1760271339417,
    "total_throughput": 5703.229002047917,
    "itl": 318.5355976933232,
    "ttft": 2331015.497161142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 500641,
    "finished_requests": 44335,
    "scheduler_time": 27.14856232510395
}
#Debug simulation 
Total elapsed time: 3.287127659190446. Arrivals time: 0.17794860852882266 Scheduler time: 2.972184730693698 Scheduler overhead time: 0.01787913218140602 Adapter cache time: 0.09230909263715148 Engine time: 0.01826932281255722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4623132180422544,
    "estimated_duration": 3600.193263779426,
    "input_throughput": 2997.849895610839,
    "output_throughput": 2627.725876601609,
    "total_throughput": 5625.575772212448,
    "itl": 192.40202783593867,
    "ttft": 2350937.8582755285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149359,
    "arrivals": 500641,
    "finished_requests": 43628,
    "scheduler_time": 18.275305055777398
}
#Debug simulation 
Total elapsed time: 3.4624008499085903. Arrivals time: 0.1762043139897287 Scheduler time: 3.0269714081659913 Scheduler overhead time: 0.02790698828175664 Adapter cache time: 0.18949876865372062 Engine time: 0.028455523308366537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.460142632946372,
    "estimated_duration": 3600.0083623143773,
    "input_throughput": 2998.097480268427,
    "output_throughput": 2627.9522289548036,
    "total_throughput": 5626.04970922323,
    "itl": 192.60555530449082,
    "ttft": 2350555.404948856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 500641,
    "finished_requests": 43630,
    "scheduler_time": 18.304955405947158
}
#Debug simulation 
Total elapsed time: 3.4602289223112166. Arrivals time: 0.17550523206591606 Scheduler time: 3.02507460443303 Scheduler overhead time: 0.02805595612153411 Adapter cache time: 0.18926764046773314 Engine time: 0.028944535180926323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.4628464966081083,
    "estimated_duration": 3600.1720164096405,
    "input_throughput": 2997.8678659814213,
    "output_throughput": 2627.833047109473,
    "total_throughput": 5625.700913090895,
    "itl": 192.4551531456642,
    "ttft": 2350763.822122024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 500641,
    "finished_requests": 43629,
    "scheduler_time": 18.285702363210756
}
#Debug simulation 
Total elapsed time: 3.4629311207681894. Arrivals time: 0.17766083544120193 Scheduler time: 3.0263397889211774 Scheduler overhead time: 0.02788169775158167 Adapter cache time: 0.18915259465575218 Engine time: 0.028555582277476788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.454875861760229,
    "estimated_duration": 3600.1575330204173,
    "input_throughput": 3163.974047114399,
    "output_throughput": 2817.546984253723,
    "total_throughput": 5981.521031368122,
    "itl": 304.50385077839945,
    "ttft": 2304893.552861026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 481654,
    "finished_requests": 46288,
    "scheduler_time": 28.924475673095124
}
#Debug simulation 
Total elapsed time: 3.4549618759192526. Arrivals time: 0.18427235167473555 Scheduler time: 3.144056804012507 Scheduler overhead time: 0.018625323195010424 Adapter cache time: 0.0801479397341609 Engine time: 0.019000418484210968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.5706406510435045,
    "estimated_duration": 3600.0114492839534,
    "input_throughput": 3063.27831323799,
    "output_throughput": 2741.9115575211117,
    "total_throughput": 5805.189870759102,
    "itl": 184.7482659888479,
    "ttft": 2333150.4740840713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 481654,
    "finished_requests": 44770,
    "scheduler_time": 19.068864408435978
}
#Debug simulation 
Total elapsed time: 3.5707468930631876. Arrivals time: 0.17528633633628488 Scheduler time: 3.1526981028728187 Scheduler overhead time: 0.029196809511631727 Adapter cache time: 0.16964518651366234 Engine time: 0.029941570479422808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.5512804207392037,
    "estimated_duration": 3600.1724188630756,
    "input_throughput": 3064.6260001859155,
    "output_throughput": 2743.194728189936,
    "total_throughput": 5807.820728375852,
    "itl": 185.12991995562305,
    "ttft": 2332510.4017887968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 481654,
    "finished_requests": 44791,
    "scheduler_time": 19.144044278150407
}
#Debug simulation 
Total elapsed time: 3.551360087003559. Arrivals time: 0.17413251660764217 Scheduler time: 3.1370190549641848 Scheduler overhead time: 0.028876814525574446 Adapter cache time: 0.16787358187139034 Engine time: 0.02948012249544263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.5607807068154216,
    "estimated_duration": 3600.043640848384,
    "input_throughput": 3067.587257747106,
    "output_throughput": 2746.006156100467,
    "total_throughput": 5813.593413847572,
    "itl": 185.1667319331732,
    "ttft": 2332062.776248815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 481654,
    "finished_requests": 44826,
    "scheduler_time": 19.176316630072815
}
#Debug simulation 
Total elapsed time: 3.560862906742841. Arrivals time: 0.1743870754726231 Scheduler time: 3.14691070234403 Scheduler overhead time: 0.028981244191527367 Adapter cache time: 0.16721629304811358 Engine time: 0.029500454664230347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6133396606892347,
    "estimated_duration": 3600.0712518806554,
    "input_throughput": 3344.794632525563,
    "output_throughput": 2924.8690548831023,
    "total_throughput": 6269.663687408665,
    "itl": 290.0021435741724,
    "ttft": 2276442.091513528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 472156,
    "finished_requests": 48562,
    "scheduler_time": 29.902662216057447
}
#Debug simulation 
Total elapsed time: 3.613479368854314. Arrivals time: 0.23175453208386898 Scheduler time: 3.2705006706528366 Scheduler overhead time: 0.01947130262851715 Adapter cache time: 0.06232353998348117 Engine time: 0.020057952031493187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.654925018083304,
    "estimated_duration": 3600.1204875808207,
    "input_throughput": 3204.7852397720585,
    "output_throughput": 2814.3291411917066,
    "total_throughput": 6019.114380963765,
    "itl": 180.4688746358671,
    "ttft": 2309949.519042227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 472156,
    "finished_requests": 46527,
    "scheduler_time": 19.718485364093475
}
#Debug simulation 
Total elapsed time: 3.655032998882234. Arrivals time: 0.18049295246601105 Scheduler time: 3.2512178560718894 Scheduler overhead time: 0.029993551783263683 Adapter cache time: 0.14871508721262217 Engine time: 0.030269762966781855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.643050313927233,
    "estimated_duration": 3600.090636099114,
    "input_throughput": 3204.8118134330102,
    "output_throughput": 2814.3524772416476,
    "total_throughput": 6019.164290674657,
    "itl": 180.45961008096208,
    "ttft": 2309908.975394274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 472156,
    "finished_requests": 46527,
    "scheduler_time": 19.71771210001398
}
#Debug simulation 
Total elapsed time: 3.6431309659965336. Arrivals time: 0.21815880900248885 Scheduler time: 3.203415653668344 Scheduler overhead time: 0.029553121887147427 Adapter cache time: 0.1475696791894734 Engine time: 0.030166909098625183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.650620295666158,
    "estimated_duration": 3600.1561637992,
    "input_throughput": 3203.195493561707,
    "output_throughput": 2812.8707587265717,
    "total_throughput": 6016.0662522882785,
    "itl": 180.19253452612406,
    "ttft": 2310819.10512553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 472156,
    "finished_requests": 46499,
    "scheduler_time": 19.647827755231553
}
#Debug simulation 
Total elapsed time: 3.650703107006848. Arrivals time: 0.21689675841480494 Scheduler time: 3.2114882660098374 Scheduler overhead time: 0.02966041723266244 Adapter cache time: 0.14810390677303076 Engine time: 0.030225851107388735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6198152708821,
    "estimated_duration": 3600.04107781677,
    "input_throughput": 3394.08710508661,
    "output_throughput": 2999.4027197457385,
    "total_throughput": 6393.489824832348,
    "itl": 284.75261873247337,
    "ttft": 2264239.1449623164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 467317,
    "finished_requests": 49563,
    "scheduler_time": 30.713947465083802
}
#Debug simulation 
Total elapsed time: 3.6199260260909796. Arrivals time: 0.1844833088107407 Scheduler time: 3.333531606476754 Scheduler overhead time: 0.01982635073363781 Adapter cache time: 0.05227299313992262 Engine time: 0.02026316523551941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6469850023277104,
    "estimated_duration": 3600.056112876282,
    "input_throughput": 3220.727854360103,
    "output_throughput": 2855.7132660318907,
    "total_throughput": 6076.4411203919935,
    "itl": 177.8862953796169,
    "ttft": 2305053.4144580397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.040856846901594,
    "arrivals": 467317,
    "finished_requests": 47002,
    "scheduler_time": 19.94836480186218
}
#Debug simulation 
Total elapsed time: 3.6470658341422677. Arrivals time: 0.18113043392077088 Scheduler time: 3.2547120163217187 Scheduler overhead time: 0.030154607258737087 Adapter cache time: 0.1359176905825734 Engine time: 0.03060918115079403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.574809988029301,
    "estimated_duration": 3600.1555839145285,
    "input_throughput": 3124.9710568806063,
    "output_throughput": 2775.304502017102,
    "total_throughput": 5900.275558897708,
    "itl": 167.3793837581409,
    "ttft": 2320984.989661467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9975457431469148,
    "arrivals": 467317,
    "finished_requests": 45643,
    "scheduler_time": 17.295904229905755
}
#Debug simulation 
Total elapsed time: 3.5748903290368617. Arrivals time: 0.17713663587346673 Scheduler time: 3.189290295355022 Scheduler overhead time: 0.031471948605030775 Adapter cache time: 0.12950117932632565 Engine time: 0.03240690566599369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.647961953189224,
    "estimated_duration": 3600.0575633408957,
    "input_throughput": 3219.8465707983923,
    "output_throughput": 2855.115736110996,
    "total_throughput": 6074.962306909389,
    "itl": 177.4622501570107,
    "ttft": 2305313.108963242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 467317,
    "finished_requests": 46989,
    "scheduler_time": 19.88075198418574
}
#Debug simulation 
Total elapsed time: 3.648071895353496. Arrivals time: 0.1791036087088287 Scheduler time: 3.259501341730356 Scheduler overhead time: 0.030017064418643713 Adapter cache time: 0.1345423236489296 Engine time: 0.030502556823194027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6748060607351363,
    "estimated_duration": 3600.182596411477,
    "input_throughput": 3447.367089761213,
    "output_throughput": 3052.0432521817997,
    "total_throughput": 6499.410341943013,
    "itl": 280.59121425483465,
    "ttft": 2253233.590673514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9548721761070179,
    "arrivals": 464889,
    "finished_requests": 50414,
    "scheduler_time": 31.247460749186207
}
#Debug simulation 
Total elapsed time: 3.6748889358714223. Arrivals time: 0.18839157605543733 Scheduler time: 3.39378562849015 Scheduler overhead time: 0.020038350950926542 Adapter cache time: 0.04269581567496061 Engine time: 0.02035387372598052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.664269487839192,
    "estimated_duration": 3600.0507600694477,
    "input_throughput": 3241.9942878180004,
    "output_throughput": 2887.1198471100156,
    "total_throughput": 6129.114134928016,
    "itl": 175.95932903241518,
    "ttft": 2296113.9122083187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0148934679501749,
    "arrivals": 464889,
    "finished_requests": 47409,
    "scheduler_time": 20.18174483878153
}
#Debug simulation 
Total elapsed time: 3.664348972029984. Arrivals time: 0.1814668164588511 Scheduler time: 3.285795125644654 Scheduler overhead time: 0.03040322568267584 Adapter cache time: 0.12120703607797623 Engine time: 0.030965551733970642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.6717624608427286,
    "estimated_duration": 3600.022375900986,
    "input_throughput": 3234.9043378057886,
    "output_throughput": 2881.0548705004117,
    "total_throughput": 6115.959208306201,
    "itl": 175.10406010447113,
    "ttft": 2297324.240546108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9719909595139361,
    "arrivals": 464889,
    "finished_requests": 47319,
    "scheduler_time": 19.985381463386055
}
#Debug simulation 
Total elapsed time: 3.6718591577373445. Arrivals time: 0.18746489565819502 Scheduler time: 3.285227185115218 Scheduler overhead time: 0.030504385940730572 Adapter cache time: 0.12283484824001789 Engine time: 0.03106467705219984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6671607750467956,
    "estimated_duration": 3600.1260415761476,
    "input_throughput": 3240.0676713233006,
    "output_throughput": 2885.535084058327,
    "total_throughput": 6125.6027553816275,
    "itl": 176.02661703029622,
    "ttft": 2296539.507860068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9299056417145779,
    "arrivals": 464889,
    "finished_requests": 47385,
    "scheduler_time": 20.16289945890782
}
#Debug simulation 
Total elapsed time: 3.667313114274293. Arrivals time: 0.18050065357238054 Scheduler time: 3.2888321527279913 Scheduler overhead time: 0.03049561847001314 Adapter cache time: 0.12181536853313446 Engine time: 0.0309986537322402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6551977382041514,
    "estimated_duration": 3600.0363033412477,
    "input_throughput": 3452.407407243269,
    "output_throughput": 3067.315179502868,
    "total_throughput": 6519.722586746137,
    "itl": 279.21672373951714,
    "ttft": 2247684.8738296456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8875414457404974,
    "arrivals": 463720,
    "finished_requests": 50521,
    "scheduler_time": 31.44355067427256
}
#Debug simulation 
Total elapsed time: 3.655278910882771. Arrivals time: 0.18575816601514816 Scheduler time: 3.3831062633544207 Scheduler overhead time: 0.020397715270519257 Adapter cache time: 0.03605144238099456 Engine time: 0.0204136879183352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6396892401389778,
    "estimated_duration": 3600.060958190368,
    "input_throughput": 3236.73880396106,
    "output_throughput": 2895.5354148336014,
    "total_throughput": 6132.2742187946615,
    "itl": 175.20593491765035,
    "ttft": 2292541.976097122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9382291170512377,
    "arrivals": 463720,
    "finished_requests": 47421,
    "scheduler_time": 20.171952780202624
}
#Debug simulation 
Total elapsed time: 3.639769858215004. Arrivals time: 0.1793592474423349 Scheduler time: 3.2702662497758865 Scheduler overhead time: 0.03018649574369192 Adapter cache time: 0.11444108234718442 Engine time: 0.030983280390501022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.667803983669728,
    "estimated_duration": 3600.09097374237,
    "input_throughput": 3235.111302727169,
    "output_throughput": 2894.0629767389864,
    "total_throughput": 6129.174279466156,
    "itl": 175.24010852290425,
    "ttft": 2292838.8217456327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8977781805256412,
    "arrivals": 463720,
    "finished_requests": 47401,
    "scheduler_time": 20.15559209023376
}
#Debug simulation 
Total elapsed time: 3.6679100929759443. Arrivals time: 0.17912905802950263 Scheduler time: 3.297608027700335 Scheduler overhead time: 0.030500884633511305 Adapter cache time: 0.11503784451633692 Engine time: 0.030968347564339638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.665772956330329,
    "estimated_duration": 3600.1092752279656,
    "input_throughput": 3235.069024193027,
    "output_throughput": 2893.850492729919,
    "total_throughput": 6128.919516922946,
    "itl": 175.2413984771089,
    "ttft": 2292781.333312248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8581444346369256,
    "arrivals": 463720,
    "finished_requests": 47400,
    "scheduler_time": 20.15627521803714
}
#Debug simulation 
Total elapsed time: 3.6658582421950996. Arrivals time: 0.18030065763741732 Scheduler time: 3.2951568998396397 Scheduler overhead time: 0.030369292944669724 Adapter cache time: 0.11431826977059245 Engine time: 0.031076586805284023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.726607824675739,
    "estimated_duration": 3600.228522773733,
    "input_throughput": 3487.7297150920767,
    "output_throughput": 3057.3059266581918,
    "total_throughput": 6545.035641750268,
    "itl": 278.1228527098993,
    "ttft": 2210962.677919229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 366022,
    "finished_requests": 50721,
    "scheduler_time": 31.380988145713786
}
#Debug simulation 
Total elapsed time: 3.7266856329515576. Arrivals time: 0.18277680221945047 Scheduler time: 3.3799211187288165 Scheduler overhead time: 0.020420926623046398 Adapter cache time: 0.11302541056647897 Engine time: 0.02086355397477746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.90240960707888,
    "estimated_duration": 3600.103536697802,
    "input_throughput": 3474.6011809076526,
    "output_throughput": 3065.0946250622414,
    "total_throughput": 6539.6958059698945,
    "itl": 165.02377997200327,
    "ttft": 2221194.0813760976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 366022,
    "finished_requests": 50553,
    "scheduler_time": 21.533182062580423
}
#Debug simulation 
Total elapsed time: 3.9024888020940125. Arrivals time: 0.1823218585923314 Scheduler time: 3.4708937611430883 Scheduler overhead time: 0.032500870525836945 Adapter cache time: 0.16837005456909537 Engine time: 0.032907724380493164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.909898465964943,
    "estimated_duration": 3600.0911839718506,
    "input_throughput": 3473.9095097591808,
    "output_throughput": 3064.8457042209943,
    "total_throughput": 6538.7552139801755,
    "itl": 164.87060045768516,
    "ttft": 2221193.5381499617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 366022,
    "finished_requests": 50546,
    "scheduler_time": 21.507666744079526
}
#Debug simulation 
Total elapsed time: 3.910002376884222. Arrivals time: 0.18270311644300818 Scheduler time: 3.4769784193485975 Scheduler overhead time: 0.032505320850759745 Adapter cache time: 0.16912629967555404 Engine time: 0.03310462739318609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.909683457110077,
    "estimated_duration": 3600.0770682874695,
    "input_throughput": 3471.5920695401132,
    "output_throughput": 3062.901652059719,
    "total_throughput": 6534.4937215998325,
    "itl": 164.83435102295272,
    "ttft": 2221093.0941198934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 366022,
    "finished_requests": 50514,
    "scheduler_time": 21.463989254014503
}
#Debug simulation 
Total elapsed time: 3.909765882883221. Arrivals time: 0.18233411060646176 Scheduler time: 3.477629281580448 Scheduler overhead time: 0.0324673717841506 Adapter cache time: 0.1682584509253502 Engine time: 0.0335243702866137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.888258197810501,
    "estimated_duration": 3600.257010307265,
    "input_throughput": 3671.570380157903,
    "output_throughput": 3216.279550834553,
    "total_throughput": 6887.8499309924555,
    "itl": 263.9711949757849,
    "ttft": 2181920.3707787623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 356416,
    "finished_requests": 53169,
    "scheduler_time": 33.02330975748329
}
#Debug simulation 
Total elapsed time: 3.8883388699032366. Arrivals time: 0.18944394402205944 Scheduler time: 3.5477143111638725 Scheduler overhead time: 0.021331933792680502 Adapter cache time: 0.09780527884140611 Engine time: 0.02182055963203311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.03754117898643,
    "estimated_duration": 3600.045702277995,
    "input_throughput": 3613.330795153198,
    "output_throughput": 3178.2388186794374,
    "total_throughput": 6791.569613832635,
    "itl": 158.06627790915402,
    "ttft": 2199959.434843165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149357,
    "arrivals": 356416,
    "finished_requests": 52271,
    "scheduler_time": 22.18104709472398
}
#Debug simulation 
Total elapsed time: 4.037629046011716. Arrivals time: 0.19307602802291512 Scheduler time: 3.609832883812487 Scheduler overhead time: 0.033666559495031834 Adapter cache time: 0.15063561405986547 Engine time: 0.03432371374219656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.289177820086479,
    "estimated_duration": 3600.130675119209,
    "input_throughput": 3619.854159757265,
    "output_throughput": 3184.2063620705694,
    "total_throughput": 6804.060521827834,
    "itl": 158.2029524360033,
    "ttft": 2199559.548419903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 356416,
    "finished_requests": 52363,
    "scheduler_time": 22.28017128927905
}
#Debug simulation 
Total elapsed time: 4.289264312013984. Arrivals time: 0.44131220504641533 Scheduler time: 3.613313981797546 Scheduler overhead time: 0.03372118342667818 Adapter cache time: 0.15009224507957697 Engine time: 0.03462589764967561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.03346442617476,
    "estimated_duration": 3600.0479153831297,
    "input_throughput": 3619.7409885343623,
    "output_throughput": 3184.2370627947666,
    "total_throughput": 6803.978051329129,
    "itl": 158.1919126233157,
    "ttft": 2199532.2413280406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 356416,
    "finished_requests": 52361,
    "scheduler_time": 22.278732192036912
}
#Debug simulation 
Total elapsed time: 4.03354417020455. Arrivals time: 0.18533085845410824 Scheduler time: 3.6113545084372163 Scheduler overhead time: 0.033659673761576414 Adapter cache time: 0.15268887113779783 Engine time: 0.034382541198283434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9750726451165974,
    "estimated_duration": 3600.0001877504533,
    "input_throughput": 3766.390636905125,
    "output_throughput": 3310.300105136015,
    "total_throughput": 7076.690742041141,
    "itl": 257.9815080898251,
    "ttft": 2169184.145524885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 351637,
    "finished_requests": 54628,
    "scheduler_time": 33.94064859367384
}
#Debug simulation 
Total elapsed time: 3.975156513042748. Arrivals time: 0.19051461573690176 Scheduler time: 3.6469612838700414 Scheduler overhead time: 0.021914702374488115 Adapter cache time: 0.08282680762931705 Engine time: 0.02245644759386778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.068157222587615,
    "estimated_duration": 3600.15487908883,
    "input_throughput": 3667.002238342941,
    "output_throughput": 3242.0660754889727,
    "total_throughput": 6909.068313831914,
    "itl": 156.86312277875885,
    "ttft": 2194613.8439004724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 351637,
    "finished_requests": 53233,
    "scheduler_time": 22.86489467554035
}
#Debug simulation 
Total elapsed time: 4.068237891886383. Arrivals time: 0.18745530024170876 Scheduler time: 3.6603214382193983 Scheduler overhead time: 0.033971475437283516 Adapter cache time: 0.13580665411427617 Engine time: 0.03440137067809701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.125840852037072,
    "estimated_duration": 3600.009294342915,
    "input_throughput": 3667.272198642951,
    "output_throughput": 3242.1977405284447,
    "total_throughput": 6909.469939171396,
    "itl": 156.85498799439242,
    "ttft": 2194512.5999772246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 351637,
    "finished_requests": 53234,
    "scheduler_time": 22.864917381661336
}
#Debug simulation 
Total elapsed time: 4.125922061037272. Arrivals time: 0.18686551321297884 Scheduler time: 3.7187616117298603 Scheduler overhead time: 0.034103124402463436 Adapter cache time: 0.13526541786268353 Engine time: 0.0345320338383317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.045911930967122,
    "estimated_duration": 3600.011817381346,
    "input_throughput": 3667.269628465639,
    "output_throughput": 3242.1954682610426,
    "total_throughput": 6909.465096726682,
    "itl": 156.85246701463169,
    "ttft": 2194499.5617934014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 351637,
    "finished_requests": 53234,
    "scheduler_time": 22.86509362910296
}
#Debug simulation 
Total elapsed time: 4.045995211228728. Arrivals time: 0.1871872958727181 Scheduler time: 3.64049971383065 Scheduler overhead time: 0.03403492225334048 Adapter cache time: 0.13360217865556479 Engine time: 0.0343388207256794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.05370797496289,
    "estimated_duration": 3600.0747172390397,
    "input_throughput": 3832.0001898682813,
    "output_throughput": 3373.0374933198113,
    "total_throughput": 7205.037683188093,
    "itl": 253.14178441041952,
    "ttft": 2143618.892453018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 349246,
    "finished_requests": 55853,
    "scheduler_time": 34.603517700498436
}
#Debug simulation 
Total elapsed time: 4.053785535041243. Arrivals time: 0.19270395720377564 Scheduler time: 3.728073530830443 Scheduler overhead time: 0.02230448415502906 Adapter cache time: 0.07748750178143382 Engine time: 0.022633299231529236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0983352940529585,
    "estimated_duration": 3600.081657349312,
    "input_throughput": 3716.5662541808724,
    "output_throughput": 3290.1278713553133,
    "total_throughput": 7006.694125536185,
    "itl": 154.59091135758405,
    "ttft": 2170292.7707201773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0408568469015933,
    "arrivals": 349246,
    "finished_requests": 54183,
    "scheduler_time": 23.254673368151735
}
#Debug simulation 
Total elapsed time: 4.098439139313996. Arrivals time: 0.1888892576098442 Scheduler time: 3.695416188798845 Scheduler overhead time: 0.03448048094287515 Adapter cache time: 0.1280247988179326 Engine time: 0.03507650038227439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.100000869017094,
    "estimated_duration": 3600.0078503129366,
    "input_throughput": 3718.2768917674484,
    "output_throughput": 3291.241711867392,
    "total_throughput": 7009.5186036348405,
    "itl": 154.885445268166,
    "ttft": 2170388.5663965903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9971371478284744,
    "arrivals": 349246,
    "finished_requests": 54208,
    "scheduler_time": 23.32004267385607
}
#Debug simulation 
Total elapsed time: 4.100088402163237. Arrivals time: 0.18984729377552867 Scheduler time: 3.6978319990448654 Scheduler overhead time: 0.034532795660197735 Adapter cache time: 0.1263483283109963 Engine time: 0.034966892562806606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.129849414341152,
    "estimated_duration": 3600.026355033047,
    "input_throughput": 3716.0255733397807,
    "output_throughput": 3289.9611924900137,
    "total_throughput": 7005.986765829794,
    "itl": 154.44495210420558,
    "ttft": 2170121.007156862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 349246,
    "finished_requests": 54178,
    "scheduler_time": 23.228077318726452
}
#Debug simulation 
Total elapsed time: 4.129927184898406. Arrivals time: 0.18759415159001946 Scheduler time: 3.728695370722562 Scheduler overhead time: 0.03467779466882348 Adapter cache time: 0.12726409174501896 Engine time: 0.03508899500593543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.12186311930418,
    "estimated_duration": 3600.0281907222043,
    "input_throughput": 3864.0469638126274,
    "output_throughput": 3430.181194643009,
    "total_throughput": 7294.228158455636,
    "itl": 250.29687159338332,
    "ttft": 2140150.6488210936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9303882741555559,
    "arrivals": 348063,
    "finished_requests": 56533,
    "scheduler_time": 35.240576951598975
}
#Debug simulation 
Total elapsed time: 4.121974038425833. Arrivals time: 0.19550891919061542 Scheduler time: 3.798252903856337 Scheduler overhead time: 0.022737686522305012 Adapter cache time: 0.07168163731694221 Engine time: 0.022931538987904787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.109487303066999,
    "estimated_duration": 3600.0593018565673,
    "input_throughput": 3727.76637125926,
    "output_throughput": 3319.1147695366685,
    "total_throughput": 7046.881140795928,
    "itl": 152.50660204994287,
    "ttft": 2171421.6568842917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9867572293407338,
    "arrivals": 348063,
    "finished_requests": 54467,
    "scheduler_time": 23.313489742131583
}
#Debug simulation 
Total elapsed time: 4.109615512192249. Arrivals time: 0.18875415297225118 Scheduler time: 3.719110465608537 Scheduler overhead time: 0.03473903797566891 Adapter cache time: 0.11519904620945454 Engine time: 0.035145852249115705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.116184653248638,
    "estimated_duration": 3600.1251908351323,
    "input_throughput": 3725.3482279289406,
    "output_throughput": 3316.607997520829,
    "total_throughput": 7041.95622544977,
    "itl": 153.0882442414858,
    "ttft": 2171712.831760047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.945080506859816,
    "arrivals": 348063,
    "finished_requests": 54433,
    "scheduler_time": 23.377135006642582
}
#Debug simulation 
Total elapsed time: 4.116265517193824. Arrivals time: 0.18955689202994108 Scheduler time: 3.7257540496066213 Scheduler overhead time: 0.034765562042593956 Adapter cache time: 0.11422720085829496 Engine time: 0.03523073671385646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.172719009686261,
    "estimated_duration": 3600.072012803618,
    "input_throughput": 3725.7160279842615,
    "output_throughput": 3316.89976131913,
    "total_throughput": 7042.6157893033915,
    "itl": 152.99235630737877,
    "ttft": 2171511.3264176375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9029951890604583,
    "arrivals": 348063,
    "finished_requests": 54437,
    "scheduler_time": 23.362806962654883
}
#Debug simulation 
Total elapsed time: 4.172809679061174. Arrivals time: 0.19658707594498992 Scheduler time: 3.7751452806405723 Scheduler overhead time: 0.034791954793035984 Adapter cache time: 0.11427005659788847 Engine time: 0.03531829081475735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.183298547752202,
    "estimated_duration": 3600.0728293692864,
    "input_throughput": 3962.4837263359454,
    "output_throughput": 3486.0580868300667,
    "total_throughput": 7448.541813166012,
    "itl": 245.4314389497737,
    "ttft": 2121491.103380197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 337149,
    "finished_requests": 57604,
    "scheduler_time": 35.76627560271331
}
#Debug simulation 
Total elapsed time: 4.183404735755175. Arrivals time: 0.19858333142474294 Scheduler time: 3.833421050570905 Scheduler overhead time: 0.02334121335297823 Adapter cache time: 0.09363324521109462 Engine time: 0.02338371705263853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2739999727346,
    "estimated_duration": 3600.1404424708544,
    "input_throughput": 3862.504872297791,
    "output_throughput": 3418.184706026125,
    "total_throughput": 7280.689578323916,
    "itl": 148.38228312530893,
    "ttft": 2146173.880273871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 337149,
    "finished_requests": 56182,
    "scheduler_time": 24.04768722274613
}
#Debug simulation 
Total elapsed time: 4.2740776520222425. Arrivals time: 0.1919977106153965 Scheduler time: 3.8617195691913366 Scheduler overhead time: 0.036093204747885466 Adapter cache time: 0.13048158679157495 Engine time: 0.0364962019957602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.513557262253016,
    "estimated_duration": 3600.1364234878906,
    "input_throughput": 3864.1855095374813,
    "output_throughput": 3419.5565256032605,
    "total_throughput": 7283.742035140742,
    "itl": 148.85353348031427,
    "ttft": 2145836.8315270673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 337149,
    "finished_requests": 56208,
    "scheduler_time": 24.162924032140772
}
#Debug simulation 
Total elapsed time: 4.5136179542168975. Arrivals time: 0.4465357172302902 Scheduler time: 3.849675788078457 Scheduler overhead time: 0.03575225593522191 Adapter cache time: 0.12787493877112865 Engine time: 0.03660040581598878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.249539025127888,
    "estimated_duration": 3600.099488403381,
    "input_throughput": 3864.1607113390055,
    "output_throughput": 3419.5599426225117,
    "total_throughput": 7283.720653961517,
    "itl": 148.77822883610796,
    "ttft": 2145772.946865348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 337149,
    "finished_requests": 56207,
    "scheduler_time": 24.14770238598735
}
#Debug simulation 
Total elapsed time: 4.24962024204433. Arrivals time: 0.19881532061845064 Scheduler time: 3.8314345963299274 Scheduler overhead time: 0.035718590952456 Adapter cache time: 0.13006434170529246 Engine time: 0.03641803003847599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.279740151949227,
    "estimated_duration": 3600.2493192522466,
    "input_throughput": 4077.125137280405,
    "output_throughput": 3581.9266546457948,
    "total_throughput": 7659.0517919262,
    "itl": 238.36704483407163,
    "ttft": 2108711.929833109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 332464,
    "finished_requests": 59008,
    "scheduler_time": 36.71597994475527
}
#Debug simulation 
Total elapsed time: 4.279824983794242. Arrivals time: 0.1999943503178656 Scheduler time: 3.9365740665234625 Scheduler overhead time: 0.023817725479602814 Adapter cache time: 0.08386712754145265 Engine time: 0.024201877415180206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.342907838989049,
    "estimated_duration": 3600.143704783432,
    "input_throughput": 3939.2533084601178,
    "output_throughput": 3478.616140616908,
    "total_throughput": 7417.869449077026,
    "itl": 145.71645557032593,
    "ttft": 2137916.1191893793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 332464,
    "finished_requests": 57037,
    "scheduler_time": 24.51704104026794
}
#Debug simulation 
Total elapsed time: 4.342986291274428. Arrivals time: 0.2122769453562796 Scheduler time: 3.9244616380892694 Scheduler overhead time: 0.036500389222055674 Adapter cache time: 0.11535302875563502 Engine time: 0.03684230661019683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.320359408389777,
    "estimated_duration": 3600.0605474437066,
    "input_throughput": 3936.4162944600016,
    "output_throughput": 3475.6304331838896,
    "total_throughput": 7412.046727643891,
    "itl": 145.0866941453674,
    "ttft": 2137984.66266352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 332464,
    "finished_requests": 56992,
    "scheduler_time": 24.358071568438532
}
#Debug simulation 
Total elapsed time: 4.320473846048117. Arrivals time: 0.19576296070590615 Scheduler time: 3.918243461754173 Scheduler overhead time: 0.036518987733870745 Adapter cache time: 0.11520656431093812 Engine time: 0.037099580746144056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.3109982307069,
    "estimated_duration": 3600.0304135018596,
    "input_throughput": 3928.6631987762494,
    "output_throughput": 3468.8687498760623,
    "total_throughput": 7397.531948652312,
    "itl": 145.05304989403763,
    "ttft": 2137548.3634545305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 332464,
    "finished_requests": 56867,
    "scheduler_time": 24.256895734118714
}
#Debug simulation 
Total elapsed time: 4.311083782929927. Arrivals time: 0.19497188227251172 Scheduler time: 3.9073117221705616 Scheduler overhead time: 0.036651013884693384 Adapter cache time: 0.11740680178627372 Engine time: 0.03712204843759537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.414625075645745,
    "estimated_duration": 3600.0067632047667,
    "input_throughput": 4155.130804999871,
    "output_throughput": 3678.231700934952,
    "total_throughput": 7833.362505934822,
    "itl": 233.55624640126192,
    "ttft": 2083901.2034403032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9701746148266817,
    "arrivals": 329992,
    "finished_requests": 60540,
    "scheduler_time": 37.75721953348256
}
#Debug simulation 
Total elapsed time: 4.414714134763926. Arrivals time: 0.21022223215550184 Scheduler time: 4.067812124732882 Scheduler overhead time: 0.024189460556954145 Adapter cache time: 0.07600416662171483 Engine time: 0.02484312141314149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.369941341690719,
    "estimated_duration": 3600.008964884135,
    "input_throughput": 3975.5173222077306,
    "output_throughput": 3537.4070243210804,
    "total_throughput": 7512.924346528811,
    "itl": 143.80109096405536,
    "ttft": 2119475.87466045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0348767463117896,
    "arrivals": 329992,
    "finished_requests": 57956,
    "scheduler_time": 25.011679455742563
}
#Debug simulation 
Total elapsed time: 4.370021597016603. Arrivals time: 0.1956696603447199 Scheduler time: 3.976546572521329 Scheduler overhead time: 0.0369925987906754 Adapter cache time: 0.10550819104537368 Engine time: 0.03743025753647089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.333002767059952,
    "estimated_duration": 3600.0088813789507,
    "input_throughput": 3975.3543592698534,
    "output_throughput": 3537.347939853463,
    "total_throughput": 7512.702299123316,
    "itl": 143.74490985719845,
    "ttft": 2119439.3243907816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.99115704723867,
    "arrivals": 329992,
    "finished_requests": 57954,
    "scheduler_time": 24.99865304090417
}
#Debug simulation 
Total elapsed time: 4.333110756706446. Arrivals time: 0.19536933163180947 Scheduler time: 3.940662939567119 Scheduler overhead time: 0.036772767547518015 Adapter cache time: 0.10531118465587497 Engine time: 0.03723972197622061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.373618978075683,
    "estimated_duration": 3600.076022757715,
    "input_throughput": 3975.9863151543573,
    "output_throughput": 3537.978898079842,
    "total_throughput": 7513.965213234199,
    "itl": 143.9330188292652,
    "ttft": 2119304.8381152865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.947845943483991,
    "arrivals": 329992,
    "finished_requests": 57965,
    "scheduler_time": 25.047119610979944
}
#Debug simulation 
Total elapsed time: 4.373696617782116. Arrivals time: 0.195552215911448 Scheduler time: 3.981361895799637 Scheduler overhead time: 0.036877005361020565 Adapter cache time: 0.10490547120571136 Engine time: 0.037385132629424334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.415446725208312,
    "estimated_duration": 3600.112453664721,
    "input_throughput": 4220.917595096651,
    "output_throughput": 3736.505504517435,
    "total_throughput": 7957.423099614087,
    "itl": 229.350974778286,
    "ttft": 2064677.4066754093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9518116883630852,
    "arrivals": 328805,
    "finished_requests": 61620,
    "scheduler_time": 38.413773329170155
}
#Debug simulation 
Total elapsed time: 4.415526153054088. Arrivals time: 0.2041045008227229 Scheduler time: 4.084994602017105 Scheduler overhead time: 0.02463114634156227 Adapter cache time: 0.06497086910530925 Engine time: 0.02513517765328288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.411683619022369,
    "estimated_duration": 3600.01414479574,
    "input_throughput": 4023.5005801128154,
    "output_throughput": 3575.9812273544358,
    "total_throughput": 7599.481807467251,
    "itl": 142.06623456092123,
    "ttft": 2104537.342373466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.015302063268615,
    "arrivals": 328805,
    "finished_requests": 58735,
    "scheduler_time": 25.290252809296067
}
#Debug simulation 
Total elapsed time: 4.411761600058526. Arrivals time: 0.20209846878424287 Scheduler time: 4.021267564501613 Scheduler overhead time: 0.037392135709524155 Adapter cache time: 0.09338101325556636 Engine time: 0.03960598912090063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.379634998273104,
    "estimated_duration": 3600.063587757708,
    "input_throughput": 4022.2778423253135,
    "output_throughput": 3575.0004649268417,
    "total_throughput": 7597.278307252155,
    "itl": 141.67162870219343,
    "ttft": 2104761.053273806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.973216745469257,
    "arrivals": 328805,
    "finished_requests": 58719,
    "scheduler_time": 25.18486499279995
}
#Debug simulation 
Total elapsed time: 4.379742433317006. Arrivals time: 0.19698651786893606 Scheduler time: 3.996466309763491 Scheduler overhead time: 0.03738077823072672 Adapter cache time: 0.09284844063222408 Engine time: 0.03797415364533663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.399799093604088,
    "estimated_duration": 3600.060059078985,
    "input_throughput": 4010.4583709899807,
    "output_throughput": 3564.5727541787246,
    "total_throughput": 7575.031125168705,
    "itl": 142.16689015141904,
    "ttft": 2105544.5459967703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9299056417145779,
    "arrivals": 328805,
    "finished_requests": 58554,
    "scheduler_time": 25.1507628151728
}
#Debug simulation 
Total elapsed time: 4.400104871019721. Arrivals time: 0.19741111574694514 Scheduler time: 4.016303662210703 Scheduler overhead time: 0.03727591224014759 Adapter cache time: 0.09324135724455118 Engine time: 0.03774697380140424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.602561308071017,
    "estimated_duration": 3600.044859293032,
    "input_throughput": 4395.048289233584,
    "output_throughput": 3870.9225980969077,
    "total_throughput": 8265.970887330492,
    "itl": 221.30345924641657,
    "ttft": 2042153.7389870635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 322791,
    "finished_requests": 64012,
    "scheduler_time": 39.74066054833893
}
#Debug simulation 
Total elapsed time: 4.602644809987396. Arrivals time: 0.2083862852305174 Scheduler time: 4.262454988434911 Scheduler overhead time: 0.025324059184640646 Adapter cache time: 0.06854756828397512 Engine time: 0.025761850643903017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.502419466152787,
    "estimated_duration": 3600.1264094965,
    "input_throughput": 4164.113226817674,
    "output_throughput": 3681.4796183375197,
    "total_throughput": 7845.5928451551945,
    "itl": 138.5665012942963,
    "ttft": 2083118.5077230067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 322791,
    "finished_requests": 60632,
    "scheduler_time": 26.155330985857518
}
#Debug simulation 
Total elapsed time: 4.502504811156541. Arrivals time: 0.20653179800137877 Scheduler time: 4.112850232981145 Scheduler overhead time: 0.03812324907630682 Adapter cache time: 0.08795052440837026 Engine time: 0.03862648969516158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.476221050135791,
    "estimated_duration": 3600.0721921785607,
    "input_throughput": 4161.541547013764,
    "output_throughput": 3679.23177451188,
    "total_throughput": 7840.773321525644,
    "itl": 138.21220102209418,
    "ttft": 2083456.696956323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418166,
    "arrivals": 322791,
    "finished_requests": 60591,
    "scheduler_time": 26.050675283598274
}
#Debug simulation 
Total elapsed time: 4.476328655146062. Arrivals time: 0.20085095800459385 Scheduler time: 4.092390203848481 Scheduler overhead time: 0.038119753357023 Adapter cache time: 0.08786189509555697 Engine time: 0.03865612158551812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.507271151058376,
    "estimated_duration": 3600.132704793393,
    "input_throughput": 4164.105945328017,
    "output_throughput": 3681.4731807950448,
    "total_throughput": 7845.5791261230615,
    "itl": 138.451122817519,
    "ttft": 2083217.4304525128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 322791,
    "finished_requests": 60632,
    "scheduler_time": 26.127552940026007
}
#Debug simulation 
Total elapsed time: 4.5073603871278465. Arrivals time: 0.20316485175862908 Scheduler time: 4.119478607084602 Scheduler overhead time: 0.0382230575196445 Adapter cache time: 0.08856573794037104 Engine time: 0.03926882892847061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.651269854977727,
    "estimated_duration": 3600.1835287100084,
    "input_throughput": 4478.195311830904,
    "output_throughput": 3933.6502950654785,
    "total_throughput": 8411.845606896382,
    "itl": 216.9737146055901,
    "ttft": 2028867.3763854376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 320386,
    "finished_requests": 65072,
    "scheduler_time": 40.34959366189701
}
#Debug simulation 
Total elapsed time: 4.65135345607996. Arrivals time: 0.21091991337016225 Scheduler time: 4.3177284160628915 Scheduler overhead time: 0.025546130258589983 Adapter cache time: 0.05864642187952995 Engine time: 0.026157968677580357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.560004684142768,
    "estimated_duration": 3600.1248939580337,
    "input_throughput": 4219.979152805774,
    "output_throughput": 3719.026810006018,
    "total_throughput": 7939.005962811792,
    "itl": 136.50592207366046,
    "ttft": 2076902.2073836785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0408568469015937,
    "arrivals": 320386,
    "finished_requests": 61342,
    "scheduler_time": 26.373465268008314
}
#Debug simulation 
Total elapsed time: 4.56009209016338. Arrivals time: 0.20740759512409568 Scheduler time: 4.181000756565481 Scheduler overhead time: 0.03858978860080242 Adapter cache time: 0.07566335797309875 Engine time: 0.038875055965036154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.505388311576098,
    "estimated_duration": 3600.136481777133,
    "input_throughput": 4220.176395229379,
    "output_throughput": 3719.1295573857274,
    "total_throughput": 7939.305952615106,
    "itl": 136.5058573624897,
    "ttft": 2077111.3399099591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9971371478284746,
    "arrivals": 320386,
    "finished_requests": 61346,
    "scheduler_time": 26.375884098559624
}
#Debug simulation 
Total elapsed time: 4.505493110977113. Arrivals time: 0.2019183444790542 Scheduler time: 4.132106852717698 Scheduler overhead time: 0.03842158894985914 Adapter cache time: 0.07562158908694983 Engine time: 0.03890817705541849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.5319029949605465,
    "estimated_duration": 3600.0116380166564,
    "input_throughput": 4220.322745503776,
    "output_throughput": 3719.2585320020153,
    "total_throughput": 7939.581277505791,
    "itl": 136.50703946199982,
    "ttft": 2077100.2441645355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 320386,
    "finished_requests": 61346,
    "scheduler_time": 26.376704419870617
}
#Debug simulation 
Total elapsed time: 4.531986982095987. Arrivals time: 0.21449047839269042 Scheduler time: 4.1466188984923065 Scheduler overhead time: 0.03854522202163935 Adapter cache time: 0.07484555011615157 Engine time: 0.038944569416344166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7215609876438975,
    "estimated_duration": 3600.214284816406,
    "input_throughput": 4542.359900345196,
    "output_throughput": 4007.6022865777204,
    "total_throughput": 8549.962186922916,
    "itl": 213.9719348874587,
    "ttft": 2022978.2907197895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9671141270827489,
    "arrivals": 319202,
    "finished_requests": 65894,
    "scheduler_time": 41.108387695566186
}
#Debug simulation 
Total elapsed time: 4.721677971072495. Arrivals time: 0.2135396171361208 Scheduler time: 4.392089492641389 Scheduler overhead time: 0.025980559643357992 Adapter cache time: 0.05119833443313837 Engine time: 0.02637479081749916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.573202793020755,
    "estimated_duration": 3600.11486853125,
    "input_throughput": 4241.15995116267,
    "output_throughput": 3756.2498680818458,
    "total_throughput": 7997.409819244516,
    "itl": 134.65386233566144,
    "ttft": 2073945.118381343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.017883518245077,
    "arrivals": 319202,
    "finished_requests": 61482,
    "scheduler_time": 26.42826403609375
}
#Debug simulation 
Total elapsed time: 4.573306351900101. Arrivals time: 0.20324174175038934 Scheduler time: 4.203268482349813 Scheduler overhead time: 0.03910025814548135 Adapter cache time: 0.06932802917435765 Engine time: 0.03937636082991958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.549744116142392,
    "estimated_duration": 3600.130658157183,
    "input_throughput": 4245.185925508354,
    "output_throughput": 3759.42022252268,
    "total_throughput": 8004.606148031034,
    "itl": 135.10499362264343,
    "ttft": 2073590.6100682032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9753896051272785,
    "arrivals": 319202,
    "finished_requests": 61545,
    "scheduler_time": 26.575168277945153
}
#Debug simulation 
Total elapsed time: 4.549826635979116. Arrivals time: 0.20065155485644937 Scheduler time: 4.182763793040067 Scheduler overhead time: 0.03885285323485732 Adapter cache time: 0.0693381717428565 Engine time: 0.03947854321449995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.556143504101783,
    "estimated_duration": 3600.0401752078847,
    "input_throughput": 4245.293179017778,
    "output_throughput": 3759.5158224084134,
    "total_throughput": 8004.809001426192,
    "itl": 135.11961456803533,
    "ttft": 2073654.529187283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9328956920094801,
    "arrivals": 319202,
    "finished_requests": 61547,
    "scheduler_time": 26.582991424506996
}
#Debug simulation 
Total elapsed time: 4.556222340092063. Arrivals time: 0.20308134937658906 Scheduler time: 4.1863820273429155 Scheduler overhead time: 0.03907870780676603 Adapter cache time: 0.06941918842494488 Engine time: 0.03939259750768542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.877294308971614,
    "estimated_duration": 3600.031256931494,
    "input_throughput": 4697.912821572436,
    "output_throughput": 4154.629205288763,
    "total_throughput": 8852.5420268612,
    "itl": 206.75726307754377,
    "ttft": 1988491.4395160538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 315552,
    "finished_requests": 68503,
    "scheduler_time": 42.67406551202022
}
#Debug simulation 
Total elapsed time: 4.87739230832085. Arrivals time: 0.2382836053147912 Scheduler time: 4.527030683588237 Scheduler overhead time: 0.02679743943735957 Adapter cache time: 0.04508868930861354 Engine time: 0.027236214373260736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.682269839104265,
    "estimated_duration": 3600.0874729302127,
    "input_throughput": 4348.082961234048,
    "output_throughput": 3859.0909538906403,
    "total_throughput": 8207.17391512469,
    "itl": 132.1088264248005,
    "ttft": 2047930.7250967363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0412654422200343,
    "arrivals": 315552,
    "finished_requests": 63422,
    "scheduler_time": 27.433689726860187
}
#Debug simulation 
Total elapsed time: 4.682373717892915. Arrivals time: 0.20751470746472478 Scheduler time: 4.317587861791253 Scheduler overhead time: 0.039922100491821766 Adapter cache time: 0.05790348211303353 Engine time: 0.040213839150965214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.671737014316022,
    "estimated_duration": 3600.059498614558,
    "input_throughput": 4345.555679293777,
    "output_throughput": 3856.644315279555,
    "total_throughput": 8202.199994573331,
    "itl": 131.88157279295777,
    "ttft": 2047758.589851583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9975457431469148,
    "arrivals": 315552,
    "finished_requests": 63387,
    "scheduler_time": 27.355897898786484
}
#Debug simulation 
Total elapsed time: 4.671818612143397. Arrivals time: 0.2066148384474218 Scheduler time: 4.307991331443191 Scheduler overhead time: 0.039749613497406244 Adapter cache time: 0.057829617988318205 Engine time: 0.04032528353855014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.561544975265861,
    "estimated_duration": 3600.098029357397,
    "input_throughput": 4191.568084242837,
    "output_throughput": 3724.634410133954,
    "total_throughput": 7916.202494376792,
    "itl": 123.97202832784751,
    "ttft": 2060125.579254464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 315552,
    "finished_requests": 61156,
    "scheduler_time": 23.36782185994403
}
#Debug simulation 
Total elapsed time: 4.561624938156456. Arrivals time: 0.20049719791859388 Scheduler time: 4.201741852797568 Scheduler overhead time: 0.042115533258765936 Adapter cache time: 0.0547020249068737 Engine time: 0.042332401033490896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.916242017876357,
    "estimated_duration": 3600.023045804599,
    "input_throughput": 4808.294219164159,
    "output_throughput": 4215.848845103138,
    "total_throughput": 9024.143064267297,
    "itl": 202.8803734654998,
    "ttft": 1972903.1313007143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456907128752197,
    "arrivals": 314288,
    "finished_requests": 69618,
    "scheduler_time": 43.21415176462823
}
#Debug simulation 
Total elapsed time: 4.916352575179189. Arrivals time: 0.2233421327546239 Scheduler time: 4.586361296009272 Scheduler overhead time: 0.027433845680207014 Adapter cache time: 0.03799291606992483 Engine time: 0.028042704798281193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.707615168299526,
    "estimated_duration": 3600.0849720462006,
    "input_throughput": 4426.703292767581,
    "output_throughput": 3895.671382453141,
    "total_throughput": 8322.374675220723,
    "itl": 130.48840081356363,
    "ttft": 2038647.4410567696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0051061264285874,
    "arrivals": 314288,
    "finished_requests": 64095,
    "scheduler_time": 27.61629620828096
}
#Debug simulation 
Total elapsed time: 4.707737022079527. Arrivals time: 0.20553039759397507 Scheduler time: 4.352156157139689 Scheduler overhead time: 0.04017145885154605 Adapter cache time: 0.04960193717852235 Engine time: 0.04082290455698967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.6804458778351545,
    "estimated_duration": 3600.1334685766783,
    "input_throughput": 4424.328747538697,
    "output_throughput": 3893.695920540963,
    "total_throughput": 8318.02466807966,
    "itl": 130.14345741463856,
    "ttft": 2038629.164348875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9626122133107887,
    "arrivals": 314288,
    "finished_requests": 64061,
    "scheduler_time": 27.494288959796084
}
#Debug simulation 
Total elapsed time: 4.68052544305101. Arrivals time: 0.20565832359716296 Scheduler time: 4.324064210057259 Scheduler overhead time: 0.040452200919389725 Adapter cache time: 0.05025348532944918 Engine time: 0.04063434340059757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.70531767886132,
    "estimated_duration": 3600.0258113635605,
    "input_throughput": 4427.166869107333,
    "output_throughput": 3896.3440083467344,
    "total_throughput": 8323.510877454068,
    "itl": 130.54242819806845,
    "ttft": 2038619.862312824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 314288,
    "finished_requests": 64105,
    "scheduler_time": 27.636196831232713
}
#Debug simulation 
Total elapsed time: 4.7053971332497895. Arrivals time: 0.20933781936764717 Scheduler time: 4.345962988678366 Scheduler overhead time: 0.04023957997560501 Adapter cache time: 0.049957369454205036 Engine time: 0.04059207206591964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.043535204138607,
    "estimated_duration": 3600.1601694262927,
    "input_throughput": 4880.8445105374785,
    "output_throughput": 4336.142078503045,
    "total_throughput": 9216.986589040524,
    "itl": 198.51399700010364,
    "ttft": 1951334.0952784389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9640536393388162,
    "arrivals": 311871,
    "finished_requests": 71393,
    "scheduler_time": 44.63183128851176
}
#Debug simulation 
Total elapsed time: 5.043646023143083. Arrivals time: 0.22749042697250843 Scheduler time: 4.718998947180808 Scheduler overhead time: 0.028368950355798006 Adapter cache time: 0.026851356029510498 Engine time: 0.028424580581486225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.76716442219913,
    "estimated_duration": 3600.0603852801687,
    "input_throughput": 4447.183459883559,
    "output_throughput": 3966.9856812383928,
    "total_throughput": 8414.169141121953,
    "itl": 129.11723383574193,
    "ttft": 2022778.2219448762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0238636188348815,
    "arrivals": 311871,
    "finished_requests": 65098,
    "scheduler_time": 28.361127453630825
}
#Debug simulation 
Total elapsed time: 4.767242429312319. Arrivals time: 0.2086666622199118 Scheduler time: 4.419011964928359 Scheduler overhead time: 0.04060775972902775 Adapter cache time: 0.03830195916816592 Engine time: 0.04096222948282957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.755196807906032,
    "estimated_duration": 3600.029188222931,
    "input_throughput": 4448.513376611069,
    "output_throughput": 3967.8558848160765,
    "total_throughput": 8416.369261427146,
    "itl": 129.23483421134264,
    "ttft": 2022856.1878560898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9817783010355233,
    "arrivals": 311871,
    "finished_requests": 65116,
    "scheduler_time": 28.40557555646131
}
#Debug simulation 
Total elapsed time: 4.755278364289552. Arrivals time: 0.20825919788330793 Scheduler time: 4.408439072780311 Scheduler overhead time: 0.040713288355618715 Adapter cache time: 0.037330010905861855 Engine time: 0.04093634709715843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.810051205102354,
    "estimated_duration": 3600.0863138421482,
    "input_throughput": 4449.36443285019,
    "output_throughput": 3968.7928995100424,
    "total_throughput": 8418.157332360232,
    "itl": 129.2892780356649,
    "ttft": 2022981.654043518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9388757925992844,
    "arrivals": 311871,
    "finished_requests": 65136,
    "scheduler_time": 28.432321027498826
}
#Debug simulation 
Total elapsed time: 4.810145372059196. Arrivals time: 0.23113239789381623 Scheduler time: 4.4394845981150866 Scheduler overhead time: 0.04052682127803564 Adapter cache time: 0.038785767275840044 Engine time: 0.04076745314523578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.407768003642559,
    "estimated_duration": 3600.007923987638,
    "input_throughput": 3090.0437540365256,
    "output_throughput": 2717.9792952126845,
    "total_throughput": 5808.02304924921,
    "itl": 313.0582058157926,
    "ttft": 2181805.887374451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 211085,
    "finished_requests": 45036,
    "scheduler_time": 28.320677172096012
}
#Debug simulation 
Total elapsed time: 3.407846367917955. Arrivals time: 0.17590991454198956 Scheduler time: 3.072458495385945 Scheduler overhead time: 0.01847054809331894 Adapter cache time: 0.11336368415504694 Engine time: 0.018881438300013542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.620184547267854,
    "estimated_duration": 3600.142985864397,
    "input_throughput": 3088.2451179450945,
    "output_throughput": 2730.0349009999572,
    "total_throughput": 5818.280018945052,
    "itl": 184.71731881587584,
    "ttft": 2193338.8293914776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149365,
    "arrivals": 211085,
    "finished_requests": 45017,
    "scheduler_time": 19.82126628646625
}
#Debug simulation 
Total elapsed time: 3.620259551331401. Arrivals time: 0.16906982706859708 Scheduler time: 3.1809665276668966 Scheduler overhead time: 0.0294262133538723 Adapter cache time: 0.1967190159484744 Engine time: 0.02999252127483487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.592955448664725,
    "estimated_duration": 3600.1289718892967,
    "input_throughput": 3091.817567346383,
    "output_throughput": 2733.9042786666732,
    "total_throughput": 5825.721846013056,
    "itl": 185.54031507633408,
    "ttft": 2192217.589234264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 211085,
    "finished_requests": 45075,
    "scheduler_time": 19.962243838207684
}
#Debug simulation 
Total elapsed time: 3.59303463390097. Arrivals time: 0.16878404701128602 Scheduler time: 3.1548602301627398 Scheduler overhead time: 0.029139547608792782 Adapter cache time: 0.1959834387525916 Engine time: 0.030276221688836813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.5960080069489777,
    "estimated_duration": 3600.031675962615,
    "input_throughput": 3091.900016969626,
    "output_throughput": 2733.776501388262,
    "total_throughput": 5825.676518357888,
    "itl": 185.29689780842713,
    "ttft": 2192179.015130482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 211085,
    "finished_requests": 45073,
    "scheduler_time": 19.934913742335404
}
#Debug simulation 
Total elapsed time: 3.59608484338969. Arrivals time: 0.16920835338532925 Scheduler time: 3.157327627297491 Scheduler overhead time: 0.029313895851373672 Adapter cache time: 0.19621960585936904 Engine time: 0.02989885490387678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.5410356409847736,
    "estimated_duration": 3600.1817247355143,
    "input_throughput": 3285.8988530277798,
    "output_throughput": 2871.7700356527257,
    "total_throughput": 6157.668888680506,
    "itl": 295.0143658313676,
    "ttft": 2128250.3065672885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 201527,
    "finished_requests": 47718,
    "scheduler_time": 29.958473225954368
}
#Debug simulation 
Total elapsed time: 3.5411406327039003. Arrivals time: 0.17278197035193443 Scheduler time: 3.2160022421739995 Scheduler overhead time: 0.019529630430042744 Adapter cache time: 0.10368147818371654 Engine time: 0.019868209026753902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7338226321153343,
    "estimated_duration": 3600.004921596211,
    "input_throughput": 3258.526656346543,
    "output_throughput": 2861.7708098665626,
    "total_throughput": 6120.2974662131055,
    "itl": 176.40412058246537,
    "ttft": 2144473.3819878255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149365,
    "arrivals": 201527,
    "finished_requests": 47291,
    "scheduler_time": 20.884748904853847
}
#Debug simulation 
Total elapsed time: 3.7339187283068895. Arrivals time: 0.1781536261551082 Scheduler time: 3.295288395602256 Scheduler overhead time: 0.030564407352358103 Adapter cache time: 0.18375226948410273 Engine time: 0.03139164065942168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.7218991848640144,
    "estimated_duration": 3600.1215881233506,
    "input_throughput": 3258.5252227870196,
    "output_throughput": 2861.74167949991,
    "total_throughput": 6120.2669022869295,
    "itl": 176.78019857610553,
    "ttft": 2144131.2715870384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 201527,
    "finished_requests": 47294,
    "scheduler_time": 20.938895308085115
}
#Debug simulation 
Total elapsed time: 3.7219760790467262. Arrivals time: 0.17079468816518784 Scheduler time: 3.293324827682227 Scheduler overhead time: 0.030704866629093885 Adapter cache time: 0.18152117729187012 Engine time: 0.030965870711952448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7162269870750606,
    "estimated_duration": 3600.136729476513,
    "input_throughput": 3251.5342831721105,
    "output_throughput": 2855.257389486618,
    "total_throughput": 6106.791672658728,
    "itl": 177.26470106932743,
    "ttft": 2144907.5528667346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 201527,
    "finished_requests": 47191,
    "scheduler_time": 20.90942367520135
}
#Debug simulation 
Total elapsed time: 3.7163319420069456. Arrivals time: 0.17995048919692636 Scheduler time: 3.2793446546420455 Scheduler overhead time: 0.030408477410674095 Adapter cache time: 0.1811665492132306 Engine time: 0.030842242762446404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6856225333176553,
    "estimated_duration": 3600.1134600192013,
    "input_throughput": 3411.371929354276,
    "output_throughput": 3016.154663065004,
    "total_throughput": 6427.52659241928,
    "itl": 282.8844350103888,
    "ttft": 2087224.333310672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 196873,
    "finished_requests": 49835,
    "scheduler_time": 31.597617388030486
}
#Debug simulation 
Total elapsed time: 3.6856988263316453. Arrivals time: 0.17654299503192306 Scheduler time: 3.370812227483839 Scheduler overhead time: 0.020208087749779224 Adapter cache time: 0.08797695906832814 Engine time: 0.020526951178908348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.825153809040785,
    "estimated_duration": 3600.0315499154935,
    "input_throughput": 3341.784601938392,
    "output_throughput": 2967.434271583194,
    "total_throughput": 6309.218873521586,
    "itl": 170.89605807298364,
    "ttft": 2114047.721181932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149365,
    "arrivals": 196873,
    "finished_requests": 48787,
    "scheduler_time": 21.822302198454896
}
#Debug simulation 
Total elapsed time: 3.8252293900586665. Arrivals time: 0.18207947351038456 Scheduler time: 3.4013599161989987 Scheduler overhead time: 0.031561494804918766 Adapter cache time: 0.16300001228228211 Engine time: 0.03203222109004855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.785326160956174,
    "estimated_duration": 3600.0731289033297,
    "input_throughput": 3341.7687833649143,
    "output_throughput": 2967.2252805748053,
    "total_throughput": 6308.99406393972,
    "itl": 170.89048865120947,
    "ttft": 2114114.441835673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.000535793441817,
    "arrivals": 196873,
    "finished_requests": 48786,
    "scheduler_time": 21.823129961641904
}
#Debug simulation 
Total elapsed time: 3.7854005321860313. Arrivals time: 0.173295927233994 Scheduler time: 3.3721484397538006 Scheduler overhead time: 0.03135288693010807 Adapter cache time: 0.16161708533763885 Engine time: 0.031992956064641476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.7906019808724523,
    "estimated_duration": 3600.1743825249077,
    "input_throughput": 3341.206486660172,
    "output_throughput": 2966.6537965056773,
    "total_throughput": 6307.860283165849,
    "itl": 170.44800719588508,
    "ttft": 2114273.238330934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 196873,
    "finished_requests": 48775,
    "scheduler_time": 21.752157693615953
}
#Debug simulation 
Total elapsed time: 3.7907107532955706. Arrivals time: 0.1815304826013744 Scheduler time: 3.3691709195263684 Scheduler overhead time: 0.03148346999660134 Adapter cache time: 0.16137672495096922 Engine time: 0.032088205218315125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.8032268271781504,
    "estimated_duration": 3600.103063016102,
    "input_throughput": 3522.0519463065402,
    "output_throughput": 3107.7538070887053,
    "total_throughput": 6629.805753395245,
    "itl": 274.66315418522396,
    "ttft": 2058033.730196088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 194481,
    "finished_requests": 51334,
    "scheduler_time": 32.53222404861086
}
#Debug simulation 
Total elapsed time: 3.80330412928015. Arrivals time: 0.19018933456391096 Scheduler time: 3.487932506483048 Scheduler overhead time: 0.020789190661162138 Adapter cache time: 0.07331565441563725 Engine time: 0.02112378040328622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8586862827651203,
    "estimated_duration": 3600.1787699907945,
    "input_throughput": 3398.0543138504427,
    "output_throughput": 3019.6158842489363,
    "total_throughput": 6417.6701980993785,
    "itl": 167.770444165289,
    "ttft": 2093166.0089581418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0408568469015935,
    "arrivals": 194481,
    "finished_requests": 49582,
    "scheduler_time": 22.241876978646992
}
#Debug simulation 
Total elapsed time: 3.8587634339928627. Arrivals time: 0.17612910363823175 Scheduler time: 3.458643336314708 Scheduler overhead time: 0.03212268091738224 Adapter cache time: 0.1435644687153399 Engine time: 0.03298106137663126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.829577629920095,
    "estimated_duration": 3600.131568472057,
    "input_throughput": 3404.356970543069,
    "output_throughput": 3023.778935007134,
    "total_throughput": 6428.1359055502035,
    "itl": 167.6368853964989,
    "ttft": 2093215.5240156886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9971371478284744,
    "arrivals": 194481,
    "finished_requests": 49652,
    "scheduler_time": 22.271991956253757
}
#Debug simulation 
Total elapsed time: 3.8296556370332837. Arrivals time: 0.17415178660303354 Scheduler time: 3.4308043429628015 Scheduler overhead time: 0.03207044955343008 Adapter cache time: 0.14471990428864956 Engine time: 0.032507193740457296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.820386097766459,
    "estimated_duration": 3600.044576639588,
    "input_throughput": 3405.3797776702754,
    "output_throughput": 3024.591159413885,
    "total_throughput": 6429.97093708416,
    "itl": 167.71872363215,
    "ttft": 2093186.477087495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 194481,
    "finished_requests": 49663,
    "scheduler_time": 22.292331110238234
}
#Debug simulation 
Total elapsed time: 3.8205212499015033. Arrivals time: 0.17528066970407963 Scheduler time: 3.4220329844392836 Scheduler overhead time: 0.03198076086118817 Adapter cache time: 0.14357865089550614 Engine time: 0.03234674781560898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.777670744806528,
    "estimated_duration": 3600.307046104111,
    "input_throughput": 3578.285917013829,
    "output_throughput": 3133.4882985071295,
    "total_throughput": 6711.774215520959,
    "itl": 270.92417139997195,
    "ttft": 2048887.3836230615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9762955903145472,
    "arrivals": 193337,
    "finished_requests": 51854,
    "scheduler_time": 32.77567688734237
}
#Debug simulation 
Total elapsed time: 3.7777500157244503. Arrivals time: 0.18164839455857873 Scheduler time: 3.4794149133376777 Scheduler overhead time: 0.020903611090034246 Adapter cache time: 0.06411509774625301 Engine time: 0.021695815958082676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.83713595289737,
    "estimated_duration": 3600.097953836902,
    "input_throughput": 3441.9863456196895,
    "output_throughput": 3028.3617667626163,
    "total_throughput": 6470.348112382306,
    "itl": 166.8516731753564,
    "ttft": 2089450.8087334053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0374582012882514,
    "arrivals": 193337,
    "finished_requests": 49854,
    "scheduler_time": 22.25143033537616
}
#Debug simulation 
Total elapsed time: 3.8372134338133037. Arrivals time: 0.17431837087497115 Scheduler time: 3.4502207045443356 Scheduler overhead time: 0.03193590650334954 Adapter cache time: 0.13284460082650185 Engine time: 0.03246700298041105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.8362815100699663,
    "estimated_duration": 3600.0545096801943,
    "input_throughput": 3441.5159455740063,
    "output_throughput": 3028.2730360570176,
    "total_throughput": 6469.788981631024,
    "itl": 166.68158755022236,
    "ttft": 2089581.2066596323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9941470975335721,
    "arrivals": 193337,
    "finished_requests": 49849,
    "scheduler_time": 22.22074487047422
}
#Debug simulation 
Total elapsed time: 3.8363548978231847. Arrivals time: 0.17666785512119532 Scheduler time: 3.446080301422626 Scheduler overhead time: 0.032267951872199774 Adapter cache time: 0.1330346711911261 Engine time: 0.032863070257008076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.829487271141261,
    "estimated_duration": 3600.1120969563653,
    "input_throughput": 3441.6014463757883,
    "output_throughput": 3028.273205497395,
    "total_throughput": 6469.874651873183,
    "itl": 166.8182649804722,
    "ttft": 2089425.7915157059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9508359937788932,
    "arrivals": 193337,
    "finished_requests": 49851,
    "scheduler_time": 22.242802005318808
}
#Debug simulation 
Total elapsed time: 3.8295897278003395. Arrivals time: 0.174760268535465 Scheduler time: 3.4436304410919547 Scheduler overhead time: 0.03211844898760319 Adapter cache time: 0.1308953738771379 Engine time: 0.03273492446169257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.73825798695907,
    "estimated_duration": 3600.2081843034252,
    "input_throughput": 3431.311015251793,
    "output_throughput": 3046.988518004954,
    "total_throughput": 6478.299533256747,
    "itl": 281.09137947152175,
    "ttft": 2060529.2988879597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 182454,
    "finished_requests": 50269,
    "scheduler_time": 32.021274578883855
}
#Debug simulation 
Total elapsed time: 3.738337714225054. Arrivals time: 0.17949488013982773 Scheduler time: 3.3936913069337606 Scheduler overhead time: 0.020428224932402372 Adapter cache time: 0.11387167777866125 Engine time: 0.021080831065773964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8929973421618342,
    "estimated_duration": 3600.046828671701,
    "input_throughput": 3422.6240897389293,
    "output_throughput": 3056.1583011572916,
    "total_throughput": 6478.782390896221,
    "itl": 166.3006281419731,
    "ttft": 2071387.6437542927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0442554925149363,
    "arrivals": 182454,
    "finished_requests": 50162,
    "scheduler_time": 22.67771163116929
}
#Debug simulation 
Total elapsed time: 3.8930737148039043. Arrivals time: 0.1781209260225296 Scheduler time: 3.465587774757296 Scheduler overhead time: 0.03233433747664094 Adapter cache time: 0.1686292546801269 Engine time: 0.0328977657482028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.9000567994080484,
    "estimated_duration": 3600.0850491726437,
    "input_throughput": 3423.6105068774823,
    "output_throughput": 3057.020834140917,
    "total_throughput": 6480.631341018399,
    "itl": 166.5471377832682,
    "ttft": 2071317.6592128822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 182454,
    "finished_requests": 50175,
    "scheduler_time": 22.7227054833846
}
#Debug simulation 
Total elapsed time: 3.9001593003049493. Arrivals time: 0.17636769590899348 Scheduler time: 3.4754957580007613 Scheduler overhead time: 0.03230300173163414 Adapter cache time: 0.16752678994089365 Engine time: 0.03294821549206972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9211347210220993,
    "estimated_duration": 3600.0742928655636,
    "input_throughput": 3423.060469730196,
    "output_throughput": 3056.6960859135056,
    "total_throughput": 6479.756555643702,
    "itl": 166.23013687160324,
    "ttft": 2071290.3637813812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 182454,
    "finished_requests": 50168,
    "scheduler_time": 22.66912043927441
}
#Debug simulation 
Total elapsed time: 3.9212380358949304. Arrivals time: 0.17665323708206415 Scheduler time: 3.491253379266709 Scheduler overhead time: 0.03249863348901272 Adapter cache time: 0.1718319426290691 Engine time: 0.0332821668125689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9154194411821663,
    "estimated_duration": 3600.1209352677843,
    "input_throughput": 3659.177632325879,
    "output_throughput": 3195.446543837925,
    "total_throughput": 6854.624176163804,
    "itl": 265.51139856780327,
    "ttft": 2010878.338590379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 177727,
    "finished_requests": 52903,
    "scheduler_time": 33.50285036490522
}
#Debug simulation 
Total elapsed time: 3.9155337777920067. Arrivals time: 0.1861144695430994 Scheduler time: 3.574941218830645 Scheduler overhead time: 0.021560631226748228 Adapter cache time: 0.10055122571066022 Engine time: 0.021978256292641163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.020364997908473,
    "estimated_duration": 3600.0347376360733,
    "input_throughput": 3610.4846056388114,
    "output_throughput": 3169.131086632679,
    "total_throughput": 6779.61569227149,
    "itl": 159.04051245120496,
    "ttft": 2030583.0772395635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 177727,
    "finished_requests": 52209,
    "scheduler_time": 23.461915095833326
}
#Debug simulation 
Total elapsed time: 4.020442434120923. Arrivals time: 0.18134603882208467 Scheduler time: 3.6017619501799345 Scheduler overhead time: 0.03367696702480316 Adapter cache time: 0.15315503953024745 Engine time: 0.03425442101433873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.007071326021105,
    "estimated_duration": 3600.091478827849,
    "input_throughput": 3609.9391019450964,
    "output_throughput": 3168.55198460513,
    "total_throughput": 6778.491086550227,
    "itl": 158.90906627112705,
    "ttft": 2030720.4759407702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 177727,
    "finished_requests": 52200,
    "scheduler_time": 23.434025771486997
}
#Debug simulation 
Total elapsed time: 4.007149404846132. Arrivals time: 0.18152553122490644 Scheduler time: 3.589903147891164 Scheduler overhead time: 0.0336527219042182 Adapter cache time: 0.15166948549449444 Engine time: 0.0342321814969182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.039092129096389,
    "estimated_duration": 3600.0346610040565,
    "input_throughput": 3610.4535716816963,
    "output_throughput": 3168.91921168843,
    "total_throughput": 6779.372783370127,
    "itl": 158.98665327594384,
    "ttft": 2030610.6254472807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 177727,
    "finished_requests": 52206,
    "scheduler_time": 23.449968514102366
}
#Debug simulation 
Total elapsed time: 4.039166762959212. Arrivals time: 0.18061798345297575 Scheduler time: 3.6211807248182595 Scheduler overhead time: 0.03386765392497182 Adapter cache time: 0.15306543558835983 Engine time: 0.03423256753012538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.024904912803322,
    "estimated_duration": 3600.2511898342314,
    "input_throughput": 3777.8072370073273,
    "output_throughput": 3323.5347671813247,
    "total_throughput": 7101.342004188652,
    "itl": 256.48997867456575,
    "ttft": 1970101.2332005005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9793560780584799,
    "arrivals": 175481,
    "finished_requests": 54981,
    "scheduler_time": 34.9342090194581
}
#Debug simulation 
Total elapsed time: 4.024980315007269. Arrivals time: 0.18900737632066011 Scheduler time: 3.693242731038481 Scheduler overhead time: 0.022343916818499565 Adapter cache time: 0.08712130878120661 Engine time: 0.022583651822060347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.336775780189782,
    "estimated_duration": 3600.0830491087336,
    "input_throughput": 3674.7480042926177,
    "output_throughput": 3249.2814305758793,
    "total_throughput": 6924.0294348684965,
    "itl": 155.52393421775557,
    "ttft": 2000985.8977974183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.044255492514936,
    "arrivals": 175481,
    "finished_requests": 53491,
    "scheduler_time": 24.21888224944484
}
#Debug simulation 
Total elapsed time: 4.33687280677259. Arrivals time: 0.18807607842609286 Scheduler time: 3.9263404072262347 Scheduler overhead time: 0.034673772752285004 Adapter cache time: 0.1361595676280558 Engine time: 0.03500659018754959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.112992885988206,
    "estimated_duration": 3600.092714964102,
    "input_throughput": 3674.654251267502,
    "output_throughput": 3249.2040972663226,
    "total_throughput": 6923.858348533825,
    "itl": 155.51955517109255,
    "ttft": 2000942.1515358805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0005357934418169,
    "arrivals": 175481,
    "finished_requests": 53490,
    "scheduler_time": 24.22072001754778
}
#Debug simulation 
Total elapsed time: 4.113068149890751. Arrivals time: 0.1868651513941586 Scheduler time: 3.70117260562256 Scheduler overhead time: 0.03453919803723693 Adapter cache time: 0.13858211785554886 Engine time: 0.03534002369269729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.08287226036191,
    "estimated_duration": 3600.0725371805315,
    "input_throughput": 3675.298723386943,
    "output_throughput": 3249.6667439824237,
    "total_throughput": 6924.965467369367,
    "itl": 155.7027203268144,
    "ttft": 2000781.7882729291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9568160943686975,
    "arrivals": 175481,
    "finished_requests": 53498,
    "scheduler_time": 24.25649936667234
}
#Debug simulation 
Total elapsed time: 4.082948086317629. Arrivals time: 0.18290527071803808 Scheduler time: 3.6777835465036333 Scheduler overhead time: 0.03440044308081269 Adapter cache time: 0.13660834589973092 Engine time: 0.03470581956207752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.08592680003494,
    "estimated_duration": 3600.1496534798735,
    "input_throughput": 3845.3259815515594,
    "output_throughput": 3398.590941399709,
    "total_throughput": 7243.916922951268,
    "itl": 251.52935593493336,
    "ttft": 1949547.7372514303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9609931515948834,
    "arrivals": 174302,
    "finished_requests": 56142,
    "scheduler_time": 35.79662658364417
}
#Debug simulation 
Total elapsed time: 4.086004794109613. Arrivals time: 0.18990764394402504 Scheduler time: 3.761451662518084 Scheduler overhead time: 0.0225955406203866 Adapter cache time: 0.07815624214708805 Engine time: 0.02308802120387554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.131442581769079,
    "estimated_duration": 3600.0739285427644,
    "input_throughput": 3726.8215226432467,
    "output_throughput": 3306.5751526992835,
    "total_throughput": 7033.39667534253,
    "itl": 152.62089933474817,
    "ttft": 1987145.1151249527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0199264948372788,
    "arrivals": 174302,
    "finished_requests": 54365,
    "scheduler_time": 24.60045543023368
}
#Debug simulation 
Total elapsed time: 4.13154814671725. Arrivals time: 0.1850148532539606 Scheduler time: 3.731967497151345 Scheduler overhead time: 0.03516365913674235 Adapter cache time: 0.1265829117037356 Engine time: 0.0359761300496757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.161192357074469,
    "estimated_duration": 3600.1661046309546,
    "input_throughput": 3727.116085766125,
    "output_throughput": 3306.814367449961,
    "total_throughput": 7033.930453216086,
    "itl": 152.61473691798656,
    "ttft": 1987058.0519295465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9766153910825995,
    "arrivals": 174302,
    "finished_requests": 54368,
    "scheduler_time": 24.601930789483006
}
#Debug simulation 
Total elapsed time: 4.16129555599764. Arrivals time: 0.18583278264850378 Scheduler time: 3.761891341302544 Scheduler overhead time: 0.03500526491552591 Adapter cache time: 0.12628943985328078 Engine time: 0.03543684259057045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_320_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.13482046732679,
    "estimated_duration": 3600.134261142896,
    "input_throughput": 3727.1318308390746,
    "output_throughput": 3306.5583493602676,
    "total_throughput": 7033.690180199342,
    "itl": 152.61546445992013,
    "ttft": 1987160.8776957593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9328956920094801,
    "arrivals": 174302,
    "finished_requests": 54367,
    "scheduler_time": 24.601857655306958
}
#Debug simulation 
Total elapsed time: 4.134896552190185. Arrivals time: 0.1856635925360024 Scheduler time: 3.737556667998433 Scheduler overhead time: 0.03511940874159336 Adapter cache time: 0.12415482057258487 Engine time: 0.03561417106539011 
