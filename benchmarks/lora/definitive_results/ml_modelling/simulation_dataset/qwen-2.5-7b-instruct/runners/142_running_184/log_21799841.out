INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 135, 8640, 135, 34560, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 8640, 34560, 135, 34560, 34560, 8640, 8640, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 135, 135, 34560, 8640, 135, 8640, 8640, 34560, 8640, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 34560, 135, 34560, 135, 8640, 34560, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 135, 135, 135, 34560, 8640, 135, 34560, 135, 34560, 135, 135, 8640, 8640, 34560, 8640, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 8640, 8640, 34560, 135, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 135, 135, 135, 135]
Prompts retrieved: 3718035 . Total input tokens: 828563720 . Total output tokens: 743735295
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 29.899091478902847,
    "estimated_duration": 3600.157911194525,
    "input_throughput": 5351.3247127562,
    "output_throughput": 4707.960155663345,
    "total_throughput": 10059.284868419545,
    "itl": 180.07288654610903,
    "ttft": 2152817.4100307953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5577251366898455,
    "arrivals": 1238735,
    "finished_requests": 77605,
    "scheduler_time": 123.33388840902346
}
#Debug simulation 
Total elapsed time: 29.899264399893582. Arrivals time: 0.3508418798446655 Scheduler time: 29.420898655429482 Scheduler overhead time: 0.0461526527069509 Adapter cache time: 0.015446315985172987 Engine time: 0.04803649475798011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 135, 8640, 135, 34560, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 8640, 34560, 135, 34560, 34560, 8640, 8640, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 135, 135, 34560, 8640, 135, 8640, 8640, 34560, 8640, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 34560, 135, 34560, 135, 8640, 34560, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 135, 135, 135, 34560, 8640, 135, 34560, 135, 34560, 135, 135, 8640, 8640, 34560, 8640, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 8640, 8640, 34560, 135, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 135, 135, 135, 135]
Prompts retrieved: 3718035 . Total input tokens: 828563720 . Total output tokens: 743735295
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 35.39744007401168,
    "estimated_duration": 3600.1434835813416,
    "input_throughput": 5350.994505595721,
    "output_throughput": 4707.081003100003,
    "total_throughput": 10058.075508695725,
    "itl": 182.39723383846828,
    "ttft": 2148449.563919407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9627961949585019,
    "arrivals": 1238735,
    "finished_requests": 77568,
    "scheduler_time": 122.66311704913669
}
#Debug simulation 
Total elapsed time: 35.3975802436471. Arrivals time: 0.3685048623010516 Scheduler time: 34.89631688082591 Scheduler overhead time: 0.04973047226667404 Adapter cache time: 0.013427800498902798 Engine time: 0.0506182792596519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 135, 8640, 135, 34560, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 8640, 34560, 135, 34560, 34560, 8640, 8640, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 135, 135, 34560, 8640, 135, 8640, 8640, 34560, 8640, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 34560, 135, 34560, 135, 8640, 34560, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 135, 135, 135, 34560, 8640, 135, 34560, 135, 34560, 135, 135, 8640, 8640, 34560, 8640, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 135, 8640, 34560, 8640, 8640, 34560, 135, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 135, 135, 135, 135]
Prompts retrieved: 3718035 . Total input tokens: 828563720 . Total output tokens: 743735295
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 30.281227835919708,
    "estimated_duration": 3600.178630062483,
    "input_throughput": 5351.2939161203885,
    "output_throughput": 4707.933061561957,
    "total_throughput": 10059.226977682345,
    "itl": 180.07375737292702,
    "ttft": 2152824.445529099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5783487576618775,
    "arrivals": 1238735,
    "finished_requests": 77605,
    "scheduler_time": 123.33398365603544
}
#Debug simulation 
Total elapsed time: 30.281376582104713. Arrivals time: 0.3682124391198158 Scheduler time: 29.78126813378185 Scheduler overhead time: 0.04770436370745301 Adapter cache time: 0.015860530082136393 Engine time: 0.05009886063635349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 33.26550654694438,
    "estimated_duration": 3600.017315322168,
    "input_throughput": 5358.2447834070335,
    "output_throughput": 4732.123628265233,
    "total_throughput": 10090.368411672265,
    "itl": 181.92697072183168,
    "ttft": 2146652.0344383363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4384292396484082,
    "arrivals": 1236839,
    "finished_requests": 77961,
    "scheduler_time": 123.17332201462177
}
#Debug simulation 
Total elapsed time: 33.26567728864029. Arrivals time: 0.5084782890044153 Scheduler time: 32.62869046954438 Scheduler overhead time: 0.04698216076940298 Adapter cache time: 0.014741221442818642 Engine time: 0.04854516591876745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 33.45614433987066,
    "estimated_duration": 3600.0941169030425,
    "input_throughput": 5366.518588858416,
    "output_throughput": 4741.341877662836,
    "total_throughput": 10107.860466521252,
    "itl": 181.6772999004347,
    "ttft": 2147971.1334520793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5435397931817045,
    "arrivals": 1236839,
    "finished_requests": 78127,
    "scheduler_time": 123.3855666140941
}
#Debug simulation 
Total elapsed time: 33.45631703082472. Arrivals time: 0.5120233879424632 Scheduler time: 32.81255391892046 Scheduler overhead time: 0.04802593123167753 Adapter cache time: 0.015004269778728485 Engine time: 0.05022316053509712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.81263618823141,
    "estimated_duration": 3600.115669962936,
    "input_throughput": 5350.996125132371,
    "output_throughput": 4721.010255810747,
    "total_throughput": 10072.006380943118,
    "itl": 179.52654350389344,
    "ttft": 2148180.635045481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8004114686697832,
    "arrivals": 1236839,
    "finished_requests": 77844,
    "scheduler_time": 123.71597877626644
}
#Debug simulation 
Total elapsed time: 24.812793099321425. Arrivals time: 0.4987798114307225 Scheduler time: 24.190831108484417 Scheduler overhead time: 0.04427547613158822 Adapter cache time: 0.015773227903991938 Engine time: 0.045702561270445585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 33.565832211170346,
    "estimated_duration": 3600.0501251653736,
    "input_throughput": 5358.195949872752,
    "output_throughput": 4732.080501022868,
    "total_throughput": 10090.27645089562,
    "itl": 181.9284032649673,
    "ttft": 2146662.9691480435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4711074848729153,
    "arrivals": 1236839,
    "finished_requests": 77961,
    "scheduler_time": 123.17345361255458
}
#Debug simulation 
Total elapsed time: 33.56597562413663. Arrivals time: 0.6012556562200189 Scheduler time: 32.83438620250672 Scheduler overhead time: 0.04782106028869748 Adapter cache time: 0.015607739798724651 Engine time: 0.04883504146710038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 24.55082063889131,
    "estimated_duration": 3600.1380269232263,
    "input_throughput": 5350.962895293129,
    "output_throughput": 4720.980938201803,
    "total_throughput": 10071.943833494932,
    "itl": 179.52749479052954,
    "ttft": 2148188.458168869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8226698888652069,
    "arrivals": 1236839,
    "finished_requests": 77844,
    "scheduler_time": 123.71607731639321
}
#Debug simulation 
Total elapsed time: 24.550918984692544. Arrivals time: 0.4903199574910104 Scheduler time: 23.9406925952062 Scheduler overhead time: 0.043397240806370974 Adapter cache time: 0.015061771497130394 Engine time: 0.044134028255939484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 33.31574885174632,
    "estimated_duration": 3600.166766310025,
    "input_throughput": 5358.5476041080465,
    "output_throughput": 4732.13745524946,
    "total_throughput": 10090.685059357507,
    "itl": 181.92326578122993,
    "ttft": 2146752.0726643438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4053236386040096,
    "arrivals": 1236839,
    "finished_requests": 77967,
    "scheduler_time": 123.18010122244286
}
#Debug simulation 
Total elapsed time: 33.31586845358834. Arrivals time: 0.5036763278767467 Scheduler time: 32.68347877729684 Scheduler overhead time: 0.04760590801015496 Adapter cache time: 0.015050551854074001 Engine time: 0.04818019922822714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 66, 8640, 66, 34560, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 8640, 34560, 66, 34560, 34560, 8640, 8640, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 66, 66, 34560, 8640, 66, 8640, 8640, 34560, 8640, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 34560, 66, 34560, 66, 8640, 34560, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 66, 66, 66, 34560, 8640, 66, 34560, 66, 34560, 66, 66, 8640, 8640, 34560, 8640, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 66, 8640, 34560, 8640, 8640, 34560, 66, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 66, 66, 66, 66]
Prompts retrieved: 3712170 . Total input tokens: 827267384 . Total output tokens: 742547406
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.7934439368546,
    "estimated_duration": 3600.161886849355,
    "input_throughput": 5350.927432004696,
    "output_throughput": 4720.949650093106,
    "total_throughput": 10071.877082097802,
    "itl": 179.52853897988643,
    "ttft": 2148196.7096679267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8464373544976074,
    "arrivals": 1236839,
    "finished_requests": 77844,
    "scheduler_time": 123.7161697769235
}
#Debug simulation 
Total elapsed time: 24.79360536672175. Arrivals time: 0.35866395849734545 Scheduler time: 24.311947803013027 Scheduler overhead time: 0.04440283216536045 Adapter cache time: 0.015585323795676231 Engine time: 0.04539807606488466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 26.284350486006588,
    "estimated_duration": 3600.1357781853167,
    "input_throughput": 5354.352776582347,
    "output_throughput": 4736.453581368857,
    "total_throughput": 10090.806357951204,
    "itl": 181.47866739028083,
    "ttft": 2144217.3742656535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 1235881,
    "finished_requests": 78328,
    "scheduler_time": 123.29859513819386
}
#Debug simulation 
Total elapsed time: 26.284519128035754. Arrivals time: 0.3779094028286636 Scheduler time: 25.783496894408017 Scheduler overhead time: 0.04508634703233838 Adapter cache time: 0.01446525938808918 Engine time: 0.04600917315110564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.787717312108725,
    "estimated_duration": 3600.097735170515,
    "input_throughput": 5353.758541526679,
    "output_throughput": 4737.494994477473,
    "total_throughput": 10091.253536004153,
    "itl": 181.49324271064103,
    "ttft": 2144179.66290885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6336688434681903,
    "arrivals": 1235881,
    "finished_requests": 78333,
    "scheduler_time": 123.29787105297606
}
#Debug simulation 
Total elapsed time: 26.78785728989169. Arrivals time: 0.3832392003387213 Scheduler time: 26.280389117076993 Scheduler overhead time: 0.04550428269430995 Adapter cache time: 0.014848993625491858 Engine time: 0.04624429950490594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.51084047695622,
    "estimated_duration": 3600.013090878187,
    "input_throughput": 5342.675294357925,
    "output_throughput": 4724.422542544442,
    "total_throughput": 10067.097836902367,
    "itl": 180.16989633187785,
    "ttft": 2144359.3983102567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6793700839020413,
    "arrivals": 1235881,
    "finished_requests": 78164,
    "scheduler_time": 123.48297488525293
}
#Debug simulation 
Total elapsed time: 26.51097649615258. Arrivals time: 0.47043830482289195 Scheduler time: 25.915749365929514 Scheduler overhead time: 0.04547125333920121 Adapter cache time: 0.015111227054148912 Engine time: 0.04650948103517294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 27.77852136362344,
    "estimated_duration": 3600.0047162164583,
    "input_throughput": 5376.39517882127,
    "output_throughput": 4751.118497971318,
    "total_throughput": 10127.513676792587,
    "itl": 180.84843763850552,
    "ttft": 2147659.1522286446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5116125199804025,
    "arrivals": 1235881,
    "finished_requests": 78599,
    "scheduler_time": 123.67428366450356
}
#Debug simulation 
Total elapsed time: 27.7786304759793. Arrivals time: 0.38227281253784895 Scheduler time: 27.272110738791525 Scheduler overhead time: 0.04546225303784013 Adapter cache time: 0.01463868748396635 Engine time: 0.04684698302298784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 26.413486787118018,
    "estimated_duration": 3600.033824185185,
    "input_throughput": 5342.644524833949,
    "output_throughput": 4724.3953336603745,
    "total_throughput": 10067.039858494323,
    "itl": 180.1707663018464,
    "ttft": 2144366.56116984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.699993704874072,
    "arrivals": 1235881,
    "finished_requests": 78164,
    "scheduler_time": 123.48308457130665
}
#Debug simulation 
Total elapsed time: 26.41358930710703. Arrivals time: 0.36407598946243525 Scheduler time: 25.924156203866005 Scheduler overhead time: 0.04501091409474611 Adapter cache time: 0.01534635853022337 Engine time: 0.04719790117815137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 26.410168282222003,
    "estimated_duration": 3600.099822946092,
    "input_throughput": 5354.406252053707,
    "output_throughput": 4736.500885702062,
    "total_throughput": 10090.907137755768,
    "itl": 181.4771244555597,
    "ttft": 2144204.9112270135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5189455498102882,
    "arrivals": 1235881,
    "finished_requests": 78328,
    "scheduler_time": 123.29842212300983
}
#Debug simulation 
Total elapsed time: 26.4102713172324. Arrivals time: 0.3532801545225084 Scheduler time: 25.936118830461055 Scheduler overhead time: 0.04421897046267986 Adapter cache time: 0.014673442114144564 Engine time: 0.04441124480217695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 33, 8640, 33, 34560, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 8640, 34560, 33, 34560, 34560, 8640, 8640, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 33, 33, 34560, 8640, 33, 8640, 8640, 34560, 8640, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 34560, 33, 34560, 33, 8640, 34560, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 33, 33, 33, 34560, 8640, 33, 34560, 33, 34560, 33, 33, 8640, 8640, 34560, 8640, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 33, 8640, 34560, 8640, 8640, 34560, 33, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 33, 33, 33, 33]
Prompts retrieved: 3709365 . Total input tokens: 826642015 . Total output tokens: 741985016
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.35159431491047,
    "estimated_duration": 3600.0561749392214,
    "input_throughput": 5342.611355314398,
    "output_throughput": 4724.366002507486,
    "total_throughput": 10066.977357821885,
    "itl": 180.1717372151425,
    "ttft": 2144374.0369306486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.722252125069497,
    "arrivals": 1235881,
    "finished_requests": 78164,
    "scheduler_time": 123.48317690517865
}
#Debug simulation 
Total elapsed time: 26.351743634790182. Arrivals time: 0.4495723368600011 Scheduler time: 25.778849181253463 Scheduler overhead time: 0.04461755929514766 Adapter cache time: 0.015099344309419394 Engine time: 0.04615011112764478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.656256350688636,
    "estimated_duration": 3600.1548664650413,
    "input_throughput": 5330.855952550829,
    "output_throughput": 4709.754893585672,
    "total_throughput": 10040.6108461365,
    "itl": 182.53865999369208,
    "ttft": 2137494.8390504303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2486789995245708,
    "arrivals": 1142437,
    "finished_requests": 77521,
    "scheduler_time": 122.51625142164605
}
#Debug simulation 
Total elapsed time: 25.656392058823258. Arrivals time: 0.5652873865328729 Scheduler time: 24.968310085125268 Scheduler overhead time: 0.045964937191456556 Adapter cache time: 0.013974751811474562 Engine time: 0.045230182353407145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.078864681068808,
    "estimated_duration": 3600.037055143861,
    "input_throughput": 5330.614298144532,
    "output_throughput": 4709.525135519052,
    "total_throughput": 10040.139433663584,
    "itl": 182.5418719069199,
    "ttft": 2137517.7712914776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3284969919594063,
    "arrivals": 1142437,
    "finished_requests": 77516,
    "scheduler_time": 122.51002886318162
}
#Debug simulation 
Total elapsed time: 26.07898139487952. Arrivals time: 0.4966828366741538 Scheduler time: 25.457403833977878 Scheduler overhead time: 0.04610413732007146 Adapter cache time: 0.014632800128310919 Engine time: 0.04629407171159983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 28.642297317273915,
    "estimated_duration": 3600.104891454041,
    "input_throughput": 5312.167721945427,
    "output_throughput": 4695.96567592559,
    "total_throughput": 10008.133397871017,
    "itl": 180.6577638494871,
    "ttft": 2137313.807643273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9295633761026085,
    "arrivals": 1142437,
    "finished_requests": 77175,
    "scheduler_time": 122.89499486574232
}
#Debug simulation 
Total elapsed time: 28.642399340867996. Arrivals time: 0.48306033574044704 Scheduler time: 28.030742621049285 Scheduler overhead time: 0.04663627315312624 Adapter cache time: 0.017271109391003847 Engine time: 0.04716401360929012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 26.023481708019972,
    "estimated_duration": 3600.1661168256815,
    "input_throughput": 5330.839293860635,
    "output_throughput": 4709.740175808947,
    "total_throughput": 10040.579469669583,
    "itl": 182.53991105096623,
    "ttft": 2137507.001142042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.274153814606833,
    "arrivals": 1142437,
    "finished_requests": 77521,
    "scheduler_time": 122.51589326211149
}
#Debug simulation 
Total elapsed time: 26.023675420787185. Arrivals time: 0.5582581702619791 Scheduler time: 25.339915219694376 Scheduler overhead time: 0.04618988838046789 Adapter cache time: 0.014234507456421852 Engine time: 0.047323220409452915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 30.08218174893409,
    "estimated_duration": 3600.0891171144945,
    "input_throughput": 5309.001910296919,
    "output_throughput": 4697.306219339955,
    "total_throughput": 10006.308129636873,
    "itl": 180.56569770915624,
    "ttft": 2134432.964127976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6721390339545952,
    "arrivals": 1142437,
    "finished_requests": 77132,
    "scheduler_time": 122.94342026367754
}
#Debug simulation 
Total elapsed time: 30.082302432041615. Arrivals time: 0.5567048736847937 Scheduler time: 29.40004383167252 Scheduler overhead time: 0.04533267067745328 Adapter cache time: 0.015884737949818373 Engine time: 0.04650164535269141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.71706775808707,
    "estimated_duration": 3600.1086305265576,
    "input_throughput": 5330.924416353781,
    "output_throughput": 4709.815380632003,
    "total_throughput": 10040.739796985785,
    "itl": 182.5375020930024,
    "ttft": 2137480.4796033558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2169504700251792,
    "arrivals": 1142437,
    "finished_requests": 77521,
    "scheduler_time": 122.51561030755721
}
#Debug simulation 
Total elapsed time: 25.717225465923548. Arrivals time: 0.5746827246621251 Scheduler time: 25.01984756300226 Scheduler overhead time: 0.04544692253693938 Adapter cache time: 0.013926179613918066 Engine time: 0.046011929865926504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 4320, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 34560, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 4320, 1080, 34560, 1080, 34560, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 3431160 . Total input tokens: 764899018 . Total output tokens: 686112732
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 29.85804476775229,
    "estimated_duration": 3600.111472681549,
    "input_throughput": 5308.968943054349,
    "output_throughput": 4697.277050536444,
    "total_throughput": 10006.245993590794,
    "itl": 180.56665802291084,
    "ttft": 2134441.4420595975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6943974541500189,
    "arrivals": 1142437,
    "finished_requests": 77132,
    "scheduler_time": 122.94351741056344
}
#Debug simulation 
Total elapsed time: 29.858185356017202. Arrivals time: 0.5778546915389597 Scheduler time: 29.1550639285706 Scheduler overhead time: 0.0450608036480844 Adapter cache time: 0.015838514547795057 Engine time: 0.04666372528299689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 22.57631798926741,
    "estimated_duration": 3600.1078781969827,
    "input_throughput": 5327.772013767006,
    "output_throughput": 4707.642263344608,
    "total_throughput": 10035.414277111615,
    "itl": 182.62540957391184,
    "ttft": 2135649.5402589496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1415619284869207,
    "arrivals": 1127186,
    "finished_requests": 77632,
    "scheduler_time": 122.4941041315917
}
#Debug simulation 
Total elapsed time: 22.57641663821414. Arrivals time: 0.34722804883494973 Scheduler time: 22.11182520724833 Scheduler overhead time: 0.04383670911192894 Adapter cache time: 0.012428796384483576 Engine time: 0.04401209997013211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.902374841738492,
    "estimated_duration": 3600.183862155167,
    "input_throughput": 5327.659568063839,
    "output_throughput": 4707.54290583772,
    "total_throughput": 10035.20247390156,
    "itl": 182.62846271084476,
    "ttft": 2135686.402442625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2170289942901633,
    "arrivals": 1127186,
    "finished_requests": 77632,
    "scheduler_time": 122.49462102395337
}
#Debug simulation 
Total elapsed time: 22.902473392896354. Arrivals time: 0.35237283166497946 Scheduler time: 22.430939477402717 Scheduler overhead time: 0.04242782248184085 Adapter cache time: 0.01334319356828928 Engine time: 0.04619662882760167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.296243524178863,
    "estimated_duration": 3600.0649070184963,
    "input_throughput": 5309.073723292679,
    "output_throughput": 4697.108090199531,
    "total_throughput": 10006.181813492209,
    "itl": 180.75887237482294,
    "ttft": 2136424.118734658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2492968063242804,
    "arrivals": 1127186,
    "finished_requests": 77373,
    "scheduler_time": 122.88380748166445
}
#Debug simulation 
Total elapsed time: 22.296352922916412. Arrivals time: 0.3685334394685924 Scheduler time: 21.807951827999204 Scheduler overhead time: 0.04412012221291661 Adapter cache time: 0.013201592955738306 Engine time: 0.04463227931410074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 22.99428734788671,
    "estimated_duration": 3600.134024541365,
    "input_throughput": 5327.733320273676,
    "output_throughput": 4707.608073607503,
    "total_throughput": 10035.34139388118,
    "itl": 182.62656626655402,
    "ttft": 2135661.1274885284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1675889607588774,
    "arrivals": 1127186,
    "finished_requests": 77632,
    "scheduler_time": 122.49422344367322
}
#Debug simulation 
Total elapsed time: 22.9944853708148. Arrivals time: 0.3642236809246242 Scheduler time: 22.510728110559285 Scheduler overhead time: 0.04453668277710676 Adapter cache time: 0.013082528486847878 Engine time: 0.045025980565696955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 22.24083825899288,
    "estimated_duration": 3600.0810030143775,
    "input_throughput": 5309.04998637434,
    "output_throughput": 4697.087089385268,
    "total_throughput": 10006.137075759609,
    "itl": 180.75948568836486,
    "ttft": 2136431.9667276517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2652675371989657,
    "arrivals": 1127186,
    "finished_requests": 77373,
    "scheduler_time": 122.88393274668421
}
#Debug simulation 
Total elapsed time: 22.24096836289391. Arrivals time: 0.3495884509757161 Scheduler time: 21.7729235063307 Scheduler overhead time: 0.04316604230552912 Adapter cache time: 0.012989706825464964 Engine time: 0.045047239400446415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 22.671903583221138,
    "estimated_duration": 3600.081433786566,
    "input_throughput": 5327.811148934454,
    "output_throughput": 4707.676843346866,
    "total_throughput": 10035.48799228132,
    "itl": 182.6243611926698,
    "ttft": 2135636.895886044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1152887599985088,
    "arrivals": 1127186,
    "finished_requests": 77632,
    "scheduler_time": 122.49393288962331
}
#Debug simulation 
Total elapsed time: 22.67200784292072. Arrivals time: 0.3523877370171249 Scheduler time: 22.203608548734337 Scheduler overhead time: 0.04265572177246213 Adapter cache time: 0.012930745724588633 Engine time: 0.04363772924989462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.276391111314297,
    "estimated_duration": 3600.097440174013,
    "input_throughput": 5309.025746557615,
    "output_throughput": 4697.065643640648,
    "total_throughput": 10006.091390198264,
    "itl": 180.76015152358778,
    "ttft": 2136439.503292906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2816155294328953,
    "arrivals": 1127186,
    "finished_requests": 77373,
    "scheduler_time": 122.8840219140997
}
#Debug simulation 
Total elapsed time: 22.276521858293563. Arrivals time: 0.3534182240255177 Scheduler time: 21.805462006945163 Scheduler overhead time: 0.04355910886079073 Adapter cache time: 0.01273023197427392 Engine time: 0.04426534520462155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 20.22529524564743,
    "estimated_duration": 3600.055645754057,
    "input_throughput": 5312.124834113322,
    "output_throughput": 4713.3324230731105,
    "total_throughput": 10025.457257186432,
    "itl": 182.77616987236289,
    "ttft": 2135262.032107406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1201385142793907,
    "arrivals": 1119422,
    "finished_requests": 77667,
    "scheduler_time": 122.4255134581974
}
#Debug simulation 
Total elapsed time: 20.225398232694715. Arrivals time: 0.3536127400584519 Scheduler time: 19.759220896288753 Scheduler overhead time: 0.04109775647521019 Adapter cache time: 0.012714024167507887 Engine time: 0.04203710099682212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 20.427118784282357,
    "estimated_duration": 3600.1307961240877,
    "input_throughput": 5312.013946990176,
    "output_throughput": 4713.234035348961,
    "total_throughput": 10025.247982339137,
    "itl": 182.7793147439761,
    "ttft": 2135295.686575969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1948728562705284,
    "arrivals": 1119422,
    "finished_requests": 77667,
    "scheduler_time": 122.42592948621808
}
#Debug simulation 
Total elapsed time: 20.427242535166442. Arrivals time: 0.34237209567800164 Scheduler time: 19.968411212787032 Scheduler overhead time: 0.04306868417188525 Adapter cache time: 0.01262087607756257 Engine time: 0.0442089126445353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.590651160106063,
    "estimated_duration": 3600.1247044892707,
    "input_throughput": 5298.486737477082,
    "output_throughput": 4700.483285731258,
    "total_throughput": 9998.97002320834,
    "itl": 180.65496016384472,
    "ttft": 2136732.833201483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2259686894156108,
    "arrivals": 1119422,
    "finished_requests": 77462,
    "scheduler_time": 122.86227308621969
}
#Debug simulation 
Total elapsed time: 19.59077566722408. Arrivals time: 0.32935573579743505 Scheduler time: 19.14869797974825 Scheduler overhead time: 0.04121307097375393 Adapter cache time: 0.012718976940959692 Engine time: 0.0421694852411747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 20.51670010201633,
    "estimated_duration": 3600.0839121513113,
    "input_throughput": 5312.083125465832,
    "output_throughput": 4713.295415900524,
    "total_throughput": 10025.378541366357,
    "itl": 182.77739705698053,
    "ttft": 2135273.465205278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1482929899683252,
    "arrivals": 1119422,
    "finished_requests": 77667,
    "scheduler_time": 122.4256253797343
}
#Debug simulation 
Total elapsed time: 20.516883607022464. Arrivals time: 0.36884724628180265 Scheduler time: 20.030343919526786 Scheduler overhead time: 0.043203691486269236 Adapter cache time: 0.012864948716014624 Engine time: 0.04480217909440398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 19.70805729087442,
    "estimated_duration": 3600.139517868954,
    "input_throughput": 5298.464935962057,
    "output_throughput": 4700.463944802035,
    "total_throughput": 9998.928880764093,
    "itl": 180.65554589493124,
    "ttft": 2136740.0140036913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2406818824261476,
    "arrivals": 1119422,
    "finished_requests": 77462,
    "scheduler_time": 122.86237327290385
}
#Debug simulation 
Total elapsed time: 19.70816999906674. Arrivals time: 0.3662474453449249 Scheduler time: 19.228407578077167 Scheduler overhead time: 0.04183437116444111 Adapter cache time: 0.01276271604001522 Engine time: 0.04219776717945933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 20.119681667070836,
    "estimated_duration": 3600.0297132778655,
    "input_throughput": 5312.163099506044,
    "output_throughput": 4713.366375120892,
    "total_throughput": 10025.529474626936,
    "itl": 182.77512717550042,
    "ttft": 2135250.1402306203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0943584079341944,
    "arrivals": 1119422,
    "finished_requests": 77667,
    "scheduler_time": 122.42536108830984
}
#Debug simulation 
Total elapsed time: 20.11981472512707. Arrivals time: 0.34191948221996427 Scheduler time: 19.664362484123558 Scheduler overhead time: 0.04143160255625844 Adapter cache time: 0.01226510712876916 Engine time: 0.043114918284118176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.71598626114428,
    "estimated_duration": 3600.1564482910494,
    "input_throughput": 5298.4400189205035,
    "output_throughput": 4700.441839974155,
    "total_throughput": 9998.881858894658,
    "itl": 180.6562494357224,
    "ttft": 2136747.527015684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2575328898057365,
    "arrivals": 1119422,
    "finished_requests": 77462,
    "scheduler_time": 122.86245268763327
}
#Debug simulation 
Total elapsed time: 19.716087725013494. Arrivals time: 0.4157104743644595 Scheduler time: 19.18596792407334 Scheduler overhead time: 0.041724370792508125 Adapter cache time: 0.012884035240858793 Engine time: 0.0430188924074173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.630041593220085,
    "estimated_duration": 3600.0726496628545,
    "input_throughput": 5323.393127023355,
    "output_throughput": 4711.918244646702,
    "total_throughput": 10035.311371670057,
    "itl": 182.44463063088608,
    "ttft": 2133275.50199089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.178287781414115,
    "arrivals": 1115519,
    "finished_requests": 77968,
    "scheduler_time": 122.47599251510255
}
#Debug simulation 
Total elapsed time: 16.630150114186108. Arrivals time: 0.33737476635724306 Scheduler time: 16.184831202030182 Scheduler overhead time: 0.03977092541754246 Adapter cache time: 0.01222530473023653 Engine time: 0.039881988894194365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.926029182970524,
    "estimated_duration": 3600.1501776276987,
    "input_throughput": 5323.278489629124,
    "output_throughput": 4711.816775148488,
    "total_throughput": 10035.095264777612,
    "itl": 182.4478086178634,
    "ttft": 2133311.2972522937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.255361169739632,
    "arrivals": 1115519,
    "finished_requests": 77968,
    "scheduler_time": 122.4764470916
}
#Debug simulation 
Total elapsed time: 16.92613100167364. Arrivals time: 0.35072747291997075 Scheduler time: 16.467035619542003 Scheduler overhead time: 0.03986948914825916 Adapter cache time: 0.012507093604654074 Engine time: 0.04002314154058695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.804754856042564,
    "estimated_duration": 3600.015609234585,
    "input_throughput": 5314.539734472937,
    "output_throughput": 4700.1540650535035,
    "total_throughput": 10014.69379952644,
    "itl": 180.711554879724,
    "ttft": 2134462.070135438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297310321517296,
    "arrivals": 1115519,
    "finished_requests": 77771,
    "scheduler_time": 122.82564712788327
}
#Debug simulation 
Total elapsed time: 16.804883834905922. Arrivals time: 0.40905623510479927 Scheduler time: 16.285116170998663 Scheduler overhead time: 0.040169799234718084 Adapter cache time: 0.012683688197284937 Engine time: 0.041593257803469896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 17.019717944785953,
    "estimated_duration": 3600.100812191663,
    "input_throughput": 5323.351483686094,
    "output_throughput": 4711.881384697432,
    "total_throughput": 10035.232868383526,
    "itl": 182.44588169644464,
    "ttft": 2133287.1115051154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2063297315267858,
    "arrivals": 1115519,
    "finished_requests": 77968,
    "scheduler_time": 122.47611309376666
}
#Debug simulation 
Total elapsed time: 17.019931346643716. Arrivals time: 0.3296128255315125 Scheduler time: 16.580702780745924 Scheduler overhead time: 0.04010208137333393 Adapter cache time: 0.012212610803544521 Engine time: 0.040833042934536934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 16.658876726869494,
    "estimated_duration": 3600.031555158295,
    "input_throughput": 5314.516194333396,
    "output_throughput": 4700.1332462642795,
    "total_throughput": 10014.649440597675,
    "itl": 180.71217859058,
    "ttft": 2134469.615838764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3131552986055661,
    "arrivals": 1115519,
    "finished_requests": 77771,
    "scheduler_time": 122.825748074517
}
#Debug simulation 
Total elapsed time: 16.658983788918704. Arrivals time: 0.339380175806582 Scheduler time: 16.210947705898434 Scheduler overhead time: 0.03939010156318545 Adapter cache time: 0.012151875533163548 Engine time: 0.04075397131964564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.791195289231837,
    "estimated_duration": 3600.0453688691327,
    "input_throughput": 5323.433467178803,
    "output_throughput": 4711.953951104953,
    "total_throughput": 10035.387418283757,
    "itl": 182.4435252384421,
    "ttft": 2133262.8930841237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1511693635373337,
    "arrivals": 1115519,
    "finished_requests": 77968,
    "scheduler_time": 122.4758301392124
}
#Debug simulation 
Total elapsed time: 16.79130667913705. Arrivals time: 0.41046275570988655 Scheduler time: 16.274364048149437 Scheduler overhead time: 0.03923034109175205 Adapter cache time: 0.011964769102633 Engine time: 0.039343852549791336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.564523421227932,
    "estimated_duration": 3600.0489978415876,
    "input_throughput": 5314.490444844185,
    "output_throughput": 4700.110473536548,
    "total_throughput": 10014.600918380733,
    "itl": 180.71290016944673,
    "ttft": 2134477.2000835743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3305093211308139,
    "arrivals": 1115519,
    "finished_requests": 77771,
    "scheduler_time": 122.82583673529943
}
#Debug simulation 
Total elapsed time: 16.564641776960343. Arrivals time: 0.32419563131406903 Scheduler time: 16.131583800539374 Scheduler overhead time: 0.0402810457162559 Adapter cache time: 0.012154296040534973 Engine time: 0.04037597542628646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.937974529806525,
    "estimated_duration": 3600.202807541986,
    "input_throughput": 5341.427421731639,
    "output_throughput": 4709.104155044822,
    "total_throughput": 10050.53157677646,
    "itl": 182.42126717878511,
    "ttft": 2130934.9767172006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0864731490961292,
    "arrivals": 1113643,
    "finished_requests": 77902,
    "scheduler_time": 122.53366601092638
}
#Debug simulation 
Total elapsed time: 16.93810242181644. Arrivals time: 0.33403420355170965 Scheduler time: 16.49868943123147 Scheduler overhead time: 0.039087825920432806 Adapter cache time: 0.011223040521144867 Engine time: 0.039027868304401636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.323060618247837,
    "estimated_duration": 3600.0696226456544,
    "input_throughput": 5341.244480118947,
    "output_throughput": 4709.070317240539,
    "total_throughput": 10050.314797359486,
    "itl": 182.42325588500924,
    "ttft": 2130951.492587298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1570791592053198,
    "arrivals": 1113643,
    "finished_requests": 77898,
    "scheduler_time": 122.52714815689109
}
#Debug simulation 
Total elapsed time: 17.323176946956664. Arrivals time: 0.43362146709114313 Scheduler time: 16.779582020826638 Scheduler overhead time: 0.04081605700775981 Adapter cache time: 0.01198688056319952 Engine time: 0.04113482544198632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.40602568211034,
    "estimated_duration": 3600.1055049815045,
    "input_throughput": 5326.4352873732005,
    "output_throughput": 4700.622794688607,
    "total_throughput": 10027.058082061807,
    "itl": 181.08048693662877,
    "ttft": 2131562.2215899993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2249569469317863,
    "arrivals": 1113643,
    "finished_requests": 77700,
    "scheduler_time": 122.81275191806846
}
#Debug simulation 
Total elapsed time: 17.406132178381085. Arrivals time: 0.7281273487024009 Scheduler time: 16.568779861554503 Scheduler overhead time: 0.04004947282373905 Adapter cache time: 0.012158561963588 Engine time: 0.040903282817453146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 17.34183720778674,
    "estimated_duration": 3600.023908982515,
    "input_throughput": 5341.312304071532,
    "output_throughput": 4709.130113747347,
    "total_throughput": 10050.442417818878,
    "itl": 182.42151325871959,
    "ttft": 2130928.5799030974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.111725078858438,
    "arrivals": 1113643,
    "finished_requests": 77898,
    "scheduler_time": 122.52678857408912
}
#Debug simulation 
Total elapsed time: 17.341956528835. Arrivals time: 0.4334033220075071 Scheduler time: 16.799439133144915 Scheduler overhead time: 0.04057912854477763 Adapter cache time: 0.011887628585100174 Engine time: 0.040746756829321384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.17112179612741,
    "estimated_duration": 3600.1203353333963,
    "input_throughput": 5326.413345631735,
    "output_throughput": 4700.603430921938,
    "total_throughput": 10027.016776553673,
    "itl": 181.08105934055027,
    "ttft": 2131569.4243210284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2396701399423231,
    "arrivals": 1113643,
    "finished_requests": 77700,
    "scheduler_time": 122.81286907695956
}
#Debug simulation 
Total elapsed time: 17.17124095140025. Arrivals time: 0.35627614334225655 Scheduler time: 16.70535818906501 Scheduler overhead time: 0.040146871004253626 Adapter cache time: 0.012126744724810123 Engine time: 0.04096992872655392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.86725732497871,
    "estimated_duration": 3600.177644558085,
    "input_throughput": 5341.4647549594665,
    "output_throughput": 4709.137068729573,
    "total_throughput": 10050.60182368904,
    "itl": 182.42027180109787,
    "ttft": 2130922.925391466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0614678546902716,
    "arrivals": 1113643,
    "finished_requests": 77902,
    "scheduler_time": 122.53350832139189
}
#Debug simulation 
Total elapsed time: 16.867365317884833. Arrivals time: 0.333154350053519 Scheduler time: 16.427660876419395 Scheduler overhead time: 0.03979468857869506 Adapter cache time: 0.011250682175159454 Engine time: 0.03955016192048788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.001278734765947,
    "estimated_duration": 3600.136895333678,
    "input_throughput": 5326.3888450616,
    "output_throughput": 4700.581808967995,
    "total_throughput": 10026.970654029594,
    "itl": 181.08175051604405,
    "ttft": 2131576.6916647875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2561438859626672,
    "arrivals": 1113643,
    "finished_requests": 77700,
    "scheduler_time": 122.81295533123505
}
#Debug simulation 
Total elapsed time: 17.001427572686225. Arrivals time: 0.33744519436731935 Scheduler time: 16.555667460430413 Scheduler overhead time: 0.039948109071701765 Adapter cache time: 0.011653491761535406 Engine time: 0.040679579600691795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 15.898231303784996,
    "estimated_duration": 3600.088587147883,
    "input_throughput": 5357.214561011511,
    "output_throughput": 4707.025838334992,
    "total_throughput": 10064.240399346503,
    "itl": 182.0334117082159,
    "ttft": 2139016.452852696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456907128752197,
    "arrivals": 1112647,
    "finished_requests": 77582,
    "scheduler_time": 122.59391675392963
}
#Debug simulation 
Total elapsed time: 15.898354792967439. Arrivals time: 0.4665500991977751 Scheduler time: 15.32825747039169 Scheduler overhead time: 0.0385085279121995 Adapter cache time: 0.010529769118875265 Engine time: 0.038585962262004614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.2194529119879,
    "estimated_duration": 3600.1497983679283,
    "input_throughput": 5357.123475457385,
    "output_throughput": 4706.945807555584,
    "total_throughput": 10064.069283012968,
    "itl": 182.03570362873663,
    "ttft": 2139046.657456202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0064617954497284,
    "arrivals": 1112647,
    "finished_requests": 77582,
    "scheduler_time": 122.59435689138537
}
#Debug simulation 
Total elapsed time: 16.219558250159025. Arrivals time: 0.4509765161201358 Scheduler time: 15.663246952928603 Scheduler overhead time: 0.03922564536333084 Adapter cache time: 0.01041156891733408 Engine time: 0.03976284246891737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.108510786667466,
    "estimated_duration": 3600.1711673765685,
    "input_throughput": 5334.664410968861,
    "output_throughput": 4693.113247810398,
    "total_throughput": 10027.77765877926,
    "itl": 179.71485053423788,
    "ttft": 2140185.997264338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.047454276811337,
    "arrivals": 1112647,
    "finished_requests": 77304,
    "scheduler_time": 123.08662176592019
}
#Debug simulation 
Total elapsed time: 15.108639101032168. Arrivals time: 0.3261065250262618 Scheduler time: 14.678471256047487 Scheduler overhead time: 0.03905430203303695 Adapter cache time: 0.010494045447558165 Engine time: 0.03843828896060586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 16.20600039465353,
    "estimated_duration": 3600.111073889009,
    "input_throughput": 5357.181099183664,
    "output_throughput": 4706.996437666699,
    "total_throughput": 10064.177536850362,
    "itl": 182.0343349133612,
    "ttft": 2139027.0335468124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9680538355163335,
    "arrivals": 1112647,
    "finished_requests": 77582,
    "scheduler_time": 122.59404037239203
}
#Debug simulation 
Total elapsed time: 16.20611972687766. Arrivals time: 0.4672097829170525 Scheduler time: 15.634576658718288 Scheduler overhead time: 0.03858665423467755 Adapter cache time: 0.01040406571701169 Engine time: 0.039529390167444944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.033498149365187,
    "estimated_duration": 3600.1833405156667,
    "input_throughput": 5334.646373106404,
    "output_throughput": 4693.097379196229,
    "total_throughput": 10027.743752302633,
    "itl": 179.71527788428284,
    "ttft": 2140192.269708416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0595266403071633,
    "arrivals": 1112647,
    "finished_requests": 77304,
    "scheduler_time": 123.08672254153014
}
#Debug simulation 
Total elapsed time: 15.033622679300606. Arrivals time: 0.4427783158607781 Scheduler time: 14.486157013103366 Scheduler overhead time: 0.038647843059152365 Adapter cache time: 0.010501809883862734 Engine time: 0.03934990847483277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.351359693799168,
    "estimated_duration": 3600.0666530140443,
    "input_throughput": 5357.247200924188,
    "output_throughput": 4707.054516841439,
    "total_throughput": 10064.301717765627,
    "itl": 182.032578079003,
    "ttft": 2139005.54089338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9239255411247735,
    "arrivals": 1112647,
    "finished_requests": 77582,
    "scheduler_time": 122.59374779180995
}
#Debug simulation 
Total elapsed time: 16.351507727988064. Arrivals time: 0.8516277964226902 Scheduler time: 15.395995520055294 Scheduler overhead time: 0.038890138268470764 Adapter cache time: 0.010396492667496204 Engine time: 0.0386649277061224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.215337743982673,
    "estimated_duration": 3600.197640747544,
    "input_throughput": 5334.625183525239,
    "output_throughput": 4693.078737891656,
    "total_throughput": 10027.703921416894,
    "itl": 179.71584834920503,
    "ttft": 2140199.1935116253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0737368181720424,
    "arrivals": 1112647,
    "finished_requests": 77304,
    "scheduler_time": 123.08681259555347
}
#Debug simulation 
Total elapsed time: 15.215437470935285. Arrivals time: 0.4427575198933482 Scheduler time: 14.666595742572099 Scheduler overhead time: 0.03909667441621423 Adapter cache time: 0.010798432864248753 Engine time: 0.04024030826985836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.601332031190395,
    "estimated_duration": 3600.075728991363,
    "input_throughput": 5341.736243250603,
    "output_throughput": 4703.609944545315,
    "total_throughput": 10045.346187795918,
    "itl": 182.32804392081698,
    "ttft": 2125368.773062241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4323082641605425,
    "arrivals": 1035175,
    "finished_requests": 77479,
    "scheduler_time": 122.48028185398469
}
#Debug simulation 
Total elapsed time: 9.60145974997431. Arrivals time: 0.289200225379318 Scheduler time: 9.215862353798002 Scheduler overhead time: 0.03445953968912363 Adapter cache time: 0.012241209391504526 Engine time: 0.03454011585563421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.78673223638907,
    "estimated_duration": 3600.169906948892,
    "input_throughput": 5341.596507120907,
    "output_throughput": 4703.486901358732,
    "total_throughput": 10045.083408479639,
    "itl": 182.33197490332108,
    "ttft": 2125413.4558602693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5260080867307313,
    "arrivals": 1035175,
    "finished_requests": 77479,
    "scheduler_time": 122.48075998891862
}
#Debug simulation 
Total elapsed time: 9.786832005251199. Arrivals time: 0.28900671610608697 Scheduler time: 9.401317815296352 Scheduler overhead time: 0.034044620115309954 Adapter cache time: 0.012421190273016691 Engine time: 0.03473877953365445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.457376847974956,
    "estimated_duration": 3600.1475461856057,
    "input_throughput": 5328.684103607282,
    "output_throughput": 4695.480055507839,
    "total_throughput": 10024.164159115122,
    "itl": 180.419499580381,
    "ttft": 2125719.2523543304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.562046712972233,
    "arrivals": 1035175,
    "finished_requests": 77300,
    "scheduler_time": 122.88718224372397
}
#Debug simulation 
Total elapsed time: 9.457504463847727. Arrivals time: 0.28824704932048917 Scheduler time: 9.073070875834674 Scheduler overhead time: 0.033959776163101196 Adapter cache time: 0.012479745782911777 Engine time: 0.03444438986480236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 10.034345839172602,
    "estimated_duration": 3600.109088431432,
    "input_throughput": 5341.686745492148,
    "output_throughput": 4703.566359812131,
    "total_throughput": 10045.253105304279,
    "itl": 182.3294870001289,
    "ttft": 2125383.9972028756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4655359796015508,
    "arrivals": 1035175,
    "finished_requests": 77479,
    "scheduler_time": 122.48041357857575
}
#Debug simulation 
Total elapsed time: 10.034489231184125. Arrivals time: 0.6568131539970636 Scheduler time: 9.280842476990074 Scheduler overhead time: 0.03475157869979739 Adapter cache time: 0.012306188698858023 Engine time: 0.034612363670021296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 9.511820429936051,
    "estimated_duration": 3600.16626122578,
    "input_throughput": 5328.65640307074,
    "output_throughput": 4695.455646607944,
    "total_throughput": 10024.112049678684,
    "itl": 180.42026836263048,
    "ttft": 2125728.4190400457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5806582733616283,
    "arrivals": 1035175,
    "finished_requests": 77300,
    "scheduler_time": 122.88728572352292
}
#Debug simulation 
Total elapsed time: 9.51191366976127. Arrivals time: 0.2992419619113207 Scheduler time: 9.115024896338582 Scheduler overhead time: 0.03488688450306654 Adapter cache time: 0.012629429344087839 Engine time: 0.03480840986594558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.800324189011008,
    "estimated_duration": 3600.0426063224177,
    "input_throughput": 5341.7853906026,
    "output_throughput": 4703.6532207317605,
    "total_throughput": 10045.43861133436,
    "itl": 182.32664547426197,
    "ttft": 2125353.3303768774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3993435380142054,
    "arrivals": 1035175,
    "finished_requests": 77479,
    "scheduler_time": 122.48012391113367
}
#Debug simulation 
Total elapsed time: 9.80042840121314. Arrivals time: 0.36240347754210234 Scheduler time: 9.34123051026836 Scheduler overhead time: 0.03432175377383828 Adapter cache time: 0.012383993715047836 Engine time: 0.03477283800020814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.529359700158238,
    "estimated_duration": 3600.1877322099585,
    "input_throughput": 5328.624623756484,
    "output_throughput": 4695.427643608824,
    "total_throughput": 10024.052267365307,
    "itl": 180.42118455032073,
    "ttft": 2125738.0402746485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6020364170521486,
    "arrivals": 1035175,
    "finished_requests": 77300,
    "scheduler_time": 122.88737856402798
}
#Debug simulation 
Total elapsed time: 9.529484868980944. Arrivals time: 0.2925761076621711 Scheduler time: 9.139712503179908 Scheduler overhead time: 0.034191330429166555 Adapter cache time: 0.012605521362274885 Engine time: 0.03503424488008022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.812912106048316,
    "estimated_duration": 3600.001021995028,
    "input_throughput": 5347.212926437493,
    "output_throughput": 4709.042829828233,
    "total_throughput": 10056.255756265726,
    "itl": 182.28673025421443,
    "ttft": 2124554.2863303493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5700302126375212,
    "arrivals": 1027687,
    "finished_requests": 77763,
    "scheduler_time": 122.45632502287422
}
#Debug simulation 
Total elapsed time: 8.813018697779626. Arrivals time: 0.2910196944139898 Scheduler time: 8.426153716165572 Scheduler overhead time: 0.03361067175865173 Adapter cache time: 0.012937800027430058 Engine time: 0.034164272248744965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.827280017081648,
    "estimated_duration": 3600.1062881663474,
    "input_throughput": 5347.05657532257,
    "output_throughput": 4708.905138640919,
    "total_throughput": 10055.96171396349,
    "itl": 182.29139488298173,
    "ttft": 2124602.0642098133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6748611861467426,
    "arrivals": 1027687,
    "finished_requests": 77763,
    "scheduler_time": 122.45676022065778
}
#Debug simulation 
Total elapsed time: 8.82743215886876. Arrivals time: 0.39787754509598017 Scheduler time: 8.333712591789663 Scheduler overhead time: 0.033400984946638346 Adapter cache time: 0.012954672798514366 Engine time: 0.03436335455626249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.407140286173671,
    "estimated_duration": 3600.1428685286123,
    "input_throughput": 5333.000578348412,
    "output_throughput": 4698.698806615307,
    "total_throughput": 10031.699384963718,
    "itl": 180.54355540817704,
    "ttft": 2125924.7831396814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680719073880474,
    "arrivals": 1027687,
    "finished_requests": 77573,
    "scheduler_time": 122.82079022456206
}
#Debug simulation 
Total elapsed time: 8.407272776123136. Arrivals time: 0.2864687433466315 Scheduler time: 8.02445412799716 Scheduler overhead time: 0.033736567478626966 Adapter cache time: 0.012944848276674747 Engine time: 0.03445153497159481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.692652964033186,
    "estimated_duration": 3600.037331180303,
    "input_throughput": 5347.158995623174,
    "output_throughput": 4708.995335457246,
    "total_throughput": 10056.154331080419,
    "itl": 182.2884080568377,
    "ttft": 2124570.3145940946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6062171726487522,
    "arrivals": 1027687,
    "finished_requests": 77763,
    "scheduler_time": 122.45644724809576
}
#Debug simulation 
Total elapsed time: 8.692802178673446. Arrivals time: 0.2906412370502949 Scheduler time: 8.30646406346932 Scheduler overhead time: 0.033447622787207365 Adapter cache time: 0.012881101109087467 Engine time: 0.03432301338762045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.497010960709304,
    "estimated_duration": 3600.1638471369424,
    "input_throughput": 5332.969502282125,
    "output_throughput": 4698.671426705361,
    "total_throughput": 10031.640928987486,
    "itl": 180.5444424442005,
    "ttft": 2125934.6416731523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.701594202425335,
    "arrivals": 1027687,
    "finished_requests": 77573,
    "scheduler_time": 122.82089370436101
}
#Debug simulation 
Total elapsed time: 8.497134230099618. Arrivals time: 0.39920657221227884 Scheduler time: 8.00148026784882 Scheduler overhead time: 0.03384987683966756 Adapter cache time: 0.012962729670107365 Engine time: 0.034436112735420465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.809430188965052,
    "estimated_duration": 3600.1645823496647,
    "input_throughput": 5347.260537582349,
    "output_throughput": 4709.092212927447,
    "total_throughput": 10056.352750509795,
    "itl": 182.28520729834477,
    "ttft": 2124630.712659393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5338958012847985,
    "arrivals": 1027687,
    "finished_requests": 77770,
    "scheduler_time": 122.46304637808163
}
#Debug simulation 
Total elapsed time: 8.809556921944022. Arrivals time: 0.2920101108029485 Scheduler time: 8.42173024918884 Scheduler overhead time: 0.03356381971389055 Adapter cache time: 0.012869371101260185 Engine time: 0.034246828872710466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.47568210400641,
    "estimated_duration": 3600.1864412924365,
    "input_throughput": 5332.936033475955,
    "output_throughput": 4698.641938645628,
    "total_throughput": 10031.577972121584,
    "itl": 180.54544619250785,
    "ttft": 2125944.9102789573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7241041301935887,
    "arrivals": 1027687,
    "finished_requests": 77573,
    "scheduler_time": 122.82097793210433
}
#Debug simulation 
Total elapsed time: 8.47579753305763. Arrivals time: 0.30576597433537245 Scheduler time: 8.073325988836586 Scheduler overhead time: 0.03412755765020847 Adapter cache time: 0.012968301773071289 Engine time: 0.0344146303832531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.166609656997025,
    "estimated_duration": 3600.1230316166043,
    "input_throughput": 5377.327894071162,
    "output_throughput": 4704.818655154174,
    "total_throughput": 10082.146549225336,
    "itl": 181.70389506788302,
    "ttft": 2125840.2410592474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5455463106860583,
    "arrivals": 1023854,
    "finished_requests": 77723,
    "scheduler_time": 122.56336455139645
}
#Debug simulation 
Total elapsed time: 8.166707179043442. Arrivals time: 0.39107786677777767 Scheduler time: 7.6789600402116776 Scheduler overhead time: 0.034885669592767954 Adapter cache time: 0.01279697846621275 Engine time: 0.03382564289495349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.147003717720509,
    "estimated_duration": 3600.0228254505428,
    "input_throughput": 5376.6903540611775,
    "output_throughput": 4704.344617004058,
    "total_throughput": 10081.034971065235,
    "itl": 181.7068114134941,
    "ttft": 2125888.2462771884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.647263425921561,
    "arrivals": 1023854,
    "finished_requests": 77713,
    "scheduler_time": 122.55689524331397
}
#Debug simulation 
Total elapsed time: 8.14710771292448. Arrivals time: 0.3971665040589869 Scheduler time: 7.65439246641472 Scheduler overhead time: 0.03383981483057141 Adapter cache time: 0.012750980909913778 Engine time: 0.033871610183268785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.070651136804372,
    "estimated_duration": 3600.16850213069,
    "input_throughput": 5363.712278625734,
    "output_throughput": 4693.150609478515,
    "total_throughput": 10056.86288810425,
    "itl": 180.10094498682483,
    "ttft": 2127087.042234136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6763265650533241,
    "arrivals": 1023854,
    "finished_requests": 77545,
    "scheduler_time": 122.89782698479513
}
#Debug simulation 
Total elapsed time: 8.07075167587027. Arrivals time: 0.39435138972476125 Scheduler time: 7.579784797038883 Scheduler overhead time: 0.033860121853649616 Adapter cache time: 0.01309047406539321 Engine time: 0.034438572358340025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.10480240592733,
    "estimated_duration": 3600.1591080094504,
    "input_throughput": 5377.274009065597,
    "output_throughput": 4704.771509213959,
    "total_throughput": 10082.045518279556,
    "itl": 181.70551827279297,
    "ttft": 2125856.292487613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.581479579652654,
    "arrivals": 1023854,
    "finished_requests": 77723,
    "scheduler_time": 122.56350767523098
}
#Debug simulation 
Total elapsed time: 8.104975720867515. Arrivals time: 0.28980145370587707 Scheduler time: 7.719388814643025 Scheduler overhead time: 0.033585247583687305 Adapter cache time: 0.01289062574505806 Engine time: 0.034047822933644056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.431036591064185,
    "estimated_duration": 3600.1893482723417,
    "input_throughput": 5363.681221174272,
    "output_throughput": 4693.123434773816,
    "total_throughput": 10056.804655948088,
    "itl": 180.10182748587312,
    "ttft": 2127096.2889255206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.69707593981177,
    "arrivals": 1023854,
    "finished_requests": 77545,
    "scheduler_time": 122.89792375170626
}
#Debug simulation 
Total elapsed time: 8.431146671064198. Arrivals time: 0.7660429263487458 Scheduler time: 7.5690377238206565 Scheduler overhead time: 0.033749987836927176 Adapter cache time: 0.013049908448010683 Engine time: 0.033992898650467396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.072243410628289,
    "estimated_duration": 3600.0873071950937,
    "input_throughput": 5377.381254423813,
    "output_throughput": 4704.865342056581,
    "total_throughput": 10082.246596480394,
    "itl": 181.7023605016003,
    "ttft": 2125824.44160213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.509975398925582,
    "arrivals": 1023854,
    "finished_requests": 77723,
    "scheduler_time": 122.56321104158455
}
#Debug simulation 
Total elapsed time: 8.072373325936496. Arrivals time: 0.39008594350889325 Scheduler time: 7.587064693681896 Scheduler overhead time: 0.03343329858034849 Adapter cache time: 0.012753795832395554 Engine time: 0.0340449083596468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.067838167306036,
    "estimated_duration": 3600.0081619487178,
    "input_throughput": 5363.705894918763,
    "output_throughput": 4692.9782489311665,
    "total_throughput": 10056.68414384993,
    "itl": 180.10377272129045,
    "ttft": 2126983.1067240583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7192086062207794,
    "arrivals": 1023854,
    "finished_requests": 77539,
    "scheduler_time": 122.89105095994313
}
#Debug simulation 
Total elapsed time: 8.067953357007354. Arrivals time: 0.409312869887799 Scheduler time: 7.562264794483781 Scheduler overhead time: 0.03396315732970834 Adapter cache time: 0.012914704624563456 Engine time: 0.0343058118596673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.504553733859211,
    "estimated_duration": 3600.187810797151,
    "input_throughput": 5370.651203810054,
    "output_throughput": 4704.541510085767,
    "total_throughput": 10075.19271389582,
    "itl": 181.7381659589918,
    "ttft": 2125056.470963274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965785067831325,
    "arrivals": 1021838,
    "finished_requests": 78053,
    "scheduler_time": 122.56686494050935
}
#Debug simulation 
Total elapsed time: 7.504651314113289. Arrivals time: 0.35128301102668047 Scheduler time: 7.059314881917089 Scheduler overhead time: 0.03301757154986262 Adapter cache time: 0.012654619757086039 Engine time: 0.03347322717308998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.479567261878401,
    "estimated_duration": 3600.0865863422464,
    "input_throughput": 5370.541384573785,
    "output_throughput": 4704.454071813793,
    "total_throughput": 10074.995456387578,
    "itl": 181.7425832626354,
    "ttft": 2125018.476628854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5977882399293655,
    "arrivals": 1021838,
    "finished_requests": 78048,
    "scheduler_time": 122.56038083817927
}
#Debug simulation 
Total elapsed time: 7.479694860987365. Arrivals time: 0.28351873345673084 Scheduler time: 7.101537289097905 Scheduler overhead time: 0.033170709386467934 Adapter cache time: 0.0126076340675354 Engine time: 0.03381114732474089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.389401397667825,
    "estimated_duration": 3600.1725138259294,
    "input_throughput": 5356.524145979415,
    "output_throughput": 4693.67118800714,
    "total_throughput": 10050.195333986554,
    "itl": 180.10757204415097,
    "ttft": 2125487.8565841117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6070084179192878,
    "arrivals": 1021838,
    "finished_requests": 77861,
    "scheduler_time": 122.90536156511152
}
#Debug simulation 
Total elapsed time: 7.389502797741443. Arrivals time: 0.280172570142895 Scheduler time: 7.0140457870438695 Scheduler overhead time: 0.033569679129868746 Adapter cache time: 0.01272069988772273 Engine time: 0.03389279963448644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.528836693614721,
    "estimated_duration": 3600.025413312547,
    "input_throughput": 5370.632642898353,
    "output_throughput": 4704.534011724104,
    "total_throughput": 10075.166654622457,
    "itl": 181.74003383073347,
    "ttft": 2124990.4468507194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5369075374817438,
    "arrivals": 1021838,
    "finished_requests": 78048,
    "scheduler_time": 122.56008851091369
}
#Debug simulation 
Total elapsed time: 7.528949923813343. Arrivals time: 0.29586114874109626 Scheduler time: 7.138167462777346 Scheduler overhead time: 0.03320944495499134 Adapter cache time: 0.012674318626523018 Engine time: 0.033901345916092396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.457834080327302,
    "estimated_duration": 3600.1913441072543,
    "input_throughput": 5356.496129452805,
    "output_throughput": 4693.646638437278,
    "total_throughput": 10050.142767890084,
    "itl": 180.10835757267537,
    "ttft": 2125496.520826149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6257457320950972,
    "arrivals": 1021838,
    "finished_requests": 77861,
    "scheduler_time": 122.90545453227483
}
#Debug simulation 
Total elapsed time: 7.457929908297956. Arrivals time: 0.2838089703582227 Scheduler time: 7.078385294415057 Scheduler overhead time: 0.03361835377290845 Adapter cache time: 0.012616311199963093 Engine time: 0.034342090133577585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.577541895210743,
    "estimated_duration": 3600.153218694468,
    "input_throughput": 5370.702807757617,
    "output_throughput": 4704.586713712699,
    "total_throughput": 10075.289521470315,
    "itl": 181.73666979213155,
    "ttft": 2125040.933893576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4621345942071489,
    "arrivals": 1021838,
    "finished_requests": 78053,
    "scheduler_time": 122.56671675034441
}
#Debug simulation 
Total elapsed time: 7.5776765528135. Arrivals time: 0.3483774922788143 Scheduler time: 7.134782166220248 Scheduler overhead time: 0.03329769987612963 Adapter cache time: 0.012419446371495724 Engine time: 0.03375717019662261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.437074752058834,
    "estimated_duration": 3600.0158765825436,
    "input_throughput": 5356.386377469317,
    "output_throughput": 4693.565133951591,
    "total_throughput": 10049.951511420908,
    "itl": 180.1083667189442,
    "ttft": 2125476.9660334797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6490101825818402,
    "arrivals": 1021838,
    "finished_requests": 77857,
    "scheduler_time": 122.89870374281318
}
#Debug simulation 
Total elapsed time: 7.437174086924642. Arrivals time: 0.2894681724719703 Scheduler time: 7.052137165796012 Scheduler overhead time: 0.033400007057935 Adapter cache time: 0.012779091019183397 Engine time: 0.03414842812344432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.388012893032283,
    "estimated_duration": 3600.2028664016175,
    "input_throughput": 5315.696284395192,
    "output_throughput": 4708.79687314511,
    "total_throughput": 10024.493157540302,
    "itl": 182.63869993761938,
    "ttft": 2126258.952941297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5057599700149311,
    "arrivals": 1020948,
    "finished_requests": 77753,
    "scheduler_time": 122.39305770275855
}
#Debug simulation 
Total elapsed time: 7.388137150090188. Arrivals time: 0.28058677818626165 Scheduler time: 7.013826745096594 Scheduler overhead time: 0.0327935041859746 Adapter cache time: 0.012368855997920036 Engine time: 0.033627253491431475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.45038660755381,
    "estimated_duration": 3600.10288154093,
    "input_throughput": 5315.657810259285,
    "output_throughput": 4708.800708701988,
    "total_throughput": 10024.458518961272,
    "itl": 182.64366238575883,
    "ttft": 2126261.635561352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6083927720878328,
    "arrivals": 1020948,
    "finished_requests": 77749,
    "scheduler_time": 122.3865554965535
}
#Debug simulation 
Total elapsed time: 7.450482822954655. Arrivals time: 0.2885596929118037 Scheduler time: 7.067273332271725 Scheduler overhead time: 0.03336618281900883 Adapter cache time: 0.01253124326467514 Engine time: 0.03376024775207043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.369312021881342,
    "estimated_duration": 3600.0591140040324,
    "input_throughput": 5305.921484926651,
    "output_throughput": 4702.011123693187,
    "total_throughput": 10007.932608619838,
    "itl": 180.94807926319973,
    "ttft": 2127771.701646779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6428478577174346,
    "arrivals": 1020948,
    "finished_requests": 77615,
    "scheduler_time": 122.73553231241432
}
#Debug simulation 
Total elapsed time: 7.369409903883934. Arrivals time: 0.3451328775845468 Scheduler time: 6.930059749633074 Scheduler overhead time: 0.03311211662366986 Adapter cache time: 0.012580676935613155 Engine time: 0.03347342601045966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.731793788261712,
    "estimated_duration": 3600.042101780899,
    "input_throughput": 5315.747554878092,
    "output_throughput": 4708.880207710337,
    "total_throughput": 10024.627762588429,
    "itl": 182.64109042065144,
    "ttft": 2126232.7896369877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5479206649586517,
    "arrivals": 1020948,
    "finished_requests": 77749,
    "scheduler_time": 122.3862478436384
}
#Debug simulation 
Total elapsed time: 7.731881664134562. Arrivals time: 0.6185818538069725 Scheduler time: 7.020520810037851 Scheduler overhead time: 0.032711847219616175 Adapter cache time: 0.01220552483573556 Engine time: 0.03301372844725847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.386515349149704,
    "estimated_duration": 3600.0779432720924,
    "input_throughput": 5305.893733689173,
    "output_throughput": 4701.986531051232,
    "total_throughput": 10007.880264740405,
    "itl": 180.94885419254118,
    "ttft": 2127780.7047117515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6615851718932442,
    "arrivals": 1020948,
    "finished_requests": 77615,
    "scheduler_time": 122.73562426631155
}
#Debug simulation 
Total elapsed time: 7.3866405501030385. Arrivals time: 0.3420620495453477 Scheduler time: 6.950813863892108 Scheduler overhead time: 0.033007408026605844 Adapter cache time: 0.012435519136488438 Engine time: 0.03336853813380003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.380351575091481,
    "estimated_duration": 3600.168069699475,
    "input_throughput": 5315.747662191092,
    "output_throughput": 4708.842385076518,
    "total_throughput": 10024.59004726761,
    "itl": 182.63717964313207,
    "ttft": 2126242.996861972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.471104745091855,
    "arrivals": 1020948,
    "finished_requests": 77753,
    "scheduler_time": 122.39291622548141
}
#Debug simulation 
Total elapsed time: 7.380447745323181. Arrivals time: 0.2744989264756441 Scheduler time: 7.012945322319865 Scheduler overhead time: 0.03279760153964162 Adapter cache time: 0.012192574329674244 Engine time: 0.0331667996942997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.354908686131239,
    "estimated_duration": 3600.102176279873,
    "input_throughput": 5305.858018657255,
    "output_throughput": 4701.954881039479,
    "total_throughput": 10007.812899696733,
    "itl": 180.94993056207454,
    "ttft": 2127791.564755921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.685729898884891,
    "arrivals": 1020948,
    "finished_requests": 77615,
    "scheduler_time": 122.73571254711923
}
#Debug simulation 
Total elapsed time: 7.3550133323296905. Arrivals time: 0.2873895247466862 Scheduler time: 6.973560309037566 Scheduler overhead time: 0.033087510615587234 Adapter cache time: 0.012400988023728132 Engine time: 0.03346791723743081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.867869902867824,
    "estimated_duration": 3600.177051945029,
    "input_throughput": 5330.538393835923,
    "output_throughput": 4707.802354010114,
    "total_throughput": 10038.340747846038,
    "itl": 182.33310773632235,
    "ttft": 2124428.7558432873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.83629264635968,
    "arrivals": 1012432,
    "finished_requests": 77681,
    "scheduler_time": 122.40759866872477
}
#Debug simulation 
Total elapsed time: 6.867996190674603. Arrivals time: 0.2633152389898896 Scheduler time: 6.511250099167228 Scheduler overhead time: 0.03234173823148012 Adapter cache time: 0.013662240467965603 Engine time: 0.03260982921347022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.8589375973679125,
    "estimated_duration": 3600.0894638811187,
    "input_throughput": 5330.37114564153,
    "output_throughput": 4707.549123440239,
    "total_throughput": 10037.92026908177,
    "itl": 182.33965108278096,
    "ttft": 2124427.301615398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9562425183621284,
    "arrivals": 1012432,
    "finished_requests": 77676,
    "scheduler_time": 122.40097194356564
}
#Debug simulation 
Total elapsed time: 6.859035308007151. Arrivals time: 0.2520162872970104 Scheduler time: 6.5146441189572215 Scheduler overhead time: 0.03196044219657779 Adapter cache time: 0.013553045224398375 Engine time: 0.032140111085027456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.839908436872065,
    "estimated_duration": 3600.1723289383085,
    "input_throughput": 5318.246531172672,
    "output_throughput": 4697.3581970136265,
    "total_throughput": 10015.604728186298,
    "itl": 180.45385920062805,
    "ttft": 2125641.1476007807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.029308420326572,
    "arrivals": 1012432,
    "finished_requests": 77497,
    "scheduler_time": 122.79648964267354
}
#Debug simulation 
Total elapsed time: 6.840003311634064. Arrivals time: 0.2546501881442964 Scheduler time: 6.491635248064995 Scheduler overhead time: 0.03229680750519037 Adapter cache time: 0.014022414572536945 Engine time: 0.03257045662030578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.890648353844881,
    "estimated_duration": 3600.0127310448574,
    "input_throughput": 5330.4847603776125,
    "output_throughput": 4707.649462973198,
    "total_throughput": 10038.134223350811,
    "itl": 182.33631336050868,
    "ttft": 2124391.776021219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8798351938137685,
    "arrivals": 1012432,
    "finished_requests": 77676,
    "scheduler_time": 122.4006464318358
}
#Debug simulation 
Total elapsed time: 6.890771853737533. Arrivals time: 0.25218958081677556 Scheduler time: 6.545571301598102 Scheduler overhead time: 0.032373353373259306 Adapter cache time: 0.013589696492999792 Engine time: 0.032220189459621906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.860243687406182,
    "estimated_duration": 3600.1965772717376,
    "input_throughput": 5318.210711291069,
    "output_throughput": 4697.326558989048,
    "total_throughput": 10015.537270280118,
    "itl": 180.45490673374064,
    "ttft": 2125652.2909575305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0534531473182183,
    "arrivals": 1012432,
    "finished_requests": 77497,
    "scheduler_time": 122.79659324913077
}
#Debug simulation 
Total elapsed time: 6.860343992244452. Arrivals time: 0.25242080073803663 Scheduler time: 6.514151182956994 Scheduler overhead time: 0.03223899798467755 Adapter cache time: 0.013895419426262379 Engine time: 0.03269750392064452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.848047578241676,
    "estimated_duration": 3600.1346388790103,
    "input_throughput": 5330.601192730822,
    "output_throughput": 4707.857816472514,
    "total_throughput": 10038.459009203336,
    "itl": 182.33120084348724,
    "ttft": 2124409.9235399677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7940301769412785,
    "arrivals": 1012432,
    "finished_requests": 77681,
    "scheduler_time": 122.40744807205286
}
#Debug simulation 
Total elapsed time: 6.8481414201669395. Arrivals time: 0.2585055432282388 Scheduler time: 6.497218847740442 Scheduler overhead time: 0.03196531441062689 Adapter cache time: 0.013566890731453896 Engine time: 0.03219058457762003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.884769469033927,
    "estimated_duration": 3600.0186696900564,
    "input_throughput": 5318.473529374342,
    "output_throughput": 4697.558693898656,
    "total_throughput": 10016.032223273,
    "itl": 180.45614931059484,
    "ttft": 2125564.785361983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0812447341158964,
    "arrivals": 1012432,
    "finished_requests": 77497,
    "scheduler_time": 122.78965547060986
}
#Debug simulation 
Total elapsed time: 6.884874873328954. Arrivals time: 0.2581629096530378 Scheduler time: 6.533111752010882 Scheduler overhead time: 0.03215737082064152 Adapter cache time: 0.013924583327025175 Engine time: 0.03259762329980731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.366570211946964,
    "estimated_duration": 3600.000664392011,
    "input_throughput": 5330.166238522259,
    "output_throughput": 4709.5499641701745,
    "total_throughput": 10039.716202692434,
    "itl": 182.47653365305598,
    "ttft": 2123673.0635940703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9556516683730616,
    "arrivals": 1008682,
    "finished_requests": 77690,
    "scheduler_time": 122.38850934404232
}
#Debug simulation 
Total elapsed time: 6.366666349116713. Arrivals time: 0.25257944129407406 Scheduler time: 6.021368951071054 Scheduler overhead time: 0.03182497154921293 Adapter cache time: 0.013782520778477192 Engine time: 0.03226714534685016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.434168527834117,
    "estimated_duration": 3600.1256429313285,
    "input_throughput": 5329.9812015383095,
    "output_throughput": 4709.386471910809,
    "total_throughput": 10039.367673449118,
    "itl": 182.48221910674968,
    "ttft": 2123729.1739852317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.080209195595239,
    "arrivals": 1008682,
    "finished_requests": 77690,
    "scheduler_time": 122.3889303561007
}
#Debug simulation 
Total elapsed time: 6.434281121939421. Arrivals time: 0.24926262767985463 Scheduler time: 6.092557400465012 Scheduler overhead time: 0.031748085748404264 Adapter cache time: 0.013682186603546143 Engine time: 0.03232146240770817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.3263549520634115,
    "estimated_duration": 3600.099437525301,
    "input_throughput": 5313.899333055729,
    "output_throughput": 4695.663631896889,
    "total_throughput": 10009.562964952618,
    "itl": 180.37402871503866,
    "ttft": 2125191.7466862896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.136497783623643,
    "arrivals": 1008682,
    "finished_requests": 77455,
    "scheduler_time": 122.8207767473571
}
#Debug simulation 
Total elapsed time: 6.326448472216725. Arrivals time: 0.25372699555009604 Scheduler time: 5.979555441066623 Scheduler overhead time: 0.03200531052425504 Adapter cache time: 0.014080545864999294 Engine time: 0.03218314005061984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.3139900751411915,
    "estimated_duration": 3600.045232990519,
    "input_throughput": 5330.100251007189,
    "output_throughput": 4709.491659891222,
    "total_throughput": 10039.59191089841,
    "itl": 182.47866034613108,
    "ttft": 2123691.9469487034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.000124513180914,
    "arrivals": 1008682,
    "finished_requests": 77690,
    "scheduler_time": 122.38860509768736
}
#Debug simulation 
Total elapsed time: 6.31411173613742. Arrivals time: 0.24964584317058325 Scheduler time: 5.9721727459691465 Scheduler overhead time: 0.031850294675678015 Adapter cache time: 0.013733376748859882 Engine time: 0.03204899141564965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.310394355095923,
    "estimated_duration": 3600.1245520761704,
    "input_throughput": 5313.862263172955,
    "output_throughput": 4695.630874840447,
    "total_throughput": 10009.493138013402,
    "itl": 180.37513574061265,
    "ttft": 2125203.2876362586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1615227871201963,
    "arrivals": 1008682,
    "finished_requests": 77455,
    "scheduler_time": 122.82086629474738
}
#Debug simulation 
Total elapsed time: 6.310487173963338. Arrivals time: 0.24908682517707348 Scheduler time: 5.968121943529695 Scheduler overhead time: 0.03197462810203433 Adapter cache time: 0.013975494541227818 Engine time: 0.032378124073147774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.411194811109453,
    "estimated_duration": 3600.1555249966686,
    "input_throughput": 5329.98557055886,
    "output_throughput": 4709.411546884683,
    "total_throughput": 10039.397117443543,
    "itl": 182.4749063937565,
    "ttft": 2123689.5460494985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9106421384424592,
    "arrivals": 1008682,
    "finished_requests": 77692,
    "scheduler_time": 122.39524069699601
}
#Debug simulation 
Total elapsed time: 6.411289501935244. Arrivals time: 0.31795378727838397 Scheduler time: 6.000813516322523 Scheduler overhead time: 0.0319047118537128 Adapter cache time: 0.01381013123318553 Engine time: 0.032087760511785746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.35323803126812,
    "estimated_duration": 3600.152925206215,
    "input_throughput": 5313.82038414499,
    "output_throughput": 4695.593868149836,
    "total_throughput": 10009.414252294826,
    "itl": 180.37646967299062,
    "ttft": 2125215.5672813696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1898173890635384,
    "arrivals": 1008682,
    "finished_requests": 77455,
    "scheduler_time": 122.82094482286898
}
#Debug simulation 
Total elapsed time: 6.353334371000528. Arrivals time: 0.2567538642324507 Scheduler time: 6.002966878935695 Scheduler overhead time: 0.032343908213078976 Adapter cache time: 0.01396510936319828 Engine time: 0.03238004120066762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.383625878952444,
    "estimated_duration": 3600.14586415901,
    "input_throughput": 5354.573877662355,
    "output_throughput": 4705.6337824126995,
    "total_throughput": 10060.207660075053,
    "itl": 182.0897613256384,
    "ttft": 2127014.2309119543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.078071178130376,
    "arrivals": 1006798,
    "finished_requests": 77587,
    "scheduler_time": 122.46294455893322
}
#Debug simulation 
Total elapsed time: 6.383691933937371. Arrivals time: 0.5624895202927291 Scheduler time: 5.7280853246338665 Scheduler overhead time: 0.031798460986465216 Adapter cache time: 0.014348211232572794 Engine time: 0.03230871772393584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.079108772799373,
    "estimated_duration": 3600.1014625864714,
    "input_throughput": 5354.376314202839,
    "output_throughput": 4705.326829269364,
    "total_throughput": 10059.703143472203,
    "itl": 182.093486199911,
    "ttft": 2127091.1316614132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2098962072865147,
    "arrivals": 1006798,
    "finished_requests": 77580,
    "scheduler_time": 122.45746622282353
}
#Debug simulation 
Total elapsed time: 6.079196122009307. Arrivals time: 0.2580755348317325 Scheduler time: 5.728594409767538 Scheduler overhead time: 0.03178227227181196 Adapter cache time: 0.014321224298328161 Engine time: 0.03175332862883806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.052338757086545,
    "estimated_duration": 3600.045822942511,
    "input_throughput": 5343.8305916550025,
    "output_throughput": 4695.908561014437,
    "total_throughput": 10039.73915266944,
    "itl": 180.24751470114848,
    "ttft": 2128924.75673685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.253138368166986,
    "arrivals": 1006798,
    "finished_requests": 77406,
    "scheduler_time": 122.84015237374999
}
#Debug simulation 
Total elapsed time: 6.052431945223361. Arrivals time: 0.2508186777122319 Scheduler time: 5.708288211375475 Scheduler overhead time: 0.0318739996291697 Adapter cache time: 0.014380060136318207 Engine time: 0.03225849475711584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.04885278083384,
    "estimated_duration": 3600.1990798668903,
    "input_throughput": 5354.494729972748,
    "output_throughput": 4705.564226916684,
    "total_throughput": 10060.058956889432,
    "itl": 182.0922228607758,
    "ttft": 2127036.4472572524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.13116719389333,
    "arrivals": 1006798,
    "finished_requests": 77587,
    "scheduler_time": 122.46306425098952
}
#Debug simulation 
Total elapsed time: 6.048948342911899. Arrivals time: 0.2518268539570272 Scheduler time: 5.7048463127575815 Scheduler overhead time: 0.03158608917146921 Adapter cache time: 0.01414287555962801 Engine time: 0.03189351689070463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.052991353906691,
    "estimated_duration": 3600.071452541059,
    "input_throughput": 5343.792547900989,
    "output_throughput": 4695.87512994152,
    "total_throughput": 10039.667677842508,
    "itl": 180.24864223995763,
    "ttft": 2128936.23440945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2786663868092036,
    "arrivals": 1006798,
    "finished_requests": 77406,
    "scheduler_time": 122.84025395367505
}
#Debug simulation 
Total elapsed time: 6.053071073256433. Arrivals time: 0.25679073575884104 Scheduler time: 5.70258301217109 Scheduler overhead time: 0.03200576500967145 Adapter cache time: 0.014567177277058363 Engine time: 0.03227695403620601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.140280806925148,
    "estimated_duration": 3600.0978848879754,
    "input_throughput": 5354.645239208503,
    "output_throughput": 4705.696495396029,
    "total_throughput": 10060.341734604532,
    "itl": 182.08758159340832,
    "ttft": 2126993.795203012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.030244150238542,
    "arrivals": 1006798,
    "finished_requests": 77587,
    "scheduler_time": 122.46279231570394
}
#Debug simulation 
Total elapsed time: 6.140374804846942. Arrivals time: 0.3175247530452907 Scheduler time: 5.730368091259152 Scheduler overhead time: 0.03159168642014265 Adapter cache time: 0.014315396081656218 Engine time: 0.03183588758111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.076446886640042,
    "estimated_duration": 3600.1128040488593,
    "input_throughput": 5343.731168191171,
    "output_throughput": 4695.821192321329,
    "total_throughput": 10039.5523605125,
    "itl": 180.250604635614,
    "ttft": 2128953.9056333113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.310230587199337,
    "arrivals": 1006798,
    "finished_requests": 77406,
    "scheduler_time": 122.84086388224925
}
#Debug simulation 
Total elapsed time: 6.076532586012036. Arrivals time: 0.25344383670017123 Scheduler time: 5.729331344366074 Scheduler overhead time: 0.032031140755862 Adapter cache time: 0.014411222655326128 Engine time: 0.03244585730135441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.024525422137231,
    "estimated_duration": 3600.010895146548,
    "input_throughput": 5335.377741743781,
    "output_throughput": 4709.262692192454,
    "total_throughput": 10044.640433936236,
    "itl": 182.65486837219757,
    "ttft": 2128042.5154438764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.004619472275987,
    "arrivals": 1005871,
    "finished_requests": 77594,
    "scheduler_time": 122.39679035272422
}
#Debug simulation 
Total elapsed time: 6.024617374874651. Arrivals time: 0.24998219683766365 Scheduler time: 5.682719775475562 Scheduler overhead time: 0.03158041648566723 Adapter cache time: 0.013714353553950787 Engine time: 0.03190132277086377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.053141004871577,
    "estimated_duration": 3600.0531532766627,
    "input_throughput": 5335.307614143973,
    "output_throughput": 4709.146859281706,
    "total_throughput": 10044.45447342568,
    "itl": 182.66112694719416,
    "ttft": 2128060.9487905866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.132135953498078,
    "arrivals": 1005871,
    "finished_requests": 77593,
    "scheduler_time": 122.39446304199994
}
#Debug simulation 
Total elapsed time: 6.053228340111673. Arrivals time: 0.3152888105250895 Scheduler time: 5.645859411451966 Scheduler overhead time: 0.03163641830906272 Adapter cache time: 0.013832527678459883 Engine time: 0.03197350725531578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.978159055113792,
    "estimated_duration": 3600.137503181882,
    "input_throughput": 5323.944705739666,
    "output_throughput": 4699.273009724619,
    "total_throughput": 10023.217715464285,
    "itl": 181.0291332831464,
    "ttft": 2129473.801849543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.163206666875637,
    "arrivals": 1005871,
    "finished_requests": 77419,
    "scheduler_time": 122.73257718255513
}
#Debug simulation 
Total elapsed time: 5.978252286091447. Arrivals time: 0.25082242162898183 Scheduler time: 5.634566769003868 Scheduler overhead time: 0.03181754145771265 Adapter cache time: 0.013989006634801626 Engine time: 0.03225016687065363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.045720625203103,
    "estimated_duration": 3600.0851010910274,
    "input_throughput": 5335.267767470018,
    "output_throughput": 4709.191178525792,
    "total_throughput": 10044.45894599581,
    "itl": 182.65798269474288,
    "ttft": 2128059.3894401565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.053685652357515,
    "arrivals": 1005871,
    "finished_requests": 77594,
    "scheduler_time": 122.39780470693832
}
#Debug simulation 
Total elapsed time: 6.045822467189282. Arrivals time: 0.25765499053522944 Scheduler time: 5.696093745529652 Scheduler overhead time: 0.03155139647424221 Adapter cache time: 0.013887928798794746 Engine time: 0.031968630850315094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.009702145121992,
    "estimated_duration": 3600.1617439158163,
    "input_throughput": 5323.9088583705,
    "output_throughput": 4699.241368416585,
    "total_throughput": 10023.150226787086,
    "itl": 181.03018932032876,
    "ttft": 2129484.7610445223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1873513938672864,
    "arrivals": 1005871,
    "finished_requests": 77419,
    "scheduler_time": 122.7326731895167
}
#Debug simulation 
Total elapsed time: 6.009789241943508. Arrivals time: 0.2526273927651346 Scheduler time: 5.664134232793003 Scheduler overhead time: 0.031938920263201 Adapter cache time: 0.014133925084024668 Engine time: 0.032174709253013134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.985883979126811,
    "estimated_duration": 3600.163773694344,
    "input_throughput": 5335.503384694307,
    "output_throughput": 4709.513807090347,
    "total_throughput": 10045.017191784653,
    "itl": 182.65216801950825,
    "ttft": 2128080.357595465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9584829431608923,
    "arrivals": 1005871,
    "finished_requests": 77603,
    "scheduler_time": 122.4034935021673
}
#Debug simulation 
Total elapsed time: 5.985977126751095. Arrivals time: 0.25286769308149815 Scheduler time: 5.640881535597146 Scheduler overhead time: 0.031649761367589235 Adapter cache time: 0.013787053991109133 Engine time: 0.0320423748344183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.072664916981012,
    "estimated_duration": 3600.191879372078,
    "input_throughput": 5323.864294517261,
    "output_throughput": 4699.20203335127,
    "total_throughput": 10023.066327868532,
    "itl": 181.03155801634296,
    "ttft": 2129496.8765028166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.217406548820438,
    "arrivals": 1005871,
    "finished_requests": 77419,
    "scheduler_time": 122.73275349085395
}
#Debug simulation 
Total elapsed time: 6.072753484826535. Arrivals time: 0.2531923712231219 Scheduler time: 5.72656739782542 Scheduler overhead time: 0.03193395538255572 Adapter cache time: 0.014188547153025866 Engine time: 0.032020616345107555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.7526044100522995,
    "estimated_duration": 3600.0335385976323,
    "input_throughput": 5332.371155485942,
    "output_throughput": 4713.338311456352,
    "total_throughput": 10045.709466942293,
    "itl": 182.47355780909976,
    "ttft": 2122961.931779223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5830516558792977,
    "arrivals": 1001073,
    "finished_requests": 77578,
    "scheduler_time": 122.47570736693703
}
#Debug simulation 
Total elapsed time: 5.7526931199245155. Arrivals time: 0.352989190723747 Scheduler time: 5.305945886299014 Scheduler overhead time: 0.031232121866196394 Adapter cache time: 0.0162528189830482 Engine time: 0.03171610971912742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.798086666036397,
    "estimated_duration": 3600.003648567375,
    "input_throughput": 5332.038207138709,
    "output_throughput": 4713.229112073897,
    "total_throughput": 10045.267319212608,
    "itl": 182.48102821760068,
    "ttft": 2122970.6775693907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.758136161682203,
    "arrivals": 1001073,
    "finished_requests": 77575,
    "scheduler_time": 122.46916347909414
}
#Debug simulation 
Total elapsed time: 5.798190938774496. Arrivals time: 0.2554886802099645 Scheduler time: 5.4479797296226025 Scheduler overhead time: 0.03153779450803995 Adapter cache time: 0.01651430269703269 Engine time: 0.03203137405216694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.775245876982808,
    "estimated_duration": 3600.068259675677,
    "input_throughput": 5320.658837098164,
    "output_throughput": 4703.932197531609,
    "total_throughput": 10024.591034629773,
    "itl": 180.43320050333864,
    "ttft": 2124305.5614807494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7853008396364562,
    "arrivals": 1001073,
    "finished_requests": 77400,
    "scheduler_time": 122.92747876208749
}
#Debug simulation 
Total elapsed time: 5.7753568617627025. Arrivals time: 0.2488085525110364 Scheduler time: 5.431439244188368 Scheduler overhead time: 0.031677575781941414 Adapter cache time: 0.01661348482593894 Engine time: 0.0320726721547544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.789228395093232,
    "estimated_duration": 3600.099245076508,
    "input_throughput": 5332.273832798751,
    "output_throughput": 4713.252286921162,
    "total_throughput": 10045.526119719912,
    "itl": 182.47669907208856,
    "ttft": 2122987.5487686964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6486326163401612,
    "arrivals": 1001073,
    "finished_requests": 77578,
    "scheduler_time": 122.47583288527332
}
#Debug simulation 
Total elapsed time: 5.78931617224589. Arrivals time: 0.3572009326890111 Scheduler time: 5.337889079935849 Scheduler overhead time: 0.03136380296200514 Adapter cache time: 0.01635774690657854 Engine time: 0.03191095823422074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.0331860249862075,
    "estimated_duration": 3600.10231490456,
    "input_throughput": 5320.60850623569,
    "output_throughput": 4703.887700605236,
    "total_throughput": 10024.496206840926,
    "itl": 180.43478252306824,
    "ttft": 2124319.436547006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8192543619684876,
    "arrivals": 1001073,
    "finished_requests": 77400,
    "scheduler_time": 122.9275804686708
}
#Debug simulation 
Total elapsed time: 6.033250933978707. Arrivals time: 0.6822768109850585 Scheduler time: 5.2566685420461 Scheduler overhead time: 0.03127529239282012 Adapter cache time: 0.01662483299151063 Engine time: 0.03175552608445287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.759741663001478,
    "estimated_duration": 3600.179206217209,
    "input_throughput": 5332.689819119435,
    "output_throughput": 4713.336761319048,
    "total_throughput": 10046.026580438484,
    "itl": 182.47098978461082,
    "ttft": 2122976.877550406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5236024488973836,
    "arrivals": 1001073,
    "finished_requests": 77584,
    "scheduler_time": 122.48255891595129
}
#Debug simulation 
Total elapsed time: 5.7598299770615995. Arrivals time: 0.36067538894712925 Scheduler time: 5.305186222307384 Scheduler overhead time: 0.03118959441781044 Adapter cache time: 0.01633802568539977 Engine time: 0.0319092464633286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.729368939064443,
    "estimated_duration": 3600.1412589521437,
    "input_throughput": 5320.550951263277,
    "output_throughput": 4703.836816927829,
    "total_throughput": 10024.387768191107,
    "itl": 180.43659900566726,
    "ttft": 2124334.8749007345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.858112281970704,
    "arrivals": 1001073,
    "finished_requests": 77400,
    "scheduler_time": 122.92766659628803
}
#Debug simulation 
Total elapsed time: 5.729472555220127. Arrivals time: 0.2494454332627356 Scheduler time: 5.385290873236954 Scheduler overhead time: 0.03149814158678055 Adapter cache time: 0.016641619615256786 Engine time: 0.031892464961856604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.653332115150988,
    "estimated_duration": 3600.0134031011103,
    "input_throughput": 5365.646967691991,
    "output_throughput": 4760.204499582718,
    "total_throughput": 10125.85146727471,
    "itl": 181.13492415482486,
    "ttft": 2120359.9222483197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.270881905998146,
    "arrivals": 999127,
    "finished_requests": 78270,
    "scheduler_time": 123.58703233938068
}
#Debug simulation 
Total elapsed time: 5.653421235270798. Arrivals time: 0.25100966496393085 Scheduler time: 5.311061941087246 Scheduler overhead time: 0.030635372269898653 Adapter cache time: 0.014891273342072964 Engine time: 0.03140530548989773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.6554281818680465,
    "estimated_duration": 3600.169149102599,
    "input_throughput": 5365.414845803823,
    "output_throughput": 4759.998569587106,
    "total_throughput": 10125.413415390929,
    "itl": 181.1420567722915,
    "ttft": 2120425.476716694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4229149780375936,
    "arrivals": 999127,
    "finished_requests": 78270,
    "scheduler_time": 123.58751754522213
}
#Debug simulation 
Total elapsed time: 5.6555175497196615. Arrivals time: 0.252562640234828 Scheduler time: 5.3113238350488245 Scheduler overhead time: 0.03070004703477025 Adapter cache time: 0.01497137825936079 Engine time: 0.03153255628421903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.674621758982539,
    "estimated_duration": 3600.05247181403,
    "input_throughput": 5355.294166111234,
    "output_throughput": 4751.00575169715,
    "total_throughput": 10106.299917808383,
    "itl": 179.22175472756925,
    "ttft": 2121418.1561821313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4302954993955757,
    "arrivals": 999127,
    "finished_requests": 78102,
    "scheduler_time": 124.03069430254087
}
#Debug simulation 
Total elapsed time: 5.674710016697645. Arrivals time: 0.2533261338248849 Scheduler time: 5.32866337755695 Scheduler overhead time: 0.031051605008542538 Adapter cache time: 0.015296067576855421 Engine time: 0.0317315049469471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.680649525951594,
    "estimated_duration": 3600.07034302342,
    "input_throughput": 5365.562102816483,
    "output_throughput": 4760.129210588739,
    "total_throughput": 10125.691313405223,
    "itl": 181.13765706169042,
    "ttft": 2120382.989649421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.327712268840971,
    "arrivals": 999127,
    "finished_requests": 78270,
    "scheduler_time": 123.58714189877615
}
#Debug simulation 
Total elapsed time: 5.6807518266141415. Arrivals time: 0.25348036643117666 Scheduler time: 5.335410909727216 Scheduler overhead time: 0.03063827659934759 Adapter cache time: 0.015020223800092936 Engine time: 0.03180916700512171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.6455886997282505,
    "estimated_duration": 3600.081866046695,
    "input_throughput": 5355.250440782598,
    "output_throughput": 4750.966960310273,
    "total_throughput": 10106.21740109287,
    "itl": 179.2230746354448,
    "ttft": 2121430.7131346134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.459596131630244,
    "arrivals": 999127,
    "finished_requests": 78102,
    "scheduler_time": 124.03078790299548
}
#Debug simulation 
Total elapsed time: 5.6457015927881. Arrivals time: 0.25070391967892647 Scheduler time: 5.302684545516968 Scheduler overhead time: 0.030942263547331095 Adapter cache time: 0.01489224936813116 Engine time: 0.03195718489587307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.644451554864645,
    "estimated_duration": 3600.164407980663,
    "input_throughput": 5365.588292906582,
    "output_throughput": 4760.042891933408,
    "total_throughput": 10125.63118483999,
    "itl": 181.13196663304146,
    "ttft": 2120400.441838457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2186173188173726,
    "arrivals": 999127,
    "finished_requests": 78273,
    "scheduler_time": 123.5938556077639
}
#Debug simulation 
Total elapsed time: 5.6445362460799515. Arrivals time: 0.25261010881513357 Scheduler time: 5.30050479946658 Scheduler overhead time: 0.0305739832110703 Adapter cache time: 0.014797535724937916 Engine time: 0.0316726821474731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.685957680922002,
    "estimated_duration": 3600.1156427897968,
    "input_throughput": 5355.2001971414675,
    "output_throughput": 4750.922386133656,
    "total_throughput": 10106.122583275122,
    "itl": 179.22465094031682,
    "ttft": 2121444.503216778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.493298146389437,
    "arrivals": 999127,
    "finished_requests": 78102,
    "scheduler_time": 124.03086263136927
}
#Debug simulation 
Total elapsed time: 5.686044217087328. Arrivals time: 0.2541063670068979 Scheduler time: 5.339249823242426 Scheduler overhead time: 0.03119336860254407 Adapter cache time: 0.014988569542765617 Engine time: 0.03186755534261465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.681175279896706,
    "estimated_duration": 3600.0099563909275,
    "input_throughput": 5416.240576053186,
    "output_throughput": 4762.932938438251,
    "total_throughput": 10179.173514491436,
    "itl": 179.6767283229766,
    "ttft": 2115982.3886660975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.160704347216563,
    "arrivals": 998127,
    "finished_requests": 79018,
    "scheduler_time": 123.95479648188478
}
#Debug simulation 
Total elapsed time: 5.681276892777532. Arrivals time: 0.25854165153577924 Scheduler time: 5.331323817837983 Scheduler overhead time: 0.030850478913635015 Adapter cache time: 0.014617569744586945 Engine time: 0.03148323902860284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.685020238161087,
    "estimated_duration": 3600.15189029844,
    "input_throughput": 5416.027043898874,
    "output_throughput": 4762.745162559962,
    "total_throughput": 10178.772206458836,
    "itl": 179.68318661846718,
    "ttft": 2116043.1139309476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3021981172310237,
    "arrivals": 998127,
    "finished_requests": 79018,
    "scheduler_time": 123.95523661934052
}
#Debug simulation 
Total elapsed time: 5.685105727054179. Arrivals time: 0.25234816689044237 Scheduler time: 5.341162745375186 Scheduler overhead time: 0.030811038333922625 Adapter cache time: 0.014697813428938389 Engine time: 0.03164375061169267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.73785752709955,
    "estimated_duration": 3600.182963935641,
    "input_throughput": 5409.238417902844,
    "output_throughput": 4757.255164964491,
    "total_throughput": 10166.493582867335,
    "itl": 178.1759049059606,
    "ttft": 2116474.239229192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.306556134670974,
    "arrivals": 998127,
    "finished_requests": 78921,
    "scheduler_time": 124.31261936915595
}
#Debug simulation 
Total elapsed time: 5.737944335211068. Arrivals time: 0.31721490854397416 Scheduler time: 5.328695002011955 Scheduler overhead time: 0.030860583297908306 Adapter cache time: 0.014733830466866493 Engine time: 0.031772179529070854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.6940085222013295,
    "estimated_duration": 3600.067388198193,
    "input_throughput": 5416.1541708692475,
    "output_throughput": 4762.856955458756,
    "total_throughput": 10179.011126328003,
    "itl": 179.67940200942434,
    "ttft": 2116005.868115178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2180274816322934,
    "arrivals": 998127,
    "finished_requests": 79018,
    "scheduler_time": 123.95490515467242
}
#Debug simulation 
Total elapsed time: 5.6940970327705145. Arrivals time: 0.25291549786925316 Scheduler time: 5.3488521496765316 Scheduler overhead time: 0.030881528742611408 Adapter cache time: 0.014894737862050533 Engine time: 0.03200666978955269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.6933497241698205,
    "estimated_duration": 3600.018020772773,
    "input_throughput": 5408.956812893982,
    "output_throughput": 4756.9095213373375,
    "total_throughput": 10165.86633423132,
    "itl": 178.1759240076094,
    "ttft": 2116440.4627877492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.332461414672436,
    "arrivals": 998127,
    "finished_requests": 78913,
    "scheduler_time": 124.30594733092097
}
#Debug simulation 
Total elapsed time: 5.6934326332993805. Arrivals time: 0.25541078858077526 Scheduler time: 5.345483953598887 Scheduler overhead time: 0.03105073096230626 Adapter cache time: 0.014735281001776457 Engine time: 0.03209970984607935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.6649011159315705,
    "estimated_duration": 3600.16095414023,
    "input_throughput": 5416.535607268975,
    "output_throughput": 4763.435362599075,
    "total_throughput": 10179.970969868049,
    "itl": 179.67677718800786,
    "ttft": 2115974.367386368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.110975508200898,
    "arrivals": 998127,
    "finished_requests": 79027,
    "scheduler_time": 123.96166941137623
}
#Debug simulation 
Total elapsed time: 5.665000963956118. Arrivals time: 0.2531042527407408 Scheduler time: 5.3205797439441085 Scheduler overhead time: 0.030792019329965115 Adapter cache time: 0.014615879394114017 Engine time: 0.031502665020525455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.720716891344637,
    "estimated_duration": 3600.051047552854,
    "input_throughput": 5408.907191256742,
    "output_throughput": 4756.86588156597,
    "total_throughput": 10165.773072822712,
    "itl": 178.17743870459526,
    "ttft": 2116454.2870545452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.365408906713135,
    "arrivals": 998127,
    "finished_requests": 78913,
    "scheduler_time": 124.30602661899214
}
#Debug simulation 
Total elapsed time: 5.720803895033896. Arrivals time: 0.31786190113052726 Scheduler time: 5.310653960332274 Scheduler overhead time: 0.031055268831551075 Adapter cache time: 0.014724514912813902 Engine time: 0.031926661264151335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.781546329148114,
    "estimated_duration": 3600.12780376615,
    "input_throughput": 5449.608755410281,
    "output_throughput": 4818.102841197555,
    "total_throughput": 10267.711596607836,
    "itl": 178.6465618096189,
    "ttft": 2115643.938191786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5149414332467297,
    "arrivals": 995247,
    "finished_requests": 79330,
    "scheduler_time": 125.14619823940741
}
#Debug simulation 
Total elapsed time: 5.781641148030758. Arrivals time: 0.3304484016261995 Scheduler time: 5.362366520334035 Scheduler overhead time: 0.030811797361820936 Adapter cache time: 0.011870596557855606 Engine time: 0.03165785642340779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.018017776310444,
    "estimated_duration": 3600.042579224743,
    "input_throughput": 5449.096106031182,
    "output_throughput": 4817.9296823025725,
    "total_throughput": 10267.025788333754,
    "itl": 178.65120982747908,
    "ttft": 2115635.4953572555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6165457323356596,
    "arrivals": 995247,
    "finished_requests": 79324,
    "scheduler_time": 125.13981561529802
}
#Debug simulation 
Total elapsed time: 6.018083928152919. Arrivals time: 0.5656919907778502 Scheduler time: 5.36365192849189 Scheduler overhead time: 0.030647469218820333 Adapter cache time: 0.011948645114898682 Engine time: 0.031782062724232674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.777829726226628,
    "estimated_duration": 3600.1381175093293,
    "input_throughput": 5435.202584265656,
    "output_throughput": 4808.336356821772,
    "total_throughput": 10243.538941087427,
    "itl": 176.76199687327963,
    "ttft": 2116793.813636318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6191824933141568,
    "arrivals": 995247,
    "finished_requests": 79139,
    "scheduler_time": 125.58110280967404
}
#Debug simulation 
Total elapsed time: 5.777918099891394. Arrivals time: 0.32241371646523476 Scheduler time: 5.365664000157267 Scheduler overhead time: 0.031131878960877657 Adapter cache time: 0.011939972173422575 Engine time: 0.032065280713140965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.792029371019453,
    "estimated_duration": 3600.163706293567,
    "input_throughput": 5449.554409346126,
    "output_throughput": 4818.054792807685,
    "total_throughput": 10267.609202153812,
    "itl": 178.64816161799897,
    "ttft": 2115657.4870371246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5507618860667531,
    "arrivals": 995247,
    "finished_requests": 79330,
    "scheduler_time": 125.1462803139603
}
#Debug simulation 
Total elapsed time: 5.792137188371271. Arrivals time: 0.3186334636993706 Scheduler time: 5.384940335992724 Scheduler overhead time: 0.030715067870914936 Adapter cache time: 0.011816597543656826 Engine time: 0.03158239182084799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.045322335790843,
    "estimated_duration": 3600.1584644355853,
    "input_throughput": 5435.171866266084,
    "output_throughput": 4808.309181666502,
    "total_throughput": 10243.481047932586,
    "itl": 176.76285539939803,
    "ttft": 2116803.071159775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6394288529269447,
    "arrivals": 995247,
    "finished_requests": 79139,
    "scheduler_time": 125.58120337633301
}
#Debug simulation 
Total elapsed time: 6.0453858226537704. Arrivals time: 0.5637048557400703 Scheduler time: 5.391797603107989 Scheduler overhead time: 0.031133821699768305 Adapter cache time: 0.011918360833078623 Engine time: 0.03220650367438793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.80741933407262,
    "estimated_duration": 3600.092801451287,
    "input_throughput": 5449.661739855977,
    "output_throughput": 4818.1496857546235,
    "total_throughput": 10267.8114256106,
    "itl": 178.6450432445974,
    "ttft": 2115628.769112217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4800748959765613,
    "arrivals": 995247,
    "finished_requests": 79330,
    "scheduler_time": 125.14606246175201
}
#Debug simulation 
Total elapsed time: 5.807514983229339. Arrivals time: 0.32551246555522084 Scheduler time: 5.392824982758611 Scheduler overhead time: 0.030799109488725662 Adapter cache time: 0.012026046868413687 Engine time: 0.03180158929899335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.80573897017166,
    "estimated_duration": 3600.1802863362004,
    "input_throughput": 5435.138921865843,
    "output_throughput": 4808.280036891312,
    "total_throughput": 10243.418958757156,
    "itl": 176.76380663039376,
    "ttft": 2116811.8873053496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6611842579767089,
    "arrivals": 995247,
    "finished_requests": 79139,
    "scheduler_time": 125.58126987191983
}
#Debug simulation 
Total elapsed time: 5.80582658899948. Arrivals time: 0.32146602403372526 Scheduler time: 5.394607366062701 Scheduler overhead time: 0.03117447253316641 Adapter cache time: 0.012007132638245821 Engine time: 0.031916748732328415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.815859986003488,
    "estimated_duration": 3600.088376610948,
    "input_throughput": 5529.452312706723,
    "output_throughput": 4836.81931619474,
    "total_throughput": 10366.271628901464,
    "itl": 176.67157765377175,
    "ttft": 2104743.633319745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3282516808668252,
    "arrivals": 994382,
    "finished_requests": 79982,
    "scheduler_time": 125.92700373109962
}
#Debug simulation 
Total elapsed time: 5.815950165037066. Arrivals time: 0.2573030199855566 Scheduler time: 5.469453340396285 Scheduler overhead time: 0.03103450546041131 Adapter cache time: 0.011416040826588869 Engine time: 0.0321658868342638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.904699361883104,
    "estimated_duration": 3600.012974622714,
    "input_throughput": 5529.470071447782,
    "output_throughput": 4836.867567630054,
    "total_throughput": 10366.337639077836,
    "itl": 176.67483461464747,
    "ttft": 2104689.234216375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4194432328827746,
    "arrivals": 994382,
    "finished_requests": 79981,
    "scheduler_time": 125.92153556603314
}
#Debug simulation 
Total elapsed time: 5.9048172468319535. Arrivals time: 0.3739286153577268 Scheduler time: 5.441144162323326 Scheduler overhead time: 0.03119976492598653 Adapter cache time: 0.011429047677665949 Engine time: 0.03238216694444418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.806785699911416,
    "estimated_duration": 3600.135134564987,
    "input_throughput": 5518.173417787685,
    "output_throughput": 4826.78103751228,
    "total_throughput": 10344.954455299965,
    "itl": 174.92148270141558,
    "ttft": 2105726.765578606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.418006167393186,
    "arrivals": 994382,
    "finished_requests": 79810,
    "scheduler_time": 126.33414672093525
}
#Debug simulation 
Total elapsed time: 5.806873721070588. Arrivals time: 0.36438186233863235 Scheduler time: 5.352361746132374 Scheduler overhead time: 0.031436603516340256 Adapter cache time: 0.011417573317885399 Engine time: 0.032481304835528135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.83645897731185,
    "estimated_duration": 3600.1471009622805,
    "input_throughput": 5529.362118197671,
    "output_throughput": 4836.74041967499,
    "total_throughput": 10366.10253787266,
    "itl": 176.6727724735089,
    "ttft": 2104758.6850131936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.361831292982678,
    "arrivals": 994382,
    "finished_requests": 79982,
    "scheduler_time": 125.92800278960435
}
#Debug simulation 
Total elapsed time: 5.836546550039202. Arrivals time: 0.36192303244024515 Scheduler time: 5.385216565802693 Scheduler overhead time: 0.031101925298571587 Adapter cache time: 0.011341641657054424 Engine time: 0.03236461477354169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.852375117130578,
    "estimated_duration": 3600.1529686953622,
    "input_throughput": 5518.14608233138,
    "output_throughput": 4826.757127016514,
    "total_throughput": 10344.903209347895,
    "itl": 174.92218264634175,
    "ttft": 2105734.709062117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4357374512776777,
    "arrivals": 994382,
    "finished_requests": 79810,
    "scheduler_time": 126.33424956744287
}
#Debug simulation 
Total elapsed time: 5.852470708079636. Arrivals time: 0.3686033980920911 Scheduler time: 5.3935762494802475 Scheduler overhead time: 0.03143366053700447 Adapter cache time: 0.011358949355781078 Engine time: 0.03267033910378814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.144344280008227,
    "estimated_duration": 3600.0576536282833,
    "input_throughput": 5529.49950119199,
    "output_throughput": 4836.860593732576,
    "total_throughput": 10366.360094924565,
    "itl": 176.67028322725864,
    "ttft": 2104730.147065586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297681827987535,
    "arrivals": 994382,
    "finished_requests": 79982,
    "scheduler_time": 125.9268506012625
}
#Debug simulation 
Total elapsed time: 6.1444066180847585. Arrivals time: 0.6899831681512296 Scheduler time: 5.365258162841201 Scheduler overhead time: 0.031105756759643555 Adapter cache time: 0.011220379266887903 Engine time: 0.03221729816868901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.795559839811176,
    "estimated_duration": 3600.172661014399,
    "input_throughput": 5518.115899030917,
    "output_throughput": 4826.7307254935295,
    "total_throughput": 10344.846624524445,
    "itl": 174.92303570992124,
    "ttft": 2105743.096322326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4553550419583916,
    "arrivals": 994382,
    "finished_requests": 79810,
    "scheduler_time": 126.33432429581666
}
#Debug simulation 
Total elapsed time: 5.79566051857546. Arrivals time: 0.3617565082386136 Scheduler time: 5.344514036085457 Scheduler overhead time: 0.03119349665939808 Adapter cache time: 0.011326550506055355 Engine time: 0.032220407854765654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.0406445120461285,
    "estimated_duration": 3600.0864140594995,
    "input_throughput": 5516.154535192719,
    "output_throughput": 4870.7369721793,
    "total_throughput": 10386.891507372018,
    "itl": 176.4882525800346,
    "ttft": 2109028.4997892985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0130214432417406,
    "arrivals": 992438,
    "finished_requests": 80432,
    "scheduler_time": 126.58116649339314
}
#Debug simulation 
Total elapsed time: 6.040711910929531. Arrivals time: 0.5658623478375375 Scheduler time: 5.387582548893988 Scheduler overhead time: 0.03098021261394024 Adapter cache time: 0.009415936656296253 Engine time: 0.03226795606315136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.738347512669861,
    "estimated_duration": 3600.1517379806432,
    "input_throughput": 5516.054445843686,
    "output_throughput": 4870.648593782766,
    "total_throughput": 10386.70303962645,
    "itl": 176.49082571472604,
    "ttft": 2109059.4215221023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.077963236395741,
    "arrivals": 992438,
    "finished_requests": 80432,
    "scheduler_time": 126.5815486213655
}
#Debug simulation 
Total elapsed time: 5.738450537901372. Arrivals time: 0.2562366221100092 Scheduler time: 5.39481612900272 Scheduler overhead time: 0.03102961601689458 Adapter cache time: 0.009509007446467876 Engine time: 0.032241382636129856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.776523082982749,
    "estimated_duration": 3600.116211816979,
    "input_throughput": 5502.338767559497,
    "output_throughput": 4859.986725586701,
    "total_throughput": 10362.325493146198,
    "itl": 174.77245828762088,
    "ttft": 2110529.8119078213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0772066789120494,
    "arrivals": 992438,
    "finished_requests": 80239,
    "scheduler_time": 126.97229988029511
}
#Debug simulation 
Total elapsed time: 5.77661701804027. Arrivals time: 0.25592475663870573 Scheduler time: 5.432261000853032 Scheduler overhead time: 0.03151729330420494 Adapter cache time: 0.009638529270887375 Engine time: 0.03246349934488535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.0868972558528185,
    "estimated_duration": 3600.1117993683292,
    "input_throughput": 5516.115639376635,
    "output_throughput": 4870.702627367484,
    "total_throughput": 10386.818266744118,
    "itl": 176.48936686161508,
    "ttft": 2109039.6840698575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.038329490507025,
    "arrivals": 992438,
    "finished_requests": 80432,
    "scheduler_time": 126.58124375493213
}
#Debug simulation 
Total elapsed time: 6.086989847011864. Arrivals time: 0.5693832137621939 Scheduler time: 5.429656045511365 Scheduler overhead time: 0.03125706687569618 Adapter cache time: 0.009580460842698812 Engine time: 0.03238030197098851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.768353150226176,
    "estimated_duration": 3600.1284994816424,
    "input_throughput": 5502.319987426052,
    "output_throughput": 4859.970137876801,
    "total_throughput": 10362.290125302852,
    "itl": 174.77290815078857,
    "ttft": 2110535.871023177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0894047961942905,
    "arrivals": 992438,
    "finished_requests": 80239,
    "scheduler_time": 126.97238942768536
}
#Debug simulation 
Total elapsed time: 5.768440769985318. Arrivals time: 0.2596777491271496 Scheduler time: 5.420441852416843 Scheduler overhead time: 0.03135045478120446 Adapter cache time: 0.009695151820778847 Engine time: 0.03254549903795123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.800642630085349,
    "estimated_duration": 3600.0629596865047,
    "input_throughput": 5516.190472882536,
    "output_throughput": 4870.768704980361,
    "total_throughput": 10386.959177862896,
    "itl": 176.48730831436285,
    "ttft": 2109017.356659337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9897066476126215,
    "arrivals": 992438,
    "finished_requests": 80432,
    "scheduler_time": 126.58102691598992
}
#Debug simulation 
Total elapsed time: 5.800749042071402. Arrivals time: 0.25921103172004223 Scheduler time: 5.453687699045986 Scheduler overhead time: 0.031147381756454706 Adapter cache time: 0.009523924440145493 Engine time: 0.03240277851000428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.0738491411320865,
    "estimated_duration": 3600.143534097574,
    "input_throughput": 5502.29700910117,
    "output_throughput": 4859.9498420792115,
    "total_throughput": 10362.246851180382,
    "itl": 174.77353123541525,
    "ttft": 2110542.7294097976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.104369496777658,
    "arrivals": 992438,
    "finished_requests": 80239,
    "scheduler_time": 126.97245934304524
}
#Debug simulation 
Total elapsed time: 6.0739146820269525. Arrivals time: 0.5683482252061367 Scheduler time: 5.41708775376901 Scheduler overhead time: 0.03150339191779494 Adapter cache time: 0.009621949400752783 Engine time: 0.03258470119908452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 55.61045261286199,
    "estimated_duration": 3600.058659320223,
    "input_throughput": 5375.7054624366265,
    "output_throughput": 4731.598735454058,
    "total_throughput": 10107.304197890686,
    "itl": 180.779582079902,
    "ttft": 2104854.070296024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5669697248935883,
    "arrivals": 861811,
    "finished_requests": 78147,
    "scheduler_time": 123.0841920537985
}
#Debug simulation 
Total elapsed time: 55.610590847209096. Arrivals time: 0.37169503048062325 Scheduler time: 55.11284874426201 Scheduler overhead time: 0.04653487214818597 Adapter cache time: 0.014557096175849438 Engine time: 0.04683014750480652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 55.27355941804126,
    "estimated_duration": 3600.043775571286,
    "input_throughput": 5375.242693244529,
    "output_throughput": 4733.467719374005,
    "total_throughput": 10108.710412618535,
    "itl": 180.73826678703605,
    "ttft": 2104732.343176514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6595023393537907,
    "arrivals": 861811,
    "finished_requests": 78143,
    "scheduler_time": 123.10178869189996
}
#Debug simulation 
Total elapsed time: 55.27369570080191. Arrivals time: 0.37322130938991904 Scheduler time: 54.77505951281637 Scheduler overhead time: 0.04631642019376159 Adapter cache time: 0.01473173825070262 Engine time: 0.04639824153855443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 56.83232662221417,
    "estimated_duration": 3600.0320116597713,
    "input_throughput": 5354.883772578488,
    "output_throughput": 4713.717251690856,
    "total_throughput": 10068.601024269345,
    "itl": 179.64161901434179,
    "ttft": 2099089.6148754805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7764005653746535,
    "arrivals": 861811,
    "finished_requests": 77765,
    "scheduler_time": 123.10536277365773
}
#Debug simulation 
Total elapsed time: 56.832469169050455. Arrivals time: 0.659426084253937 Scheduler time: 56.04507266357541 Scheduler overhead time: 0.04768909187987447 Adapter cache time: 0.015415931586176157 Engine time: 0.046847663819789886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 55.72722348989919,
    "estimated_duration": 3600.091424027614,
    "input_throughput": 5375.65653773007,
    "output_throughput": 4731.555672812086,
    "total_throughput": 10107.212210542157,
    "itl": 180.78094910043217,
    "ttft": 2104868.1339166067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5995497644878844,
    "arrivals": 861811,
    "finished_requests": 78147,
    "scheduler_time": 123.08437672154251
}
#Debug simulation 
Total elapsed time: 55.727411970030516. Arrivals time: 0.37868847232311964 Scheduler time: 55.220954046584666 Scheduler overhead time: 0.04686023574322462 Adapter cache time: 0.015145496930927038 Engine time: 0.04762041429057717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 56.59965528175235,
    "estimated_duration": 3600.054245526113,
    "input_throughput": 5354.850700918465,
    "output_throughput": 4713.688139863034,
    "total_throughput": 10068.538840781499,
    "itl": 179.64255152259776,
    "ttft": 2099098.9990386595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7985332317836624,
    "arrivals": 861811,
    "finished_requests": 77765,
    "scheduler_time": 123.10546397360798
}
#Debug simulation 
Total elapsed time: 56.599795673042536. Arrivals time: 0.36320994794368744 Scheduler time: 56.10831418912858 Scheduler overhead time: 0.047488296404480934 Adapter cache time: 0.015251674689352512 Engine time: 0.04737404827028513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 55.65505124395713,
    "estimated_duration": 3600.0224197980374,
    "input_throughput": 5375.759576821109,
    "output_throughput": 4731.646365956692,
    "total_throughput": 10107.405942777801,
    "itl": 180.77804194140117,
    "ttft": 2104839.9303453024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5309057509898965,
    "arrivals": 861811,
    "finished_requests": 78147,
    "scheduler_time": 123.08401650544924
}
#Debug simulation 
Total elapsed time: 55.65518450317904. Arrivals time: 0.6661957870237529 Scheduler time: 54.862618138082325 Scheduler overhead time: 0.04641628637909889 Adapter cache time: 0.014753111638128757 Engine time: 0.04680321924388409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_96_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 56.844305546954274,
    "estimated_duration": 3600.0783701322853,
    "input_throughput": 5354.814817348445,
    "output_throughput": 4713.656552809002,
    "total_throughput": 10068.471370157447,
    "itl": 179.64358087626871,
    "ttft": 2099109.0050445674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8225522049888931,
    "arrivals": 861811,
    "finished_requests": 77765,
    "scheduler_time": 123.10556960659736
}
#Debug simulation 
Total elapsed time: 56.84444752102718. Arrivals time: 0.37198464618995786 Scheduler time: 56.34348452370614 Scheduler overhead time: 0.04773885942995548 Adapter cache time: 0.015520128887146711 Engine time: 0.04740499472245574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 52.34234971413389,
    "estimated_duration": 3600.184761534667,
    "input_throughput": 5372.207339646494,
    "output_throughput": 4704.555216432857,
    "total_throughput": 10076.762556079351,
    "itl": 181.73166147024784,
    "ttft": 2085344.1049644025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.206611663375556,
    "arrivals": 769968,
    "finished_requests": 77871,
    "scheduler_time": 122.23746460459084
}
#Debug simulation 
Total elapsed time: 52.34248182736337. Arrivals time: 0.3592705326154828 Scheduler time: 51.85815728176385 Scheduler overhead time: 0.044852773658931255 Adapter cache time: 0.017575953621417284 Engine time: 0.045100023970007896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 52.589674671180546,
    "estimated_duration": 3600.125637251724,
    "input_throughput": 5372.1705709038,
    "output_throughput": 4704.531648770278,
    "total_throughput": 10076.702219674076,
    "itl": 181.73770533445418,
    "ttft": 2085384.928054172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3535863967496025,
    "arrivals": 769968,
    "finished_requests": 77869,
    "scheduler_time": 122.23095383234808
}
#Debug simulation 
Total elapsed time: 52.58978463290259. Arrivals time: 0.3507014103233814 Scheduler time: 52.11309571983293 Scheduler overhead time: 0.045707583893090487 Adapter cache time: 0.018001829739660025 Engine time: 0.04483479494228959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 37.01662819599733,
    "estimated_duration": 3600.0220708676684,
    "input_throughput": 5358.411037560854,
    "output_throughput": 4693.721779302149,
    "total_throughput": 10052.132816863004,
    "itl": 179.8747292924568,
    "ttft": 2092079.9633146517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5509996366687027,
    "arrivals": 769968,
    "finished_requests": 77646,
    "scheduler_time": 122.61121574052486
}
#Debug simulation 
Total elapsed time: 37.01677044201642. Arrivals time: 0.3930132510140538 Scheduler time: 36.50090461829677 Scheduler overhead time: 0.04313113633543253 Adapter cache time: 0.019073807634413242 Engine time: 0.043233003467321396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 52.22017524484545,
    "estimated_duration": 3600.0260086385947,
    "input_throughput": 5372.319242580668,
    "output_throughput": 4704.661843930664,
    "total_throughput": 10076.981086511332,
    "itl": 181.73320231205622,
    "ttft": 2085341.553228841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2542977343685746,
    "arrivals": 769968,
    "finished_requests": 77869,
    "scheduler_time": 122.23061388157653
}
#Debug simulation 
Total elapsed time: 52.2203480489552. Arrivals time: 0.361463728826493 Scheduler time: 51.73283952381462 Scheduler overhead time: 0.0450295121408999 Adapter cache time: 0.018094880506396294 Engine time: 0.04492649668827653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 33.48579739499837,
    "estimated_duration": 3600.1568463364006,
    "input_throughput": 5350.3796701528845,
    "output_throughput": 4694.262700581476,
    "total_throughput": 10044.64237073436,
    "itl": 180.16866331218569,
    "ttft": 2092179.4056722196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5834384013712453,
    "arrivals": 769968,
    "finished_requests": 77658,
    "scheduler_time": 122.56136497052105
}
#Debug simulation 
Total elapsed time: 33.48588663386181. Arrivals time: 0.33518229238688946 Scheduler time: 33.028507919982076 Scheduler overhead time: 0.042944103479385376 Adapter cache time: 0.019179699011147022 Engine time: 0.043014767579734325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 52.383849021047354,
    "estimated_duration": 3600.133808438461,
    "input_throughput": 5372.283373097465,
    "output_throughput": 4704.6218005287,
    "total_throughput": 10076.905173626166,
    "itl": 181.72935322208576,
    "ttft": 2085322.4549945348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.155826262624429,
    "arrivals": 769968,
    "finished_requests": 77871,
    "scheduler_time": 122.23729690905374
}
#Debug simulation 
Total elapsed time: 52.383982102852315. Arrivals time: 0.34955385234206915 Scheduler time: 51.90767005831003 Scheduler overhead time: 0.04514354467391968 Adapter cache time: 0.01819791691377759 Engine time: 0.04528820374980569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_96_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 33.42904935311526,
    "estimated_duration": 3600.1891418988894,
    "input_throughput": 5350.331674474279,
    "output_throughput": 4694.220590612135,
    "total_throughput": 10044.552265086413,
    "itl": 180.17009442884466,
    "ttft": 2092193.171677275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.61563137069346,
    "arrivals": 769968,
    "finished_requests": 77658,
    "scheduler_time": 122.56146756371217
}
#Debug simulation 
Total elapsed time: 33.42918455787003. Arrivals time: 0.335731019731611 Scheduler time: 32.9717621775344 Scheduler overhead time: 0.043028547428548336 Adapter cache time: 0.018955701030790806 Engine time: 0.04254584200680256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 48.96997620211914,
    "estimated_duration": 3600.0028165597737,
    "input_throughput": 5365.236080136633,
    "output_throughput": 4706.746317546572,
    "total_throughput": 10071.982397683205,
    "itl": 181.774034149481,
    "ttft": 2090161.8005338628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1545833717286973,
    "arrivals": 754714,
    "finished_requests": 77903,
    "scheduler_time": 122.21499508346376
}
#Debug simulation 
Total elapsed time: 48.97011599969119. Arrivals time: 0.42055636271834373 Scheduler time: 48.426494635175914 Scheduler overhead time: 0.04405614547431469 Adapter cache time: 0.017765519209206104 Engine time: 0.04323867056518793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 47.37355391308665,
    "estimated_duration": 3600.0596496842904,
    "input_throughput": 5366.947462021746,
    "output_throughput": 4706.1709106641565,
    "total_throughput": 10073.118372685902,
    "itl": 181.7553810316719,
    "ttft": 2090862.3872526272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5345128587726564,
    "arrivals": 754714,
    "finished_requests": 77907,
    "scheduler_time": 122.22322104171116
}
#Debug simulation 
Total elapsed time: 47.3736954103224. Arrivals time: 0.41901293490082026 Scheduler time: 46.831817417405546 Scheduler overhead time: 0.043881417252123356 Adapter cache time: 0.018115089274942875 Engine time: 0.04342556232586503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 41.8356490759179,
    "estimated_duration": 3600.0951211041665,
    "input_throughput": 5349.314490916414,
    "output_throughput": 4693.075163752357,
    "total_throughput": 10042.389654668772,
    "itl": 179.59348383414113,
    "ttft": 2092164.914909571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7200545366294535,
    "arrivals": 754714,
    "finished_requests": 77657,
    "scheduler_time": 122.65119409120094
}
#Debug simulation 
Total elapsed time: 41.835787083022296. Arrivals time: 0.4168880023062229 Scheduler time: 41.29498556163162 Scheduler overhead time: 0.04367296025156975 Adapter cache time: 0.018722154200077057 Engine time: 0.04379474883899093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 47.188252351246774,
    "estimated_duration": 3600.029035642113,
    "input_throughput": 5367.616429947317,
    "output_throughput": 4703.736784439482,
    "total_throughput": 10071.353214386798,
    "itl": 181.70816221851553,
    "ttft": 2090775.1659844134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.689527300645107,
    "arrivals": 754714,
    "finished_requests": 77884,
    "scheduler_time": 122.23202625999029
}
#Debug simulation 
Total elapsed time: 47.18842506501824. Arrivals time: 0.6215440738014877 Scheduler time: 46.44277266552672 Scheduler overhead time: 0.04344748193398118 Adapter cache time: 0.019793629180639982 Engine time: 0.04332368588075042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_96_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 41.96241413522512,
    "estimated_duration": 3600.1328973515765,
    "input_throughput": 5349.2583604808315,
    "output_throughput": 4693.0259192456815,
    "total_throughput": 10042.284279726513,
    "itl": 179.5945837535971,
    "ttft": 2092181.0489584887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.755894365757707,
    "arrivals": 754714,
    "finished_requests": 77657,
    "scheduler_time": 122.65143801849835
}
#Debug simulation 
Total elapsed time: 41.962540389969945. Arrivals time: 0.41222244454547763 Scheduler time: 41.427351175341755 Scheduler overhead time: 0.04345916258171201 Adapter cache time: 0.01897444436326623 Engine time: 0.04306659568101168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_96_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 49.04713385505602,
    "estimated_duration": 3600.1532428142336,
    "input_throughput": 5365.210505567547,
    "output_throughput": 4707.20601513974,
    "total_throughput": 10072.416520707287,
    "itl": 181.77292750531473,
    "ttft": 2090161.7204910468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.104995407611094,
    "arrivals": 754714,
    "finished_requests": 77908,
    "scheduler_time": 122.22170514957337
}
#Debug simulation 
Total elapsed time: 49.047238775063306. Arrivals time: 0.33027628995478153 Scheduler time: 48.594777152407914 Scheduler overhead time: 0.04364476399496198 Adapter cache time: 0.01766203949227929 Engine time: 0.04351835884153843 
