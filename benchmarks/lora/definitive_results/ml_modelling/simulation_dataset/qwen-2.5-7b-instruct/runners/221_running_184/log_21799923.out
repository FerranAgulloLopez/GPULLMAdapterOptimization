INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.474077178165317,
    "estimated_duration": 3600.0585501621767,
    "input_throughput": 4623.942018734697,
    "output_throughput": 4073.4898601411287,
    "total_throughput": 8697.431878875825,
    "itl": 210.26790015532762,
    "ttft": 2042495.031926672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9839484757510806,
    "arrivals": 376270,
    "finished_requests": 67332,
    "scheduler_time": 108.84893896445172
}
#Debug simulation 
Total elapsed time: 8.474220784381032. Arrivals time: 0.25310600036755204 Scheduler time: 8.132882670033723 Scheduler overhead time: 0.029064489528536797 Adapter cache time: 0.01608626777306199 Engine time: 0.029755452182143927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.157630704343319,
    "estimated_duration": 3600.038400216179,
    "input_throughput": 4432.392998652961,
    "output_throughput": 3911.264112947925,
    "total_throughput": 8343.657111600885,
    "itl": 179.14199658592167,
    "ttft": 2072006.9729206015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 975,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.223310416378081,
    "arrivals": 376270,
    "finished_requests": 64555,
    "scheduler_time": 115.00090073959865
}
#Debug simulation 
Total elapsed time: 6.15773735428229. Arrivals time: 0.22608442045748234 Scheduler time: 5.828064962290227 Scheduler overhead time: 0.03247958421707153 Adapter cache time: 0.022761231753975153 Engine time: 0.033173035364598036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.488475682213902,
    "estimated_duration": 3600.167822076541,
    "input_throughput": 4624.036940144084,
    "output_throughput": 4073.3581668260963,
    "total_throughput": 8697.39510697018,
    "itl": 210.25280013039296,
    "ttft": 2042496.3003670776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8927018366730468,
    "arrivals": 376270,
    "finished_requests": 67334,
    "scheduler_time": 108.85575784658099
}
#Debug simulation 
Total elapsed time: 8.488572163973004. Arrivals time: 0.2467299592681229 Scheduler time: 8.154131905175745 Scheduler overhead time: 0.029193586204200983 Adapter cache time: 0.01549881836399436 Engine time: 0.02979294676333666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.153727165888995,
    "estimated_duration": 3600.035181753424,
    "input_throughput": 4431.14169574041,
    "output_throughput": 3910.851502607433,
    "total_throughput": 8341.993198347842,
    "itl": 179.2384942486374,
    "ttft": 2071774.9011433267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.306755941472989,
    "arrivals": 376270,
    "finished_requests": 64532,
    "scheduler_time": 114.97866616418466
}
#Debug simulation 
Total elapsed time: 6.1538219368085265. Arrivals time: 0.24014289351180196 Scheduler time: 5.810556937009096 Scheduler overhead time: 0.032269558403640985 Adapter cache time: 0.022631447296589613 Engine time: 0.03307270212098956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.573091669939458,
    "estimated_duration": 3600.209602858927,
    "input_throughput": 4636.884193282382,
    "output_throughput": 4073.4072783857987,
    "total_throughput": 8710.29147166818,
    "itl": 209.87911657910092,
    "ttft": 2035020.6873543784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551667286173924,
    "arrivals": 373284,
    "finished_requests": 67486,
    "scheduler_time": 108.81747161357042
}
#Debug simulation 
Total elapsed time: 8.573213555850089. Arrivals time: 0.24159004911780357 Scheduler time: 8.244011348579079 Scheduler overhead time: 0.030076796654611826 Adapter cache time: 0.01342852134257555 Engine time: 0.030782958026975393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.589689747896045,
    "estimated_duration": 3600.048421346191,
    "input_throughput": 4634.062947898258,
    "output_throughput": 4072.849385319425,
    "total_throughput": 8706.912333217682,
    "itl": 209.90791078803255,
    "ttft": 2035233.4833498944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6758082598494408,
    "arrivals": 373284,
    "finished_requests": 67453,
    "scheduler_time": 108.80426774002434
}
#Debug simulation 
Total elapsed time: 8.589791839942336. Arrivals time: 0.24712430499494076 Scheduler time: 8.255568177904934 Scheduler overhead time: 0.029687771573662758 Adapter cache time: 0.013372561894357204 Engine time: 0.030728407204151154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.766216775868088,
    "estimated_duration": 3600.1609812786573,
    "input_throughput": 4447.6686135054315,
    "output_throughput": 3910.673459662792,
    "total_throughput": 8358.342073168224,
    "itl": 179.176713378701,
    "ttft": 2064663.7378402762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6669740176200754,
    "arrivals": 373284,
    "finished_requests": 64787,
    "scheduler_time": 114.88318961037284
}
#Debug simulation 
Total elapsed time: 5.766330575104803. Arrivals time: 0.23070067446678877 Scheduler time: 5.4351311745122075 Scheduler overhead time: 0.03255977062508464 Adapter cache time: 0.01969172665849328 Engine time: 0.033109334763139486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.5505939447321,
    "estimated_duration": 3600.110045588753,
    "input_throughput": 4637.012421455007,
    "output_throughput": 4073.5199241949013,
    "total_throughput": 8710.532345649908,
    "itl": 209.88163163579114,
    "ttft": 2034969.9268950347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.587868275560898,
    "arrivals": 373284,
    "finished_requests": 67486,
    "scheduler_time": 108.81362038896569
}
#Debug simulation 
Total elapsed time: 8.550720585044473. Arrivals time: 0.24427191633731127 Scheduler time: 8.220270276069641 Scheduler overhead time: 0.02919651661068201 Adapter cache time: 0.013172670733183622 Engine time: 0.03054619114845991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.748094173148274,
    "estimated_duration": 3600.062441861832,
    "input_throughput": 4446.763982160507,
    "output_throughput": 3910.9027210979584,
    "total_throughput": 8357.666703258465,
    "itl": 179.18695427064034,
    "ttft": 2064421.1267004549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.71281580610201,
    "arrivals": 373284,
    "finished_requests": 64772,
    "scheduler_time": 114.87850981325785
}
#Debug simulation 
Total elapsed time: 5.748190778773278. Arrivals time: 0.24393319338560104 Scheduler time: 5.403507329989225 Scheduler overhead time: 0.03240639390423894 Adapter cache time: 0.019999193493276834 Engine time: 0.033260549418628216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.48321349080652,
    "estimated_duration": 3600.0867931591356,
    "input_throughput": 4644.205531869504,
    "output_throughput": 4071.6165587600212,
    "total_throughput": 8715.822090629525,
    "itl": 209.70189220895938,
    "ttft": 2035284.013840413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6116371089522523,
    "arrivals": 373284,
    "finished_requests": 67538,
    "scheduler_time": 108.83894561920829
}
#Debug simulation 
Total elapsed time: 8.483312080614269. Arrivals time: 0.24594051064923406 Scheduler time: 8.149469027295709 Scheduler overhead time: 0.02965322695672512 Adapter cache time: 0.01410223264247179 Engine time: 0.03079028520733118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.748514400795102,
    "estimated_duration": 3600.1387230008218,
    "input_throughput": 4447.491952936155,
    "output_throughput": 3910.9004078220864,
    "total_throughput": 8358.392360758242,
    "itl": 179.18749123411587,
    "ttft": 2064482.1705719524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7437861215323402,
    "arrivals": 373284,
    "finished_requests": 64783,
    "scheduler_time": 114.88012796699023
}
#Debug simulation 
Total elapsed time: 5.748610302805901. Arrivals time: 0.22508214320987463 Scheduler time: 5.422415817156434 Scheduler overhead time: 0.03269970417022705 Adapter cache time: 0.020050049759447575 Engine time: 0.03323343116790056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 28.83793711895123,
    "estimated_duration": 3600.2013442361454,
    "input_throughput": 4616.603742623849,
    "output_throughput": 4077.1997442588554,
    "total_throughput": 8693.803486882704,
    "itl": 209.21900445458851,
    "ttft": 1933269.2874511012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.705471165636612,
    "arrivals": 253064,
    "finished_requests": 67314,
    "scheduler_time": 107.66458418671863
}
#Debug simulation 
Total elapsed time: 28.838054096791893. Arrivals time: 0.31475420389324427 Scheduler time: 28.406106491107494 Scheduler overhead time: 0.04032932873815298 Adapter cache time: 0.02189565682783723 Engine time: 0.03950697975233197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 30.202306415885687,
    "estimated_duration": 3600.0424676668117,
    "input_throughput": 4611.429489819139,
    "output_throughput": 4071.2316956357877,
    "total_throughput": 8682.661185454926,
    "itl": 209.44659923525268,
    "ttft": 1927375.5253172156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5622405020636556,
    "arrivals": 253064,
    "finished_requests": 67199,
    "scheduler_time": 107.50422951386388
}
#Debug simulation 
Total elapsed time: 30.202426018659025. Arrivals time: 0.31507592741400003 Scheduler time: 29.770822159945965 Scheduler overhead time: 0.04105763928964734 Adapter cache time: 0.02063012309372425 Engine time: 0.03935180464759469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.828574617858976,
    "estimated_duration": 3600.0801938319187,
    "input_throughput": 4418.336576849777,
    "output_throughput": 3907.954612817954,
    "total_throughput": 8326.29118966773,
    "itl": 178.85038085997076,
    "ttft": 1970164.9028224603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.414428515285193,
    "arrivals": 253064,
    "finished_requests": 64421,
    "scheduler_time": 113.2194951915771
}
#Debug simulation 
Total elapsed time: 15.828721953555942. Arrivals time: 0.27060212288051844 Scheduler time: 15.425156621262431 Scheduler overhead time: 0.03878260077908635 Adapter cache time: 0.03942868439480662 Engine time: 0.038655337411910295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 28.86197701888159,
    "estimated_duration": 3600.0299997259417,
    "input_throughput": 4616.174032234481,
    "output_throughput": 4077.154635132868,
    "total_throughput": 8693.32866736735,
    "itl": 209.22350492035687,
    "ttft": 1933301.791083281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7637400796333993,
    "arrivals": 253064,
    "finished_requests": 67306,
    "scheduler_time": 107.65786885753255
}
#Debug simulation 
Total elapsed time: 28.862096636090428. Arrivals time: 0.314561537001282 Scheduler time: 28.429093407001346 Scheduler overhead time: 0.042195257265120745 Adapter cache time: 0.021864977665245533 Engine time: 0.03898670105263591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 15.842687053140253,
    "estimated_duration": 3600.201956519027,
    "input_throughput": 4416.384745086166,
    "output_throughput": 3909.8589940243555,
    "total_throughput": 8326.243739110521,
    "itl": 178.7935596471139,
    "ttft": 1969724.9831465024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.427011770866745,
    "arrivals": 253064,
    "finished_requests": 64394,
    "scheduler_time": 113.29681076069299
}
#Debug simulation 
Total elapsed time: 15.842812570277601. Arrivals time: 0.27285725623369217 Scheduler time: 15.439179670065641 Scheduler overhead time: 0.038315446581691504 Adapter cache time: 0.038403397891670465 Engine time: 0.038044555112719536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 28.77871697722003,
    "estimated_duration": 3600.080237914972,
    "input_throughput": 4621.1678353133775,
    "output_throughput": 4076.5785843983804,
    "total_throughput": 8697.746419711759,
    "itl": 209.51690986340898,
    "ttft": 1934367.4301969097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.708985567181312,
    "arrivals": 253064,
    "finished_requests": 67337,
    "scheduler_time": 107.4966498503187
}
#Debug simulation 
Total elapsed time: 28.778887799941003. Arrivals time: 0.31498209619894624 Scheduler time: 28.34860899252817 Scheduler overhead time: 0.039349880535155535 Adapter cache time: 0.0221463767811656 Engine time: 0.038867197930812836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.555400003679097,
    "estimated_duration": 3600.0167458016276,
    "input_throughput": 4414.328632924554,
    "output_throughput": 3906.7368273777993,
    "total_throughput": 8321.065460302354,
    "itl": 178.9915618381172,
    "ttft": 1968641.9212208411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.978990782164001,
    "arrivals": 253064,
    "finished_requests": 64383,
    "scheduler_time": 113.1801266290208
}
#Debug simulation 
Total elapsed time: 15.555498742032796. Arrivals time: 0.27314433129504323 Scheduler time: 15.154641337692738 Scheduler overhead time: 0.037841996643692255 Adapter cache time: 0.03533719712868333 Engine time: 0.03849005699157715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 41.938163090031594,
    "estimated_duration": 3600.045517542783,
    "input_throughput": 4638.10385691924,
    "output_throughput": 4092.194648154174,
    "total_throughput": 8730.298505073413,
    "itl": 209.5999367813107,
    "ttft": 1903589.0680041336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3504545873404004,
    "arrivals": 241330,
    "finished_requests": 67389,
    "scheduler_time": 107.4043579777041
}
#Debug simulation 
Total elapsed time: 41.938314964063466. Arrivals time: 0.32165891863405704 Scheduler time: 41.491747949272394 Scheduler overhead time: 0.04373811883851886 Adapter cache time: 0.022486406844109297 Engine time: 0.042465778067708015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 41.381159650627524,
    "estimated_duration": 3600.0581646703527,
    "input_throughput": 4650.855412368912,
    "output_throughput": 4101.869004483757,
    "total_throughput": 8752.724416852669,
    "itl": 209.04459403812822,
    "ttft": 1914634.0726989796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.257755958125933,
    "arrivals": 241330,
    "finished_requests": 67559,
    "scheduler_time": 107.7297028562179
}
#Debug simulation 
Total elapsed time: 41.38133676489815. Arrivals time: 0.3249436807818711 Scheduler time: 40.93208191264421 Scheduler overhead time: 0.044313115533441305 Adapter cache time: 0.021078507881611586 Engine time: 0.04280082229524851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.49232074059546,
    "estimated_duration": 3600.018348810411,
    "input_throughput": 4424.633003679965,
    "output_throughput": 3914.2644938619173,
    "total_throughput": 8338.897497541882,
    "itl": 178.60669770939205,
    "ttft": 1950679.5038602569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.159488883968384,
    "arrivals": 241330,
    "finished_requests": 64332,
    "scheduler_time": 113.12775185467163
}
#Debug simulation 
Total elapsed time: 15.492436977569014. Arrivals time: 0.2748627313412726 Scheduler time: 15.087354008574039 Scheduler overhead time: 0.03819570178166032 Adapter cache time: 0.037276667077094316 Engine time: 0.038506791926920414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 42.3875490501523,
    "estimated_duration": 3600.1637708536136,
    "input_throughput": 4638.968408939939,
    "output_throughput": 4092.6196522738974,
    "total_throughput": 8731.588061213837,
    "itl": 209.63020916277296,
    "ttft": 1902999.3584861122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3605838759639086,
    "arrivals": 241330,
    "finished_requests": 67397,
    "scheduler_time": 107.39889736533435
}
#Debug simulation 
Total elapsed time: 42.38768858881667. Arrivals time: 0.32790668215602636 Scheduler time: 41.935705905314535 Scheduler overhead time: 0.04349686158820987 Adapter cache time: 0.02262355014681816 Engine time: 0.04165655095130205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 15.551734114997089,
    "estimated_duration": 3600.14463134297,
    "input_throughput": 4435.81623387248,
    "output_throughput": 3916.972356396588,
    "total_throughput": 8352.788590269069,
    "itl": 178.39475174234548,
    "ttft": 1950063.736171842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.357036847621142,
    "arrivals": 241330,
    "finished_requests": 64394,
    "scheduler_time": 113.2124779099809
}
#Debug simulation 
Total elapsed time: 15.551830776967108. Arrivals time: 0.2697512162849307 Scheduler time: 15.151689514517784 Scheduler overhead time: 0.03838846646249294 Adapter cache time: 0.037978523410856724 Engine time: 0.03805952938273549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 40.980926040094346,
    "estimated_duration": 3600.0018753060085,
    "input_throughput": 4640.589249298639,
    "output_throughput": 4094.0425895603703,
    "total_throughput": 8734.631838859008,
    "itl": 209.5234453703355,
    "ttft": 1903283.9668147678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4398810406401257,
    "arrivals": 241330,
    "finished_requests": 67434,
    "scheduler_time": 107.42671014553555
}
#Debug simulation 
Total elapsed time: 40.98107728920877. Arrivals time: 0.31531782541424036 Scheduler time: 40.54166246578097 Scheduler overhead time: 0.043542010709643364 Adapter cache time: 0.02307614218443632 Engine time: 0.04187034955248237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.347796604968607,
    "estimated_duration": 3600.10567756206,
    "input_throughput": 4420.838837924819,
    "output_throughput": 3910.102163871088,
    "total_throughput": 8330.941001795907,
    "itl": 178.772986496523,
    "ttft": 1951243.6457022598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.521779462844044,
    "arrivals": 241330,
    "finished_requests": 64240,
    "scheduler_time": 113.03387838267676
}
#Debug simulation 
Total elapsed time: 15.34794447105378. Arrivals time: 0.2642507990822196 Scheduler time: 14.953075928147882 Scheduler overhead time: 0.03805724997073412 Adapter cache time: 0.03805818920955062 Engine time: 0.03844790440052748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 40.512415705714375,
    "estimated_duration": 3600.1796396938134,
    "input_throughput": 4611.701265387979,
    "output_throughput": 4076.2385404879656,
    "total_throughput": 8687.939805875945,
    "itl": 210.54672094683548,
    "ttft": 1908721.103553189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.209672151119489,
    "arrivals": 235580,
    "finished_requests": 67058,
    "scheduler_time": 106.82471747916686
}
#Debug simulation 
Total elapsed time: 40.51259334105998. Arrivals time: 0.3232279964722693 Scheduler time: 40.06825828272849 Scheduler overhead time: 0.04366919118911028 Adapter cache time: 0.019538992550224066 Engine time: 0.04201316740363836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 40.94821378774941,
    "estimated_duration": 3600.150078223765,
    "input_throughput": 4613.704328735936,
    "output_throughput": 4075.967023919146,
    "total_throughput": 8689.671352655081,
    "itl": 210.46127062790103,
    "ttft": 1908642.2995420524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.252165506733585,
    "arrivals": 235580,
    "finished_requests": 67086,
    "scheduler_time": 106.85333949446171
}
#Debug simulation 
Total elapsed time: 40.94836519891396. Arrivals time: 0.3261392735876143 Scheduler time: 40.50028156070039 Scheduler overhead time: 0.04426412144675851 Adapter cache time: 0.019298029597848654 Engine time: 0.042106746695935726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 16.045210554730147,
    "estimated_duration": 3600.002023119467,
    "input_throughput": 4416.955851102954,
    "output_throughput": 3910.459746853545,
    "total_throughput": 8327.415597956498,
    "itl": 178.50365801220713,
    "ttft": 1941612.251889176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9789426949992235,
    "arrivals": 235580,
    "finished_requests": 64273,
    "scheduler_time": 112.9442201197068
}
#Debug simulation 
Total elapsed time: 16.045309117995203. Arrivals time: 0.2694851108826697 Scheduler time: 15.64723859122023 Scheduler overhead time: 0.03812253102660179 Adapter cache time: 0.03560733608901501 Engine time: 0.038786297198385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 40.902057982981205,
    "estimated_duration": 3600.1137334462546,
    "input_throughput": 4612.265675313807,
    "output_throughput": 4076.3306624626903,
    "total_throughput": 8688.596337776497,
    "itl": 210.55498988294153,
    "ttft": 1908824.992405393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.223171445464232,
    "arrivals": 235580,
    "finished_requests": 67061,
    "scheduler_time": 106.81734571786423
}
#Debug simulation 
Total elapsed time: 40.90224024420604. Arrivals time: 0.5533568658865988 Scheduler time: 40.22674491722137 Scheduler overhead time: 0.04390452755615115 Adapter cache time: 0.019787124823778868 Engine time: 0.04240201832726598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 14.753357713110745,
    "estimated_duration": 3600.0259412447112,
    "input_throughput": 4417.886220703456,
    "output_throughput": 3911.44903670649,
    "total_throughput": 8329.335257409946,
    "itl": 178.43511978329767,
    "ttft": 1942466.2663418676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.43983233407133,
    "arrivals": 235580,
    "finished_requests": 64246,
    "scheduler_time": 112.9647322591737
}
#Debug simulation 
Total elapsed time: 14.753473702352494. Arrivals time: 0.2796584777534008 Scheduler time: 14.342598987743258 Scheduler overhead time: 0.038246190175414085 Adapter cache time: 0.038883890956640244 Engine time: 0.037994963582605124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 40.79575502919033,
    "estimated_duration": 3600.0652597100357,
    "input_throughput": 4612.832213307588,
    "output_throughput": 4075.7744489281367,
    "total_throughput": 8688.606662235725,
    "itl": 210.49577210572807,
    "ttft": 1908925.19917975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1647964135091353,
    "arrivals": 235580,
    "finished_requests": 67060,
    "scheduler_time": 106.84008392400379
}
#Debug simulation 
Total elapsed time: 40.795933534856886. Arrivals time: 0.3217212026938796 Scheduler time: 40.350674675777555 Scheduler overhead time: 0.045183354523032904 Adapter cache time: 0.019721025601029396 Engine time: 0.04251677077263594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.872838059905916,
    "estimated_duration": 3600.198607932796,
    "input_throughput": 4417.876548519819,
    "output_throughput": 3910.1895570375655,
    "total_throughput": 8328.066105557386,
    "itl": 178.58256307655037,
    "ttft": 1943322.492119357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.904822837114306,
    "arrivals": 235580,
    "finished_requests": 64253,
    "scheduler_time": 112.91454657282266
}
#Debug simulation 
Total elapsed time: 15.872989386785775. Arrivals time: 0.27703262120485306 Scheduler time: 15.466962452512234 Scheduler overhead time: 0.03888912592083216 Adapter cache time: 0.03526636911556125 Engine time: 0.038485076278448105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.57931773038581,
    "estimated_duration": 3600.0156225073724,
    "input_throughput": 4618.136070315332,
    "output_throughput": 4085.248105050378,
    "total_throughput": 8703.38417536571,
    "itl": 209.86038092030424,
    "ttft": 1895999.109734121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.837072138625725,
    "arrivals": 232701,
    "finished_requests": 67553,
    "scheduler_time": 106.89282184297994
}
#Debug simulation 
Total elapsed time: 25.57941780705005. Arrivals time: 0.29843984451144934 Scheduler time: 25.163960826117545 Scheduler overhead time: 0.03966213436797261 Adapter cache time: 0.023880618158727884 Engine time: 0.03850498190149665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 26.120831014122814,
    "estimated_duration": 3600.1379308901605,
    "input_throughput": 4621.542096273541,
    "output_throughput": 4088.581127323782,
    "total_throughput": 8710.123223597322,
    "itl": 209.71832215578846,
    "ttft": 1896547.8511282625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.006756823719485,
    "arrivals": 232701,
    "finished_requests": 67575,
    "scheduler_time": 106.98912310515087
}
#Debug simulation 
Total elapsed time: 26.12098810635507. Arrivals time: 0.3042289651930332 Scheduler time: 25.698785924352705 Scheduler overhead time: 0.03969620727002621 Adapter cache time: 0.024189674761146307 Engine time: 0.03887246735394001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.581061163917184,
    "estimated_duration": 3600.1263325393434,
    "input_throughput": 4421.435119131627,
    "output_throughput": 3915.042056332052,
    "total_throughput": 8336.477175463679,
    "itl": 179.4630716805144,
    "ttft": 1931198.7601995282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.597886383701056,
    "arrivals": 232701,
    "finished_requests": 64722,
    "scheduler_time": 112.44276116566759
}
#Debug simulation 
Total elapsed time: 13.581179287750274. Arrivals time: 0.27187902946025133 Scheduler time: 13.184639314189553 Scheduler overhead time: 0.03721475461497903 Adapter cache time: 0.033618584275245667 Engine time: 0.037989732809364796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 26.087010339833796,
    "estimated_duration": 3600.083296398622,
    "input_throughput": 4629.293721251349,
    "output_throughput": 4092.826689521272,
    "total_throughput": 8722.12041077262,
    "itl": 209.41369770718208,
    "ttft": 1895469.2919867397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9953485674829827,
    "arrivals": 232701,
    "finished_requests": 67696,
    "scheduler_time": 107.09479931362131
}
#Debug simulation 
Total elapsed time: 26.087135581765324. Arrivals time: 0.30267516104504466 Scheduler time: 25.666953749023378 Scheduler overhead time: 0.03898885753005743 Adapter cache time: 0.02489219419658184 Engine time: 0.03836686396971345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 14.240551237948239,
    "estimated_duration": 3600.007847607662,
    "input_throughput": 4424.957298519778,
    "output_throughput": 3917.0247946461695,
    "total_throughput": 8341.982093165947,
    "itl": 178.9853648096158,
    "ttft": 1933380.5757707292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.110440945364483,
    "arrivals": 232701,
    "finished_requests": 64708,
    "scheduler_time": 112.60245287013224
}
#Debug simulation 
Total elapsed time: 14.240681800059974. Arrivals time: 0.2763970233500004 Scheduler time: 13.837014891207218 Scheduler overhead time: 0.03727389173582196 Adapter cache time: 0.036213839426636696 Engine time: 0.037915507797151804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 26.219938583672047,
    "estimated_duration": 3600.2008773534617,
    "input_throughput": 4622.726221941877,
    "output_throughput": 4088.3660388472595,
    "total_throughput": 8711.092260789137,
    "itl": 209.6555823775415,
    "ttft": 1896448.012130127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7867268748487657,
    "arrivals": 232701,
    "finished_requests": 67584,
    "scheduler_time": 107.0020770431366
}
#Debug simulation 
Total elapsed time: 26.22004606295377. Arrivals time: 0.3066055681556463 Scheduler time: 25.795922791119665 Scheduler overhead time: 0.038777329958975315 Adapter cache time: 0.02455906243994832 Engine time: 0.038838776759803295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.997982505708933,
    "estimated_duration": 3600.0650020992607,
    "input_throughput": 4425.783698546867,
    "output_throughput": 3913.4285052588475,
    "total_throughput": 8339.212203805715,
    "itl": 178.917042043693,
    "ttft": 1932597.338100953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.25792589858168,
    "arrivals": 232701,
    "finished_requests": 64674,
    "scheduler_time": 112.57747967027281
}
#Debug simulation 
Total elapsed time: 12.998130689840764. Arrivals time: 0.2625448484905064 Scheduler time: 12.610418966505677 Scheduler overhead time: 0.03663082979619503 Adapter cache time: 0.036324453074485064 Engine time: 0.03636441798880696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 34.23383605899289,
    "estimated_duration": 3600.032143582213,
    "input_throughput": 4592.253441256657,
    "output_throughput": 4091.615689115198,
    "total_throughput": 8683.869130371855,
    "itl": 210.28349949808614,
    "ttft": 1895542.713925238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0444058129471143,
    "arrivals": 231176,
    "finished_requests": 67446,
    "scheduler_time": 106.91741966631389
}
#Debug simulation 
Total elapsed time: 34.23398427525535. Arrivals time: 0.3198363082483411 Scheduler time: 33.794263310264796 Scheduler overhead time: 0.04381075827404857 Adapter cache time: 0.018516110256314278 Engine time: 0.04161213431507349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 34.165840388741344,
    "estimated_duration": 3600.1812259656303,
    "input_throughput": 4593.644586756667,
    "output_throughput": 4092.6195308537676,
    "total_throughput": 8686.264117610435,
    "itl": 210.19692611484953,
    "ttft": 1895930.8339910936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.218327879786962,
    "arrivals": 231176,
    "finished_requests": 67476,
    "scheduler_time": 106.97174413504447
}
#Debug simulation 
Total elapsed time: 34.165951809845865. Arrivals time: 0.3216741061769426 Scheduler time: 33.72371041914448 Scheduler overhead time: 0.04390888102352619 Adapter cache time: 0.019206061027944088 Engine time: 0.041633703745901585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.580707032699138,
    "estimated_duration": 3600.184255097712,
    "input_throughput": 4384.9889009559965,
    "output_throughput": 3915.6348678652266,
    "total_throughput": 8300.623768821224,
    "itl": 178.97034414954217,
    "ttft": 1933936.057447733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.360204414389962,
    "arrivals": 231176,
    "finished_requests": 64400,
    "scheduler_time": 112.67216180816997
}
#Debug simulation 
Total elapsed time: 13.580832479987293. Arrivals time: 0.2638191948644817 Scheduler time: 13.194238812197 Scheduler overhead time: 0.03749914839863777 Adapter cache time: 0.031646210700273514 Engine time: 0.037698183208703995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 23.604485378134996,
    "estimated_duration": 3600.0979579087434,
    "input_throughput": 4588.495977924924,
    "output_throughput": 4090.9953485141614,
    "total_throughput": 8679.491326439085,
    "itl": 210.61256017202922,
    "ttft": 1893436.2923109129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.720115111165189,
    "arrivals": 231176,
    "finished_requests": 67291,
    "scheduler_time": 106.83361093462923
}
#Debug simulation 
Total elapsed time: 23.60463017784059. Arrivals time: 0.31412622099742293 Scheduler time: 23.175320141017437 Scheduler overhead time: 0.03978891996666789 Adapter cache time: 0.02197006205096841 Engine time: 0.03868286358192563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 13.67070774268359,
    "estimated_duration": 3600.0431461061457,
    "input_throughput": 4383.373298475108,
    "output_throughput": 3909.9973052336773,
    "total_throughput": 8293.370603708785,
    "itl": 178.2195640580088,
    "ttft": 1931709.7542312616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.604458885509491,
    "arrivals": 231176,
    "finished_requests": 64294,
    "scheduler_time": 112.81765215859153
}
#Debug simulation 
Total elapsed time: 13.670806218869984. Arrivals time: 0.27226987900212407 Scheduler time: 13.275556112173945 Scheduler overhead time: 0.0374312880448997 Adapter cache time: 0.03219849616289139 Engine time: 0.037501389626413584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 34.01870364230126,
    "estimated_duration": 3600.2343590137075,
    "input_throughput": 4601.797368696497,
    "output_throughput": 4099.834213027075,
    "total_throughput": 8701.631581723572,
    "itl": 209.95789657954836,
    "ttft": 1896126.1231265152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0930352064314857,
    "arrivals": 231176,
    "finished_requests": 67577,
    "scheduler_time": 107.09870052959656
}
#Debug simulation 
Total elapsed time: 34.0188800310716. Arrivals time: 0.32457879185676575 Scheduler time: 33.574365256819874 Scheduler overhead time: 0.04272767389193177 Adapter cache time: 0.0198069391772151 Engine time: 0.04140432924032211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.962209115736187,
    "estimated_duration": 3600.171797942504,
    "input_throughput": 4390.199381327529,
    "output_throughput": 3914.587356096242,
    "total_throughput": 8304.786737423772,
    "itl": 178.43974892636254,
    "ttft": 1935309.6086970738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.026427548974711,
    "arrivals": 231176,
    "finished_requests": 64423,
    "scheduler_time": 112.81405125309897
}
#Debug simulation 
Total elapsed time: 12.962304810993373. Arrivals time: 0.2626268034800887 Scheduler time: 12.575907221063972 Scheduler overhead time: 0.03682462591677904 Adapter cache time: 0.034012998919934034 Engine time: 0.03714580275118351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 33.991442484781146,
    "estimated_duration": 3600.158908747069,
    "input_throughput": 4652.847117192862,
    "output_throughput": 4086.899876628114,
    "total_throughput": 8739.746993820976,
    "itl": 209.01344892255347,
    "ttft": 1873053.799148267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4514506828901848,
    "arrivals": 218283,
    "finished_requests": 67489,
    "scheduler_time": 106.69702427056066
}
#Debug simulation 
Total elapsed time: 33.99156973697245. Arrivals time: 0.3189512095414102 Scheduler time: 33.55010907491669 Scheduler overhead time: 0.04269623151049018 Adapter cache time: 0.02218552492558956 Engine time: 0.041763460729271173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 32.28141278214753,
    "estimated_duration": 3600.000345101022,
    "input_throughput": 4644.487332550743,
    "output_throughput": 4083.6157196500117,
    "total_throughput": 8728.103052200755,
    "itl": 209.27757144246584,
    "ttft": 1873534.7213907512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 857,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7937380529684055,
    "arrivals": 218283,
    "finished_requests": 67370,
    "scheduler_time": 106.58532559614916
}
#Debug simulation 
Total elapsed time: 32.28157248022035. Arrivals time: 0.311257594730705 Scheduler time: 31.846815813798457 Scheduler overhead time: 0.04305624309927225 Adapter cache time: 0.023270482197403908 Engine time: 0.04132977593690157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.32247774163261,
    "estimated_duration": 3600.070850805535,
    "input_throughput": 4437.683218491461,
    "output_throughput": 3907.486430955208,
    "total_throughput": 8345.16964944667,
    "itl": 178.24606295644745,
    "ttft": 1918864.3847718425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.511121749263203,
    "arrivals": 218283,
    "finished_requests": 64450,
    "scheduler_time": 112.2448103898104
}
#Debug simulation 
Total elapsed time: 14.322593550663441. Arrivals time: 0.27423822367563844 Scheduler time: 13.918671299237758 Scheduler overhead time: 0.03771302429959178 Adapter cache time: 0.03805749211460352 Engine time: 0.037713324185460806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 32.23054747423157,
    "estimated_duration": 3600.1830675210344,
    "input_throughput": 4647.743096998008,
    "output_throughput": 4083.913991108203,
    "total_throughput": 8731.65708810621,
    "itl": 209.23447528117245,
    "ttft": 1873870.4519808746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6929259462584483,
    "arrivals": 218283,
    "finished_requests": 67417,
    "scheduler_time": 106.5793646866064
}
#Debug simulation 
Total elapsed time: 32.2306694611907. Arrivals time: 0.3120031817816198 Scheduler time: 31.795675631146878 Scheduler overhead time: 0.042540408205240965 Adapter cache time: 0.023325162939727306 Engine time: 0.041416050400584936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 16.190724299754947,
    "estimated_duration": 3600.105289912701,
    "input_throughput": 4438.742956983766,
    "output_throughput": 3910.773398613963,
    "total_throughput": 8349.516355597729,
    "itl": 178.3150798673305,
    "ttft": 1916849.4791963813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767020343150907,
    "arrivals": 218283,
    "finished_requests": 64490,
    "scheduler_time": 112.2380365620846
}
#Debug simulation 
Total elapsed time: 16.19087277073413. Arrivals time: 0.271508258767426 Scheduler time: 15.790746020618826 Scheduler overhead time: 0.03906896151602268 Adapter cache time: 0.03437294531613588 Engine time: 0.039136325009167194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 32.38617594819516,
    "estimated_duration": 3600.2203752961673,
    "input_throughput": 4648.49516291715,
    "output_throughput": 4085.462684708577,
    "total_throughput": 8733.957847625727,
    "itl": 209.22556268296748,
    "ttft": 1873318.4664378366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5564930021413064,
    "arrivals": 218283,
    "finished_requests": 67401,
    "scheduler_time": 106.61993114001525
}
#Debug simulation 
Total elapsed time: 32.38632073998451. Arrivals time: 0.3109265621751547 Scheduler time: 31.954106352292 Scheduler overhead time: 0.04198855720460415 Adapter cache time: 0.023221854586154222 Engine time: 0.04046234581619501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.287727417889982,
    "estimated_duration": 3600.01358093623,
    "input_throughput": 4436.772984574731,
    "output_throughput": 3906.0252645888804,
    "total_throughput": 8342.79824916361,
    "itl": 178.40889361829807,
    "ttft": 1911972.2421286437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.080184990242178,
    "arrivals": 218283,
    "finished_requests": 64407,
    "scheduler_time": 112.20637991766463
}
#Debug simulation 
Total elapsed time: 17.287822477985173. Arrivals time: 0.2749723116867244 Scheduler time: 16.886785646434873 Scheduler overhead time: 0.03987739980220795 Adapter cache time: 0.03055806551128626 Engine time: 0.03937498852610588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 32.40596839087084,
    "estimated_duration": 3600.0206705602677,
    "input_throughput": 4621.073744393518,
    "output_throughput": 4097.018420092731,
    "total_throughput": 8718.092164486248,
    "itl": 209.7843551007507,
    "ttft": 1870528.4355428785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8332321586157472,
    "arrivals": 212473,
    "finished_requests": 67166,
    "scheduler_time": 106.69120716438063
}
#Debug simulation 
Total elapsed time: 32.40612772013992. Arrivals time: 0.3160779536701739 Scheduler time: 31.97279710555449 Scheduler overhead time: 0.042277705390006304 Adapter cache time: 0.017487382981926203 Engine time: 0.041385456919670105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 32.40073926700279,
    "estimated_duration": 3600.2105609026253,
    "input_throughput": 4620.154215599471,
    "output_throughput": 4094.9754884069257,
    "total_throughput": 8715.129704006396,
    "itl": 209.841037977279,
    "ttft": 1870294.4367275224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9516180867934645,
    "arrivals": 212473,
    "finished_requests": 67150,
    "scheduler_time": 106.64914377404891
}
#Debug simulation 
Total elapsed time: 32.40090934606269. Arrivals time: 0.31769579416140914 Scheduler time: 31.963855529669672 Scheduler overhead time: 0.04355691559612751 Adapter cache time: 0.017790958285331726 Engine time: 0.042061183135956526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.697008240036666,
    "estimated_duration": 3600.032876549965,
    "input_throughput": 4389.550190759397,
    "output_throughput": 3906.715989071274,
    "total_throughput": 8296.26617983067,
    "itl": 177.8258049312944,
    "ttft": 1912675.8271695918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.387596084028422,
    "arrivals": 212473,
    "finished_requests": 63807,
    "scheduler_time": 112.38539655875613
}
#Debug simulation 
Total elapsed time: 13.697112368885428. Arrivals time: 0.25974971801042557 Scheduler time: 13.31407432211563 Scheduler overhead time: 0.03767615836113691 Adapter cache time: 0.03240638226270676 Engine time: 0.03729482460767031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 36.19380511902273,
    "estimated_duration": 3600.1359989123134,
    "input_throughput": 4598.038797701316,
    "output_throughput": 4079.7397666192273,
    "total_throughput": 8677.778564320543,
    "itl": 210.72313818964196,
    "ttft": 1849290.0140398962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3305561748915327,
    "arrivals": 212473,
    "finished_requests": 66885,
    "scheduler_time": 106.16390786779073
}
#Debug simulation 
Total elapsed time: 36.193982186261564. Arrivals time: 0.3267675112001598 Scheduler time: 35.74832739075646 Scheduler overhead time: 0.045312216039747 Adapter cache time: 0.014569902326911688 Engine time: 0.042687855660915375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 13.417971493676305,
    "estimated_duration": 3600.032321241272,
    "input_throughput": 4397.986347672819,
    "output_throughput": 3909.757119943559,
    "total_throughput": 8307.743467616378,
    "itl": 177.80256925830145,
    "ttft": 1913368.4567691027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.166553558837572,
    "arrivals": 212473,
    "finished_requests": 63842,
    "scheduler_time": 112.41760394139511
}
#Debug simulation 
Total elapsed time: 13.41807011468336. Arrivals time: 0.2614912372082472 Scheduler time: 13.02898623375222 Scheduler overhead time: 0.03764817398041487 Adapter cache time: 0.0359421307221055 Engine time: 0.03787043737247586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 35.578904590103775,
    "estimated_duration": 3600.126207563884,
    "input_throughput": 4595.7477727414935,
    "output_throughput": 4077.831762996462,
    "total_throughput": 8673.579535737956,
    "itl": 210.73937005769108,
    "ttft": 1851679.224637012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3275823309365558,
    "arrivals": 212473,
    "finished_requests": 66854,
    "scheduler_time": 106.15943008134495
}
#Debug simulation 
Total elapsed time: 35.579058377072215. Arrivals time: 0.30842033168300986 Scheduler time: 35.15273714996874 Scheduler overhead time: 0.04414031468331814 Adapter cache time: 0.014940562658011913 Engine time: 0.042425342835485935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.270829764194787,
    "estimated_duration": 3600.0240435353826,
    "input_throughput": 4391.698168902691,
    "output_throughput": 3904.8528093148097,
    "total_throughput": 8296.550978217501,
    "itl": 177.80248434985003,
    "ttft": 1913972.1912657795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4087742852046325,
    "arrivals": 212473,
    "finished_requests": 63764,
    "scheduler_time": 112.33025552159164
}
#Debug simulation 
Total elapsed time: 13.270942294038832. Arrivals time: 0.26451721508055925 Scheduler time: 12.880001993384212 Scheduler overhead time: 0.03722772654145956 Adapter cache time: 0.035909831058233976 Engine time: 0.037327075842767954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 32.16182857984677,
    "estimated_duration": 3600.150936949651,
    "input_throughput": 4667.185152586003,
    "output_throughput": 4072.582582446612,
    "total_throughput": 8739.767735032616,
    "itl": 208.82823935464236,
    "ttft": 1842494.1066425382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3925219234894153,
    "arrivals": 209565,
    "finished_requests": 67500,
    "scheduler_time": 106.20635991750616
}
#Debug simulation 
Total elapsed time: 32.1619537207298. Arrivals time: 0.30635159788653255 Scheduler time: 31.739392491523176 Scheduler overhead time: 0.043643418699502945 Adapter cache time: 0.014864074997603893 Engine time: 0.04190445598214865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 32.431305491831154,
    "estimated_duration": 3600.19727386371,
    "input_throughput": 4667.125082834025,
    "output_throughput": 4072.5301656219867,
    "total_throughput": 8739.655248456012,
    "itl": 208.83321706734372,
    "ttft": 1842516.5299835675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.485911646941682,
    "arrivals": 209565,
    "finished_requests": 67500,
    "scheduler_time": 106.20629481189373
}
#Debug simulation 
Total elapsed time: 32.431428557727486. Arrivals time: 0.3098867814987898 Scheduler time: 32.00436130957678 Scheduler overhead time: 0.04410042241215706 Adapter cache time: 0.014978870283812284 Engine time: 0.04206065693870187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.267685268074274,
    "estimated_duration": 3600.0754648747643,
    "input_throughput": 4453.790526459915,
    "output_throughput": 3904.0273286296024,
    "total_throughput": 8357.817855089517,
    "itl": 178.2057881900204,
    "ttft": 1900442.62417249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.83794566826889,
    "arrivals": 209565,
    "finished_requests": 64532,
    "scheduler_time": 111.87237037188193
}
#Debug simulation 
Total elapsed time: 11.267779749818146. Arrivals time: 0.2513707592152059 Scheduler time: 10.894475160166621 Scheduler overhead time: 0.03578290529549122 Adapter cache time: 0.03449401259422302 Engine time: 0.03598152752965689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 32.42362580308691,
    "estimated_duration": 3600.1455224813326,
    "input_throughput": 4667.313000286401,
    "output_throughput": 4071.0515473547766,
    "total_throughput": 8738.364547641177,
    "itl": 208.8050980947439,
    "ttft": 1843886.783509306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.454931447443082,
    "arrivals": 209565,
    "finished_requests": 67500,
    "scheduler_time": 106.20100948804942
}
#Debug simulation 
Total elapsed time: 32.42378242313862. Arrivals time: 0.32988586788997054 Scheduler time: 31.976578483823687 Scheduler overhead time: 0.04359663464128971 Adapter cache time: 0.015177574940025806 Engine time: 0.042345032561570406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.503509369678795,
    "estimated_duration": 3600.081906653557,
    "input_throughput": 4452.5423075443805,
    "output_throughput": 3904.4758881794737,
    "total_throughput": 8357.018195723855,
    "itl": 178.33803158457226,
    "ttft": 1899433.130256296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0951916286535,
    "arrivals": 209565,
    "finished_requests": 64513,
    "scheduler_time": 111.84429951506581
}
#Debug simulation 
Total elapsed time: 11.50363059900701. Arrivals time: 0.2676588403992355 Scheduler time: 11.112743725068867 Scheduler overhead time: 0.03622924955561757 Adapter cache time: 0.034989345353096724 Engine time: 0.03623253805562854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 32.40815483313054,
    "estimated_duration": 3600.0397998933868,
    "input_throughput": 4667.484509615037,
    "output_throughput": 4072.5991419412067,
    "total_throughput": 8740.083651556244,
    "itl": 208.82427164613213,
    "ttft": 1842505.5187439467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3604728841804785,
    "arrivals": 209565,
    "finished_requests": 67499,
    "scheduler_time": 106.20359938738284
}
#Debug simulation 
Total elapsed time: 32.40832728333771. Arrivals time: 0.3317378768697381 Scheduler time: 31.959445346612483 Scheduler overhead time: 0.04391001723706722 Adapter cache time: 0.015356347430497408 Engine time: 0.04213631711900234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.130352566950023,
    "estimated_duration": 3600.0414501582227,
    "input_throughput": 4454.717042020492,
    "output_throughput": 3905.3833670115328,
    "total_throughput": 8360.100409032024,
    "itl": 178.40436491769765,
    "ttft": 1900177.8183108647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9534511176496405,
    "arrivals": 209565,
    "finished_requests": 64508,
    "scheduler_time": 111.82732034724668
}
#Debug simulation 
Total elapsed time: 12.13041491014883. Arrivals time: 0.48029622714966536 Scheduler time: 11.528357353061438 Scheduler overhead time: 0.03638315014541149 Adapter cache time: 0.033304113894701004 Engine time: 0.03639206616207957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 18.019931039307266,
    "estimated_duration": 3600.1453545720224,
    "input_throughput": 4620.186231891,
    "output_throughput": 4079.1239113026795,
    "total_throughput": 8699.31014319368,
    "itl": 210.30602652422706,
    "ttft": 1858206.1610490642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.601414582342895,
    "arrivals": 208142,
    "finished_requests": 67141,
    "scheduler_time": 106.05537232700868
}
#Debug simulation 
Total elapsed time: 18.020099697168916. Arrivals time: 0.2881196574307978 Scheduler time: 17.624200723599643 Scheduler overhead time: 0.036797950975596905 Adapter cache time: 0.0206471118144691 Engine time: 0.03600986022502184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 18.20643478585407,
    "estimated_duration": 3600.1084131821253,
    "input_throughput": 4619.603937232501,
    "output_throughput": 4078.5235650783156,
    "total_throughput": 8698.127502310817,
    "itl": 210.32184260747954,
    "ttft": 1858278.9269365284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.778379206175454,
    "arrivals": 208142,
    "finished_requests": 67136,
    "scheduler_time": 106.0483441957654
}
#Debug simulation 
Total elapsed time: 18.206501819659024. Arrivals time: 0.5048140264116228 Scheduler time: 17.594727200455964 Scheduler overhead time: 0.03592639463022351 Adapter cache time: 0.020889457780867815 Engine time: 0.03584751207381487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.669968705624342,
    "estimated_duration": 3600.035393957687,
    "input_throughput": 4422.637907039181,
    "output_throughput": 3906.221873152307,
    "total_throughput": 8328.859780191488,
    "itl": 178.80435752281699,
    "ttft": 1899563.2947436813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.050843565482584,
    "arrivals": 208142,
    "finished_requests": 64270,
    "scheduler_time": 111.88030062351265
}
#Debug simulation 
Total elapsed time: 10.67009372357279. Arrivals time: 0.2631480530835688 Scheduler time: 10.290450821630657 Scheduler overhead time: 0.034922156017273664 Adapter cache time: 0.03034555446356535 Engine time: 0.035527418833225965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 18.41888200864196,
    "estimated_duration": 3600.061516027176,
    "input_throughput": 4621.654915041847,
    "output_throughput": 4078.0730925402263,
    "total_throughput": 8699.728007582073,
    "itl": 210.30509062026064,
    "ttft": 1858188.1971329227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.616540307612134,
    "arrivals": 208142,
    "finished_requests": 67142,
    "scheduler_time": 106.04204571251202
}
#Debug simulation 
Total elapsed time: 18.418957486748695. Arrivals time: 0.2816459443420172 Scheduler time: 18.030838382896036 Scheduler overhead time: 0.03626135038211942 Adapter cache time: 0.02041103970259428 Engine time: 0.035510148387402296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.042609503027052,
    "estimated_duration": 3600.167353765252,
    "input_throughput": 4419.354279005952,
    "output_throughput": 3903.078001444552,
    "total_throughput": 8322.432280450503,
    "itl": 177.97214569654497,
    "ttft": 1901698.8237374667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.127430975884194,
    "arrivals": 208142,
    "finished_requests": 64132,
    "scheduler_time": 112.08896027999117
}
#Debug simulation 
Total elapsed time: 11.042738390155137. Arrivals time: 0.25392480473965406 Scheduler time: 10.670738175977021 Scheduler overhead time: 0.035655317828059196 Adapter cache time: 0.03019684413447976 Engine time: 0.0366317848674953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 18.174637021962553,
    "estimated_duration": 3600.1524592437213,
    "input_throughput": 4620.1771142475845,
    "output_throughput": 4079.1158614113106,
    "total_throughput": 8699.292975658895,
    "itl": 210.30695309126028,
    "ttft": 1858214.5947852903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5475228512566,
    "arrivals": 208142,
    "finished_requests": 67141,
    "scheduler_time": 106.05539214191752
}
#Debug simulation 
Total elapsed time: 18.174702253658324. Arrivals time: 0.5080647557042539 Scheduler time: 17.559260319918394 Scheduler overhead time: 0.036100939847528934 Adapter cache time: 0.020873754285275936 Engine time: 0.03591815195977688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.497108248993754,
    "estimated_duration": 3600.182336489962,
    "input_throughput": 4417.953734950876,
    "output_throughput": 3902.970096147845,
    "total_throughput": 8320.923831098722,
    "itl": 178.42869221569202,
    "ttft": 1900398.371227135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.161297954507218,
    "arrivals": 208142,
    "finished_requests": 64183,
    "scheduler_time": 111.97321757651196
}
#Debug simulation 
Total elapsed time: 10.497232155874372. Arrivals time: 0.2583099342882633 Scheduler time: 10.1239234036766 Scheduler overhead time: 0.034903116058558226 Adapter cache time: 0.02884387131780386 Engine time: 0.03546720137819648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.116795776877552,
    "estimated_duration": 3600.1928602218118,
    "input_throughput": 4629.623647154584,
    "output_throughput": 4074.40005841694,
    "total_throughput": 8704.023705571524,
    "itl": 209.8588856043512,
    "ttft": 1847207.1906091284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316789222157139,
    "arrivals": 200966,
    "finished_requests": 67068,
    "scheduler_time": 105.76042127708642
}
#Debug simulation 
Total elapsed time: 25.11690757377073. Arrivals time: 0.29068733705207705 Scheduler time: 24.711583834141493 Scheduler overhead time: 0.03926070732995868 Adapter cache time: 0.020731616765260696 Engine time: 0.03954088408499956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 25.28697353042662,
    "estimated_duration": 3600.137251221781,
    "input_throughput": 4628.507147705265,
    "output_throughput": 4072.997215598847,
    "total_throughput": 8701.504363304113,
    "itl": 209.89124466278358,
    "ttft": 1847375.5044295103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4530941932392363,
    "arrivals": 200966,
    "finished_requests": 67049,
    "scheduler_time": 105.74073806063014
}
#Debug simulation 
Total elapsed time: 25.287129401229322. Arrivals time: 0.29422259563580155 Scheduler time: 24.87620925810188 Scheduler overhead time: 0.04094987781718373 Adapter cache time: 0.020371940918266773 Engine time: 0.03985632164403796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.808201782871038,
    "estimated_duration": 3600.03223434637,
    "input_throughput": 4425.752871874717,
    "output_throughput": 3903.033385630543,
    "total_throughput": 8328.78625750526,
    "itl": 178.13196479891275,
    "ttft": 1889002.8100700532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5042366685717665,
    "arrivals": 200966,
    "finished_requests": 64127,
    "scheduler_time": 111.62370521797727
}
#Debug simulation 
Total elapsed time: 11.808295529801399. Arrivals time: 0.258004326839 Scheduler time: 11.428881746716797 Scheduler overhead time: 0.03616956761106849 Adapter cache time: 0.03271668357774615 Engine time: 0.03684095712378621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 25.236462883185595,
    "estimated_duration": 3600.2174610742595,
    "input_throughput": 4629.451465141989,
    "output_throughput": 4074.2927777543614,
    "total_throughput": 8703.74424289635,
    "itl": 209.8723270078878,
    "ttft": 1847213.3426474896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3861576057178717,
    "arrivals": 200966,
    "finished_requests": 67065,
    "scheduler_time": 105.75552994837764
}
#Debug simulation 
Total elapsed time: 25.236618447117507. Arrivals time: 0.29186428245157003 Scheduler time: 24.82813733490184 Scheduler overhead time: 0.04057892179116607 Adapter cache time: 0.020242150872945786 Engine time: 0.03998850705102086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.983085969928652,
    "estimated_duration": 3600.0236959389867,
    "input_throughput": 4425.413371020769,
    "output_throughput": 3903.777360091627,
    "total_throughput": 8329.190731112396,
    "itl": 178.12307190106696,
    "ttft": 1888224.7541317844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.770095584467014,
    "arrivals": 200966,
    "finished_requests": 64118,
    "scheduler_time": 111.6359454973055
}
#Debug simulation 
Total elapsed time: 11.983153970912099. Arrivals time: 0.26222773641347885 Scheduler time: 11.59791662497446 Scheduler overhead time: 0.03664091415703297 Adapter cache time: 0.033643724862486124 Engine time: 0.036931576672941446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.10500030219555,
    "estimated_duration": 3600.2133124673196,
    "input_throughput": 4629.494853064014,
    "output_throughput": 4074.3483029752147,
    "total_throughput": 8703.84315603923,
    "itl": 209.86377629164608,
    "ttft": 1847166.016470648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2604780229460015,
    "arrivals": 200966,
    "finished_requests": 67070,
    "scheduler_time": 105.7606656554517
}
#Debug simulation 
Total elapsed time: 25.10512815322727. Arrivals time: 0.29484247462823987 Scheduler time: 24.695830568205565 Scheduler overhead time: 0.04007997736334801 Adapter cache time: 0.020295027177780867 Engine time: 0.0387972230091691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.60983228078112,
    "estimated_duration": 3600.076208944613,
    "input_throughput": 4419.469221365247,
    "output_throughput": 3901.2510249379775,
    "total_throughput": 8320.720246303224,
    "itl": 177.80963911030528,
    "ttft": 1887800.5813666314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.968668711893225,
    "arrivals": 200966,
    "finished_requests": 64071,
    "scheduler_time": 111.70973188737786
}
#Debug simulation 
Total elapsed time: 11.609941499773413. Arrivals time: 0.25172816030681133 Scheduler time: 11.234306670259684 Scheduler overhead time: 0.0367459268309176 Adapter cache time: 0.034531309735029936 Engine time: 0.03675842238590121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 24.161022493150085,
    "estimated_duration": 3600.0265599871445,
    "input_throughput": 4628.649739756226,
    "output_throughput": 4076.3913141941944,
    "total_throughput": 8705.041053950421,
    "itl": 209.79414805033898,
    "ttft": 1822204.8427853435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3282516808668252,
    "arrivals": 198105,
    "finished_requests": 67313,
    "scheduler_time": 105.70965847245293
}
#Debug simulation 
Total elapsed time: 24.161157469265163. Arrivals time: 0.29150216467678547 Scheduler time: 23.76039327075705 Scheduler overhead time: 0.03999163908883929 Adapter cache time: 0.014585425611585379 Engine time: 0.03924522316083312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 21.952301706187427,
    "estimated_duration": 3600.0264840141604,
    "input_throughput": 4624.116537453373,
    "output_throughput": 4077.601669094349,
    "total_throughput": 8701.718206547721,
    "itl": 209.99106111079305,
    "ttft": 1838600.2017592553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5404929593624592,
    "arrivals": 198105,
    "finished_requests": 67234,
    "scheduler_time": 105.68181034977648
}
#Debug simulation 
Total elapsed time: 21.952471405267715. Arrivals time: 0.29296266939491034 Scheduler time: 21.547511119861156 Scheduler overhead time: 0.03882129164412618 Adapter cache time: 0.020011311396956444 Engine time: 0.0383621659129858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.926932944916189,
    "estimated_duration": 3600.1100939752014,
    "input_throughput": 4424.76246119759,
    "output_throughput": 3909.3848889658284,
    "total_throughput": 8334.14735016342,
    "itl": 178.6863936332322,
    "ttft": 1880170.4376576561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.591807637400861,
    "arrivals": 198105,
    "finished_requests": 64419,
    "scheduler_time": 111.41935856623036
}
#Debug simulation 
Total elapsed time: 9.927031659986824. Arrivals time: 0.24729459639638662 Scheduler time: 9.561098438687623 Scheduler overhead time: 0.03466413449496031 Adapter cache time: 0.03301921812817454 Engine time: 0.035464192274957895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 24.369512884877622,
    "estimated_duration": 3600.203284138022,
    "input_throughput": 4628.4961389311275,
    "output_throughput": 4076.4012034153147,
    "total_throughput": 8704.897342346443,
    "itl": 209.79795290390567,
    "ttft": 1822220.3693901466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3569281491613927,
    "arrivals": 198105,
    "finished_requests": 67315,
    "scheduler_time": 105.71469884781193
}
#Debug simulation 
Total elapsed time: 24.36968359723687. Arrivals time: 0.29900263901799917 Scheduler time: 23.95992597285658 Scheduler overhead time: 0.040848521050065756 Adapter cache time: 0.01434420607984066 Engine time: 0.040157015435397625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.578921912238002,
    "estimated_duration": 3600.0328907477574,
    "input_throughput": 4416.87186827264,
    "output_throughput": 3909.980666058938,
    "total_throughput": 8326.852534331578,
    "itl": 178.76611779797102,
    "ttft": 1880430.631549923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.448100791871539,
    "arrivals": 198105,
    "finished_requests": 64349,
    "scheduler_time": 111.42098499625425
}
#Debug simulation 
Total elapsed time: 10.579020554199815. Arrivals time: 0.258282364346087 Scheduler time: 10.202018073759973 Scheduler overhead time: 0.03527594218030572 Adapter cache time: 0.03202439844608307 Engine time: 0.035765479784458876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 24.239589780103415,
    "estimated_duration": 3600.2214122647247,
    "input_throughput": 4628.432002330067,
    "output_throughput": 4076.358178973268,
    "total_throughput": 8704.790181303335,
    "itl": 209.79142691203774,
    "ttft": 1822265.9627301216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.297681827987535,
    "arrivals": 198105,
    "finished_requests": 67316,
    "scheduler_time": 105.71629084520498
}
#Debug simulation 
Total elapsed time: 24.239774306304753. Arrivals time: 0.2976635410450399 Scheduler time: 23.83311589807272 Scheduler overhead time: 0.040187424048781395 Adapter cache time: 0.014595060143619776 Engine time: 0.03855569567531347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.351252507884055,
    "estimated_duration": 3600.1051676001407,
    "input_throughput": 4421.260840724385,
    "output_throughput": 3908.1605522593763,
    "total_throughput": 8329.42139298376,
    "itl": 178.73735208009688,
    "ttft": 1879235.6723263308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.582018922045831,
    "arrivals": 198105,
    "finished_requests": 64384,
    "scheduler_time": 111.41413292162396
}
#Debug simulation 
Total elapsed time: 10.351351993624121. Arrivals time: 0.26446465449407697 Scheduler time: 9.968727336265147 Scheduler overhead time: 0.035170689690858126 Adapter cache time: 0.031863531563431025 Engine time: 0.03557163290679455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.32815702818334,
    "estimated_duration": 3600.2293889995826,
    "input_throughput": 4656.318581038599,
    "output_throughput": 4073.1840712168855,
    "total_throughput": 8729.502652255485,
    "itl": 209.3894607683704,
    "ttft": 1831120.6466404684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9219863031898001,
    "arrivals": 196756,
    "finished_requests": 67607,
    "scheduler_time": 105.66992915695363
}
#Debug simulation 
Total elapsed time: 19.328297520056367. Arrivals time: 0.28949243761599064 Scheduler time: 18.93262425158173 Scheduler overhead time: 0.037587772123515606 Adapter cache time: 0.017486674711108208 Engine time: 0.0366238234564662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 20.208540985826403,
    "estimated_duration": 3600.0523354920583,
    "input_throughput": 4653.302074207292,
    "output_throughput": 4072.708570220269,
    "total_throughput": 8726.01064442756,
    "itl": 209.33612294254203,
    "ttft": 1828282.2429174222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.703406020074622,
    "arrivals": 196756,
    "finished_requests": 67605,
    "scheduler_time": 105.66643632826225
}
#Debug simulation 
Total elapsed time: 20.208643037825823. Arrivals time: 0.3143908577039838 Scheduler time: 19.786717404145747 Scheduler overhead time: 0.03843558859080076 Adapter cache time: 0.01623233873397112 Engine time: 0.0381734287366271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.425826210994273,
    "estimated_duration": 3600.089741892813,
    "input_throughput": 4453.185100761114,
    "output_throughput": 3910.3339108981404,
    "total_throughput": 8363.519011659255,
    "itl": 178.8536185339659,
    "ttft": 1870495.64813598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.218878431562268,
    "arrivals": 196756,
    "finished_requests": 64805,
    "scheduler_time": 111.29915199676311
}
#Debug simulation 
Total elapsed time: 9.425955007784069. Arrivals time: 0.24302853923290968 Scheduler time: 9.068165451753885 Scheduler overhead time: 0.034218060318380594 Adapter cache time: 0.03026382438838482 Engine time: 0.03479095734655857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 20.134851375129074,
    "estimated_duration": 3600.0243976381466,
    "input_throughput": 4656.416498454225,
    "output_throughput": 4072.077958587628,
    "total_throughput": 8728.494457041854,
    "itl": 209.31790970228013,
    "ttft": 1830152.0291276693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.89913116460432,
    "arrivals": 196756,
    "finished_requests": 67606,
    "scheduler_time": 105.66746098000543
}
#Debug simulation 
Total elapsed time: 20.13494964176789. Arrivals time: 0.298133525531739 Scheduler time: 19.728794129099697 Scheduler overhead time: 0.03793312143534422 Adapter cache time: 0.01743498584255576 Engine time: 0.03756970074027777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.162521691992879,
    "estimated_duration": 3600.1459805491836,
    "input_throughput": 4459.581107750211,
    "output_throughput": 3911.262231053197,
    "total_throughput": 8370.843338803408,
    "itl": 178.74278807064425,
    "ttft": 1871239.324294632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.732976770699024,
    "arrivals": 196756,
    "finished_requests": 64811,
    "scheduler_time": 111.31741415034416
}
#Debug simulation 
Total elapsed time: 10.162624553777277. Arrivals time: 0.2465081913396716 Scheduler time: 9.802741124294698 Scheduler overhead time: 0.03487093327566981 Adapter cache time: 0.027563591953366995 Engine time: 0.035371205769479275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.60316659323871,
    "estimated_duration": 3600.110586074532,
    "input_throughput": 4660.251289195443,
    "output_throughput": 4076.204785698267,
    "total_throughput": 8736.456074893711,
    "itl": 209.3572626969692,
    "ttft": 1830116.2825090636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9136321887373613,
    "arrivals": 196756,
    "finished_requests": 67629,
    "scheduler_time": 105.6714476326534
}
#Debug simulation 
Total elapsed time: 19.60326838493347. Arrivals time: 0.30160166323184967 Scheduler time: 19.194339744746685 Scheduler overhead time: 0.03725894493982196 Adapter cache time: 0.01791259739547968 Engine time: 0.037378616631031036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.863872375804931,
    "estimated_duration": 3600.1409265092107,
    "input_throughput": 4461.938387388543,
    "output_throughput": 3910.820517143436,
    "total_throughput": 8372.758904531978,
    "itl": 178.76802855871378,
    "ttft": 1871749.06841503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5630654431507462,
    "arrivals": 196756,
    "finished_requests": 64862,
    "scheduler_time": 111.31253403781113
}
#Debug simulation 
Total elapsed time: 9.863994514103979. Arrivals time: 0.24532927479594946 Scheduler time: 9.507131204009056 Scheduler overhead time: 0.034575877245515585 Adapter cache time: 0.02644154569134116 Engine time: 0.03503488842397928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.27473957883194,
    "estimated_duration": 3600.094168165279,
    "input_throughput": 4623.429894469317,
    "output_throughput": 4074.1289852078758,
    "total_throughput": 8697.558879677194,
    "itl": 210.19488659073048,
    "ttft": 1824983.5797224375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.442269219658386,
    "arrivals": 192504,
    "finished_requests": 67272,
    "scheduler_time": 105.32634308778523
}
#Debug simulation 
Total elapsed time: 17.274834271054715. Arrivals time: 0.2750808419659734 Scheduler time: 16.894892308861017 Scheduler overhead time: 0.03516189428046346 Adapter cache time: 0.019859284162521362 Engine time: 0.03548761177808046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.487409471999854,
    "estimated_duration": 3600.023634379787,
    "input_throughput": 4623.345758358461,
    "output_throughput": 4074.0604755854015,
    "total_throughput": 8697.406233943862,
    "itl": 210.20670880743575,
    "ttft": 1824706.3164965236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5796423254488086,
    "arrivals": 192504,
    "finished_requests": 67265,
    "scheduler_time": 105.32048141001478
}
#Debug simulation 
Total elapsed time: 17.487549589946866. Arrivals time: 0.2868604245595634 Scheduler time: 17.093798214569688 Scheduler overhead time: 0.03622511401772499 Adapter cache time: 0.020468727219849825 Engine time: 0.03575354162603617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.34149028128013,
    "estimated_duration": 3600.1422768242346,
    "input_throughput": 4432.577874138026,
    "output_throughput": 3910.874325894703,
    "total_throughput": 8343.452200032729,
    "itl": 178.73508016460272,
    "ttft": 1866402.180787047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.459842493403662,
    "arrivals": 192504,
    "finished_requests": 64479,
    "scheduler_time": 111.09831019901432
}
#Debug simulation 
Total elapsed time: 9.341594944242388. Arrivals time: 0.24152505118399858 Scheduler time: 8.988425616174936 Scheduler overhead time: 0.03453933307901025 Adapter cache time: 0.026989147998392582 Engine time: 0.03453729208558798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.52977314731106,
    "estimated_duration": 3600.0289329484935,
    "input_throughput": 4623.660062189325,
    "output_throughput": 4073.6633713631936,
    "total_throughput": 8697.323433552518,
    "itl": 210.2018449429577,
    "ttft": 1824901.6134934537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4891749847656826,
    "arrivals": 192504,
    "finished_requests": 67261,
    "scheduler_time": 105.32365821108999
}
#Debug simulation 
Total elapsed time: 17.529880618210882. Arrivals time: 0.28135506343096495 Scheduler time: 17.141574523877352 Scheduler overhead time: 0.036078040022403 Adapter cache time: 0.020375960040837526 Engine time: 0.03625411866232753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 8.87453703628853,
    "estimated_duration": 3600.0628030509165,
    "input_throughput": 4426.745829682295,
    "output_throughput": 3908.7859767542445,
    "total_throughput": 8335.53180643654,
    "itl": 178.7820098639228,
    "ttft": 1866138.5961655732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9448410038650024,
    "arrivals": 192504,
    "finished_requests": 64432,
    "scheduler_time": 111.07510879123414
}
#Debug simulation 
Total elapsed time: 8.874662776943296. Arrivals time: 0.24702012911438942 Scheduler time: 8.514961648266762 Scheduler overhead time: 0.03423257265239954 Adapter cache time: 0.02892355155199766 Engine time: 0.034156108275055885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.23365111136809,
    "estimated_duration": 3600.0257102672595,
    "input_throughput": 4623.441147247901,
    "output_throughput": 4074.049237529243,
    "total_throughput": 8697.490384777144,
    "itl": 210.19242785263043,
    "ttft": 1824982.2622874992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3860601353318884,
    "arrivals": 192504,
    "finished_requests": 67271,
    "scheduler_time": 105.32566723309411
}
#Debug simulation 
Total elapsed time: 17.23375147115439. Arrivals time: 0.2713186894543469 Scheduler time: 16.85676330840215 Scheduler overhead time: 0.03568070102483034 Adapter cache time: 0.019804774317890406 Engine time: 0.03577062347903848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.92736771889031,
    "estimated_duration": 3600.060113249705,
    "input_throughput": 4430.583517562964,
    "output_throughput": 3909.4911077180063,
    "total_throughput": 8340.07462528097,
    "itl": 178.74053072582993,
    "ttft": 1866181.6019137811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9845829441771503,
    "arrivals": 192504,
    "finished_requests": 64448,
    "scheduler_time": 111.08929299331096
}
#Debug simulation 
Total elapsed time: 8.927494323812425. Arrivals time: 0.2407487230375409 Scheduler time: 8.574331299867481 Scheduler overhead time: 0.03374818246811628 Adapter cache time: 0.028680493123829365 Engine time: 0.03440826432779431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.853573670145124,
    "estimated_duration": 3600.07031725384,
    "input_throughput": 4618.667285555577,
    "output_throughput": 4079.045881304261,
    "total_throughput": 8697.713166859838,
    "itl": 209.97563273006222,
    "ttft": 1819026.7055434145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4904575312952668,
    "arrivals": 191087,
    "finished_requests": 67261,
    "scheduler_time": 105.28111309885544
}
#Debug simulation 
Total elapsed time: 15.85367268603295. Arrivals time: 0.2648381213657558 Scheduler time: 15.490138108376414 Scheduler overhead time: 0.03507033875212073 Adapter cache time: 0.014604753814637661 Engine time: 0.03462569275870919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.87269267020747,
    "estimated_duration": 3600.1442623857292,
    "input_throughput": 4618.544643814191,
    "output_throughput": 4078.825716353107,
    "total_throughput": 8697.370360167297,
    "itl": 209.98330037247254,
    "ttft": 1819057.7554240753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5918081393395611,
    "arrivals": 191087,
    "finished_requests": 67259,
    "scheduler_time": 105.28130620494757
}
#Debug simulation 
Total elapsed time: 15.87281551817432. Arrivals time: 0.2632454223930836 Scheduler time: 15.510976031888276 Scheduler overhead time: 0.03458546753972769 Adapter cache time: 0.014717697631567717 Engine time: 0.03492044843733311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.006136790849268,
    "estimated_duration": 3600.0835351232536,
    "input_throughput": 4417.719712566475,
    "output_throughput": 3909.4942833092177,
    "total_throughput": 8327.213995875692,
    "itl": 178.38343353611376,
    "ttft": 1865278.308861198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.708004009239324,
    "arrivals": 191087,
    "finished_requests": 64338,
    "scheduler_time": 111.0623174161992
}
#Debug simulation 
Total elapsed time: 8.006257682107389. Arrivals time: 0.23738904111087322 Scheduler time: 7.658363958355039 Scheduler overhead time: 0.033333413768559694 Adapter cache time: 0.027548678684979677 Engine time: 0.03417410561814904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 15.86799224326387,
    "estimated_duration": 3600.017048664235,
    "input_throughput": 4619.11701395138,
    "output_throughput": 4079.277348269491,
    "total_throughput": 8698.39436222087,
    "itl": 209.9796350171299,
    "ttft": 1818583.9478271632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5129681890015432,
    "arrivals": 191087,
    "finished_requests": 67260,
    "scheduler_time": 105.28045187217187
}
#Debug simulation 
Total elapsed time: 15.868092879187316. Arrivals time: 0.2790534715168178 Scheduler time: 15.490522161591798 Scheduler overhead time: 0.034908991772681475 Adapter cache time: 0.014407338108867407 Engine time: 0.035018498077988625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 8.02900089789182,
    "estimated_duration": 3600.161572318314,
    "input_throughput": 4419.832465950532,
    "output_throughput": 3910.8086448835456,
    "total_throughput": 8330.641110834078,
    "itl": 178.2652671606114,
    "ttft": 1865529.9070265926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8846851357445127,
    "arrivals": 191087,
    "finished_requests": 64398,
    "scheduler_time": 111.08649371128574
}
#Debug simulation 
Total elapsed time: 8.029108128044754. Arrivals time: 0.23256879718974233 Scheduler time: 7.68522443016991 Scheduler overhead time: 0.033689519856125116 Adapter cache time: 0.02799473935738206 Engine time: 0.034210510551929474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.909488869830966,
    "estimated_duration": 3600.0280933173353,
    "input_throughput": 4618.6936793257755,
    "output_throughput": 4078.957335710325,
    "total_throughput": 8697.651015036101,
    "itl": 209.97686714954494,
    "ttft": 1819018.7854307373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4561544936173447,
    "arrivals": 191087,
    "finished_requests": 67259,
    "scheduler_time": 105.28052830754612
}
#Debug simulation 
Total elapsed time: 15.909585942979902. Arrivals time: 0.2681599147617817 Scheduler time: 15.542232348583639 Scheduler overhead time: 0.03482711315155029 Adapter cache time: 0.01457354798913002 Engine time: 0.03512309631332755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.344204091001302,
    "estimated_duration": 3600.149540291893,
    "input_throughput": 4421.229680006424,
    "output_throughput": 3910.576169805027,
    "total_throughput": 8331.805849811451,
    "itl": 178.49101457359802,
    "ttft": 1864964.9483386455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.61381123997276,
    "arrivals": 191087,
    "finished_requests": 64362,
    "scheduler_time": 111.04321327145458
}
#Debug simulation 
Total elapsed time: 8.344271254725754. Arrivals time: 0.2345197508111596 Scheduler time: 8.000900816638023 Scheduler overhead time: 0.033406554721295834 Adapter cache time: 0.02614271128550172 Engine time: 0.03391789458692074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.71878020465374,
    "estimated_duration": 3600.020632072986,
    "input_throughput": 4606.960819124482,
    "output_throughput": 4077.09885583301,
    "total_throughput": 8684.059674957492,
    "itl": 210.39060084835253,
    "ttft": 1811568.176277207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.989317033556323,
    "arrivals": 188115,
    "finished_requests": 67130,
    "scheduler_time": 105.10113956967409
}
#Debug simulation 
Total elapsed time: 11.718907454051077. Arrivals time: 0.25775482319295406 Scheduler time: 11.36584290675819 Scheduler overhead time: 0.03204850433394313 Adapter cache time: 0.017303343396633863 Engine time: 0.032169312704354525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.892695093993098,
    "estimated_duration": 3600.094757621994,
    "input_throughput": 4607.402892627312,
    "output_throughput": 4077.356288726127,
    "total_throughput": 8684.75918135344,
    "itl": 210.39049937043566,
    "ttft": 1811309.0497071238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.12275720729493,
    "arrivals": 188115,
    "finished_requests": 67142,
    "scheduler_time": 105.09830130639769
}
#Debug simulation 
Total elapsed time: 10.892823186703026. Arrivals time: 0.2520173452794552 Scheduler time: 10.546193928457797 Scheduler overhead time: 0.03207301115617156 Adapter cache time: 0.016995464451611042 Engine time: 0.03191646933555603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.8983917511068285,
    "estimated_duration": 3600.015361251523,
    "input_throughput": 4420.894747089954,
    "output_throughput": 3912.794970714527,
    "total_throughput": 8333.689717804482,
    "itl": 178.86886275071058,
    "ttft": 1853782.1135602377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1047,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.420613995864945,
    "arrivals": 188115,
    "finished_requests": 64416,
    "scheduler_time": 110.86442826158144
}
#Debug simulation 
Total elapsed time: 6.898487308993936. Arrivals time: 0.22188197635114193 Scheduler time: 6.570632923394442 Scheduler overhead time: 0.03283442510291934 Adapter cache time: 0.024309765081852674 Engine time: 0.03357810154557228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.908841027878225,
    "estimated_duration": 3600.0655491509274,
    "input_throughput": 4602.293145442221,
    "output_throughput": 4075.085800440507,
    "total_throughput": 8677.378945882729,
    "itl": 210.47935959234619,
    "ttft": 1813126.6686200877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3077100443583713,
    "arrivals": 188115,
    "finished_requests": 67103,
    "scheduler_time": 105.07981804072224
}
#Debug simulation 
Total elapsed time: 11.908976707141846. Arrivals time: 0.2574497736059129 Scheduler time: 11.553518825210631 Scheduler overhead time: 0.03290284937247634 Adapter cache time: 0.01829379517585039 Engine time: 0.03308558510616422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.898761447053403,
    "estimated_duration": 3600.144963776436,
    "input_throughput": 4419.040388671398,
    "output_throughput": 3910.841686005598,
    "total_throughput": 8329.882074676998,
    "itl": 178.64490931188075,
    "ttft": 1853996.7367739684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1070,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.541619499903173,
    "arrivals": 188115,
    "finished_requests": 64387,
    "scheduler_time": 110.91734449435066
}
#Debug simulation 
Total elapsed time: 6.898860580287874. Arrivals time: 0.22110549407079816 Scheduler time: 6.571124960668385 Scheduler overhead time: 0.032811586279422045 Adapter cache time: 0.024983790703117847 Engine time: 0.033583042211830616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.87252381304279,
    "estimated_duration": 3600.1660781050514,
    "input_throughput": 4607.615771084426,
    "output_throughput": 4077.489393968912,
    "total_throughput": 8685.105165053337,
    "itl": 210.38255256233978,
    "ttft": 1811298.7716650073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9495127922761861,
    "arrivals": 188115,
    "finished_requests": 67146,
    "scheduler_time": 105.1046152742143
}
#Debug simulation 
Total elapsed time: 10.872619145084172. Arrivals time: 0.25397501280531287 Scheduler time: 10.524266684427857 Scheduler overhead time: 0.031439367681741714 Adapter cache time: 0.017085124738514423 Engine time: 0.032219645101577044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.880298111587763,
    "estimated_duration": 3600.103100322036,
    "input_throughput": 4418.657620826757,
    "output_throughput": 3911.1468776381626,
    "total_throughput": 8329.80449846492,
    "itl": 178.71457215050899,
    "ttft": 1854058.4687123126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.503917602226185,
    "arrivals": 188115,
    "finished_requests": 64396,
    "scheduler_time": 110.90157584135727
}
#Debug simulation 
Total elapsed time: 6.880424825940281. Arrivals time: 0.2205545725300908 Scheduler time: 6.5538141848519444 Scheduler overhead time: 0.03295132610946894 Adapter cache time: 0.024271459318697453 Engine time: 0.03361068246886134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 22.325860043987632,
    "estimated_duration": 3600.020844256017,
    "input_throughput": 4536.657343542463,
    "output_throughput": 3985.20720314466,
    "total_throughput": 8521.864546687124,
    "itl": 192.7464369617747,
    "ttft": 948150.591585994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.294643797003812,
    "arrivals": 80883,
    "finished_requests": 65752,
    "scheduler_time": 72.41615435905616
}
#Debug simulation 
Total elapsed time: 22.32595700165257. Arrivals time: 0.2338813403621316 Scheduler time: 21.95940776821226 Scheduler overhead time: 0.03892278112471104 Adapter cache time: 0.03872077073901892 Engine time: 0.03909447090700269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 28.26691986201331,
    "estimated_duration": 3600.1697484260408,
    "input_throughput": 4523.435320548344,
    "output_throughput": 3979.0512673083995,
    "total_throughput": 8502.486587856743,
    "itl": 191.73112239038997,
    "ttft": 926747.6510797113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.380735094149011,
    "arrivals": 80883,
    "finished_requests": 65631,
    "scheduler_time": 72.5713988207358
}
#Debug simulation 
Total elapsed time: 28.267087946645916. Arrivals time: 0.24028756842017174 Scheduler time: 27.891300757881254 Scheduler overhead time: 0.040950787253677845 Adapter cache time: 0.03781861439347267 Engine time: 0.04034436494112015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 19.953034115955234,
    "estimated_duration": 3600.1791560292163,
    "input_throughput": 4399.36634083203,
    "output_throughput": 3871.6264929919184,
    "total_throughput": 8270.992833823948,
    "itl": 170.0836222722553,
    "ttft": 1039623.9454920297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.896882942691397,
    "arrivals": 80883,
    "finished_requests": 63801,
    "scheduler_time": 74.94079087912111
}
#Debug simulation 
Total elapsed time: 19.95315522281453. Arrivals time: 0.2289702990092337 Scheduler time: 19.582955251913518 Scheduler overhead time: 0.041015179827809334 Adapter cache time: 0.0414660251699388 Engine time: 0.04144513700157404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 28.288275084923953,
    "estimated_duration": 3600.052362950382,
    "input_throughput": 4530.079942124657,
    "output_throughput": 3978.8071271999497,
    "total_throughput": 8508.887069324606,
    "itl": 191.08526292013767,
    "ttft": 926759.2529264686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.226691919315942,
    "arrivals": 80883,
    "finished_requests": 65673,
    "scheduler_time": 72.58041261766445
}
#Debug simulation 
Total elapsed time: 28.288396552205086. Arrivals time: 0.24145183339715004 Scheduler time: 27.908945556730032 Scheduler overhead time: 0.042058521416038275 Adapter cache time: 0.0385554782114923 Engine time: 0.04099925793707371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 20.417115238960832,
    "estimated_duration": 3600.1068401582866,
    "input_throughput": 4389.193349413277,
    "output_throughput": 3872.7253437253544,
    "total_throughput": 8261.918693138632,
    "itl": 169.97907344245354,
    "ttft": 1045940.5288929149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.859298314433454,
    "arrivals": 80883,
    "finished_requests": 63709,
    "scheduler_time": 75.00282086922874
}
#Debug simulation 
Total elapsed time: 20.41726696304977. Arrivals time: 0.23049134155735373 Scheduler time: 20.044394462835044 Scheduler overhead time: 0.04219977045431733 Adapter cache time: 0.04100762167945504 Engine time: 0.04170029843226075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 27.713554047979414,
    "estimated_duration": 3600.059072684579,
    "input_throughput": 4546.103458184542,
    "output_throughput": 3988.3164998437232,
    "total_throughput": 8534.419958028266,
    "itl": 192.39456451706428,
    "ttft": 930829.6393239168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.68540881211158,
    "arrivals": 80883,
    "finished_requests": 65824,
    "scheduler_time": 72.37421632431194
}
#Debug simulation 
Total elapsed time: 27.71365504199639. Arrivals time: 0.24832074204459786 Scheduler time: 27.330426758620888 Scheduler overhead time: 0.04104157676920295 Adapter cache time: 0.03701313538476825 Engine time: 0.04058236489072442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 18.237763760145754,
    "estimated_duration": 3600.136340809386,
    "input_throughput": 4398.016214141575,
    "output_throughput": 3871.9394712884973,
    "total_throughput": 8269.955685430072,
    "itl": 169.87341451426008,
    "ttft": 1058245.4659827156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.428987298868415,
    "arrivals": 80883,
    "finished_requests": 63784,
    "scheduler_time": 74.99155218904247
}
#Debug simulation 
Total elapsed time: 18.2379206600599. Arrivals time: 0.23467020550742745 Scheduler time: 17.861362571828067 Scheduler overhead time: 0.04089803388342261 Adapter cache time: 0.042616862803697586 Engine time: 0.040993457194417715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 21.58492903318256,
    "estimated_duration": 3600.1781748653357,
    "input_throughput": 4521.520382976292,
    "output_throughput": 3938.043983206557,
    "total_throughput": 8459.564366182849,
    "itl": 184.87078699989482,
    "ttft": 683802.9272914325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9863140271326385,
    "arrivals": 75147,
    "finished_requests": 65166,
    "scheduler_time": 66.65823329217109
}
#Debug simulation 
Total elapsed time: 21.58503742981702. Arrivals time: 0.22125198738649487 Scheduler time: 21.224820046685636 Scheduler overhead time: 0.03995806025341153 Adapter cache time: 0.04324418539181352 Engine time: 0.03951644245535135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 21.28720017289743,
    "estimated_duration": 3600.110325382641,
    "input_throughput": 4519.870650983596,
    "output_throughput": 3942.1639109050266,
    "total_throughput": 8462.034561888622,
    "itl": 184.94355449208965,
    "ttft": 686467.150625217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.101859487264696,
    "arrivals": 75147,
    "finished_requests": 65195,
    "scheduler_time": 66.62099306114786
}
#Debug simulation 
Total elapsed time: 21.28731672791764. Arrivals time: 0.21329379361122847 Scheduler time: 20.93640773370862 Scheduler overhead time: 0.03988317679613829 Adapter cache time: 0.04092370858415961 Engine time: 0.04035219457000494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.360503671690822,
    "estimated_duration": 3600.185022276866,
    "input_throughput": 4415.270576829137,
    "output_throughput": 3854.7191086371777,
    "total_throughput": 8269.989685466315,
    "itl": 167.53293870238898,
    "ttft": 784757.5505595237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.878416421506513,
    "arrivals": 75147,
    "finished_requests": 63669,
    "scheduler_time": 67.87265516367854
}
#Debug simulation 
Total elapsed time: 15.360615714918822. Arrivals time: 0.20813071355223656 Scheduler time: 15.010408986359835 Scheduler overhead time: 0.03939195116981864 Adapter cache time: 0.04652275051921606 Engine time: 0.039291133638471365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 20.873894442804158,
    "estimated_duration": 3600.115635537635,
    "input_throughput": 4522.5125102317825,
    "output_throughput": 3943.718601660893,
    "total_throughput": 8466.231111892675,
    "itl": 185.03965510252374,
    "ttft": 683618.2987831208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.948297952452967,
    "arrivals": 75147,
    "finished_requests": 65281,
    "scheduler_time": 66.57861171205467
}
#Debug simulation 
Total elapsed time: 20.874035021755844. Arrivals time: 0.21344651794061065 Scheduler time: 20.523571335710585 Scheduler overhead time: 0.039617661852389574 Adapter cache time: 0.04138839617371559 Engine time: 0.03963474044576287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 15.85938789183274,
    "estimated_duration": 3600.0151888093737,
    "input_throughput": 4422.692173492127,
    "output_throughput": 3861.466208034962,
    "total_throughput": 8284.15838152709,
    "itl": 167.75837126026178,
    "ttft": 779536.062789025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8983771682343065,
    "arrivals": 75147,
    "finished_requests": 63793,
    "scheduler_time": 67.8257324849928
}
#Debug simulation 
Total elapsed time: 15.85948109999299. Arrivals time: 0.2021051743067801 Scheduler time: 15.515670561231673 Scheduler overhead time: 0.03982568345963955 Adapter cache time: 0.045532632153481245 Engine time: 0.03926893277093768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 21.588367111980915,
    "estimated_duration": 3600.034640323311,
    "input_throughput": 4526.154225709518,
    "output_throughput": 3943.187612973947,
    "total_throughput": 8469.341838683466,
    "itl": 185.27806089532078,
    "ttft": 682947.0538688537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.48076219055553,
    "arrivals": 75147,
    "finished_requests": 65205,
    "scheduler_time": 66.63082290581539
}
#Debug simulation 
Total elapsed time: 21.588489816058427. Arrivals time: 0.21769344294443727 Scheduler time: 21.232460083439946 Scheduler overhead time: 0.040734786074608564 Adapter cache time: 0.0407461728900671 Engine time: 0.04054771922528744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.168320877011865,
    "estimated_duration": 3600.1706538403837,
    "input_throughput": 4413.098857703317,
    "output_throughput": 3856.808839099995,
    "total_throughput": 8269.907696803311,
    "itl": 167.57915883139378,
    "ttft": 784225.2982976735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.087824676036591,
    "arrivals": 75147,
    "finished_requests": 63665,
    "scheduler_time": 67.8336504188714
}
#Debug simulation 
Total elapsed time: 15.168460377957672. Arrivals time: 0.19834422320127487 Scheduler time: 14.830210412386805 Scheduler overhead time: 0.038952425587922335 Adapter cache time: 0.04548673750832677 Engine time: 0.03859988274052739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.054379405919462,
    "estimated_duration": 3600.033873859374,
    "input_throughput": 4434.615217352152,
    "output_throughput": 3928.2572041021895,
    "total_throughput": 8362.872421454342,
    "itl": 182.04547511147686,
    "ttft": 537488.6310170708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.36275401963638,
    "arrivals": 72240,
    "finished_requests": 64620,
    "scheduler_time": 63.132589887550786
}
#Debug simulation 
Total elapsed time: 17.054526804946363. Arrivals time: 0.186451671179384 Scheduler time: 16.73399883462116 Scheduler overhead time: 0.03721193689852953 Adapter cache time: 0.04442100180312991 Engine time: 0.03664021799340844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 18.15112744970247,
    "estimated_duration": 3600.1892104166764,
    "input_throughput": 4430.565469683714,
    "output_throughput": 3932.1680535678174,
    "total_throughput": 8362.73352325153,
    "itl": 181.04490939521244,
    "ttft": 537451.0197297293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.345317239349035,
    "arrivals": 72240,
    "finished_requests": 64614,
    "scheduler_time": 63.21228700290779
}
#Debug simulation 
Total elapsed time: 18.151243512984365. Arrivals time: 0.19125506887212396 Scheduler time: 17.825738242827356 Scheduler overhead time: 0.03781300690025091 Adapter cache time: 0.04280961258336902 Engine time: 0.037515824660658836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.865894232876599,
    "estimated_duration": 3600.011618367024,
    "input_throughput": 4354.633723963095,
    "output_throughput": 3860.057264566102,
    "total_throughput": 8214.690988529197,
    "itl": 167.35135288039746,
    "ttft": 617339.5703709272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3206554830818975,
    "arrivals": 72240,
    "finished_requests": 63465,
    "scheduler_time": 63.753730485142974
}
#Debug simulation 
Total elapsed time: 13.86599109089002. Arrivals time: 0.18108352180570364 Scheduler time: 13.544731737114489 Scheduler overhead time: 0.03797307284548879 Adapter cache time: 0.04749208455905318 Engine time: 0.03790273051708937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.891901546623558,
    "estimated_duration": 3600.050373905095,
    "input_throughput": 4439.184550260768,
    "output_throughput": 3933.74828937139,
    "total_throughput": 8372.932839632158,
    "itl": 181.82438798459566,
    "ttft": 534027.8853079185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.012723389919673,
    "arrivals": 72240,
    "finished_requests": 64715,
    "scheduler_time": 63.19864070672783
}
#Debug simulation 
Total elapsed time: 17.892042307648808. Arrivals time: 0.1859194370917976 Scheduler time: 17.57150713633746 Scheduler overhead time: 0.03789717610925436 Adapter cache time: 0.04226133693009615 Engine time: 0.038006999995559454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 14.564030832145363,
    "estimated_duration": 3600.113405819617,
    "input_throughput": 4353.326752058784,
    "output_throughput": 3858.7689980941827,
    "total_throughput": 8212.095750152967,
    "itl": 167.1286449500191,
    "ttft": 614600.613094586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.283303839731807,
    "arrivals": 72240,
    "finished_requests": 63468,
    "scheduler_time": 63.729212478951574
}
#Debug simulation 
Total elapsed time: 14.5641402550973. Arrivals time: 0.1880285805091262 Scheduler time: 14.234909118618816 Scheduler overhead time: 0.03844119841232896 Adapter cache time: 0.0475925225764513 Engine time: 0.03831850225105882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 18.042642809916288,
    "estimated_duration": 3600.0614348506188,
    "input_throughput": 4434.2068292127315,
    "output_throughput": 3939.4436057973767,
    "total_throughput": 8373.65043501011,
    "itl": 181.8140858057032,
    "ttft": 537336.7174931994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.884418980367309,
    "arrivals": 72240,
    "finished_requests": 64666,
    "scheduler_time": 63.22962845819319
}
#Debug simulation 
Total elapsed time: 18.042745461687446. Arrivals time: 0.18994983937591314 Scheduler time: 17.718195855617523 Scheduler overhead time: 0.03772468492388725 Adapter cache time: 0.0428745630197227 Engine time: 0.037994927726686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.269085149746388,
    "estimated_duration": 3600.0852635927895,
    "input_throughput": 4352.602189305377,
    "output_throughput": 3862.8390667952217,
    "total_throughput": 8215.441256100597,
    "itl": 167.47353772476202,
    "ttft": 613516.9298016059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.5637239630889965,
    "arrivals": 72240,
    "finished_requests": 63496,
    "scheduler_time": 63.70197776445757
}
#Debug simulation 
Total elapsed time: 14.269177340902388. Arrivals time: 0.18058964842930436 Scheduler time: 13.946507318411022 Scheduler overhead time: 0.03864877950400114 Adapter cache time: 0.047772131860256195 Engine time: 0.03879810590296984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.17542608315125,
    "estimated_duration": 3600.1408227034185,
    "input_throughput": 4430.866953704748,
    "output_throughput": 3919.77944612822,
    "total_throughput": 8350.646399832967,
    "itl": 180.06040598650193,
    "ttft": 476942.113008913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.462970622920119,
    "arrivals": 70816,
    "finished_requests": 64387,
    "scheduler_time": 62.14711812045354
}
#Debug simulation 
Total elapsed time: 17.175529656000435. Arrivals time: 0.1838800422847271 Scheduler time: 16.861899591516703 Scheduler overhead time: 0.03699165070429444 Adapter cache time: 0.039548422675579786 Engine time: 0.037265156395733356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.937779068946838,
    "estimated_duration": 3600.224708291896,
    "input_throughput": 4433.432991901432,
    "output_throughput": 3924.2517189164646,
    "total_throughput": 8357.684710817895,
    "itl": 181.58778047171745,
    "ttft": 472044.19336414186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.526931008943137,
    "arrivals": 70816,
    "finished_requests": 64472,
    "scheduler_time": 62.05288430197199
}
#Debug simulation 
Total elapsed time: 15.937913788948208. Arrivals time: 0.178992863278836 Scheduler time: 15.627949230838567 Scheduler overhead time: 0.03681480884552002 Adapter cache time: 0.04185317875817418 Engine time: 0.03650911431759596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.285229470115155,
    "estimated_duration": 3600.120447248108,
    "input_throughput": 4346.059869180179,
    "output_throughput": 3854.5713131924135,
    "total_throughput": 8200.631182372592,
    "itl": 166.23529011757066,
    "ttft": 558882.8192421197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.761200015786997,
    "arrivals": 70816,
    "finished_requests": 63156,
    "scheduler_time": 62.52524808909298
}
#Debug simulation 
Total elapsed time: 12.285334148909897. Arrivals time: 0.1772823017090559 Scheduler time: 11.966935628093779 Scheduler overhead time: 0.037686670664697886 Adapter cache time: 0.0493280696682632 Engine time: 0.03738792613148689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 15.702277353964746,
    "estimated_duration": 3600.1264628034664,
    "input_throughput": 4442.864761907441,
    "output_throughput": 3932.188534559489,
    "total_throughput": 8375.05329646693,
    "itl": 182.61165447857098,
    "ttft": 467650.18256600545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.336503904647928,
    "arrivals": 70816,
    "finished_requests": 64616,
    "scheduler_time": 62.03440382935235
}
#Debug simulation 
Total elapsed time: 15.702366444282234. Arrivals time: 0.1818809900432825 Scheduler time: 15.387582772877067 Scheduler overhead time: 0.03708277456462383 Adapter cache time: 0.0431712563149631 Engine time: 0.03667783550918102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.805814965162426,
    "estimated_duration": 3600.005040418245,
    "input_throughput": 4349.816131974279,
    "output_throughput": 3855.716823770715,
    "total_throughput": 8205.532955744995,
    "itl": 166.32538866320292,
    "ttft": 556619.6287922164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6474403188189655,
    "arrivals": 70816,
    "finished_requests": 63196,
    "scheduler_time": 62.51497699483293
}
#Debug simulation 
Total elapsed time: 12.805905130226165. Arrivals time: 0.18382171029224992 Scheduler time: 12.481525029521435 Scheduler overhead time: 0.03807227918878198 Adapter cache time: 0.047932113986462355 Engine time: 0.03775189816951752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 16.42675687139854,
    "estimated_duration": 3600.2084837396865,
    "input_throughput": 4434.084045993335,
    "output_throughput": 3927.7183707182326,
    "total_throughput": 8361.802416711567,
    "itl": 181.58268699952825,
    "ttft": 471953.53732328385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.728936365032402,
    "arrivals": 70816,
    "finished_requests": 64539,
    "scheduler_time": 62.09285984020089
}
#Debug simulation 
Total elapsed time: 16.42688961699605. Arrivals time: 0.18638706114143133 Scheduler time: 16.10922659887001 Scheduler overhead time: 0.03706718748435378 Adapter cache time: 0.0411078785546124 Engine time: 0.03698680177330971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.280580305028707,
    "estimated_duration": 3600.132564283381,
    "input_throughput": 4351.734476510461,
    "output_throughput": 3856.59132048203,
    "total_throughput": 8208.32579699249,
    "itl": 166.57753043093734,
    "ttft": 554158.7613755097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.049216807968575,
    "arrivals": 70816,
    "finished_requests": 63226,
    "scheduler_time": 62.49412882622344
}
#Debug simulation 
Total elapsed time: 12.280717562884092. Arrivals time: 0.17863634135574102 Scheduler time: 11.960929215420038 Scheduler overhead time: 0.03744944231584668 Adapter cache time: 0.049527259543538094 Engine time: 0.037509032525122166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.526240986771882,
    "estimated_duration": 3600.054611039378,
    "input_throughput": 4219.91681832124,
    "output_throughput": 3701.0244120028046,
    "total_throughput": 7920.941230324044,
    "itl": 145.80608044062657,
    "ttft": 245048.0972190832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.34288958996084,
    "arrivals": 63706,
    "finished_requests": 60868,
    "scheduler_time": 54.762404480919955
}
#Debug simulation 
Total elapsed time: 13.526351575739682. Arrivals time: 0.16849875170737505 Scheduler time: 13.20288119930774 Scheduler overhead time: 0.041263108141720295 Adapter cache time: 0.05431148502975702 Engine time: 0.04091410432010889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.467222263105214,
    "estimated_duration": 3600.149055138929,
    "input_throughput": 4220.246375163954,
    "output_throughput": 3699.178782886832,
    "total_throughput": 7919.425158050786,
    "itl": 145.77251137857297,
    "ttft": 244111.68017860744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.019434334400408,
    "arrivals": 63706,
    "finished_requests": 60870,
    "scheduler_time": 54.7030472590667
}
#Debug simulation 
Total elapsed time: 13.467318126000464. Arrivals time: 0.16443367023020983 Scheduler time: 13.146906062029302 Scheduler overhead time: 0.04112799372524023 Adapter cache time: 0.05545589094981551 Engine time: 0.040896378457546234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.415225896053016,
    "estimated_duration": 3600.148432724795,
    "input_throughput": 4217.606102565023,
    "output_throughput": 3698.1511314863474,
    "total_throughput": 7915.757234051371,
    "itl": 145.80796653436167,
    "ttft": 247357.24484971244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.878655226118674,
    "arrivals": 63706,
    "finished_requests": 60830,
    "scheduler_time": 54.7546224908804
}
#Debug simulation 
Total elapsed time: 13.415309858042747. Arrivals time: 0.15959632629528642 Scheduler time: 13.099638987332582 Scheduler overhead time: 0.04120262386277318 Adapter cache time: 0.055216153617948294 Engine time: 0.0412109843455255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 13.280272617004812,
    "estimated_duration": 3600.1396520279827,
    "input_throughput": 4220.949871052915,
    "output_throughput": 3704.0749217848256,
    "total_throughput": 7925.024792837741,
    "itl": 146.31643603044222,
    "ttft": 240632.76809850748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.697886025127804,
    "arrivals": 63706,
    "finished_requests": 60917,
    "scheduler_time": 54.7145393647982
}
#Debug simulation 
Total elapsed time: 13.280384517740458. Arrivals time: 0.15942005766555667 Scheduler time: 12.964243880007416 Scheduler overhead time: 0.041731227189302444 Adapter cache time: 0.05530873592942953 Engine time: 0.04111472237855196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 13.299754582811147,
    "estimated_duration": 3600.1199086168617,
    "input_throughput": 4220.5327560430005,
    "output_throughput": 3699.4176133196647,
    "total_throughput": 7919.950369362666,
    "itl": 146.18987944392975,
    "ttft": 244502.325516433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.050638515129354,
    "arrivals": 63706,
    "finished_requests": 60874,
    "scheduler_time": 54.76070733201205
}
#Debug simulation 
Total elapsed time: 13.299877215642482. Arrivals time: 0.16126569407060742 Scheduler time: 12.983240701258183 Scheduler overhead time: 0.04098073020577431 Adapter cache time: 0.05497052567079663 Engine time: 0.040977292228490114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.366705781314522,
    "estimated_duration": 3600.032000951884,
    "input_throughput": 4221.198310454437,
    "output_throughput": 3701.0609895903754,
    "total_throughput": 7922.259300044812,
    "itl": 145.94087383408706,
    "ttft": 240007.84226349383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.291409467763561,
    "arrivals": 63706,
    "finished_requests": 60930,
    "scheduler_time": 54.70192195546173
}
#Debug simulation 
Total elapsed time: 13.366808067075908. Arrivals time: 0.15883281081914902 Scheduler time: 13.051964654121548 Scheduler overhead time: 0.04114689165726304 Adapter cache time: 0.05546591617166996 Engine time: 0.04087795643135905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.412027440033853,
    "estimated_duration": 3600.0059936476823,
    "input_throughput": 4217.617144746882,
    "output_throughput": 3698.8166196100947,
    "total_throughput": 7916.433764356977,
    "itl": 145.79128842819497,
    "ttft": 245962.58048720786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.156432333476392,
    "arrivals": 63706,
    "finished_requests": 60840,
    "scheduler_time": 54.71942419511949
}
#Debug simulation 
Total elapsed time: 13.412113330792636. Arrivals time: 0.1609967635013163 Scheduler time: 13.09485444240272 Scheduler overhead time: 0.041530610993504524 Adapter cache time: 0.05516680097207427 Engine time: 0.041092274710536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.849350119940937,
    "estimated_duration": 3600.081653549951,
    "input_throughput": 4068.930488161427,
    "output_throughput": 3602.469679322803,
    "total_throughput": 7671.40016748423,
    "itl": 134.32676555428213,
    "ttft": 167996.09173916414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.961887606500854,
    "arrivals": 60894,
    "finished_requests": 59062,
    "scheduler_time": 51.48387608838199
}
#Debug simulation 
Total elapsed time: 10.849433215800673. Arrivals time: 0.15157683426514268 Scheduler time: 10.527975929435343 Scheduler overhead time: 0.043303232640028 Adapter cache time: 0.06398095935583115 Engine time: 0.042999775148928165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.763306059874594,
    "estimated_duration": 3600.0186376541924,
    "input_throughput": 4066.868389753696,
    "output_throughput": 3604.100507783628,
    "total_throughput": 7670.968897537324,
    "itl": 134.5821498085404,
    "ttft": 168630.38733753856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.595345148563034,
    "arrivals": 60894,
    "finished_requests": 59050,
    "scheduler_time": 51.4911527728646
}
#Debug simulation 
Total elapsed time: 10.763401670847088. Arrivals time: 0.14705020654946566 Scheduler time: 10.44858021568507 Scheduler overhead time: 0.04293669015169144 Adapter cache time: 0.06219133595004678 Engine time: 0.04311084095388651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.795989828649908,
    "estimated_duration": 3600.1523662993886,
    "input_throughput": 4067.6403413038756,
    "output_throughput": 3603.2099978407523,
    "total_throughput": 7670.8503391446275,
    "itl": 134.33540037896722,
    "ttft": 168439.85924612082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.682093630842356,
    "arrivals": 60894,
    "finished_requests": 59052,
    "scheduler_time": 51.46211746023232
}
#Debug simulation 
Total elapsed time: 10.796098813880235. Arrivals time: 0.15047746011987329 Scheduler time: 10.47718254942447 Scheduler overhead time: 0.04258851008489728 Adapter cache time: 0.06358892936259508 Engine time: 0.04265663353726268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.733996820170432,
    "estimated_duration": 3600.082290926733,
    "input_throughput": 4066.9845344649025,
    "output_throughput": 3602.248768780693,
    "total_throughput": 7669.233303245595,
    "itl": 134.40947086810428,
    "ttft": 169025.3623228751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.179338276027876,
    "arrivals": 60894,
    "finished_requests": 59040,
    "scheduler_time": 51.4765483348502
}
#Debug simulation 
Total elapsed time: 10.734099470078945. Arrivals time: 0.14630589773878455 Scheduler time: 10.42017473326996 Scheduler overhead time: 0.042643158696591854 Adapter cache time: 0.0627792039886117 Engine time: 0.042719084303826094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.708143411204219,
    "estimated_duration": 3600.0682954031417,
    "input_throughput": 4068.4569841916946,
    "output_throughput": 3601.8919464826226,
    "total_throughput": 7670.348930674317,
    "itl": 134.41860889784388,
    "ttft": 168220.41330385604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.798040397334278,
    "arrivals": 60894,
    "finished_requests": 59053,
    "scheduler_time": 51.46954396449537
}
#Debug simulation 
Total elapsed time: 10.708249414339662. Arrivals time: 0.15143506415188313 Scheduler time: 10.389345050323755 Scheduler overhead time: 0.04255081806331873 Adapter cache time: 0.06288833729922771 Engine time: 0.042610091622918844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.892798638902605,
    "estimated_duration": 3600.124312280069,
    "input_throughput": 4066.9528966145804,
    "output_throughput": 3601.5142465423087,
    "total_throughput": 7668.4671431568895,
    "itl": 134.3346083451026,
    "ttft": 170192.57563027722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.666832603418921,
    "arrivals": 60894,
    "finished_requests": 59032,
    "scheduler_time": 51.49955553447796
}
#Debug simulation 
Total elapsed time: 10.89288678765297. Arrivals time: 0.1539393807761371 Scheduler time: 10.571230318862945 Scheduler overhead time: 0.04270678199827671 Adapter cache time: 0.06250619888305664 Engine time: 0.04293528851121664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.830822985153645,
    "estimated_duration": 3600.030191467054,
    "input_throughput": 4067.9114399404953,
    "output_throughput": 3601.9559032408383,
    "total_throughput": 7669.867343181333,
    "itl": 134.3252451848498,
    "ttft": 169486.8952798915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.95205587010768,
    "arrivals": 60894,
    "finished_requests": 59034,
    "scheduler_time": 51.46865175656246
}
#Debug simulation 
Total elapsed time: 10.830914322752506. Arrivals time: 0.14836147846654058 Scheduler time: 10.514631068333983 Scheduler overhead time: 0.042491162195801735 Adapter cache time: 0.0631187716498971 Engine time: 0.042724703904241323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.050815431866795,
    "estimated_duration": 3600.1355504507965,
    "input_throughput": 4020.80943818558,
    "output_throughput": 3546.6681243158123,
    "total_throughput": 7567.477562501392,
    "itl": 128.0858385705369,
    "ttft": 124763.3472642157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.56174320431152,
    "arrivals": 59412,
    "finished_requests": 58061,
    "scheduler_time": 49.45663236710726
}
#Debug simulation 
Total elapsed time: 9.05090190609917. Arrivals time: 0.1419139662757516 Scheduler time: 8.735702251084149 Scheduler overhead time: 0.04392365785315633 Adapter cache time: 0.06529541732743382 Engine time: 0.043944628443568945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.99357345700264,
    "estimated_duration": 3600.024684614899,
    "input_throughput": 4021.0307617789304,
    "output_throughput": 3544.610695180562,
    "total_throughput": 7565.641456959493,
    "itl": 128.1386277635568,
    "ttft": 125111.71895287411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.29048721660652,
    "arrivals": 59412,
    "finished_requests": 58052,
    "scheduler_time": 49.44588904825219
}
#Debug simulation 
Total elapsed time: 8.99365466600284. Arrivals time: 0.14026223588734865 Scheduler time: 8.681365030817688 Scheduler overhead time: 0.043282425962388515 Adapter cache time: 0.06532434420660138 Engine time: 0.04344698414206505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.030192243400961,
    "estimated_duration": 3600.0427949445575,
    "input_throughput": 4023.513559433416,
    "output_throughput": 3546.5236740877767,
    "total_throughput": 7570.037233521192,
    "itl": 128.1408661320781,
    "ttft": 123303.47912815902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.329934692754714,
    "arrivals": 59412,
    "finished_requests": 58081,
    "scheduler_time": 49.441065498058116
}
#Debug simulation 
Total elapsed time: 9.030274059157819. Arrivals time: 0.1402206397615373 Scheduler time: 8.71602279227227 Scheduler overhead time: 0.043712811544537544 Adapter cache time: 0.06580773368477821 Engine time: 0.04444705508649349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 9.068687330931425,
    "estimated_duration": 3600.0760514983504,
    "input_throughput": 4023.2030637163434,
    "output_throughput": 3547.635332504823,
    "total_throughput": 7570.8383962211665,
    "itl": 128.14845782825935,
    "ttft": 123632.97226473158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.837057350082645,
    "arrivals": 59412,
    "finished_requests": 58071,
    "scheduler_time": 49.43657432552213
}
#Debug simulation 
Total elapsed time: 9.068784633651376. Arrivals time: 0.1441669245250523 Scheduler time: 8.750002273358405 Scheduler overhead time: 0.04423463437706232 Adapter cache time: 0.06582032842561603 Engine time: 0.04423032747581601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 9.132412801031023,
    "estimated_duration": 3600.1220064479344,
    "input_throughput": 4019.4573889670414,
    "output_throughput": 3545.152074607775,
    "total_throughput": 7564.609463574816,
    "itl": 128.14278852504717,
    "ttft": 126769.8202121003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.395693859624943,
    "arrivals": 59412,
    "finished_requests": 58036,
    "scheduler_time": 49.47266053123687
}
#Debug simulation 
Total elapsed time: 9.132515304721892. Arrivals time: 0.1406536395661533 Scheduler time: 8.817666146438569 Scheduler overhead time: 0.04411942884325981 Adapter cache time: 0.06560484925284982 Engine time: 0.0443639331497252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.103192676324397,
    "estimated_duration": 3600.117950135557,
    "input_throughput": 4022.1598849156508,
    "output_throughput": 3547.5051586904565,
    "total_throughput": 7569.665043606107,
    "itl": 128.09167231087966,
    "ttft": 124317.49245069057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.327633718592475,
    "arrivals": 59412,
    "finished_requests": 58069,
    "scheduler_time": 49.46244659962927
}
#Debug simulation 
Total elapsed time: 9.103299843147397. Arrivals time: 0.14282548008486629 Scheduler time: 8.786797870881855 Scheduler overhead time: 0.04384992877021432 Adapter cache time: 0.06537173083052039 Engine time: 0.04431079747155309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.072966014966369,
    "estimated_duration": 3600.0284182945884,
    "input_throughput": 4019.966322059118,
    "output_throughput": 3546.5220038591474,
    "total_throughput": 7566.488325918265,
    "itl": 128.27886549913254,
    "ttft": 125323.07466152974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.578081604353386,
    "arrivals": 59412,
    "finished_requests": 58048,
    "scheduler_time": 49.45633864650185
}
#Debug simulation 
Total elapsed time: 9.073053796775639. Arrivals time: 0.1433703415095806 Scheduler time: 8.75566245848313 Scheduler overhead time: 0.044019849970936775 Adapter cache time: 0.06547854375094175 Engine time: 0.04443337954580784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.927216574084014,
    "estimated_duration": 3600.0992876765445,
    "input_throughput": 3763.7517516204143,
    "output_throughput": 3314.538585323624,
    "total_throughput": 7078.290336944038,
    "itl": 110.20280605596496,
    "ttft": 77678.29974919981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.935959682656064,
    "arrivals": 55057,
    "finished_requests": 54242,
    "scheduler_time": 44.21470488159525
}
#Debug simulation 
Total elapsed time: 6.927291723899543. Arrivals time: 0.1302218595519662 Scheduler time: 6.58229571627453 Scheduler overhead time: 0.04919168073683977 Adapter cache time: 0.09353905031457543 Engine time: 0.0493648792617023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.912271647714078,
    "estimated_duration": 3600.045007691035,
    "input_throughput": 3763.753778370225,
    "output_throughput": 3314.5332834750143,
    "total_throughput": 7078.28706184524,
    "itl": 110.32785420667433,
    "ttft": 78045.42178970038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.021023042798767,
    "arrivals": 55057,
    "finished_requests": 54236,
    "scheduler_time": 44.217950803706586
}
#Debug simulation 
Total elapsed time: 6.912352666724473. Arrivals time: 0.1333184139803052 Scheduler time: 6.564172791317105 Scheduler overhead time: 0.05008083814755082 Adapter cache time: 0.09299861267209053 Engine time: 0.04917225334793329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.946695876773447,
    "estimated_duration": 3600.052528337779,
    "input_throughput": 3764.5456262988214,
    "output_throughput": 3315.548566595825,
    "total_throughput": 7080.094192894647,
    "itl": 110.31011262803892,
    "ttft": 77367.37456028527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.026282638924823,
    "arrivals": 55057,
    "finished_requests": 54248,
    "scheduler_time": 44.221919231609746
}
#Debug simulation 
Total elapsed time: 6.946761824656278. Arrivals time: 0.13046334451064467 Scheduler time: 6.6020908248610795 Scheduler overhead time: 0.04926201421767473 Adapter cache time: 0.09322016639634967 Engine time: 0.04922124370932579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.888391703832895,
    "estimated_duration": 3600.075479666277,
    "input_throughput": 3763.4733150805932,
    "output_throughput": 3314.860498732167,
    "total_throughput": 7078.33381381276,
    "itl": 110.2195018609291,
    "ttft": 78286.41417407837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.21191506124473,
    "arrivals": 55057,
    "finished_requests": 54236,
    "scheduler_time": 44.220879810599115
}
#Debug simulation 
Total elapsed time: 6.888464519754052. Arrivals time: 0.13050773087888956 Scheduler time: 6.545116050168872 Scheduler overhead time: 0.04871517000719905 Adapter cache time: 0.09274998120963573 Engine time: 0.04899439588189125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.933691183105111,
    "estimated_duration": 3600.0014296548707,
    "input_throughput": 3763.304338826006,
    "output_throughput": 3314.7134058621764,
    "total_throughput": 7078.017744688183,
    "itl": 110.30580526781937,
    "ttft": 78450.49269302726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.245848750005184,
    "arrivals": 55057,
    "finished_requests": 54231,
    "scheduler_time": 44.22105187854076
}
#Debug simulation 
Total elapsed time: 6.933758263941854. Arrivals time: 0.13056366425007582 Scheduler time: 6.589796583168209 Scheduler overhead time: 0.04902907833456993 Adapter cache time: 0.09263229416683316 Engine time: 0.049172202590852976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.850210291799158,
    "estimated_duration": 3600.0104166959877,
    "input_throughput": 3763.650220888846,
    "output_throughput": 3315.0423522810083,
    "total_throughput": 7078.692573169854,
    "itl": 110.18368598330133,
    "ttft": 78122.0034529691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.533311282018524,
    "arrivals": 55057,
    "finished_requests": 54235,
    "scheduler_time": 44.214357922700216
}
#Debug simulation 
Total elapsed time: 6.85028816992417. Arrivals time: 0.12998046539723873 Scheduler time: 6.508668295573443 Scheduler overhead time: 0.048739691730588675 Adapter cache time: 0.09205136261880398 Engine time: 0.048453282564878464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.973687103018165,
    "estimated_duration": 3600.1095569399845,
    "input_throughput": 3764.485992898334,
    "output_throughput": 3315.496045666307,
    "total_throughput": 7079.982038564642,
    "itl": 110.3561155392766,
    "ttft": 77316.73541133982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.465792122444732,
    "arrivals": 55057,
    "finished_requests": 54248,
    "scheduler_time": 44.22094449155043
}
#Debug simulation 
Total elapsed time: 6.973756373859942. Arrivals time: 0.13244223035871983 Scheduler time: 6.6264666905626655 Scheduler overhead time: 0.04899926809594035 Adapter cache time: 0.0935288816690445 Engine time: 0.04976137774065137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.718089465051889,
    "estimated_duration": 3600.0532111390658,
    "input_throughput": 3680.618652802505,
    "output_throughput": 3215.4144178156275,
    "total_throughput": 6896.033070618133,
    "itl": 103.98692571939768,
    "ttft": 58455.234373681844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.10506600083872,
    "arrivals": 53529,
    "finished_requests": 52869,
    "scheduler_time": 41.76777627877523
}
#Debug simulation 
Total elapsed time: 5.7181580532342196. Arrivals time: 0.12638360867276788 Scheduler time: 5.368991459254175 Scheduler overhead time: 0.05042953370139003 Adapter cache time: 0.09830963844433427 Engine time: 0.050657867919653654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.707331584300846,
    "estimated_duration": 3600.0327540692565,
    "input_throughput": 3680.672623053887,
    "output_throughput": 3215.0190819562026,
    "total_throughput": 6895.691705010089,
    "itl": 104.08225889223219,
    "ttft": 58834.20256702979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.161647452321212,
    "arrivals": 53529,
    "finished_requests": 52865,
    "scheduler_time": 41.778374736528455
}
#Debug simulation 
Total elapsed time: 5.7074184929952025. Arrivals time: 0.12598127080127597 Scheduler time: 5.358681136742234 Scheduler overhead time: 0.05042002722620964 Adapter cache time: 0.0984063046053052 Engine time: 0.05052250577136874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.75390848191455,
    "estimated_duration": 3600.0392382718446,
    "input_throughput": 3680.9054354533027,
    "output_throughput": 3215.0605129393325,
    "total_throughput": 6895.965948392635,
    "itl": 104.08275057359587,
    "ttft": 58624.61494676896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.252596867232516,
    "arrivals": 53529,
    "finished_requests": 52867,
    "scheduler_time": 41.77388572005148
}
#Debug simulation 
Total elapsed time: 5.753975921776146. Arrivals time: 0.12663197377696633 Scheduler time: 5.403404346201569 Scheduler overhead time: 0.05103402817621827 Adapter cache time: 0.09851412661373615 Engine time: 0.0509735057130456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.7500700587406754,
    "estimated_duration": 3600.007590917867,
    "input_throughput": 3680.5833502761348,
    "output_throughput": 3215.0276652747366,
    "total_throughput": 6895.611015550871,
    "itl": 104.01828808359545,
    "ttft": 58676.56870585074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.507315832409994,
    "arrivals": 53529,
    "finished_requests": 52864,
    "scheduler_time": 41.76967012321338
}
#Debug simulation 
Total elapsed time: 5.750136604066938. Arrivals time: 0.1270462847314775 Scheduler time: 5.399443794041872 Scheduler overhead time: 0.0507345930673182 Adapter cache time: 0.09894420485943556 Engine time: 0.05065198801457882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.706086192280054,
    "estimated_duration": 3600.0875789548045,
    "input_throughput": 3680.3435220447273,
    "output_throughput": 3214.572075315972,
    "total_throughput": 6894.915597360699,
    "itl": 104.09261994137165,
    "ttft": 59068.24075548215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.467654171696633,
    "arrivals": 53529,
    "finished_requests": 52860,
    "scheduler_time": 41.77195844050881
}
#Debug simulation 
Total elapsed time: 5.706176673993468. Arrivals time: 0.12674520630389452 Scheduler time: 5.357424991670996 Scheduler overhead time: 0.050427934154868126 Adapter cache time: 0.09798676893115044 Engine time: 0.05021966993808746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.760258369147778,
    "estimated_duration": 3600.074879122676,
    "input_throughput": 3680.765107649434,
    "output_throughput": 3215.1375703665135,
    "total_throughput": 6895.9026780159475,
    "itl": 103.96025778439703,
    "ttft": 58667.51274516985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.72036124909457,
    "arrivals": 53529,
    "finished_requests": 52866,
    "scheduler_time": 41.76699375243634
}
#Debug simulation 
Total elapsed time: 5.76032679900527. Arrivals time: 0.12780308444052935 Scheduler time: 5.4069572212174535 Scheduler overhead time: 0.051185968331992626 Adapter cache time: 0.0993679235689342 Engine time: 0.05140886176377535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.768821415025741,
    "estimated_duration": 3600.105921216708,
    "input_throughput": 3680.798368155108,
    "output_throughput": 3215.114847534304,
    "total_throughput": 6895.913215689412,
    "itl": 104.12371375264638,
    "ttft": 58658.90755634167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.678468763007324,
    "arrivals": 53529,
    "finished_requests": 52867,
    "scheduler_time": 41.778733609585395
}
#Debug simulation 
Total elapsed time: 5.768890114035457. Arrivals time: 0.12685256358236074 Scheduler time: 5.416871837340295 Scheduler overhead time: 0.051591737661510706 Adapter cache time: 0.09875104855746031 Engine time: 0.05130104161798954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.514688414055854,
    "estimated_duration": 3600.0015843246865,
    "input_throughput": 3475.2068039289084,
    "output_throughput": 3073.4528140702314,
    "total_throughput": 6548.65961799914,
    "itl": 96.44461824140308,
    "ttft": 34222.91581774794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.137229862810727,
    "arrivals": 50610,
    "finished_requests": 50194,
    "scheduler_time": 38.583762273299364
}
#Debug simulation 
Total elapsed time: 4.514755153097212. Arrivals time: 0.11952037829905748 Scheduler time: 4.15483938716352 Scheduler overhead time: 0.05323088634759188 Adapter cache time: 0.10883132694289088 Engine time: 0.05357208289206028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.501990091055632,
    "estimated_duration": 3600.03818142243,
    "input_throughput": 3474.6639812185363,
    "output_throughput": 3073.051296258419,
    "total_throughput": 6547.715277476955,
    "itl": 96.52890495673564,
    "ttft": 34831.514575209636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.517834250167397,
    "arrivals": 50610,
    "finished_requests": 50187,
    "scheduler_time": 38.58817204071385
}
#Debug simulation 
Total elapsed time: 4.50206184387207. Arrivals time: 0.11960529116913676 Scheduler time: 4.1430316236801445 Scheduler overhead time: 0.05305103538557887 Adapter cache time: 0.10887966677546501 Engine time: 0.052810017485171556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.5149544309824705,
    "estimated_duration": 3600.108884243244,
    "input_throughput": 3474.96823075386,
    "output_throughput": 3073.370932869935,
    "total_throughput": 6548.339163623796,
    "itl": 96.53711923126994,
    "ttft": 34477.69436527504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.542224295995563,
    "arrivals": 50610,
    "finished_requests": 50192,
    "scheduler_time": 38.589179014639285
}
#Debug simulation 
Total elapsed time: 4.515022275969386. Arrivals time: 0.11973458807915449 Scheduler time: 4.152346147689968 Scheduler overhead time: 0.05368096614256501 Adapter cache time: 0.11068392498418689 Engine time: 0.05375034362077713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.418935859575868,
    "estimated_duration": 3600.111872026676,
    "input_throughput": 3475.3022808029264,
    "output_throughput": 3073.420880604794,
    "total_throughput": 6548.723161407721,
    "itl": 96.47006373925961,
    "ttft": 34235.75022994983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.584532237928553,
    "arrivals": 50610,
    "finished_requests": 50196,
    "scheduler_time": 38.587818792488626
}
#Debug simulation 
Total elapsed time: 4.419001534581184. Arrivals time: 0.11857556877657771 Scheduler time: 4.063426502514631 Scheduler overhead time: 0.052657260559499264 Adapter cache time: 0.10712053766474128 Engine time: 0.052902459632605314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.530026267748326,
    "estimated_duration": 3600.0980190971104,
    "input_throughput": 3474.6062283985216,
    "output_throughput": 3073.00021869254,
    "total_throughput": 6547.606447091061,
    "itl": 96.54919836323171,
    "ttft": 34837.71487198873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.784901707413507,
    "arrivals": 50610,
    "finished_requests": 50187,
    "scheduler_time": 38.590395156001605
}
#Debug simulation 
Total elapsed time: 4.53009304497391. Arrivals time: 0.12008142005652189 Scheduler time: 4.16735538514331 Scheduler overhead time: 0.05355385737493634 Adapter cache time: 0.11023550853133202 Engine time: 0.05408173892647028 
