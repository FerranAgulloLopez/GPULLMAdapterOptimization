INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.42180103296414,
    "estimated_duration": 3600.0559344233916,
    "input_throughput": 3647.2199985701104,
    "output_throughput": 3202.5827403836256,
    "total_throughput": 6849.8027389537365,
    "itl": 159.1351519821055,
    "ttft": 2286105.7722419454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2914,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.779074443652723,
    "arrivals": 774377,
    "finished_requests": 52878,
    "scheduler_time": 90.71889230171884
}
#Debug simulation 
Total elapsed time: 4.421940846950747. Arrivals time: 0.22941473848186433 Scheduler time: 4.034318171266932 Scheduler overhead time: 0.03498452086932957 Adapter cache time: 0.0714701569522731 Engine time: 0.03560343157732859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.9019400459947065,
    "estimated_duration": 3600.095793027736,
    "input_throughput": 4092.9633118477627,
    "output_throughput": 3604.9726857643127,
    "total_throughput": 7697.935997612075,
    "itl": 237.42070269678678,
    "ttft": 2226180.5795547487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0696692071646225,
    "arrivals": 771975,
    "finished_requests": 59649,
    "scheduler_time": 82.38707169528652
}
#Debug simulation 
Total elapsed time: 5.902046794013586. Arrivals time: 0.2396485943463631 Scheduler time: 5.574040173378307 Scheduler overhead time: 0.02549116115551442 Adapter cache time: 0.025484699406661093 Engine time: 0.02586268086452037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.929220081015956,
    "estimated_duration": 3600.00079528606,
    "input_throughput": 4093.1452068829653,
    "output_throughput": 3606.464481063631,
    "total_throughput": 7699.609687946597,
    "itl": 237.4404461491381,
    "ttft": 2226349.896619091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2582376529858506,
    "arrivals": 771975,
    "finished_requests": 59661,
    "scheduler_time": 82.3819335680793
}
#Debug simulation 
Total elapsed time: 5.9293309560162015. Arrivals time: 0.24320596095640212 Scheduler time: 5.596815098077059 Scheduler overhead time: 0.02571939124027267 Adapter cache time: 0.02605000342009589 Engine time: 0.025986087799537927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.342525451036636,
    "estimated_duration": 3600.0327555097747,
    "input_throughput": 3610.343261490558,
    "output_throughput": 3200.208937645795,
    "total_throughput": 6810.552199136353,
    "itl": 159.24405234058537,
    "ttft": 2295401.3778829034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.33268965860804,
    "arrivals": 771975,
    "finished_requests": 52670,
    "scheduler_time": 90.72942517918572
}
#Debug simulation 
Total elapsed time: 4.342645472032018. Arrivals time: 0.21081055758986622 Scheduler time: 3.9751559346332215 Scheduler overhead time: 0.03498321329243481 Adapter cache time: 0.07038736098911613 Engine time: 0.035060404101386666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.932458387978841,
    "estimated_duration": 3600.1192736020826,
    "input_throughput": 4093.7390902757547,
    "output_throughput": 3606.9063309137605,
    "total_throughput": 7700.645421189515,
    "itl": 237.42780833749478,
    "ttft": 2226353.816333633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.112369124302605,
    "arrivals": 771975,
    "finished_requests": 59670,
    "scheduler_time": 82.38774697639732
}
#Debug simulation 
Total elapsed time: 5.932555973995477. Arrivals time: 0.24000528338365257 Scheduler time: 5.6039286680170335 Scheduler overhead time: 0.02564548805821687 Adapter cache time: 0.025500722229480743 Engine time: 0.025829334976151586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.405094856978394,
    "estimated_duration": 3600.160525242102,
    "input_throughput": 3610.2151303728215,
    "output_throughput": 3200.0953621992317,
    "total_throughput": 6810.310492572054,
    "itl": 159.24957494055403,
    "ttft": 2295445.122869985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.460329751818996,
    "arrivals": 771975,
    "finished_requests": 52670,
    "scheduler_time": 90.72955481840762
}
#Debug simulation 
Total elapsed time: 4.405206519004423. Arrivals time: 0.21909960120683536 Scheduler time: 4.029115176585037 Scheduler overhead time: 0.03520291863242164 Adapter cache time: 0.07023462635697797 Engine time: 0.035222059406805784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.915018508967478,
    "estimated_duration": 3600.025468521185,
    "input_throughput": 4093.0432656224666,
    "output_throughput": 3605.0431069120164,
    "total_throughput": 7698.0863725344825,
    "itl": 237.41669940101124,
    "ttft": 2226153.402936822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9990204457868126,
    "arrivals": 771975,
    "finished_requests": 59649,
    "scheduler_time": 82.38693086743434
}
#Debug simulation 
Total elapsed time: 5.915116322983522. Arrivals time: 0.2425499545643106 Scheduler time: 5.584205725172069 Scheduler overhead time: 0.02573711989680305 Adapter cache time: 0.02528249565511942 Engine time: 0.025767211220227182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.368944392015692,
    "estimated_duration": 3600.103270788279,
    "input_throughput": 3609.9933869825677,
    "output_throughput": 3199.967926886034,
    "total_throughput": 6809.961313868602,
    "itl": 159.25509088293478,
    "ttft": 2295419.4487000406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.57602323532056,
    "arrivals": 771975,
    "finished_requests": 52665,
    "scheduler_time": 90.725256385997
}
#Debug simulation 
Total elapsed time: 4.369043620012235. Arrivals time: 0.21762419410515577 Scheduler time: 3.994564160180744 Scheduler overhead time: 0.035185734333936125 Adapter cache time: 0.07028230634750798 Engine time: 0.03514443163294345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.768857530027162,
    "estimated_duration": 3600.2262513217793,
    "input_throughput": 4087.407560732426,
    "output_throughput": 3607.323566187518,
    "total_throughput": 7694.731126919944,
    "itl": 237.16862393168847,
    "ttft": 2218654.584217824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.907463356736181,
    "arrivals": 770785,
    "finished_requests": 59725,
    "scheduler_time": 82.38112699857386
}
#Debug simulation 
Total elapsed time: 5.768955628038384. Arrivals time: 0.3190248007886112 Scheduler time: 5.363142395566683 Scheduler overhead time: 0.025649475282989442 Adapter cache time: 0.024049577361438423 Engine time: 0.02558870770735666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.7435652679996565,
    "estimated_duration": 3600.2301184465628,
    "input_throughput": 4086.3299055861066,
    "output_throughput": 3607.1891442326864,
    "total_throughput": 7693.519049818793,
    "itl": 237.1664078142594,
    "ttft": 2218721.415349771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 965,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.154254254114356,
    "arrivals": 770785,
    "finished_requests": 59727,
    "scheduler_time": 82.37584354502981
}
#Debug simulation 
Total elapsed time: 5.743660483974963. Arrivals time: 0.3214081202750094 Scheduler time: 5.334344682167284 Scheduler overhead time: 0.026647758961189538 Adapter cache time: 0.023639660619664937 Engine time: 0.0260543599142693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.728192102047615,
    "estimated_duration": 3600.039467676387,
    "input_throughput": 3609.7959804834495,
    "output_throughput": 3196.85328545252,
    "total_throughput": 6806.64926593597,
    "itl": 158.49394428784214,
    "ttft": 2287016.277297054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.675191967356632,
    "arrivals": 770785,
    "finished_requests": 52742,
    "scheduler_time": 90.79578563895231
}
#Debug simulation 
Total elapsed time: 4.72825687204022. Arrivals time: 0.6290553424041718 Scheduler time: 3.9403101741336286 Scheduler overhead time: 0.035151216317899525 Adapter cache time: 0.07193937298143283 Engine time: 0.03561802877811715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.797101058997214,
    "estimated_duration": 3600.02833047151,
    "input_throughput": 4087.2961680478775,
    "output_throughput": 3607.3349451389195,
    "total_throughput": 7694.631113186797,
    "itl": 237.17122999511585,
    "ttft": 2218614.5380304554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9700724961026275,
    "arrivals": 770785,
    "finished_requests": 59721,
    "scheduler_time": 82.37521298571495
}
#Debug simulation 
Total elapsed time: 5.797202592948452. Arrivals time: 0.32169620878994465 Scheduler time: 5.387001699593384 Scheduler overhead time: 0.025905107788275927 Adapter cache time: 0.025282694317866117 Engine time: 0.02578121650731191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.396075154014397,
    "estimated_duration": 3600.1673743382917,
    "input_throughput": 3609.667731736652,
    "output_throughput": 3196.739707724091,
    "total_throughput": 6806.407439460743,
    "itl": 158.49945349850682,
    "ttft": 2287060.354900466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.802957814354025,
    "arrivals": 770785,
    "finished_requests": 52742,
    "scheduler_time": 90.7959264539692
}
#Debug simulation 
Total elapsed time: 4.396171986008994. Arrivals time: 0.21375209098914638 Scheduler time: 4.022953086183406 Scheduler overhead time: 0.03539360291324556 Adapter cache time: 0.07258980855112895 Engine time: 0.03521689085755497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.823600517003797,
    "estimated_duration": 3600.1591939058544,
    "input_throughput": 4087.4836937515765,
    "output_throughput": 3607.390757048734,
    "total_throughput": 7694.87445080031,
    "itl": 237.164689592819,
    "ttft": 2218627.4950124533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.840547780157003,
    "arrivals": 770785,
    "finished_requests": 59725,
    "scheduler_time": 82.3809851591091
}
#Debug simulation 
Total elapsed time: 5.823722138011362. Arrivals time: 0.32335475378204137 Scheduler time: 5.412240637640934 Scheduler overhead time: 0.02583252335898578 Adapter cache time: 0.024496913887560368 Engine time: 0.026057369424961507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.400449676031712,
    "estimated_duration": 3600.109004983516,
    "input_throughput": 3609.6526471868597,
    "output_throughput": 3196.7870928543443,
    "total_throughput": 6806.439740041204,
    "itl": 158.50467316200098,
    "ttft": 2287123.3735951907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.927076801545399,
    "arrivals": 770785,
    "finished_requests": 52741,
    "scheduler_time": 90.79144599236143
}
#Debug simulation 
Total elapsed time: 4.400541762006469. Arrivals time: 0.294924299698323 Scheduler time: 3.9463347114506178 Scheduler overhead time: 0.03529202175559476 Adapter cache time: 0.0724606680450961 Engine time: 0.03521733632078394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.8970807699952275,
    "estimated_duration": 3600.1187689245626,
    "input_throughput": 4099.906127377346,
    "output_throughput": 3601.5886786627552,
    "total_throughput": 7701.4948060401,
    "itl": 237.16283273656953,
    "ttft": 2211639.0324594793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.026879860069811,
    "arrivals": 673640,
    "finished_requests": 59566,
    "scheduler_time": 82.22381357133116
}
#Debug simulation 
Total elapsed time: 4.89717643102631. Arrivals time: 0.2313940479652956 Scheduler time: 4.5544475120841525 Scheduler overhead time: 0.025486157450359315 Adapter cache time: 0.049035472446121275 Engine time: 0.02533098397543654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.907448292011395,
    "estimated_duration": 3600.1100285981943,
    "input_throughput": 4099.453317471699,
    "output_throughput": 3600.991329992181,
    "total_throughput": 7700.44464746388,
    "itl": 237.18872774097986,
    "ttft": 2211774.607032241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.504607150454227,
    "arrivals": 673640,
    "finished_requests": 59559,
    "scheduler_time": 82.213090686229
}
#Debug simulation 
Total elapsed time: 4.907543457986321. Arrivals time: 0.23529980290913954 Scheduler time: 4.558951204351615 Scheduler overhead time: 0.02576928719645366 Adapter cache time: 0.050564216217026114 Engine time: 0.025390242866706103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.556921874987893,
    "estimated_duration": 3600.1446739027874,
    "input_throughput": 3761.8038236553643,
    "output_throughput": 3324.1736330074914,
    "total_throughput": 7085.977456662856,
    "itl": 153.37874568659447,
    "ttft": 2262721.7126441686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.24649278487935,
    "arrivals": 673640,
    "finished_requests": 54749,
    "scheduler_time": 94.0752978293865
}
#Debug simulation 
Total elapsed time: 4.557029110030271. Arrivals time: 0.5234989708987996 Scheduler time: 3.850142460083589 Scheduler overhead time: 0.03560801426647231 Adapter cache time: 0.09529136645141989 Engine time: 0.03589632944203913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.9359726869734,
    "estimated_duration": 3600.0242633321004,
    "input_throughput": 4099.706257629321,
    "output_throughput": 3601.502115432809,
    "total_throughput": 7701.208373062131,
    "itl": 237.1713119615935,
    "ttft": 2211659.500221729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.187796949476217,
    "arrivals": 673640,
    "finished_requests": 59563,
    "scheduler_time": 82.2180580428269
}
#Debug simulation 
Total elapsed time: 4.936068728973623. Arrivals time: 0.2321620109723881 Scheduler time: 4.5909945706953295 Scheduler overhead time: 0.025421267782803625 Adapter cache time: 0.05042839684756473 Engine time: 0.02553089160937816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.29676014703,
    "estimated_duration": 3600.13984943195,
    "input_throughput": 3761.808864768655,
    "output_throughput": 3324.1780876618723,
    "total_throughput": 7085.986952430527,
    "itl": 153.38568657536018,
    "ttft": 2262776.814341487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.405319817121292,
    "arrivals": 673640,
    "finished_requests": 54749,
    "scheduler_time": 94.07103911283858
}
#Debug simulation 
Total elapsed time: 4.296871503000148. Arrivals time: 0.22211726888781413 Scheduler time: 3.890727353747934 Scheduler overhead time: 0.035505177453160286 Adapter cache time: 0.09580115467542782 Engine time: 0.03613356844289228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.233960345969535,
    "estimated_duration": 3600.2220660087523,
    "input_throughput": 4099.853767177071,
    "output_throughput": 3601.766436139741,
    "total_throughput": 7701.620203316812,
    "itl": 237.15400360795826,
    "ttft": 2211646.6576936007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.865155477095188,
    "arrivals": 673640,
    "finished_requests": 59569,
    "scheduler_time": 82.2297593470011
}
#Debug simulation 
Total elapsed time: 5.23405513598118. Arrivals time: 0.5443159737042151 Scheduler time: 4.57755363866454 Scheduler overhead time: 0.025630519725382328 Adapter cache time: 0.049290326540358365 Engine time: 0.025728454755153507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.290838768996764,
    "estimated_duration": 3600.133781486099,
    "input_throughput": 3761.3946652866316,
    "output_throughput": 3323.7906495409507,
    "total_throughput": 7085.185314827582,
    "itl": 153.39132946020231,
    "ttft": 2262765.8217458124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.562889311499113,
    "arrivals": 673640,
    "finished_requests": 54745,
    "scheduler_time": 94.06679445916602
}
#Debug simulation 
Total elapsed time: 4.290932894975413. Arrivals time: 0.22211849904851988 Scheduler time: 3.882932099979371 Scheduler overhead time: 0.03572148556122556 Adapter cache time: 0.09693879971746355 Engine time: 0.03666823246749118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.864313362981193,
    "estimated_duration": 3600.148864196383,
    "input_throughput": 4083.140324054706,
    "output_throughput": 3607.012512494718,
    "total_throughput": 7690.152836549424,
    "itl": 237.46980604412155,
    "ttft": 2205250.817754885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.128655447885603,
    "arrivals": 664253,
    "finished_requests": 59916,
    "scheduler_time": 82.26251094143008
}
#Debug simulation 
Total elapsed time: 4.86441564996494. Arrivals time: 0.5445011352421716 Scheduler time: 4.201232945022639 Scheduler overhead time: 0.025300498818978667 Adapter cache time: 0.05654827051330358 Engine time: 0.02527664677472785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.542554398998618,
    "estimated_duration": 3600.0247003608165,
    "input_throughput": 4081.715050045976,
    "output_throughput": 3606.255812272289,
    "total_throughput": 7687.970862318265,
    "itl": 237.50286925250228,
    "ttft": 2205340.1510656364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.672829320202341,
    "arrivals": 664253,
    "finished_requests": 59900,
    "scheduler_time": 82.24729007745977
}
#Debug simulation 
Total elapsed time: 4.542653184966184. Arrivals time: 0.23091418406693265 Scheduler time: 4.1929968821350485 Scheduler overhead time: 0.025065365305636078 Adapter cache time: 0.057132994290441275 Engine time: 0.025172493304125965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.40564940602053,
    "estimated_duration": 3600.0984393397434,
    "input_throughput": 3865.5540215039946,
    "output_throughput": 3429.782881788237,
    "total_throughput": 7295.336903292232,
    "itl": 149.2213535219384,
    "ttft": 2242252.825099586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.402682300731273,
    "arrivals": 664253,
    "finished_requests": 56716,
    "scheduler_time": 96.86702694929838
}
#Debug simulation 
Total elapsed time: 4.405760055989958. Arrivals time: 0.2282757357461378 Scheduler time: 4.003511676273774 Scheduler overhead time: 0.036505703639704734 Adapter cache time: 0.08334578975336626 Engine time: 0.037030004954431206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.561491027998272,
    "estimated_duration": 3600.0865187366157,
    "input_throughput": 4082.9993733479487,
    "output_throughput": 3606.9183149956416,
    "total_throughput": 7689.91768834359,
    "itl": 237.4784445669074,
    "ttft": 2205279.163854662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.287932530231533,
    "arrivals": 664253,
    "finished_requests": 59913,
    "scheduler_time": 82.25742524513412
}
#Debug simulation 
Total elapsed time: 4.561588750977535. Arrivals time: 0.22892554523423314 Scheduler time: 4.214629504305776 Scheduler overhead time: 0.025053865218069404 Adapter cache time: 0.05611751542892307 Engine time: 0.025393859366886318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.380228414025623,
    "estimated_duration": 3600.137861025768,
    "input_throughput": 3865.621133751464,
    "output_throughput": 3429.807267569974,
    "total_throughput": 7295.428401321438,
    "itl": 149.22940873790435,
    "ttft": 2242294.886603204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.534034695587657,
    "arrivals": 664253,
    "finished_requests": 56715,
    "scheduler_time": 96.8620803452362
}
#Debug simulation 
Total elapsed time: 4.3803253910155036. Arrivals time: 0.2222873066784814 Scheduler time: 3.9841745042358525 Scheduler overhead time: 0.0363672255189158 Adapter cache time: 0.08307778020389378 Engine time: 0.037341378803830594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.544683084997814,
    "estimated_duration": 3600.16699705879,
    "input_throughput": 4083.200865962482,
    "output_throughput": 3607.1937803467213,
    "total_throughput": 7690.394646309203,
    "itl": 237.45884931616519,
    "ttft": 2205198.559152251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.935593482670129,
    "arrivals": 664253,
    "finished_requests": 59919,
    "scheduler_time": 82.26684891225807
}
#Debug simulation 
Total elapsed time: 4.544806779013015. Arrivals time: 0.22984140028711408 Scheduler time: 4.196712510369252 Scheduler overhead time: 0.025159746641293168 Adapter cache time: 0.056480296480003744 Engine time: 0.02511340647470206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.420781445980538,
    "estimated_duration": 3600.118060618863,
    "input_throughput": 3865.5326757833504,
    "output_throughput": 3429.723356871655,
    "total_throughput": 7295.256032655006,
    "itl": 149.23507976571253,
    "ttft": 2242366.137106135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.666334777175885,
    "arrivals": 664253,
    "finished_requests": 56715,
    "scheduler_time": 96.85941300939128
}
#Debug simulation 
Total elapsed time: 4.420873958035372. Arrivals time: 0.22092379454988986 Scheduler time: 4.025892961886711 Scheduler overhead time: 0.03654629515949637 Adapter cache time: 0.0830826060846448 Engine time: 0.03730646934127435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.512426600966137,
    "estimated_duration": 3600.257569169077,
    "input_throughput": 4141.432581847529,
    "output_throughput": 3656.6278237249494,
    "total_throughput": 7798.060405572479,
    "itl": 234.70262766679164,
    "ttft": 2202929.139659028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.482892533915807,
    "arrivals": 659440,
    "finished_requests": 60270,
    "scheduler_time": 83.38930256729671
}
#Debug simulation 
Total elapsed time: 4.512529796978924. Arrivals time: 0.2271910957642831 Scheduler time: 4.170310041226912 Scheduler overhead time: 0.024788913840893656 Adapter cache time: 0.053369550325442106 Engine time: 0.025359077961184084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.521731165004894,
    "estimated_duration": 3600.2223544934764,
    "input_throughput": 4140.995619726802,
    "output_throughput": 3656.1183460158563,
    "total_throughput": 7797.113965742658,
    "itl": 234.73264064706476,
    "ttft": 2203030.930920248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9775005307301114,
    "arrivals": 659440,
    "finished_requests": 60262,
    "scheduler_time": 83.37736066368436
}
#Debug simulation 
Total elapsed time: 4.521853515994735. Arrivals time: 0.23222742771031335 Scheduler time: 4.17418237432139 Scheduler overhead time: 0.02490942011354491 Adapter cache time: 0.0535552209476009 Engine time: 0.025432766182348132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.440261904965155,
    "estimated_duration": 3600.0104526776677,
    "input_throughput": 3928.5408156192084,
    "output_throughput": 3481.3907250402544,
    "total_throughput": 7409.931540659462,
    "itl": 146.49918626479922,
    "ttft": 2238424.9389805193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.690203922577165,
    "arrivals": 659440,
    "finished_requests": 57153,
    "scheduler_time": 98.5280918770968
}
#Debug simulation 
Total elapsed time: 4.4403551439754665. Arrivals time: 0.2183098583482206 Scheduler time: 4.055495830485597 Scheduler overhead time: 0.037064169300720096 Adapter cache time: 0.07448804436717182 Engine time: 0.03772232658229768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.5185637610265985,
    "estimated_duration": 3600.135789571875,
    "input_throughput": 4141.324347594401,
    "output_throughput": 3656.5131898998297,
    "total_throughput": 7797.837537494231,
    "itl": 234.70992532912555,
    "ttft": 2202966.9147369545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.626108556871491,
    "arrivals": 659440,
    "finished_requests": 60266,
    "scheduler_time": 83.38324733136997
}
#Debug simulation 
Total elapsed time: 4.518660394998733. Arrivals time: 0.23250493919476867 Scheduler time: 4.170856978103984 Scheduler overhead time: 0.02520692953839898 Adapter cache time: 0.053286124661099166 Engine time: 0.02536921459250152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.388284446962643,
    "estimated_duration": 3600.11457296824,
    "input_throughput": 3928.427196787653,
    "output_throughput": 3481.2900384074987,
    "total_throughput": 7409.717235195151,
    "itl": 146.50351540328404,
    "ttft": 2238461.8828626834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.7942023039421,
    "arrivals": 659440,
    "finished_requests": 57153,
    "scheduler_time": 98.52821378639382
}
#Debug simulation 
Total elapsed time: 4.388382899982389. Arrivals time: 0.22007500438485295 Scheduler time: 4.002392431721091 Scheduler overhead time: 0.03694408980663866 Adapter cache time: 0.07405426603509113 Engine time: 0.037625743134412915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.546935304009821,
    "estimated_duration": 3600.0851942629733,
    "input_throughput": 4141.630876891649,
    "output_throughput": 3656.8029059365526,
    "total_throughput": 7798.433782828201,
    "itl": 234.69180625447666,
    "ttft": 2202866.9859492714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.310672971035596,
    "arrivals": 659440,
    "finished_requests": 60270,
    "scheduler_time": 83.38914722374633
}
#Debug simulation 
Total elapsed time: 4.547028511005919. Arrivals time: 0.23318280489183962 Scheduler time: 4.198969618068077 Scheduler overhead time: 0.024875327188055962 Adapter cache time: 0.053333211166318506 Engine time: 0.02520180935971439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.429787212982774,
    "estimated_duration": 3600.04252026157,
    "input_throughput": 3928.2313807150513,
    "output_throughput": 3481.196382949783,
    "total_throughput": 7409.427763664834,
    "itl": 146.50660814644513,
    "ttft": 2238491.4349579928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.887385859675382,
    "arrivals": 659440,
    "finished_requests": 57150,
    "scheduler_time": 98.52380160802936
}
#Debug simulation 
Total elapsed time: 4.429909555008635. Arrivals time: 0.21990424464456737 Scheduler time: 4.041967187658884 Scheduler overhead time: 0.0372242815210484 Adapter cache time: 0.07542576623382047 Engine time: 0.037804051069542766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.578037670988124,
    "estimated_duration": 3600.0058613809697,
    "input_throughput": 4165.852106209373,
    "output_throughput": 3662.8923695534363,
    "total_throughput": 7828.744475762809,
    "itl": 233.35348020861733,
    "ttft": 2193227.0498334705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.008516933606214,
    "arrivals": 657053,
    "finished_requests": 60566,
    "scheduler_time": 83.54684892876618
}
#Debug simulation 
Total elapsed time: 4.5781341650290415. Arrivals time: 0.2695804844261147 Scheduler time: 4.196192441158928 Scheduler overhead time: 0.02493495843373239 Adapter cache time: 0.05068887973902747 Engine time: 0.02526964183198288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.53705581399845,
    "estimated_duration": 3600.0566126909166,
    "input_throughput": 4165.45671730176,
    "output_throughput": 3662.358240012481,
    "total_throughput": 7827.814957314242,
    "itl": 233.38506276498788,
    "ttft": 2193298.3190027685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.492108470890358,
    "arrivals": 657053,
    "finished_requests": 60559,
    "scheduler_time": 83.53727179818398
}
#Debug simulation 
Total elapsed time: 4.537167533999309. Arrivals time: 0.23985314171295613 Scheduler time: 4.184096273325849 Scheduler overhead time: 0.024899300769902766 Adapter cache time: 0.05158309725811705 Engine time: 0.025255002197809517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.384392712963745,
    "estimated_duration": 3600.12830851758,
    "input_throughput": 3937.4429979238557,
    "output_throughput": 3478.236031303064,
    "total_throughput": 7415.67902922692,
    "itl": 146.2510489106967,
    "ttft": 2229802.339102342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.216139225549964,
    "arrivals": 657053,
    "finished_requests": 57304,
    "scheduler_time": 98.4920902179439
}
#Debug simulation 
Total elapsed time: 4.384506831993349. Arrivals time: 0.21800015057669953 Scheduler time: 4.002651700458955 Scheduler overhead time: 0.036953757517039776 Adapter cache time: 0.07199623453198001 Engine time: 0.037651541526429355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.505602940975223,
    "estimated_duration": 3600.186127236491,
    "input_throughput": 4165.643516745562,
    "output_throughput": 3662.7089639173546,
    "total_throughput": 7828.352480662916,
    "itl": 233.35959087394826,
    "ttft": 2193286.7549273255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.149575710971592,
    "arrivals": 657053,
    "finished_requests": 60566,
    "scheduler_time": 83.54834058861864
}
#Debug simulation 
Total elapsed time: 4.505701681948267. Arrivals time: 0.22838819277239963 Scheduler time: 4.1640981684904546 Scheduler overhead time: 0.024969645077362657 Adapter cache time: 0.05131454061483964 Engine time: 0.02552301890682429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.429564355057664,
    "estimated_duration": 3600.073579538339,
    "input_throughput": 3937.174529032165,
    "output_throughput": 3478.03724656252,
    "total_throughput": 7415.211775594686,
    "itl": 146.25445912406445,
    "ttft": 2229854.7306428244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3163649933224875,
    "arrivals": 657053,
    "finished_requests": 57300,
    "scheduler_time": 98.48776560106907
}
#Debug simulation 
Total elapsed time: 4.429660087043885. Arrivals time: 0.25927907502045855 Scheduler time: 4.007333428191487 Scheduler overhead time: 0.036937938013579696 Adapter cache time: 0.07134739583125338 Engine time: 0.037496283650398254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.505715225997847,
    "estimated_duration": 3600.0946223457318,
    "input_throughput": 4165.749396394551,
    "output_throughput": 3662.8020602991955,
    "total_throughput": 7828.551456693746,
    "itl": 233.343443481724,
    "ttft": 2193234.945892072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.844225125030873,
    "arrivals": 657053,
    "finished_requests": 60566,
    "scheduler_time": 83.55266544236477
}
#Debug simulation 
Total elapsed time: 4.505815023032483. Arrivals time: 0.23145517543889582 Scheduler time: 4.161562412744388 Scheduler overhead time: 0.024921719392295927 Adapter cache time: 0.05103506083833054 Engine time: 0.0254244013922289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.423974008997902,
    "estimated_duration": 3600.00903291626,
    "input_throughput": 3937.1551211131914,
    "output_throughput": 3477.7712737731426,
    "total_throughput": 7414.926394886334,
    "itl": 146.2574585154796,
    "ttft": 2229900.625756103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.406781965754657,
    "arrivals": 657053,
    "finished_requests": 57297,
    "scheduler_time": 98.48343213668988
}
#Debug simulation 
Total elapsed time: 4.424108799954411. Arrivals time: 0.21881777566159144 Scheduler time: 4.040828558790963 Scheduler overhead time: 0.037153656070586294 Adapter cache time: 0.07226923870621249 Engine time: 0.037619914510287344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.583163386967499,
    "estimated_duration": 3600.0825969406665,
    "input_throughput": 4199.368373616558,
    "output_throughput": 3693.0227687826355,
    "total_throughput": 7892.391142399193,
    "itl": 231.94645690831814,
    "ttft": 2193133.612793655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.681044745005398,
    "arrivals": 655825,
    "finished_requests": 61031,
    "scheduler_time": 84.22944397000056
}
#Debug simulation 
Total elapsed time: 4.58326030295575. Arrivals time: 0.2784419908421114 Scheduler time: 4.19232858257601 Scheduler overhead time: 0.025005250819958746 Adapter cache time: 0.05035120737738907 Engine time: 0.025591280893422663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.536618071026169,
    "estimated_duration": 3600.0340120557817,
    "input_throughput": 4198.711720328543,
    "output_throughput": 3692.8656661241585,
    "total_throughput": 7891.577386452702,
    "itl": 231.97694262921186,
    "ttft": 2193235.6592819565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.145075915252976,
    "arrivals": 655825,
    "finished_requests": 61024,
    "scheduler_time": 84.21778595919707
}
#Debug simulation 
Total elapsed time: 4.53671617701184. Arrivals time: 0.2304407749325037 Scheduler time: 4.19298714667093 Scheduler overhead time: 0.02521647367393598 Adapter cache time: 0.05081644072197378 Engine time: 0.025728680251631886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.479942195001058,
    "estimated_duration": 3600.031852019348,
    "input_throughput": 3969.492656567528,
    "output_throughput": 3503.3226144723058,
    "total_throughput": 7472.8152710398335,
    "itl": 145.7264538109481,
    "ttft": 2229285.4597852565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.780653405263984,
    "arrivals": 655825,
    "finished_requests": 57669,
    "scheduler_time": 99.0726965994459
}
#Debug simulation 
Total elapsed time: 4.4800532889785245. Arrivals time: 0.2596154841594398 Scheduler time: 4.057243189832661 Scheduler overhead time: 0.03718440362717956 Adapter cache time: 0.07082494761561975 Engine time: 0.037642510200385004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.560967176978011,
    "estimated_duration": 3600.213802298115,
    "input_throughput": 4199.215332808769,
    "output_throughput": 3692.888181116721,
    "total_throughput": 7892.10351392549,
    "itl": 231.95437132590553,
    "ttft": 2193183.444347925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8120707307241455,
    "arrivals": 655825,
    "finished_requests": 61031,
    "scheduler_time": 84.22962334151016
}
#Debug simulation 
Total elapsed time: 4.561071075964719. Arrivals time: 0.23507494444493204 Scheduler time: 4.213010754319839 Scheduler overhead time: 0.025013231730554253 Adapter cache time: 0.05078894359758124 Engine time: 0.02557266433723271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.49816534697311,
    "estimated_duration": 3600.128936896505,
    "input_throughput": 3969.3856110384113,
    "output_throughput": 3503.2281401766268,
    "total_throughput": 7472.613751215038,
    "itl": 145.7304857410576,
    "ttft": 2229320.277916042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.877609574589746,
    "arrivals": 655825,
    "finished_requests": 57669,
    "scheduler_time": 99.07282530735156
}
#Debug simulation 
Total elapsed time: 4.49828446097672. Arrivals time: 0.22126397263491526 Scheduler time: 4.112629233626649 Scheduler overhead time: 0.03748506441479549 Adapter cache time: 0.07126489951042458 Engine time: 0.03800980019150302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.5306821599951945,
    "estimated_duration": 3600.1855463538554,
    "input_throughput": 4199.43300292168,
    "output_throughput": 3693.4649141811337,
    "total_throughput": 7892.897917102813,
    "itl": 231.93961204381648,
    "ttft": 2193093.486064169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.527279793771254,
    "arrivals": 655825,
    "finished_requests": 61038,
    "scheduler_time": 84.23536020682549
}
#Debug simulation 
Total elapsed time: 4.530776111991145. Arrivals time: 0.2308828562963754 Scheduler time: 4.18756484775804 Scheduler overhead time: 0.02480671281227842 Adapter cache time: 0.050372073834296316 Engine time: 0.025632147793658078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.463427047012374,
    "estimated_duration": 3600.0445678168926,
    "input_throughput": 3969.510302108806,
    "output_throughput": 3503.220796971385,
    "total_throughput": 7472.731099080192,
    "itl": 145.7321160332038,
    "ttft": 2229401.969865299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.971040894090904,
    "arrivals": 655825,
    "finished_requests": 57669,
    "scheduler_time": 99.06965729200098
}
#Debug simulation 
Total elapsed time: 4.463531579996925. Arrivals time: 0.2202030504704453 Scheduler time: 4.080347470764536 Scheduler overhead time: 0.037159585393965244 Adapter cache time: 0.07106908468995243 Engine time: 0.03745956683997065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.652732106973417,
    "estimated_duration": 3600.1006338809625,
    "input_throughput": 4347.243200012582,
    "output_throughput": 3823.2084043612613,
    "total_throughput": 8170.451604373843,
    "itl": 223.7596561085601,
    "ttft": 2168943.131133698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.7973432792748465,
    "arrivals": 644956,
    "finished_requests": 63190,
    "scheduler_time": 87.01441890102437
}
#Debug simulation 
Total elapsed time: 4.6528546959743835. Arrivals time: 0.2353983023785986 Scheduler time: 4.303579351399094 Scheduler overhead time: 0.0256356461904943 Adapter cache time: 0.050097698462195694 Engine time: 0.02634877437958494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.674401672033127,
    "estimated_duration": 3600.076938132182,
    "input_throughput": 4346.567939772586,
    "output_throughput": 3822.560805364301,
    "total_throughput": 8169.128745136887,
    "itl": 223.78765845602612,
    "ttft": 2168964.756588263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.243988394995402,
    "arrivals": 644956,
    "finished_requests": 63180,
    "scheduler_time": 87.0030308294059
}
#Debug simulation 
Total elapsed time: 4.674496337014716. Arrivals time: 0.23726222082041204 Scheduler time: 4.324238198809326 Scheduler overhead time: 0.025583184091374278 Adapter cache time: 0.049463817616924644 Engine time: 0.026057577459141612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.557804754993413,
    "estimated_duration": 3600.10293705741,
    "input_throughput": 4083.5793467662065,
    "output_throughput": 3603.2691916867643,
    "total_throughput": 7686.84853845297,
    "itl": 140.5385139357911,
    "ttft": 2207713.865963165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.851361999362664,
    "arrivals": 644956,
    "finished_requests": 59379,
    "scheduler_time": 102.10574859349778
}
#Debug simulation 
Total elapsed time: 4.5579228670103475. Arrivals time: 0.2221377588575706 Scheduler time: 4.175249224761501 Scheduler overhead time: 0.03833468444645405 Adapter cache time: 0.06527480809018016 Engine time: 0.03888099134201184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.7120123589993455,
    "estimated_duration": 3600.003348370915,
    "input_throughput": 4347.066234558293,
    "output_throughput": 3822.9892220039114,
    "total_throughput": 8170.055456562204,
    "itl": 223.76858711917902,
    "ttft": 2168954.7130616885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.936316120209868,
    "arrivals": 644956,
    "finished_requests": 63185,
    "scheduler_time": 87.00865888145889
}
#Debug simulation 
Total elapsed time: 4.712115367001388. Arrivals time: 0.23760338785359636 Scheduler time: 4.361395973712206 Scheduler overhead time: 0.02563157759141177 Adapter cache time: 0.04940260952571407 Engine time: 0.026211928576231003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.531170180009212,
    "estimated_duration": 3600.0824278994864,
    "input_throughput": 4083.5198344548708,
    "output_throughput": 3603.359161853665,
    "total_throughput": 7686.8789963085355,
    "itl": 140.56595622259513,
    "ttft": 2207639.3167205676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2094,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.934428684040764,
    "arrivals": 644956,
    "finished_requests": 59375,
    "scheduler_time": 102.09864705689819
}
#Debug simulation 
Total elapsed time: 4.531263598008081. Arrivals time: 0.2225939944619313 Scheduler time: 4.14751018997049 Scheduler overhead time: 0.03843430883716792 Adapter cache time: 0.06564458104548976 Engine time: 0.03902021999238059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.692389461037237,
    "estimated_duration": 3600.1807789620166,
    "input_throughput": 4347.3953006639085,
    "output_throughput": 3823.601603686367,
    "total_throughput": 8170.996904350275,
    "itl": 223.75195909237257,
    "ttft": 2168949.9394304524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.640901704977533,
    "arrivals": 644956,
    "finished_requests": 63197,
    "scheduler_time": 87.02019199916552
}
#Debug simulation 
Total elapsed time: 4.692482137994375. Arrivals time: 0.2362631267751567 Scheduler time: 4.342515115160495 Scheduler overhead time: 0.025811551488004625 Adapter cache time: 0.049688846222124994 Engine time: 0.026213657052721828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.514007612015121,
    "estimated_duration": 3600.0192418528104,
    "input_throughput": 4083.469840687325,
    "output_throughput": 3603.101574902732,
    "total_throughput": 7686.571415590057,
    "itl": 140.56966445667146,
    "ttft": 2207593.988528777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2094,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.019941258802773,
    "arrivals": 644956,
    "finished_requests": 59370,
    "scheduler_time": 102.09442165744372
}
#Debug simulation 
Total elapsed time: 4.5141038239817135. Arrivals time: 0.22329081752104685 Scheduler time: 4.128788534726482 Scheduler overhead time: 0.038262014219071716 Adapter cache time: 0.06700865924358368 Engine time: 0.03887902409769595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.106891033006832,
    "estimated_duration": 3600.132964587771,
    "input_throughput": 4451.847794970312,
    "output_throughput": 3908.568416336597,
    "total_throughput": 8360.416211306909,
    "itl": 218.80689544216094,
    "ttft": 2160665.8466422586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3283091621870735,
    "arrivals": 640132,
    "finished_requests": 64600,
    "scheduler_time": 89.077477048291
}
#Debug simulation 
Total elapsed time: 5.10700237803394. Arrivals time: 0.5708059673779644 Scheduler time: 4.4279535712557845 Scheduler overhead time: 0.026283298851922154 Adapter cache time: 0.043027216161135584 Engine time: 0.026813554111868143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.785097352985758,
    "estimated_duration": 3600.002832251322,
    "input_throughput": 4451.503442284303,
    "output_throughput": 3908.1288697769005,
    "total_throughput": 8359.632312061203,
    "itl": 218.8256009808726,
    "ttft": 2160671.0235928637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.687151677734071,
    "arrivals": 640132,
    "finished_requests": 64595,
    "scheduler_time": 89.06615506204446
}
#Debug simulation 
Total elapsed time: 4.785193612973671. Arrivals time: 0.23863351345062256 Scheduler time: 4.437012619513553 Scheduler overhead time: 0.02638257114449516 Adapter cache time: 0.04424073488917202 Engine time: 0.02681218012003228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.637393742974382,
    "estimated_duration": 3600.073004220093,
    "input_throughput": 4155.491008783278,
    "output_throughput": 3659.296626639912,
    "total_throughput": 7814.787635423189,
    "itl": 139.2256398381815,
    "ttft": 2203173.47250102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.371111590824975,
    "arrivals": 640132,
    "finished_requests": 60307,
    "scheduler_time": 103.46318539845586
}
#Debug simulation 
Total elapsed time: 4.637493687972892. Arrivals time: 0.2294949297211133 Scheduler time: 4.2532723807380535 Scheduler overhead time: 0.038781703216955066 Adapter cache time: 0.058104532421566546 Engine time: 0.039566377410665154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.099204621044919,
    "estimated_duration": 3600.2314359917705,
    "input_throughput": 4451.726030658612,
    "output_throughput": 3908.4615114816093,
    "total_throughput": 8360.187542140222,
    "itl": 218.8126505257831,
    "ttft": 2160694.2305411412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.438038416551289,
    "arrivals": 640132,
    "finished_requests": 64600,
    "scheduler_time": 89.0781144148496
}
#Debug simulation 
Total elapsed time: 5.099268030025996. Arrivals time: 0.5470047675771639 Scheduler time: 4.4445000679115765 Scheduler overhead time: 0.026244965672958642 Adapter cache time: 0.042552568775136024 Engine time: 0.026848574460018426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.608371603011619,
    "estimated_duration": 3600.083439672559,
    "input_throughput": 4155.593405179718,
    "output_throughput": 3659.3840728308874,
    "total_throughput": 7814.977478010605,
    "itl": 139.22667262753018,
    "ttft": 2203203.836797278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.443923033159167,
    "arrivals": 640132,
    "finished_requests": 60308,
    "scheduler_time": 103.46220683266147
}
#Debug simulation 
Total elapsed time: 4.608469370985404. Arrivals time: 0.22647600516211241 Scheduler time: 4.226967664435506 Scheduler overhead time: 0.038831515412312 Adapter cache time: 0.05838085029972717 Engine time: 0.03977406595367938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.768595687986817,
    "estimated_duration": 3600.233533660917,
    "input_throughput": 4451.792043529565,
    "output_throughput": 3908.5086754611925,
    "total_throughput": 8360.300718990757,
    "itl": 218.80078934903477,
    "ttft": 2160667.293602809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.20567756342454,
    "arrivals": 640132,
    "finished_requests": 64602,
    "scheduler_time": 89.0823536703547
}
#Debug simulation 
Total elapsed time: 4.768693261023145. Arrivals time: 0.23866404889849946 Scheduler time: 4.422292159113567 Scheduler overhead time: 0.02622525510378182 Adapter cache time: 0.04276083188597113 Engine time: 0.026641453383490443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8933411069447175,
    "estimated_duration": 3600.1523578435995,
    "input_throughput": 4155.513854130593,
    "output_throughput": 3659.31402077965,
    "total_throughput": 7814.827874910244,
    "itl": 139.22935981110453,
    "ttft": 2203229.719187004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.512710354328069,
    "arrivals": 640132,
    "finished_requests": 60308,
    "scheduler_time": 103.4623376825945
}
#Debug simulation 
Total elapsed time: 4.893406388000585. Arrivals time: 0.5323221985599957 Scheduler time: 4.206138244073372 Scheduler overhead time: 0.038726939528714865 Adapter cache time: 0.05792326491791755 Engine time: 0.0401456996332854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.922590777976438,
    "estimated_duration": 3600.170708735849,
    "input_throughput": 4484.159031911199,
    "output_throughput": 3960.7999602349546,
    "total_throughput": 8444.958992146154,
    "itl": 216.61921275292255,
    "ttft": 2156664.9748174413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.57542917717959,
    "arrivals": 637737,
    "finished_requests": 65296,
    "scheduler_time": 90.17303284543821
}
#Debug simulation 
Total elapsed time: 4.922683893004432. Arrivals time: 0.28466012864373624 Scheduler time: 4.532122731790878 Scheduler overhead time: 0.026607745967339724 Adapter cache time: 0.04004623112268746 Engine time: 0.02702057402348146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.813341618981212,
    "estimated_duration": 3600.232577698325,
    "input_throughput": 4483.374240871758,
    "output_throughput": 3959.9841655548257,
    "total_throughput": 8443.358406426583,
    "itl": 216.63501529473766,
    "ttft": 2156774.1417548778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.879946295274349,
    "arrivals": 637737,
    "finished_requests": 65288,
    "scheduler_time": 90.1675346540914
}
#Debug simulation 
Total elapsed time: 4.813445680949371. Arrivals time: 0.23829702707007527 Scheduler time: 4.470499434042722 Scheduler overhead time: 0.026468375173863024 Adapter cache time: 0.039048814272973686 Engine time: 0.026953245513141155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.612451280001551,
    "estimated_duration": 3600.06772801997,
    "input_throughput": 4159.494801570281,
    "output_throughput": 3690.45362580087,
    "total_throughput": 7849.948427371151,
    "itl": 138.31404784172105,
    "ttft": 2202865.6868525655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.548523878529602,
    "arrivals": 637737,
    "finished_requests": 60543,
    "scheduler_time": 104.25862438263864
}
#Debug simulation 
Total elapsed time: 4.612550470978022. Arrivals time: 0.22427225369028747 Scheduler time: 4.238443795999046 Scheduler overhead time: 0.03906960756285116 Adapter cache time: 0.053002357948571444 Engine time: 0.03950728214113042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.892709432984702,
    "estimated_duration": 3600.019366147664,
    "input_throughput": 4483.639769213933,
    "output_throughput": 3960.218696061097,
    "total_throughput": 8443.858465275029,
    "itl": 216.62264129714924,
    "ttft": 2156694.253454687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.662573585864065,
    "arrivals": 637737,
    "finished_requests": 65288,
    "scheduler_time": 90.1672802184921
}
#Debug simulation 
Total elapsed time: 4.892825442017056. Arrivals time: 0.25253153819357976 Scheduler time: 4.535614693479147 Scheduler overhead time: 0.0265491881291382 Adapter cache time: 0.03874058852670714 Engine time: 0.027085959154646844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.599463131045923,
    "estimated_duration": 3600.111484084527,
    "input_throughput": 4158.261783331072,
    "output_throughput": 3689.355470995228,
    "total_throughput": 7847.617254326301,
    "itl": 138.260482846927,
    "ttft": 2202653.21563734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.609302971232653,
    "arrivals": 637737,
    "finished_requests": 60524,
    "scheduler_time": 104.27472841660513
}
#Debug simulation 
Total elapsed time: 4.59961341903545. Arrivals time: 0.22567937948042527 Scheduler time: 4.224853343272116 Scheduler overhead time: 0.0390311959781684 Adapter cache time: 0.052251509216148406 Engine time: 0.03961507329950109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.8272922150208615,
    "estimated_duration": 3600.065075953062,
    "input_throughput": 4484.2906056986185,
    "output_throughput": 3960.916177667983,
    "total_throughput": 8445.2067833666,
    "itl": 216.61326882047464,
    "ttft": 2156624.375688437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.470125190878631,
    "arrivals": 637737,
    "finished_requests": 65296,
    "scheduler_time": 90.17288690818195
}
#Debug simulation 
Total elapsed time: 4.827389187004883. Arrivals time: 0.24022186471847817 Scheduler time: 4.482065323798452 Scheduler overhead time: 0.026659762661438435 Adapter cache time: 0.038956192904151976 Engine time: 0.027152142953127623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.666687436983921,
    "estimated_duration": 3600.0163680623723,
    "input_throughput": 4158.423870738531,
    "output_throughput": 3689.3885032941284,
    "total_throughput": 7847.81237403266,
    "itl": 138.26173247967324,
    "ttft": 2202598.62831344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.655458354651924,
    "arrivals": 637737,
    "finished_requests": 60524,
    "scheduler_time": 104.26991153102514
}
#Debug simulation 
Total elapsed time: 4.666801021026913. Arrivals time: 0.26773654925636947 Scheduler time: 4.249311028339434 Scheduler overhead time: 0.03896526503376663 Adapter cache time: 0.0530444917967543 Engine time: 0.03949767991434783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.89068007300375,
    "estimated_duration": 3600.0591861449725,
    "input_throughput": 4506.601742115544,
    "output_throughput": 3958.5268639042097,
    "total_throughput": 8465.128606019754,
    "itl": 216.03467708128403,
    "ttft": 2150119.036564659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.281622353762035,
    "arrivals": 636613,
    "finished_requests": 65753,
    "scheduler_time": 90.22376805451412
}
#Debug simulation 
Total elapsed time: 4.890796929015778. Arrivals time: 0.28071793576236814 Scheduler time: 4.505527448432986 Scheduler overhead time: 0.026726884301751852 Adapter cache time: 0.03810326388338581 Engine time: 0.027269891987089068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.856472166022286,
    "estimated_duration": 3600.053321266089,
    "input_throughput": 4506.142146332106,
    "output_throughput": 3958.153040630139,
    "total_throughput": 8464.295186962245,
    "itl": 216.05283269871978,
    "ttft": 2150137.751513655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.570837319767992,
    "arrivals": 636613,
    "finished_requests": 65748,
    "scheduler_time": 90.21654737345082
}
#Debug simulation 
Total elapsed time: 4.856567703012843. Arrivals time: 0.2453643293119967 Scheduler time: 4.506491200358141 Scheduler overhead time: 0.026708835386671126 Adapter cache time: 0.03829257265897468 Engine time: 0.02735226263757795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.639253770001233,
    "estimated_duration": 3600.118077909428,
    "input_throughput": 4186.079643463056,
    "output_throughput": 3685.5468939799057,
    "total_throughput": 7871.626537442961,
    "itl": 138.02990111383193,
    "ttft": 2197214.059747463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.355795322768329,
    "arrivals": 636613,
    "finished_requests": 61073,
    "scheduler_time": 104.2406470777411
}
#Debug simulation 
Total elapsed time: 4.6393481100094505. Arrivals time: 0.2288779960363172 Scheduler time: 4.261046380153857 Scheduler overhead time: 0.03913972346344963 Adapter cache time: 0.05207920289831236 Engine time: 0.03997421183157712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.805720945005305,
    "estimated_duration": 3600.068630687064,
    "input_throughput": 4506.2360372013045,
    "output_throughput": 3958.264261556708,
    "total_throughput": 8464.500298758012,
    "itl": 216.04190684608963,
    "ttft": 2150138.873073024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.368991232458429,
    "arrivals": 636613,
    "finished_requests": 65750,
    "scheduler_time": 90.22216234857062
}
#Debug simulation 
Total elapsed time: 4.805818670021836. Arrivals time: 0.2402813616208732 Scheduler time: 4.461681495071389 Scheduler overhead time: 0.026504257519263774 Adapter cache time: 0.03817249718122184 Engine time: 0.026912727335002273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.672819640021771,
    "estimated_duration": 3600.0186465527922,
    "input_throughput": 4186.139706368047,
    "output_throughput": 3685.4725774002836,
    "total_throughput": 7871.612283768331,
    "itl": 138.03246267416824,
    "ttft": 2197189.3304809215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.416157140247509,
    "arrivals": 636613,
    "finished_requests": 61069,
    "scheduler_time": 104.23615143567848
}
#Debug simulation 
Total elapsed time: 4.672926480008755. Arrivals time: 0.23213872773339972 Scheduler time: 4.292088728398085 Scheduler overhead time: 0.038756200403440744 Adapter cache time: 0.05175855220295489 Engine time: 0.039805587206501514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.818409961008001,
    "estimated_duration": 3600.1951963174433,
    "input_throughput": 4506.771193016545,
    "output_throughput": 3958.4737001419544,
    "total_throughput": 8465.2448931585,
    "itl": 216.02809912022997,
    "ttft": 2150146.3990654713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.183080362568032,
    "arrivals": 636613,
    "finished_requests": 65756,
    "scheduler_time": 90.22967673319984
}
#Debug simulation 
Total elapsed time: 4.818504219001625. Arrivals time: 0.2391543506528251 Scheduler time: 4.476100349100307 Scheduler overhead time: 0.026220151805318892 Adapter cache time: 0.037929284502752125 Engine time: 0.026872859860304743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.639315581007395,
    "estimated_duration": 3600.1384779680734,
    "input_throughput": 4185.881763221898,
    "output_throughput": 3685.279630545828,
    "total_throughput": 7871.161393767726,
    "itl": 138.03589264328016,
    "ttft": 2197240.3911812822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4764897859469235,
    "arrivals": 636613,
    "finished_requests": 61068,
    "scheduler_time": 104.23753123982513
}
#Debug simulation 
Total elapsed time: 4.63946042500902. Arrivals time: 0.22640923137078062 Scheduler time: 4.265150950290263 Scheduler overhead time: 0.03872418438550085 Adapter cache time: 0.051375819370150566 Engine time: 0.0395193244330585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.987824487034231,
    "estimated_duration": 3600.199834943122,
    "input_throughput": 4643.858609660798,
    "output_throughput": 4086.7953654112785,
    "total_throughput": 8730.653975072077,
    "itl": 209.5162562266699,
    "ttft": 2133013.7907070233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.889879922538629,
    "arrivals": 630527,
    "finished_requests": 67739,
    "scheduler_time": 93.05395974758254
}
#Debug simulation 
Total elapsed time: 4.987919075996615. Arrivals time: 0.24455593229504302 Scheduler time: 4.644007649680134 Scheduler overhead time: 0.027473944588564336 Adapter cache time: 0.031467768538277596 Engine time: 0.02781356149353087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.99494624696672,
    "estimated_duration": 3600.116984625973,
    "input_throughput": 4643.517994384508,
    "output_throughput": 4086.569981705327,
    "total_throughput": 8730.087976089835,
    "itl": 209.53081822194747,
    "ttft": 2132990.521076064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.138411082357624,
    "arrivals": 630527,
    "finished_requests": 67733,
    "scheduler_time": 93.04613248473731
}
#Debug simulation 
Total elapsed time: 4.995037095970474. Arrivals time: 0.24850831629009917 Scheduler time: 4.646262652066071 Scheduler overhead time: 0.02762061485555023 Adapter cache time: 0.03186763799749315 Engine time: 0.028131617873441428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.67525306600146,
    "estimated_duration": 3600.124267156334,
    "input_throughput": 4239.3511633017315,
    "output_throughput": 3748.313946579114,
    "total_throughput": 7987.665109880846,
    "itl": 136.00772389342666,
    "ttft": 2180723.9786315593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.857103267237487,
    "arrivals": 630527,
    "finished_requests": 61876,
    "scheduler_time": 105.89934833298874
}
#Debug simulation 
Total elapsed time: 4.6753704469883814. Arrivals time: 0.218278743152041 Scheduler time: 4.3166998975211754 Scheduler overhead time: 0.03963759390171617 Adapter cache time: 0.04275659774430096 Engine time: 0.03947468823753297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.906992886972148,
    "estimated_duration": 3600.1006766224614,
    "input_throughput": 4643.667914221824,
    "output_throughput": 4086.7323782186827,
    "total_throughput": 8730.400292440507,
    "itl": 209.52130164736772,
    "ttft": 2133029.5338554084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.959984811264971,
    "arrivals": 630527,
    "finished_requests": 67735,
    "scheduler_time": 93.04895216469217
}
#Debug simulation 
Total elapsed time: 4.907120771997143. Arrivals time: 0.22217805101536214 Scheduler time: 4.587148925056681 Scheduler overhead time: 0.02720006270101294 Adapter cache time: 0.030886997701600194 Engine time: 0.027187091298401356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.660464896995109,
    "estimated_duration": 3600.033380107141,
    "input_throughput": 4239.073194245166,
    "output_throughput": 3748.1958013396015,
    "total_throughput": 7987.268995584767,
    "itl": 136.00915118944528,
    "ttft": 2180745.7216064786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9100456113182074,
    "arrivals": 630527,
    "finished_requests": 61872,
    "scheduler_time": 105.89505060712526
}
#Debug simulation 
Total elapsed time: 4.660559362964705. Arrivals time: 0.20942731032846496 Scheduler time: 4.310736855317373 Scheduler overhead time: 0.039568056527059525 Adapter cache time: 0.04278498736675829 Engine time: 0.0396292392979376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.914054988010321,
    "estimated_duration": 3600.1116510409793,
    "input_throughput": 4643.887084770221,
    "output_throughput": 4086.8879707510278,
    "total_throughput": 8730.775055521248,
    "itl": 209.51172771178784,
    "ttft": 2132987.653586914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.800353924820567,
    "arrivals": 630527,
    "finished_requests": 67738,
    "scheduler_time": 93.0537826411007
}
#Debug simulation 
Total elapsed time: 4.9141497170203365. Arrivals time: 0.22545005386928096 Scheduler time: 4.590691074670758 Scheduler overhead time: 0.02723318024072796 Adapter cache time: 0.031021465314552188 Engine time: 0.02726520475698635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6821133000194095,
    "estimated_duration": 3600.1181907484147,
    "input_throughput": 4258.173812013966,
    "output_throughput": 3765.6380378950116,
    "total_throughput": 8023.811849908978,
    "itl": 135.71908800167478,
    "ttft": 2179988.967573788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.955734249651491,
    "arrivals": 630527,
    "finished_requests": 62153,
    "scheduler_time": 106.23841773949376
}
#Debug simulation 
Total elapsed time: 4.6822069130139425. Arrivals time: 0.24919932952616364 Scheduler time: 4.293068937317003 Scheduler overhead time: 0.039832010166719556 Adapter cache time: 0.04183658299734816 Engine time: 0.039830818539485335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.944911068014335,
    "estimated_duration": 3600.0460057359737,
    "input_throughput": 4700.6602062965685,
    "output_throughput": 4139.725708020021,
    "total_throughput": 8840.385914316588,
    "itl": 206.8939167530984,
    "ttft": 2127707.174525082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3298106653989157,
    "arrivals": 628242,
    "finished_requests": 68596,
    "scheduler_time": 94.19091025258324
}
#Debug simulation 
Total elapsed time: 4.94500591699034. Arrivals time: 0.22726789879379794 Scheduler time: 4.621334181749262 Scheduler overhead time: 0.02745043148752302 Adapter cache time: 0.028867921326309443 Engine time: 0.02748646168038249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.943409699015319,
    "estimated_duration": 3600.1270540614782,
    "input_throughput": 4700.524383135013,
    "output_throughput": 4139.631400838194,
    "total_throughput": 8840.155783973207,
    "itl": 206.9093577957453,
    "ttft": 2127704.1961954385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.557578233091633,
    "arrivals": 628242,
    "finished_requests": 68594,
    "scheduler_time": 94.18733220089635
}
#Debug simulation 
Total elapsed time: 4.943501884990837. Arrivals time: 0.22755649051396176 Scheduler time: 4.619757739128545 Scheduler overhead time: 0.02752689365297556 Adapter cache time: 0.028617196308914572 Engine time: 0.02740052284207195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.648000827000942,
    "estimated_duration": 3600.1417899556504,
    "input_throughput": 4294.675849472714,
    "output_throughput": 3797.527930189777,
    "total_throughput": 8092.203779662491,
    "itl": 133.8209471343339,
    "ttft": 2180432.678360933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.250530770625882,
    "arrivals": 628242,
    "finished_requests": 62721,
    "scheduler_time": 107.36001216970581
}
#Debug simulation 
Total elapsed time: 4.648098749050405. Arrivals time: 0.21166330977575853 Scheduler time: 4.298186391184572 Scheduler overhead time: 0.03980936895823106 Adapter cache time: 0.039955646148882806 Engine time: 0.03989546973025426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.936202003969811,
    "estimated_duration": 3600.185751301039,
    "input_throughput": 4700.521075581847,
    "output_throughput": 4139.576685623581,
    "total_throughput": 8840.097761205428,
    "itl": 206.8982671806244,
    "ttft": 2127740.2274115873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.400677630810494,
    "arrivals": 628242,
    "finished_requests": 68597,
    "scheduler_time": 94.19251846353059
}
#Debug simulation 
Total elapsed time: 4.936336304002907. Arrivals time: 0.23234957340173423 Scheduler time: 4.607310395047534 Scheduler overhead time: 0.027603101509157568 Adapter cache time: 0.028982431744225323 Engine time: 0.027411783055868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.659265782975126,
    "estimated_duration": 3600.040480773593,
    "input_throughput": 4294.6119863290305,
    "output_throughput": 3797.4778542107665,
    "total_throughput": 8092.0898405397975,
    "itl": 133.82332188836023,
    "ttft": 2180335.219488636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2941673345118767,
    "arrivals": 628242,
    "finished_requests": 62718,
    "scheduler_time": 107.35568947008925
}
#Debug simulation 
Total elapsed time: 4.65938708500471. Arrivals time: 0.21105394745245576 Scheduler time: 4.309576344909146 Scheduler overhead time: 0.039834534691181034 Adapter cache time: 0.04040279763285071 Engine time: 0.03979887854075059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.9225687510333955,
    "estimated_duration": 3600.1949198455736,
    "input_throughput": 4700.621043242264,
    "output_throughput": 4139.610585484428,
    "total_throughput": 8840.231628726693,
    "itl": 206.890112903854,
    "ttft": 2127698.7421569857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2531747208534885,
    "arrivals": 628242,
    "finished_requests": 68598,
    "scheduler_time": 94.19681978228886
}
#Debug simulation 
Total elapsed time: 4.922676406044047. Arrivals time: 0.22980743000516668 Scheduler time: 4.596685966127552 Scheduler overhead time: 0.027402628387790173 Adapter cache time: 0.028857223864179105 Engine time: 0.027357632818166167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.686736418982036,
    "estimated_duration": 3600.0821005941857,
    "input_throughput": 4294.562337188986,
    "output_throughput": 3797.4339523378144,
    "total_throughput": 8091.9962895268,
    "itl": 133.8248324340282,
    "ttft": 2180351.7697944967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3356660840288215,
    "arrivals": 628242,
    "finished_requests": 62718,
    "scheduler_time": 107.35581054120165
}
#Debug simulation 
Total elapsed time: 4.686842318973504. Arrivals time: 0.21059282874921337 Scheduler time: 4.337564409826882 Scheduler overhead time: 0.039791185001377016 Adapter cache time: 0.04025351727614179 Engine time: 0.03994206094648689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.031770308036357,
    "estimated_duration": 3600.0914444842965,
    "input_throughput": 4727.50797096433,
    "output_throughput": 4183.55901016772,
    "total_throughput": 8911.06698113205,
    "itl": 205.60309014825162,
    "ttft": 2126066.7709073112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6748662881972836,
    "arrivals": 627073,
    "finished_requests": 68806,
    "scheduler_time": 95.18775999690739
}
#Debug simulation 
Total elapsed time: 5.031863078998867. Arrivals time: 0.26344673964194953 Scheduler time: 4.675471949623898 Scheduler overhead time: 0.027647422451991588 Adapter cache time: 0.025050424213986844 Engine time: 0.02757219603518024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.005655218032189,
    "estimated_duration": 3600.146826080891,
    "input_throughput": 4727.324695956054,
    "output_throughput": 4183.388824837224,
    "total_throughput": 8910.713520793277,
    "itl": 205.61138125902713,
    "ttft": 2126121.1580067957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.856696884469137,
    "arrivals": 627073,
    "finished_requests": 68804,
    "scheduler_time": 95.18529923668405
}
#Debug simulation 
Total elapsed time: 5.005746976006776. Arrivals time: 0.22895290976157412 Scheduler time: 4.683216308942065 Scheduler overhead time: 0.027686679328326136 Adapter cache time: 0.0251631474820897 Engine time: 0.02808598126284778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.727496651001275,
    "estimated_duration": 3600.0352022863517,
    "input_throughput": 4309.047308800759,
    "output_throughput": 3822.9131735321575,
    "total_throughput": 8131.960482332916,
    "itl": 133.76128349371467,
    "ttft": 2178542.182994456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6774369813501697,
    "arrivals": 627073,
    "finished_requests": 62648,
    "scheduler_time": 107.93866974116703
}
#Debug simulation 
Total elapsed time: 4.727588829002343. Arrivals time: 0.21228292281739414 Scheduler time: 4.3804272811394185 Scheduler overhead time: 0.0401636844035238 Adapter cache time: 0.0359319617273286 Engine time: 0.04002918128389865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.014733420975972,
    "estimated_duration": 3600.1595167800374,
    "input_throughput": 4727.504134378575,
    "output_throughput": 4183.491850791847,
    "total_throughput": 8910.995985170423,
    "itl": 205.6064445694945,
    "ttft": 2126103.067090175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.731796600092176,
    "arrivals": 627073,
    "finished_requests": 68807,
    "scheduler_time": 95.18831853652064
}
#Debug simulation 
Total elapsed time: 5.014829316991381. Arrivals time: 0.2265206251759082 Scheduler time: 4.695131701941136 Scheduler overhead time: 0.027637607825454324 Adapter cache time: 0.025163385667838156 Engine time: 0.027667894843034446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.707335559010971,
    "estimated_duration": 3600.0720270719003,
    "input_throughput": 4309.00323197622,
    "output_throughput": 3822.874069326262,
    "total_throughput": 8131.877301302482,
    "itl": 133.76259222993144,
    "ttft": 2178556.90164189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7141570869833256,
    "arrivals": 627073,
    "finished_requests": 62648,
    "scheduler_time": 107.93877442111345
}
#Debug simulation 
Total elapsed time: 4.707435951044317. Arrivals time: 0.2147509220521897 Scheduler time: 4.358032377203926 Scheduler overhead time: 0.040057487261947244 Adapter cache time: 0.03587962716119364 Engine time: 0.04003697435837239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.027724258019589,
    "estimated_duration": 3600.029754563629,
    "input_throughput": 4727.588981292457,
    "output_throughput": 4183.630699415043,
    "total_throughput": 8911.2196807075,
    "itl": 205.59987022591636,
    "ttft": 2126041.3736080998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6133039577444457,
    "arrivals": 627073,
    "finished_requests": 68806,
    "scheduler_time": 95.18763240658124
}
#Debug simulation 
Total elapsed time: 5.0278402480180375. Arrivals time: 0.22934331931173801 Scheduler time: 4.705526146979537 Scheduler overhead time: 0.027589616540353745 Adapter cache time: 0.025028310250490904 Engine time: 0.027691252005752176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.767688740976155,
    "estimated_duration": 3600.076048952502,
    "input_throughput": 4308.53370570135,
    "output_throughput": 3822.468695905474,
    "total_throughput": 8131.002401606825,
    "itl": 133.6977169040896,
    "ttft": 2178537.755595702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7521201445907564,
    "arrivals": 627073,
    "finished_requests": 62640,
    "scheduler_time": 107.95603170461159
}
#Debug simulation 
Total elapsed time: 4.767798757995479. Arrivals time: 0.24835828092182055 Scheduler time: 4.385076594888233 Scheduler overhead time: 0.04023337486432865 Adapter cache time: 0.035186347900889814 Engine time: 0.0400308285607025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.09625533700455,
    "estimated_duration": 3600.1066418514833,
    "input_throughput": 4824.233481891529,
    "output_throughput": 4274.195886621403,
    "total_throughput": 9098.42936851293,
    "itl": 201.16460855820273,
    "ttft": 2109640.810420601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1515228839847644,
    "arrivals": 623634,
    "finished_requests": 70565,
    "scheduler_time": 97.18725127095708
}
#Debug simulation 
Total elapsed time: 5.096345812024083. Arrivals time: 0.2325493399403058 Scheduler time: 4.774347398953978 Scheduler overhead time: 0.028217520099133253 Adapter cache time: 0.020070277096237987 Engine time: 0.028152018319815397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0922607079846784,
    "estimated_duration": 3600.1279603424714,
    "input_throughput": 4824.204636978472,
    "output_throughput": 4274.155854875843,
    "total_throughput": 9098.360491854315,
    "itl": 201.17363384406005,
    "ttft": 2109706.6649873257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.295679538256961,
    "arrivals": 623634,
    "finished_requests": 70564,
    "scheduler_time": 97.18403761959448
}
#Debug simulation 
Total elapsed time: 5.092351150989998. Arrivals time: 0.2314230669871904 Scheduler time: 4.771341643529013 Scheduler overhead time: 0.028232206590473652 Adapter cache time: 0.02026709564961493 Engine time: 0.02814557176316157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.750923959014472,
    "estimated_duration": 3600.0675849925897,
    "input_throughput": 4353.54354605325,
    "output_throughput": 3874.8055892480456,
    "total_throughput": 8228.349135301296,
    "itl": 131.78488002755108,
    "ttft": 2168466.662382328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.109772317577162,
    "arrivals": 623634,
    "finished_requests": 63747,
    "scheduler_time": 109.3970100695424
}
#Debug simulation 
Total elapsed time: 4.751012480002828. Arrivals time: 0.2149918440845795 Scheduler time: 4.407177556015085 Scheduler overhead time: 0.04033823549980298 Adapter cache time: 0.029315708728972822 Engine time: 0.04034719668561593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.131679966987576,
    "estimated_duration": 3600.001698679166,
    "input_throughput": 4824.373834704633,
    "output_throughput": 4274.3057609238485,
    "total_throughput": 9098.67959562848,
    "itl": 201.16848358561847,
    "ttft": 2109653.2686984334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2025198056525395,
    "arrivals": 623634,
    "finished_requests": 70564,
    "scheduler_time": 97.18290447829548
}
#Debug simulation 
Total elapsed time: 5.131771226995625. Arrivals time: 0.2360317045240663 Scheduler time: 4.806351389619522 Scheduler overhead time: 0.02818090235814452 Adapter cache time: 0.020111425372306257 Engine time: 0.028120670467615128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.781701061001513,
    "estimated_duration": 3600.1367016688055,
    "input_throughput": 4353.7460654575825,
    "output_throughput": 3875.027577017654,
    "total_throughput": 8228.773642475237,
    "itl": 131.78605475037148,
    "ttft": 2168565.053377056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.135929105151447,
    "arrivals": 623634,
    "finished_requests": 63752,
    "scheduler_time": 109.39847968511833
}
#Debug simulation 
Total elapsed time: 4.781793923000805. Arrivals time: 0.21423920977395028 Scheduler time: 4.438499643700197 Scheduler overhead time: 0.04040615662233904 Adapter cache time: 0.029316178523004055 Engine time: 0.04048388858791441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.17887265002355,
    "estimated_duration": 3600.0621377171833,
    "input_throughput": 4824.293119288484,
    "output_throughput": 4274.248724428219,
    "total_throughput": 9098.541843716705,
    "itl": 201.1627384989987,
    "ttft": 2109625.4460965204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.102005357316192,
    "arrivals": 623634,
    "finished_requests": 70565,
    "scheduler_time": 97.18700288562941
}
#Debug simulation 
Total elapsed time: 5.1789649440324865. Arrivals time: 0.27027163188904524 Scheduler time: 4.818945669976529 Scheduler overhead time: 0.028290396323427558 Adapter cache time: 0.020210584858432412 Engine time: 0.028263999440241605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.752087600994855,
    "estimated_duration": 3600.114967314267,
    "input_throughput": 4353.382084264943,
    "output_throughput": 3874.7229259754645,
    "total_throughput": 8228.105010240408,
    "itl": 131.78531943717906,
    "ttft": 2168491.856852737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.164475214667617,
    "arrivals": 623634,
    "finished_requests": 63746,
    "scheduler_time": 109.3970319696483
}
#Debug simulation 
Total elapsed time: 4.752175599976908. Arrivals time: 0.2170412814593874 Scheduler time: 4.405541107989848 Scheduler overhead time: 0.04043699527392164 Adapter cache time: 0.029955584148410708 Engine time: 0.04034642066108063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.135837913956493,
    "estimated_duration": 3600.005819776694,
    "input_throughput": 4903.259017813179,
    "output_throughput": 4320.834126030626,
    "total_throughput": 9224.093143843806,
    "itl": 198.75176555184126,
    "ttft": 2106912.2211031984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7659014282492242,
    "arrivals": 622407,
    "finished_requests": 71316,
    "scheduler_time": 98.23424737429877
}
#Debug simulation 
Total elapsed time: 5.135930730961263. Arrivals time: 0.23451086145360023 Scheduler time: 4.813324754300993 Scheduler overhead time: 0.028390765306539834 Adapter cache time: 0.018117573636118323 Engine time: 0.02852441422874108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.183836245036218,
    "estimated_duration": 3600.1237026724466,
    "input_throughput": 4903.098464893506,
    "output_throughput": 4320.69264410364,
    "total_throughput": 9223.791108997146,
    "itl": 198.75728373776994,
    "ttft": 2106961.0314416015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8813424318027734,
    "arrivals": 622407,
    "finished_requests": 71316,
    "scheduler_time": 98.23456238396005
}
#Debug simulation 
Total elapsed time: 5.183925753983203. Arrivals time: 0.2734118896187283 Scheduler time: 4.82189131953055 Scheduler overhead time: 0.028624193102587014 Adapter cache time: 0.018228396540507674 Engine time: 0.028650753432884812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.801910976995714,
    "estimated_duration": 3600.01047302877,
    "input_throughput": 4407.506066683934,
    "output_throughput": 3901.723926981406,
    "total_throughput": 8309.22999366534,
    "itl": 130.78458497743893,
    "ttft": 2168575.2177427188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7425929019413995,
    "arrivals": 622407,
    "finished_requests": 64154,
    "scheduler_time": 110.18275987769792
}
#Debug simulation 
Total elapsed time: 4.802030320977792. Arrivals time: 0.216240756213665 Scheduler time: 4.4582722642226145 Scheduler overhead time: 0.04086277284659445 Adapter cache time: 0.026610189815983176 Engine time: 0.04094463447108865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.191066227038391,
    "estimated_duration": 3600.0407035700678,
    "input_throughput": 4903.211506051918,
    "output_throughput": 4320.792257869329,
    "total_throughput": 9224.003763921248,
    "itl": 198.75331854044327,
    "ttft": 2106928.3504497143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7979889868409253,
    "arrivals": 622407,
    "finished_requests": 71316,
    "scheduler_time": 98.23437419390135
}
#Debug simulation 
Total elapsed time: 5.191154549014755. Arrivals time: 0.2359878313727677 Scheduler time: 4.866783169505652 Scheduler overhead time: 0.028492577315773815 Adapter cache time: 0.01822178123984486 Engine time: 0.028528012451715767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.80836815800285,
    "estimated_duration": 3600.0889650956333,
    "input_throughput": 4410.191846350174,
    "output_throughput": 3904.564063912402,
    "total_throughput": 8314.755910262576,
    "itl": 130.98762661952256,
    "ttft": 2168748.3002021806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7667376289330454,
    "arrivals": 622407,
    "finished_requests": 64192,
    "scheduler_time": 110.13106382835952
}
#Debug simulation 
Total elapsed time: 4.808460230997298. Arrivals time: 0.21543781069340184 Scheduler time: 4.465495552227367 Scheduler overhead time: 0.040847989614121616 Adapter cache time: 0.026633023924659938 Engine time: 0.04107776941964403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.1406210259883665,
    "estimated_duration": 3600.101886330013,
    "input_throughput": 4903.19734200486,
    "output_throughput": 4320.845768022818,
    "total_throughput": 9224.043110027678,
    "itl": 198.75058457250188,
    "ttft": 2106952.5027005486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.725259020158531,
    "arrivals": 622407,
    "finished_requests": 71317,
    "scheduler_time": 98.23787698629562
}
#Debug simulation 
Total elapsed time: 5.140709538012743. Arrivals time: 0.23415809322614223 Scheduler time: 4.817878572968766 Scheduler overhead time: 0.028603245969861746 Adapter cache time: 0.018536001502070576 Engine time: 0.028443343879189342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.854245182010345,
    "estimated_duration": 3600.045295098983,
    "input_throughput": 4408.886749732852,
    "output_throughput": 3902.9297823358847,
    "total_throughput": 8311.816532068737,
    "itl": 130.9042387667078,
    "ttft": 2168711.2868522587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7874870036914916,
    "arrivals": 622407,
    "finished_requests": 64173,
    "scheduler_time": 110.14961876462905
}
#Debug simulation 
Total elapsed time: 4.854337578988634. Arrivals time: 0.2531314513180405 Scheduler time: 4.472935539670289 Scheduler overhead time: 0.040871678153052926 Adapter cache time: 0.027278063469566405 Engine time: 0.04117161990143359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.233373323979322,
    "estimated_duration": 3600.064166105559,
    "input_throughput": 4955.095569670729,
    "output_throughput": 4372.533175437418,
    "total_throughput": 9327.628745108146,
    "itl": 196.12468235270453,
    "ttft": 2098021.47641272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2915258279396309,
    "arrivals": 619978,
    "finished_requests": 72190,
    "scheduler_time": 99.40876685262793
}
#Debug simulation 
Total elapsed time: 5.233464106975589. Arrivals time: 0.27980930858757347 Scheduler time: 4.869002485182136 Scheduler overhead time: 0.02893438993487507 Adapter cache time: 0.013756852131336927 Engine time: 0.028778096253518015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.284461356000975,
    "estimated_duration": 3600.197117401002,
    "input_throughput": 4955.258675635713,
    "output_throughput": 4372.641132317912,
    "total_throughput": 9327.899807953625,
    "itl": 196.13025829710702,
    "ttft": 2098055.497819511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3786594855226637,
    "arrivals": 619978,
    "finished_requests": 72192,
    "scheduler_time": 99.41034068815222
}
#Debug simulation 
Total elapsed time: 5.284563852008432. Arrivals time: 0.23912667675176635 Scheduler time: 4.96062307280954 Scheduler overhead time: 0.02897931431652978 Adapter cache time: 0.01361796708079055 Engine time: 0.02892857580445707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.840671751997434,
    "estimated_duration": 3600.013429003519,
    "input_throughput": 4432.560687535258,
    "output_throughput": 3927.6731264621567,
    "total_throughput": 8360.233813997414,
    "itl": 129.41049663550555,
    "ttft": 2160244.3399368976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2631571191921902,
    "arrivals": 619978,
    "finished_requests": 64561,
    "scheduler_time": 111.03889705328574
}
#Debug simulation 
Total elapsed time: 4.8407625340041704. Arrivals time: 0.21704300172859803 Scheduler time: 4.500591185525991 Scheduler overhead time: 0.041043527773581445 Adapter cache time: 0.022080765920691192 Engine time: 0.04086146655026823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.243661966989748,
    "estimated_duration": 3600.108444848377,
    "input_throughput": 4955.3807262468035,
    "output_throughput": 4372.748832754401,
    "total_throughput": 9328.129559001203,
    "itl": 196.12657087590787,
    "ttft": 2098021.9520885814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3169615924381626,
    "arrivals": 619978,
    "finished_requests": 72192,
    "scheduler_time": 99.40956018527905
}
#Debug simulation 
Total elapsed time: 5.2437749819946475. Arrivals time: 0.27503990317927673 Scheduler time: 4.884015771909617 Scheduler overhead time: 0.028884072555229068 Adapter cache time: 0.013644872058648616 Engine time: 0.028919156757183373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.895077553985175,
    "estimated_duration": 3600.1281704238527,
    "input_throughput": 4432.656073497852,
    "output_throughput": 3927.648775442141,
    "total_throughput": 8360.304848939993,
    "itl": 129.4128193358666,
    "ttft": 2160299.7409935747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2803853879310236,
    "arrivals": 619978,
    "finished_requests": 64564,
    "scheduler_time": 111.04124074663066
}
#Debug simulation 
Total elapsed time: 4.895185664994642. Arrivals time: 0.26283752359449863 Scheduler time: 4.5080821246956475 Scheduler overhead time: 0.041198205086402595 Adapter cache time: 0.02246110193664208 Engine time: 0.04135470400797203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.195320098020602,
    "estimated_duration": 3600.0343222936367,
    "input_throughput": 4955.1366467625,
    "output_throughput": 4372.56942316342,
    "total_throughput": 9327.70606992592,
    "itl": 196.1233605835468,
    "ttft": 2098007.907747418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2618012244487102,
    "arrivals": 619978,
    "finished_requests": 72190,
    "scheduler_time": 99.40864764414802
}
#Debug simulation 
Total elapsed time: 5.195413363981061. Arrivals time: 0.27339266176568344 Scheduler time: 4.837754419015255 Scheduler overhead time: 0.02863513247575611 Adapter cache time: 0.013646107516251504 Engine time: 0.028791546414140612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.854016796976794,
    "estimated_duration": 3600.0530177861924,
    "input_throughput": 4432.600831476901,
    "output_throughput": 3927.673267627351,
    "total_throughput": 8360.27409910425,
    "itl": 129.41649725406606,
    "ttft": 2160232.56980372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2961046112328787,
    "arrivals": 619978,
    "finished_requests": 64563,
    "scheduler_time": 111.03821770333815
}
#Debug simulation 
Total elapsed time: 4.854121371987276. Arrivals time: 0.21737446374027058 Scheduler time: 4.513452503597364 Scheduler overhead time: 0.04106384131591767 Adapter cache time: 0.02215067931683734 Engine time: 0.04106332780793309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.85094225697685,
    "estimated_duration": 3600.03043232845,
    "input_throughput": 4130.286473823732,
    "output_throughput": 3620.197174714035,
    "total_throughput": 7750.483648537767,
    "itl": 236.0378152343183,
    "ttft": 2166416.694796835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.868456508331099,
    "arrivals": 500641,
    "finished_requests": 60063,
    "scheduler_time": 82.3671577912164
}
#Debug simulation 
Total elapsed time: 11.851044436974917. Arrivals time: 0.250378297700081 Scheduler time: 11.500301360967569 Scheduler overhead time: 0.028139194939285517 Adapter cache time: 0.032438693568110466 Engine time: 0.027873869345057756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.336902921029832,
    "estimated_duration": 3600.102255180378,
    "input_throughput": 4128.993830275307,
    "output_throughput": 3615.7020210382348,
    "total_throughput": 7744.695851313542,
    "itl": 235.88312316169996,
    "ttft": 2165839.5715599316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.520117401699493,
    "arrivals": 500641,
    "finished_requests": 60020,
    "scheduler_time": 82.35488816486
}
#Debug simulation 
Total elapsed time: 11.337027659988962. Arrivals time: 0.24447687051724643 Scheduler time: 10.990333957888652 Scheduler overhead time: 0.028340631630271673 Adapter cache time: 0.033927179232705384 Engine time: 0.02790128265041858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.428365028987173,
    "estimated_duration": 3600.0259658707396,
    "input_throughput": 3635.52572233584,
    "output_throughput": 3194.116683883072,
    "total_throughput": 6829.642406218912,
    "itl": 158.50724088924355,
    "ttft": 2243773.4016446825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.603315971064834,
    "arrivals": 500641,
    "finished_requests": 52881,
    "scheduler_time": 90.26405262324589
}
#Debug simulation 
Total elapsed time: 5.428481473005377. Arrivals time: 0.2393947140662931 Scheduler time: 5.02490877447417 Scheduler overhead time: 0.03549916745396331 Adapter cache time: 0.07776310370536521 Engine time: 0.03473782789660618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 11.958698822010774,
    "estimated_duration": 3600.1294881494287,
    "input_throughput": 4130.187552682502,
    "output_throughput": 3620.0095143519648,
    "total_throughput": 7750.197067034467,
    "itl": 236.04386671476124,
    "ttft": 2166467.09054994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.952389275522389,
    "arrivals": 500641,
    "finished_requests": 60063,
    "scheduler_time": 82.36747892682094
}
#Debug simulation 
Total elapsed time: 11.958816579019185. Arrivals time: 0.2562303872546181 Scheduler time: 11.600422618852463 Scheduler overhead time: 0.028747314237989485 Adapter cache time: 0.03275149594992399 Engine time: 0.02864048012997955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.39547180297086,
    "estimated_duration": 3600.0486073145726,
    "input_throughput": 3637.5683854358917,
    "output_throughput": 3194.394091411536,
    "total_throughput": 6831.962476847428,
    "itl": 158.5033998765862,
    "ttft": 2243958.398423028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.765099006816182,
    "arrivals": 500641,
    "finished_requests": 52902,
    "scheduler_time": 90.26268319953645
}
#Debug simulation 
Total elapsed time: 5.395561876008287. Arrivals time: 0.20387414237484336 Scheduler time: 5.028213107842021 Scheduler overhead time: 0.035489248344674706 Adapter cache time: 0.07707261218456551 Engine time: 0.034735104243736714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.352709772996604,
    "estimated_duration": 3600.1218616403044,
    "input_throughput": 4113.337150552142,
    "output_throughput": 3603.2571947688352,
    "total_throughput": 7716.594345320977,
    "itl": 236.77373768585304,
    "ttft": 2167265.7274895096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.090388803426068,
    "arrivals": 500641,
    "finished_requests": 59818,
    "scheduler_time": 82.04675186347933
}
#Debug simulation 
Total elapsed time: 11.352845789981075. Arrivals time: 0.27759803098160774 Scheduler time: 10.973325279483106 Scheduler overhead time: 0.028308243432547897 Adapter cache time: 0.03415264276554808 Engine time: 0.027565881027840078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.386730051017366,
    "estimated_duration": 3600.1526018535506,
    "input_throughput": 3636.285026712468,
    "output_throughput": 3194.8690158517584,
    "total_throughput": 6831.154042564226,
    "itl": 158.52599220066207,
    "ttft": 2244436.519113864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.817746060527252,
    "arrivals": 500641,
    "finished_requests": 52908,
    "scheduler_time": 90.25807981152009
}
#Debug simulation 
Total elapsed time: 5.386823236010969. Arrivals time: 0.2063595904619433 Scheduler time: 5.01591091073351 Scheduler overhead time: 0.03557329979958013 Adapter cache time: 0.07820757362060249 Engine time: 0.034609496069606394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.227494814957026,
    "estimated_duration": 3600.083439487988,
    "input_throughput": 4057.3523490548355,
    "output_throughput": 3612.275720434282,
    "total_throughput": 7669.6280694891175,
    "itl": 238.39020363812142,
    "ttft": 2170127.644343744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.779702363757046,
    "arrivals": 481654,
    "finished_requests": 59334,
    "scheduler_time": 81.9416249703313
}
#Debug simulation 
Total elapsed time: 10.227620031975675. Arrivals time: 0.24617546738591045 Scheduler time: 9.883565551019274 Scheduler overhead time: 0.027221449359785765 Adapter cache time: 0.031681742635555565 Engine time: 0.02722222002921626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.383629726013169,
    "estimated_duration": 3600.110560465616,
    "input_throughput": 4057.08651295169,
    "output_throughput": 3610.297178850804,
    "total_throughput": 7667.3836918024945,
    "itl": 238.42818197034674,
    "ttft": 2170593.8456183905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.29963297827167,
    "arrivals": 481654,
    "finished_requests": 59306,
    "scheduler_time": 81.90842882891872
}
#Debug simulation 
Total elapsed time: 10.383743948012125. Arrivals time: 0.2645246272441 Scheduler time: 10.02002286433708 Scheduler overhead time: 0.027264406729955226 Adapter cache time: 0.03318191156722605 Engine time: 0.027023897506296635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.318878930993378,
    "estimated_duration": 3600.1675574564647,
    "input_throughput": 3567.7533878658433,
    "output_throughput": 3199.6877412390545,
    "total_throughput": 6767.441129104898,
    "itl": 159.09974245994326,
    "ttft": 2247112.7470188923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.849001497830841,
    "arrivals": 481654,
    "finished_requests": 52243,
    "scheduler_time": 90.13707963908728
}
#Debug simulation 
Total elapsed time: 5.318946618994232. Arrivals time: 0.20045832346659154 Scheduler time: 4.95916733314516 Scheduler overhead time: 0.035386583709623665 Adapter cache time: 0.07345101836835966 Engine time: 0.03439565747976303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.387862496019807,
    "estimated_duration": 3600.1953055775075,
    "input_throughput": 4057.5343169213825,
    "output_throughput": 3610.7954976389087,
    "total_throughput": 7668.329814560291,
    "itl": 238.4178672523413,
    "ttft": 2170630.2155937604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.11617368029192,
    "arrivals": 481654,
    "finished_requests": 59312,
    "scheduler_time": 81.91430388246408
}
#Debug simulation 
Total elapsed time: 10.387952043965925. Arrivals time: 0.2679246132611297 Scheduler time: 10.019414565467741 Scheduler overhead time: 0.027551571663934737 Adapter cache time: 0.033999615465290844 Engine time: 0.02739577932516113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.080889378034044,
    "estimated_duration": 3600.041282909591,
    "input_throughput": 3565.697721562037,
    "output_throughput": 3198.521932141181,
    "total_throughput": 6764.219653703218,
    "itl": 158.98448343058826,
    "ttft": 2246622.885923143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.252526894118139,
    "arrivals": 481654,
    "finished_requests": 52219,
    "scheduler_time": 90.14990157218962
}
#Debug simulation 
Total elapsed time: 5.080975815013517. Arrivals time: 0.21026115881977603 Scheduler time: 4.709240472991951 Scheduler overhead time: 0.03537572134518996 Adapter cache time: 0.07499014999484643 Engine time: 0.034960129705723375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.065155144024175,
    "estimated_duration": 3600.252732592401,
    "input_throughput": 4059.1153136844214,
    "output_throughput": 3613.769634064456,
    "total_throughput": 7672.8849477488775,
    "itl": 238.3544587940895,
    "ttft": 2170546.45364379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.024607696938222,
    "arrivals": 481654,
    "finished_requests": 59356,
    "scheduler_time": 81.94727133307283
}
#Debug simulation 
Total elapsed time: 10.065254688030109. Arrivals time: 0.24144596845144406 Scheduler time: 9.725996701687109 Scheduler overhead time: 0.0270671101170592 Adapter cache time: 0.032146019220817834 Engine time: 0.026930822583381087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0635559559450485,
    "estimated_duration": 3600.0335871880566,
    "input_throughput": 3565.7970096959066,
    "output_throughput": 3197.5710007170765,
    "total_throughput": 6763.368010412983,
    "itl": 158.8179440088592,
    "ttft": 2247464.780258262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.1586431721965,
    "arrivals": 481654,
    "finished_requests": 52207,
    "scheduler_time": 90.17149976040528
}
#Debug simulation 
Total elapsed time: 5.06364551698789. Arrivals time: 0.20008093398064375 Scheduler time: 4.7046566412900575 Scheduler overhead time: 0.035180312232114375 Adapter cache time: 0.07330392085714266 Engine time: 0.03437202284112573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.140233843994793,
    "estimated_duration": 3600.078966670138,
    "input_throughput": 4094.289079895772,
    "output_throughput": 3605.7125746901393,
    "total_throughput": 7700.001654585911,
    "itl": 237.0113015492695,
    "ttft": 2162386.4394169296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.143120913019011,
    "arrivals": 472156,
    "finished_requests": 59645,
    "scheduler_time": 81.94955873893552
}
#Debug simulation 
Total elapsed time: 9.140346739033703. Arrivals time: 0.28134622902143747 Scheduler time: 8.768995280202944 Scheduler overhead time: 0.02633510751184076 Adapter cache time: 0.026266861706972122 Engine time: 0.025819767266511917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.332095079997089,
    "estimated_duration": 3600.117881854737,
    "input_throughput": 4091.353251025107,
    "output_throughput": 3606.6232901547833,
    "total_throughput": 7697.97654117989,
    "itl": 237.07093338302266,
    "ttft": 2162468.819301235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.588555692809174,
    "arrivals": 472156,
    "finished_requests": 59650,
    "scheduler_time": 81.94480557879253
}
#Debug simulation 
Total elapsed time: 9.332186149025802. Arrivals time: 0.2422788487165235 Scheduler time: 8.996702285599895 Scheduler overhead time: 0.027032721554860473 Adapter cache time: 0.028163969342131168 Engine time: 0.02636094845365733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.161622158018872,
    "estimated_duration": 3600.1187267257,
    "input_throughput": 3627.7681352688055,
    "output_throughput": 3200.689720163762,
    "total_throughput": 6828.457855432568,
    "itl": 158.81173208422263,
    "ttft": 2239240.8259148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.218763636816044,
    "arrivals": 472156,
    "finished_requests": 52783,
    "scheduler_time": 90.12740920922595
}
#Debug simulation 
Total elapsed time: 5.161685577011667. Arrivals time: 0.4371017832891084 Scheduler time: 4.569615810352843 Scheduler overhead time: 0.03512771229725331 Adapter cache time: 0.06929575989488512 Engine time: 0.03448670927900821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.351785637030844,
    "estimated_duration": 3600.0465426222177,
    "input_throughput": 4093.6542973873743,
    "output_throughput": 3606.5619836522474,
    "total_throughput": 7700.216281039621,
    "itl": 237.03558620227957,
    "ttft": 2162099.5757955094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1034,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.231860199153854,
    "arrivals": 472156,
    "finished_requests": 59667,
    "scheduler_time": 81.94747001205963
}
#Debug simulation 
Total elapsed time: 9.351872785016894. Arrivals time: 0.2912159657571465 Scheduler time: 8.967312513734214 Scheduler overhead time: 0.027040063578169793 Adapter cache time: 0.027890454337466508 Engine time: 0.026695530104916543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.929190607042983,
    "estimated_duration": 3600.0647879944904,
    "input_throughput": 3627.7066578225113,
    "output_throughput": 3200.4912907188586,
    "total_throughput": 6828.197948541369,
    "itl": 158.81643098258536,
    "ttft": 2239295.283875377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.33797822633721,
    "arrivals": 472156,
    "finished_requests": 52781,
    "scheduler_time": 90.12312303004164
}
#Debug simulation 
Total elapsed time: 4.929280489042867. Arrivals time: 0.24475915846414864 Scheduler time: 4.529199311393313 Scheduler overhead time: 0.035364841867703944 Adapter cache time: 0.06924566440284252 Engine time: 0.034549768664874136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.276162958005443,
    "estimated_duration": 3600.012137717128,
    "input_throughput": 4093.05619990046,
    "output_throughput": 3606.2478412177247,
    "total_throughput": 7699.304041118185,
    "itl": 237.05819734502532,
    "ttft": 2162826.5888623223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.06779160256956,
    "arrivals": 472156,
    "finished_requests": 59671,
    "scheduler_time": 81.94564850600442
}
#Debug simulation 
Total elapsed time: 9.276257980964147. Arrivals time: 0.2814292531693354 Scheduler time: 8.902893314894754 Scheduler overhead time: 0.027075968973804265 Adapter cache time: 0.026731751742772758 Engine time: 0.026385271281469613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 270, 8640, 8640, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 8640, 4320, 270, 270, 4320, 8640, 8640, 4320, 4320, 270, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 8640, 4320, 270, 270, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 270, 8640, 4320, 8640, 8640, 4320, 270, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 4320, 270, 8640, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 4320, 270, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 4320, 8640, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 4320, 270, 4320, 270, 270, 270, 8640, 8640, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 270, 4320, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 4320, 270, 4320, 270, 4320, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 8640, 270, 8640, 270, 270, 270, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1415340 . Total input tokens: 315451202 . Total output tokens: 283391522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.917465799022466,
    "estimated_duration": 3600.1023960161315,
    "input_throughput": 3628.186246717376,
    "output_throughput": 3201.1061720779903,
    "total_throughput": 6829.292418795366,
    "itl": 158.93281612720523,
    "ttft": 2238965.47853052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.47671717900735,
    "arrivals": 472156,
    "finished_requests": 52776,
    "scheduler_time": 90.1049584606136
}
#Debug simulation 
Total elapsed time: 4.917576214007568. Arrivals time: 0.24412562977522612 Scheduler time: 4.51857805531472 Scheduler overhead time: 0.03515188256278634 Adapter cache time: 0.06901051668683067 Engine time: 0.03461610624799505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.811245705990586,
    "estimated_duration": 3600.168021154194,
    "input_throughput": 4080.650379003738,
    "output_throughput": 3608.552968545904,
    "total_throughput": 7689.203347549643,
    "itl": 237.52512415311648,
    "ttft": 2162586.966059984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9992779890541668,
    "arrivals": 467317,
    "finished_requests": 59623,
    "scheduler_time": 81.92540295758052
}
#Debug simulation 
Total elapsed time: 8.811361170955934. Arrivals time: 0.2653877370757982 Scheduler time: 8.456960235082079 Scheduler overhead time: 0.02624563645804301 Adapter cache time: 0.025432540976908058 Engine time: 0.02575692138634622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.131277389009483,
    "estimated_duration": 3600.095014575118,
    "input_throughput": 4074.9963377650997,
    "output_throughput": 3608.1181044975906,
    "total_throughput": 7683.11444226269,
    "itl": 237.66048245602565,
    "ttft": 2161584.2394189006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.020630118425477,
    "arrivals": 467317,
    "finished_requests": 59543,
    "scheduler_time": 81.91486824831449
}
#Debug simulation 
Total elapsed time: 9.131393064046279. Arrivals time: 0.2415997221833095 Scheduler time: 8.801592112111393 Scheduler overhead time: 0.02667771535925567 Adapter cache time: 0.02359876368427649 Engine time: 0.02625253313453868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.764678870036732,
    "estimated_duration": 3600.0081653647344,
    "input_throughput": 3593.508793802784,
    "output_throughput": 3196.816082452972,
    "total_throughput": 6790.324876255756,
    "itl": 158.39278590656744,
    "ttft": 2241892.9679627856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.21020890144624,
    "arrivals": 467317,
    "finished_requests": 52547,
    "scheduler_time": 90.22892937800385
}
#Debug simulation 
Total elapsed time: 4.7647686510463245. Arrivals time: 0.19893338077235967 Scheduler time: 4.417462434968911 Scheduler overhead time: 0.03537300880998373 Adapter cache time: 0.06238799454877153 Engine time: 0.034478894143830985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.170211526972707,
    "estimated_duration": 3600.2395025620867,
    "input_throughput": 4075.448311024405,
    "output_throughput": 3608.4810443179567,
    "total_throughput": 7683.929355342361,
    "itl": 237.65794390980636,
    "ttft": 2161577.624877037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.88893254282183,
    "arrivals": 467317,
    "finished_requests": 59549,
    "scheduler_time": 81.9201638218056
}
#Debug simulation 
Total elapsed time: 9.170303369988687. Arrivals time: 0.24540045781759545 Scheduler time: 8.835541429114528 Scheduler overhead time: 0.026731328514870256 Adapter cache time: 0.02462075062794611 Engine time: 0.02643435593927279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.7762654080288485,
    "estimated_duration": 3600.1358213547787,
    "input_throughput": 3597.8328715180896,
    "output_throughput": 3200.028713268009,
    "total_throughput": 6797.861584786099,
    "itl": 158.81396407460426,
    "ttft": 2241500.988290374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.512398404925799,
    "arrivals": 467317,
    "finished_requests": 52614,
    "scheduler_time": 90.157234108855
}
#Debug simulation 
Total elapsed time: 4.776366139005404. Arrivals time: 0.22538777539739385 Scheduler time: 4.401294634619262 Scheduler overhead time: 0.03526083001634106 Adapter cache time: 0.0638289712369442 Engine time: 0.03447848616633564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.117720031994395,
    "estimated_duration": 3600.127560260739,
    "input_throughput": 4075.442537635354,
    "output_throughput": 3608.593246362387,
    "total_throughput": 7684.0357839977405,
    "itl": 237.64626687278798,
    "ttft": 2161593.3611266823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.765796522784451,
    "arrivals": 467317,
    "finished_requests": 59549,
    "scheduler_time": 81.92058572984176
}
#Debug simulation 
Total elapsed time: 9.11781638598768. Arrivals time: 0.23713136493461207 Scheduler time: 8.792270033038221 Scheduler overhead time: 0.02656220883363858 Adapter cache time: 0.024156878178473562 Engine time: 0.026151721307542175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 135, 8640, 8640, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 8640, 4320, 135, 135, 4320, 8640, 8640, 4320, 4320, 135, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 8640, 4320, 135, 135, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 135, 8640, 4320, 8640, 8640, 4320, 135, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 4320, 135, 8640, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 4320, 135, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 4320, 8640, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 4320, 135, 4320, 135, 135, 135, 8640, 8640, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 135, 4320, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 4320, 135, 4320, 135, 4320, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 8640, 135, 8640, 135, 135, 135, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1401030 . Total input tokens: 312221278 . Total output tokens: 280496191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.739204661978874,
    "estimated_duration": 3600.148492305726,
    "input_throughput": 3589.822760816972,
    "output_throughput": 3193.647435535728,
    "total_throughput": 6783.4701963527,
    "itl": 157.93231673212955,
    "ttft": 2242546.4040091787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.585189938507584,
    "arrivals": 467317,
    "finished_requests": 52485,
    "scheduler_time": 90.3034633963413
}
#Debug simulation 
Total elapsed time: 4.739313736965414. Arrivals time: 0.19951882562600076 Scheduler time: 4.39000219135778 Scheduler overhead time: 0.03549493051832542 Adapter cache time: 0.06356629740912467 Engine time: 0.03458772483281791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.179721863998566,
    "estimated_duration": 3600.1787824312346,
    "input_throughput": 4085.7054299027595,
    "output_throughput": 3609.787953703721,
    "total_throughput": 7695.49338360648,
    "itl": 237.44431471769346,
    "ttft": 2160100.4932964854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4086038544751247,
    "arrivals": 464889,
    "finished_requests": 59603,
    "scheduler_time": 81.89647402972575
}
#Debug simulation 
Total elapsed time: 8.17981336300727. Arrivals time: 0.2324195053661242 Scheduler time: 7.863487271999475 Scheduler overhead time: 0.026026888226624578 Adapter cache time: 0.020949116733390838 Engine time: 0.02539433032507077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.033017938025296,
    "estimated_duration": 3600.0451888744346,
    "input_throughput": 4083.941792018656,
    "output_throughput": 3609.193862386595,
    "total_throughput": 7693.135654405251,
    "itl": 237.4903870117861,
    "ttft": 2160227.720728411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6923361090733735,
    "arrivals": 464889,
    "finished_requests": 59575,
    "scheduler_time": 81.88428046400608
}
#Debug simulation 
Total elapsed time: 8.033112458011601. Arrivals time: 0.2349379510851577 Scheduler time: 7.712582640291657 Scheduler overhead time: 0.02629225904820487 Adapter cache time: 0.02187713561579585 Engine time: 0.025829202902968973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.651535317010712,
    "estimated_duration": 3600.1308637461852,
    "input_throughput": 3597.709219526069,
    "output_throughput": 3199.931456939447,
    "total_throughput": 6797.640676465516,
    "itl": 158.83402663806925,
    "ttft": 2239047.7225906337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9086047449148875,
    "arrivals": 464889,
    "finished_requests": 52585,
    "scheduler_time": 90.13057076828964
}
#Debug simulation 
Total elapsed time: 4.651630313019268. Arrivals time: 0.22049151721876115 Scheduler time: 4.284808006021194 Scheduler overhead time: 0.03525872033787891 Adapter cache time: 0.06034494057530537 Engine time: 0.03455329011194408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.597217185015325,
    "estimated_duration": 3600.201058774112,
    "input_throughput": 4087.814474731365,
    "output_throughput": 3610.0575461820254,
    "total_throughput": 7697.87202091339,
    "itl": 237.4152820889346,
    "ttft": 2160225.179889942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.377168508712182,
    "arrivals": 464889,
    "finished_requests": 59608,
    "scheduler_time": 81.89967331844969
}
#Debug simulation 
Total elapsed time: 8.59728248004103. Arrivals time: 0.47383226454257965 Scheduler time: 8.038899309409317 Scheduler overhead time: 0.02632626093691215 Adapter cache time: 0.0205844072625041 Engine time: 0.026122492214199156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6414544159779325,
    "estimated_duration": 3600.1395586599733,
    "input_throughput": 3596.9508373225426,
    "output_throughput": 3198.3015692552235,
    "total_throughput": 6795.252406577766,
    "itl": 158.70137456409205,
    "ttft": 2238972.622930181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.053086582477942,
    "arrivals": 464889,
    "finished_requests": 52555,
    "scheduler_time": 90.14895736810132
}
#Debug simulation 
Total elapsed time: 4.64154718699865. Arrivals time: 0.20039905176963657 Scheduler time: 4.294240464805625 Scheduler overhead time: 0.03513358923373744 Adapter cache time: 0.06124112522229552 Engine time: 0.03438611951423809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.20034704101272,
    "estimated_duration": 3600.122869585614,
    "input_throughput": 4085.768884241744,
    "output_throughput": 3609.844016655984,
    "total_throughput": 7695.612900897729,
    "itl": 237.441252146661,
    "ttft": 2160077.84633774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3531695820879657,
    "arrivals": 464889,
    "finished_requests": 59603,
    "scheduler_time": 81.8962927152873
}
#Debug simulation 
Total elapsed time: 8.200459837040398. Arrivals time: 0.236273757298477 Scheduler time: 7.87955467752181 Scheduler overhead time: 0.02630405279342085 Adapter cache time: 0.020847352221608162 Engine time: 0.02589183917734772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 66, 8640, 8640, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 8640, 4320, 66, 66, 4320, 8640, 8640, 4320, 4320, 66, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 8640, 4320, 66, 66, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 66, 8640, 4320, 8640, 8640, 4320, 66, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 4320, 66, 8640, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 4320, 66, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 4320, 8640, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 4320, 66, 4320, 66, 66, 66, 8640, 8640, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 66, 4320, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 4320, 66, 4320, 66, 4320, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 8640, 66, 8640, 66, 66, 66, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1393716 . Total input tokens: 310571983 . Total output tokens: 279037290
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.618804440018721,
    "estimated_duration": 3600.07038455789,
    "input_throughput": 3596.4235742546502,
    "output_throughput": 3198.0441408547313,
    "total_throughput": 6794.467715109382,
    "itl": 158.70749391332032,
    "ttft": 2239008.086729525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.155072903260242,
    "arrivals": 464889,
    "finished_requests": 52549,
    "scheduler_time": 90.14470535703038
}
#Debug simulation 
Total elapsed time: 4.618891877005808. Arrivals time: 0.20134172140387818 Scheduler time: 4.271596806705929 Scheduler overhead time: 0.03503666410688311 Adapter cache time: 0.06052909494610503 Engine time: 0.03443714673630893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.18596177897416,
    "estimated_duration": 3600.2537347081384,
    "input_throughput": 4057.3256987911095,
    "output_throughput": 3611.0688184742435,
    "total_throughput": 7668.394517265353,
    "itl": 238.17068621342796,
    "ttft": 2157776.350393629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0811316658743086,
    "arrivals": 463720,
    "finished_requests": 59308,
    "scheduler_time": 81.86592167107345
}
#Debug simulation 
Total elapsed time: 8.186066591995768. Arrivals time: 0.24257025180850178 Scheduler time: 7.861977628082968 Scheduler overhead time: 0.026035484217572957 Adapter cache time: 0.018281337223015726 Engine time: 0.025661676307208836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.338569923012983,
    "estimated_duration": 3600.2375543817257,
    "input_throughput": 4057.4842019025155,
    "output_throughput": 3611.161986846362,
    "total_throughput": 7668.646188748878,
    "itl": 238.16386313179726,
    "ttft": 2157794.018217377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.165324165115606,
    "arrivals": 463720,
    "finished_requests": 59288,
    "scheduler_time": 81.86734378041591
}
#Debug simulation 
Total elapsed time: 8.338662576046772. Arrivals time: 0.26254887104732916 Scheduler time: 7.994385423196945 Scheduler overhead time: 0.026105395634658635 Adapter cache time: 0.018153136014007032 Engine time: 0.026001818652730435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.590916629007552,
    "estimated_duration": 3600.1056988306505,
    "input_throughput": 3578.289660824201,
    "output_throughput": 3199.101627416347,
    "total_throughput": 6777.3912882405475,
    "itl": 158.57032813263038,
    "ttft": 2235279.427266237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.7006585949100295,
    "arrivals": 463720,
    "finished_requests": 52366,
    "scheduler_time": 90.19727794239569
}
#Debug simulation 
Total elapsed time: 4.591011511976831. Arrivals time: 0.20044971024617553 Scheduler time: 4.245892371807713 Scheduler overhead time: 0.03507197881117463 Adapter cache time: 0.05904064833885059 Engine time: 0.034486157761421055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.175156023993623,
    "estimated_duration": 3600.0308923160405,
    "input_throughput": 4057.443793378894,
    "output_throughput": 3611.1673451880824,
    "total_throughput": 7668.6111385669765,
    "itl": 238.17354389906205,
    "ttft": 2157760.0148571795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.121899384635019,
    "arrivals": 463720,
    "finished_requests": 59305,
    "scheduler_time": 81.85996036973506
}
#Debug simulation 
Total elapsed time: 8.17524630803382. Arrivals time: 0.23731201043119654 Scheduler time: 7.856452125764918 Scheduler overhead time: 0.02610744588309899 Adapter cache time: 0.018044388678390533 Engine time: 0.025827428326010704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.618025286006741,
    "estimated_duration": 3600.0382264619557,
    "input_throughput": 3577.6736772759127,
    "output_throughput": 3198.144096185105,
    "total_throughput": 6775.817773461018,
    "itl": 158.46313994450426,
    "ttft": 2235626.519400434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.79819467412291,
    "arrivals": 463720,
    "finished_requests": 52346,
    "scheduler_time": 90.21037899058724
}
#Debug simulation 
Total elapsed time: 4.61811746400781. Arrivals time: 0.21130936371628195 Scheduler time: 4.261902174039278 Scheduler overhead time: 0.03545788419432938 Adapter cache time: 0.058509782305918634 Engine time: 0.034740804869215935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.15033576200949,
    "estimated_duration": 3600.1981995630813,
    "input_throughput": 4057.38828539294,
    "output_throughput": 3611.1245213049015,
    "total_throughput": 7668.512806697841,
    "itl": 238.1680559754661,
    "ttft": 2157739.1523266076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0332342005334443,
    "arrivals": 463720,
    "finished_requests": 59308,
    "scheduler_time": 81.86559283285648
}
#Debug simulation 
Total elapsed time: 8.150452321977355. Arrivals time: 0.23951184313045815 Scheduler time: 7.830186492181383 Scheduler overhead time: 0.02589967002859339 Adapter cache time: 0.01792188116814941 Engine time: 0.025457655603531748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 33, 8640, 8640, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 8640, 4320, 33, 33, 4320, 8640, 8640, 4320, 4320, 33, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 8640, 4320, 33, 33, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 33, 8640, 4320, 8640, 8640, 4320, 33, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 4320, 33, 8640, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 4320, 33, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 4320, 8640, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 4320, 33, 4320, 33, 33, 33, 8640, 8640, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 33, 4320, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 4320, 33, 4320, 33, 4320, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 8640, 33, 8640, 33, 33, 33, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1390218 . Total input tokens: 309782656 . Total output tokens: 278354098
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.59083721798379,
    "estimated_duration": 3600.124667588368,
    "input_throughput": 3575.307576396327,
    "output_throughput": 3194.9846358251607,
    "total_throughput": 6770.292212221488,
    "itl": 158.2096794103525,
    "ttft": 2235877.352767567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8800392872091924,
    "arrivals": 463720,
    "finished_requests": 52312,
    "scheduler_time": 90.25153302577634
}
#Debug simulation 
Total elapsed time: 4.59092700999463. Arrivals time: 0.2077085598721169 Scheduler time: 4.238543615618255 Scheduler overhead time: 0.03521574422484264 Adapter cache time: 0.058750060212332755 Engine time: 0.03460992412874475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.389771276037209,
    "estimated_duration": 3600.017770077201,
    "input_throughput": 4113.028030881767,
    "output_throughput": 3605.28803715368,
    "total_throughput": 7718.316068035447,
    "itl": 236.527910951313,
    "ttft": 2112506.2158638127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.501977471325201,
    "arrivals": 366022,
    "finished_requests": 59610,
    "scheduler_time": 81.5351139443894
}
#Debug simulation 
Total elapsed time: 6.389886746008415. Arrivals time: 0.22383788728620857 Scheduler time: 6.069468566449359 Scheduler overhead time: 0.025718993158079684 Adapter cache time: 0.03428553824778646 Engine time: 0.025043636036571115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.402730588975828,
    "estimated_duration": 3600.098075845695,
    "input_throughput": 4111.867979186265,
    "output_throughput": 3604.6351312114125,
    "total_throughput": 7716.503110397678,
    "itl": 236.5777676892289,
    "ttft": 2112624.6319968086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.751893664856845,
    "arrivals": 366022,
    "finished_requests": 59604,
    "scheduler_time": 81.52996728951214
}
#Debug simulation 
Total elapsed time: 6.402821578958537. Arrivals time: 0.22628757072379813 Scheduler time: 6.0801394247682765 Scheduler overhead time: 0.025771455315407366 Adapter cache time: 0.03399278246797621 Engine time: 0.0250946824089624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.470361744984984,
    "estimated_duration": 3600.010638368446,
    "input_throughput": 3608.53128086519,
    "output_throughput": 3181.1225439017517,
    "total_throughput": 6789.653824766942,
    "itl": 156.8363984981358,
    "ttft": 2196422.4404210746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.440924160908104,
    "arrivals": 366022,
    "finished_requests": 52456,
    "scheduler_time": 89.84816811970005
}
#Debug simulation 
Total elapsed time: 4.470469246967696. Arrivals time: 0.19573197251884267 Scheduler time: 4.101504591701087 Scheduler overhead time: 0.03552840556949377 Adapter cache time: 0.08668208116432652 Engine time: 0.03472299064742401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.4182693070033565,
    "estimated_duration": 3600.142573952676,
    "input_throughput": 4112.067701737248,
    "output_throughput": 3605.2322188311796,
    "total_throughput": 7717.299920568428,
    "itl": 236.55764710349519,
    "ttft": 2112574.0424314607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.592446760060177,
    "arrivals": 366022,
    "finished_requests": 59605,
    "scheduler_time": 81.53618234308868
}
#Debug simulation 
Total elapsed time: 6.418376380985137. Arrivals time: 0.2267739842645824 Scheduler time: 6.094091603008565 Scheduler overhead time: 0.025910641357768327 Adapter cache time: 0.034802403301000595 Engine time: 0.025213938963133842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4358221890288405,
    "estimated_duration": 3600.0978431816893,
    "input_throughput": 3623.8220649220257,
    "output_throughput": 3194.0715227443534,
    "total_throughput": 6817.893587666379,
    "itl": 158.41792081604822,
    "ttft": 2197482.9291998465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.292635734639155,
    "arrivals": 366022,
    "finished_requests": 52673,
    "scheduler_time": 89.55980621969678
}
#Debug simulation 
Total elapsed time: 4.435913807014003. Arrivals time: 0.2022981716436334 Scheduler time: 4.057335664110724 Scheduler overhead time: 0.03531095047947019 Adapter cache time: 0.09032001561718062 Engine time: 0.03445561829721555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.432668316992931,
    "estimated_duration": 3600.15831488828,
    "input_throughput": 4111.688071822852,
    "output_throughput": 3603.8595709374026,
    "total_throughput": 7715.547642760254,
    "itl": 236.52008093732087,
    "ttft": 2112690.4141885876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.398363983800981,
    "arrivals": 366022,
    "finished_requests": 59603,
    "scheduler_time": 81.5405667289896
}
#Debug simulation 
Total elapsed time: 6.432762003969401. Arrivals time: 0.2260947871254757 Scheduler time: 6.109135284088552 Scheduler overhead time: 0.025926016503944993 Adapter cache time: 0.03480566618964076 Engine time: 0.025276382686570287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 540, 8640, 8640, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 8640, 1080, 540, 540, 1080, 8640, 8640, 1080, 1080, 540, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 8640, 1080, 540, 540, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 540, 8640, 1080, 8640, 8640, 1080, 540, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 1080, 540, 8640, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 1080, 540, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 1080, 8640, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 1080, 540, 1080, 540, 540, 540, 8640, 8640, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 540, 1080, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 1080, 540, 1080, 540, 1080, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 8640, 540, 8640, 540, 540, 540, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1097280 . Total input tokens: 244619944 . Total output tokens: 219483476
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.438156432996038,
    "estimated_duration": 3600.1416079030173,
    "input_throughput": 3623.577186898095,
    "output_throughput": 3193.9793631333628,
    "total_throughput": 6817.556550031458,
    "itl": 158.3754878082538,
    "ttft": 2197575.79549852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.41128283880564,
    "arrivals": 366022,
    "finished_requests": 52669,
    "scheduler_time": 89.56662763798347
}
#Debug simulation 
Total elapsed time: 4.438246077974327. Arrivals time: 0.19320103141944855 Scheduler time: 4.0700802023056895 Scheduler overhead time: 0.0353110964060761 Adapter cache time: 0.08904642809648067 Engine time: 0.034457750618457794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.655848272959702,
    "estimated_duration": 3600.0523644775076,
    "input_throughput": 4090.109950980408,
    "output_throughput": 3603.686193015389,
    "total_throughput": 7693.796143995797,
    "itl": 237.01702175314932,
    "ttft": 2110892.1426728833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.979413559378727,
    "arrivals": 356416,
    "finished_requests": 59357,
    "scheduler_time": 81.46616906890236
}
#Debug simulation 
Total elapsed time: 5.655939539952669. Arrivals time: 0.21954803599510342 Scheduler time: 5.337839629501104 Scheduler overhead time: 0.025436162599362433 Adapter cache time: 0.036672114685643464 Engine time: 0.024993206548970193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.666766099981032,
    "estimated_duration": 3600.095119858051,
    "input_throughput": 4090.0383211487415,
    "output_throughput": 3603.824779082937,
    "total_throughput": 7693.863100231678,
    "itl": 237.0403877621112,
    "ttft": 2110964.037976563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.312223703497908,
    "arrivals": 356416,
    "finished_requests": 59356,
    "scheduler_time": 81.46025564962912
}
#Debug simulation 
Total elapsed time: 5.666851613961626. Arrivals time: 0.21052733925171196 Scheduler time: 5.357761343067978 Scheduler overhead time: 0.02536688494728878 Adapter cache time: 0.03695462370524183 Engine time: 0.024786791764199734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4322297549806535,
    "estimated_duration": 3600.0584011176884,
    "input_throughput": 3620.635430790028,
    "output_throughput": 3185.720541766588,
    "total_throughput": 6806.355972556616,
    "itl": 157.63005689080796,
    "ttft": 2196709.4687068886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.110439444891014,
    "arrivals": 356416,
    "finished_requests": 52378,
    "scheduler_time": 89.63610592200706
}
#Debug simulation 
Total elapsed time: 4.432292658020742. Arrivals time: 0.4007740039960481 Scheduler time: 3.8483982852776535 Scheduler overhead time: 0.03541341290110722 Adapter cache time: 0.09696664684452116 Engine time: 0.03454342717304826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.659455406013876,
    "estimated_duration": 3600.2348059397364,
    "input_throughput": 4090.919841033983,
    "output_throughput": 3604.047707830863,
    "total_throughput": 7694.967548864846,
    "itl": 237.02573725509322,
    "ttft": 2110932.472689839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.110450660891245,
    "arrivals": 356416,
    "finished_requests": 59364,
    "scheduler_time": 81.46744331610846
}
#Debug simulation 
Total elapsed time: 5.659544799011201. Arrivals time: 0.22014866053359583 Scheduler time: 5.339386537380051 Scheduler overhead time: 0.025463161116931587 Adapter cache time: 0.03810399607755244 Engine time: 0.02496015402721241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.201661931001581,
    "estimated_duration": 3600.006207100804,
    "input_throughput": 3623.656252111212,
    "output_throughput": 3188.3411693458233,
    "total_throughput": 6811.997421457036,
    "itl": 157.87308621425393,
    "ttft": 2196471.2837907476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.30519717607544,
    "arrivals": 356416,
    "finished_requests": 52417,
    "scheduler_time": 89.58967476161706
}
#Debug simulation 
Total elapsed time: 4.20175983698573. Arrivals time: 0.1895444673136808 Scheduler time: 3.8313181645353325 Scheduler overhead time: 0.035201692837290466 Adapter cache time: 0.09491860680282116 Engine time: 0.0345282664638944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.829818255966529,
    "estimated_duration": 3600.0247518211268,
    "input_throughput": 4090.8174291163145,
    "output_throughput": 3604.4638285989045,
    "total_throughput": 7695.281257715219,
    "itl": 237.01926152673545,
    "ttft": 2110793.5037988056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.885742181870018,
    "arrivals": 356416,
    "finished_requests": 59361,
    "scheduler_time": 81.46686844506331
}
#Debug simulation 
Total elapsed time: 5.829880460980348. Arrivals time: 0.42455595423234627 Scheduler time: 5.306263451871928 Scheduler overhead time: 0.02550538576906547 Adapter cache time: 0.03705978178186342 Engine time: 0.02510790666565299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 270, 8640, 8640, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 8640, 1080, 270, 270, 1080, 8640, 8640, 1080, 1080, 270, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 8640, 1080, 270, 270, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 270, 8640, 1080, 8640, 8640, 1080, 270, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 1080, 270, 8640, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 1080, 270, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 1080, 8640, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 1080, 270, 1080, 270, 270, 270, 8640, 8640, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 270, 1080, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 1080, 270, 1080, 270, 1080, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 8640, 270, 8640, 270, 270, 270, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1068660 . Total input tokens: 238230045 . Total output tokens: 213754789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.223315007984638,
    "estimated_duration": 3600.1206408130142,
    "input_throughput": 3623.17386037772,
    "output_throughput": 3187.8967804279455,
    "total_throughput": 6811.070640805666,
    "itl": 157.87242906822934,
    "ttft": 2196549.720539671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.445181827767717,
    "arrivals": 356416,
    "finished_requests": 52413,
    "scheduler_time": 89.58856494276662
}
#Debug simulation 
Total elapsed time: 4.223400863003917. Arrivals time: 0.18738610780565068 Scheduler time: 3.853185667481739 Scheduler overhead time: 0.035528013890143484 Adapter cache time: 0.09598458762047812 Engine time: 0.03502480481984094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.240491401986219,
    "estimated_duration": 3600.1726667298476,
    "input_throughput": 4089.154427521433,
    "output_throughput": 3605.4409611943256,
    "total_throughput": 7694.595388715758,
    "itl": 237.36710021927777,
    "ttft": 2112701.234221206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8906594148046745,
    "arrivals": 351637,
    "finished_requests": 59380,
    "scheduler_time": 81.4633119621157
}
#Debug simulation 
Total elapsed time: 5.240583012986463. Arrivals time: 0.21139941806904972 Scheduler time: 4.931300996220671 Scheduler overhead time: 0.025335859158076346 Adapter cache time: 0.03631647164002061 Engine time: 0.024796133278869092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.236889640975278,
    "estimated_duration": 3600.110940093421,
    "input_throughput": 4090.4167246628986,
    "output_throughput": 3605.582221214317,
    "total_throughput": 7695.998945877215,
    "itl": 237.36367941748028,
    "ttft": 2112703.713575407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.23405485439104,
    "arrivals": 351637,
    "finished_requests": 59395,
    "scheduler_time": 81.45651235669375
}
#Debug simulation 
Total elapsed time: 5.236979336012155. Arrivals time: 0.21045040857279673 Scheduler time: 4.928404358448461 Scheduler overhead time: 0.02527677023317665 Adapter cache time: 0.036581776570528746 Engine time: 0.02480981353437528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.168331142980605,
    "estimated_duration": 3600.025598876555,
    "input_throughput": 3627.1400414693976,
    "output_throughput": 3204.9727656382806,
    "total_throughput": 6832.112807107678,
    "itl": 158.5152828317463,
    "ttft": 2199098.2933763214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.138727600405932,
    "arrivals": 351637,
    "finished_requests": 52632,
    "scheduler_time": 89.68849571803088
}
#Debug simulation 
Total elapsed time: 4.1684213079861365. Arrivals time: 0.20221505244262516 Scheduler time: 3.787909571721684 Scheduler overhead time: 0.03492990683298558 Adapter cache time: 0.09269057324854657 Engine time: 0.0344541851663962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.2257279379991814,
    "estimated_duration": 3600.0744320013614,
    "input_throughput": 4089.380727557811,
    "output_throughput": 3605.5385090424406,
    "total_throughput": 7694.919236600252,
    "itl": 237.37595045088486,
    "ttft": 2112665.4145266516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.974115187160094,
    "arrivals": 351637,
    "finished_requests": 59381,
    "scheduler_time": 81.4596457338816
}
#Debug simulation 
Total elapsed time: 5.225832108990289. Arrivals time: 0.20984838262666017 Scheduler time: 4.9178959565469995 Scheduler overhead time: 0.02546727523440495 Adapter cache time: 0.036253696656785905 Engine time: 0.02489475253969431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.1497598820133135,
    "estimated_duration": 3600.1625486966504,
    "input_throughput": 3626.786241839822,
    "output_throughput": 3204.9469555693163,
    "total_throughput": 6831.7331974091385,
    "itl": 158.52940429428043,
    "ttft": 2199115.7852493348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.320236622559882,
    "arrivals": 351637,
    "finished_requests": 52631,
    "scheduler_time": 89.68534862639382
}
#Debug simulation 
Total elapsed time: 4.149845762993209. Arrivals time: 0.1848543756059371 Scheduler time: 3.787820415571332 Scheduler overhead time: 0.03501426731236279 Adapter cache time: 0.09142546739894897 Engine time: 0.03447573311859742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.214735854999162,
    "estimated_duration": 3600.0577313889944,
    "input_throughput": 4089.284977749511,
    "output_throughput": 3605.5560684000206,
    "total_throughput": 7694.841046149532,
    "itl": 237.3603718928703,
    "ttft": 2112658.1333575193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.778100371253544,
    "arrivals": 351637,
    "finished_requests": 59380,
    "scheduler_time": 81.46306717041492
}
#Debug simulation 
Total elapsed time: 5.214835235034116. Arrivals time: 0.20755296014249325 Scheduler time: 4.909049474343192 Scheduler overhead time: 0.025338365288916975 Adapter cache time: 0.03663786483230069 Engine time: 0.024796854064334184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 135, 8640, 8640, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 8640, 1080, 135, 135, 1080, 8640, 8640, 1080, 1080, 135, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 8640, 1080, 135, 135, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 135, 8640, 1080, 8640, 8640, 1080, 135, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 1080, 135, 8640, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 1080, 135, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 1080, 8640, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 1080, 135, 1080, 135, 135, 135, 8640, 8640, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 135, 1080, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 1080, 135, 1080, 135, 1080, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 8640, 135, 8640, 135, 135, 135, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1054350 . Total input tokens: 235062740 . Total output tokens: 210899556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.158688370021991,
    "estimated_duration": 3600.155902298714,
    "input_throughput": 3626.649610274758,
    "output_throughput": 3204.854265514712,
    "total_throughput": 6831.50387578947,
    "itl": 158.5367861858923,
    "ttft": 2199111.1154515287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.490734715051081,
    "arrivals": 351637,
    "finished_requests": 52629,
    "scheduler_time": 89.68267713454439
}
#Debug simulation 
Total elapsed time: 4.158764143998269. Arrivals time: 0.18966597691178322 Scheduler time: 3.791697219479829 Scheduler overhead time: 0.035143035696819425 Adapter cache time: 0.09143267694162205 Engine time: 0.034540452528744936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.977773629012518,
    "estimated_duration": 3600.247483952525,
    "input_throughput": 4091.414844578568,
    "output_throughput": 3603.1892412458005,
    "total_throughput": 7694.604085824369,
    "itl": 237.08920569009476,
    "ttft": 2104700.831137711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.783542343767024,
    "arrivals": 349246,
    "finished_requests": 59632,
    "scheduler_time": 81.46060839671969
}
#Debug simulation 
Total elapsed time: 4.977852000040002. Arrivals time: 0.19891144306166098 Scheduler time: 4.6820677274954505 Scheduler overhead time: 0.02530105266487226 Adapter cache time: 0.03527757525444031 Engine time: 0.024844131781719625 
