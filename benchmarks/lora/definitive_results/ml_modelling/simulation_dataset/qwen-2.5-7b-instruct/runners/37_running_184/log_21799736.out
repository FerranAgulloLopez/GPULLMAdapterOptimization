INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.379550994839519,
    "estimated_duration": 3600.124594230725,
    "input_throughput": 6362.5864606762525,
    "output_throughput": 5635.037196354281,
    "total_throughput": 11997.623657030534,
    "itl": 153.06838791335025,
    "ttft": 1891311.6349208355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8644925056211692,
    "arrivals": 462529,
    "finished_requests": 92669,
    "scheduler_time": 103.8826644426119
}
#Debug simulation 
Total elapsed time: 7.379719289019704. Arrivals time: 0.3393356348387897 Scheduler time: 6.933300819713622 Scheduler overhead time: 0.0388541747815907 Adapter cache time: 0.01096602063626051 Engine time: 0.039405905175954103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.357899405062199,
    "estimated_duration": 3600.153053601522,
    "input_throughput": 6362.931980651145,
    "output_throughput": 5635.178198800404,
    "total_throughput": 11998.110179451549,
    "itl": 153.06450023183586,
    "ttft": 1891283.4469794037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7833931772643711,
    "arrivals": 462529,
    "finished_requests": 92674,
    "scheduler_time": 103.8855085801053
}
#Debug simulation 
Total elapsed time: 7.358042834326625. Arrivals time: 0.39228750532492995 Scheduler time: 6.859029409475625 Scheduler overhead time: 0.038857974112033844 Adapter cache time: 0.010821178555488586 Engine time: 0.039219178725034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.328794179018587,
    "estimated_duration": 3600.160187343399,
    "input_throughput": 6362.535222884823,
    "output_throughput": 5634.982040887991,
    "total_throughput": 11997.517263772816,
    "itl": 153.06812599455657,
    "ttft": 1891336.0353969287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.876439115330581,
    "arrivals": 462529,
    "finished_requests": 92670,
    "scheduler_time": 103.88346468977551
}
#Debug simulation 
Total elapsed time: 7.328989619389176. Arrivals time: 0.31513736955821514 Scheduler time: 6.908618646208197 Scheduler overhead time: 0.03869717847555876 Adapter cache time: 0.00961063476279378 Engine time: 0.03916808217763901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.010217688977718,
    "estimated_duration": 3600.0594307084853,
    "input_throughput": 6392.0611431326615,
    "output_throughput": 5631.6639739500215,
    "total_throughput": 12023.725117082684,
    "itl": 152.3344208782845,
    "ttft": 1891040.401982352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6702468159212722,
    "arrivals": 461810,
    "finished_requests": 92809,
    "scheduler_time": 103.89139012542029
}
#Debug simulation 
Total elapsed time: 7.010329596232623. Arrivals time: 0.37979947263374925 Scheduler time: 6.52376520819962 Scheduler overhead time: 0.038568305782973766 Adapter cache time: 0.009228145238012075 Engine time: 0.04122129874303937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.029453455936164,
    "estimated_duration": 3600.03070142497,
    "input_throughput": 6392.023543269105,
    "output_throughput": 5631.560306409386,
    "total_throughput": 12023.58384967849,
    "itl": 152.3367132490929,
    "ttft": 1891051.367536741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7177446936233927,
    "arrivals": 461810,
    "finished_requests": 92807,
    "scheduler_time": 103.88964120742808
}
#Debug simulation 
Total elapsed time: 7.0295714661479. Arrivals time: 0.32681830832734704 Scheduler time: 6.596986898686737 Scheduler overhead time: 0.03885600762441754 Adapter cache time: 0.009888457600027323 Engine time: 0.039297080133110285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.0120163802057505,
    "estimated_duration": 3600.0292596738805,
    "input_throughput": 6392.026103166885,
    "output_throughput": 5631.562561754446,
    "total_throughput": 12023.588664921332,
    "itl": 152.33656037489382,
    "ttft": 1891050.9100222713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7184667420387301,
    "arrivals": 461810,
    "finished_requests": 92807,
    "scheduler_time": 103.88958605436491
}
#Debug simulation 
Total elapsed time: 7.012229360174388. Arrivals time: 0.3771523335017264 Scheduler time: 6.529735846444964 Scheduler overhead time: 0.038645843509584665 Adapter cache time: 0.009547230787575245 Engine time: 0.039293233305215836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.039390201680362,
    "estimated_duration": 3600.104483053829,
    "input_throughput": 6392.015595191803,
    "output_throughput": 5631.62238635974,
    "total_throughput": 12023.637981551543,
    "itl": 152.33529187764483,
    "ttft": 1891040.869349788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6875086400588059,
    "arrivals": 461810,
    "finished_requests": 92810,
    "scheduler_time": 103.89234345947736
}
#Debug simulation 
Total elapsed time: 7.039506569970399. Arrivals time: 0.3165953094139695 Scheduler time: 6.617170956451446 Scheduler overhead time: 0.039113848470151424 Adapter cache time: 0.009348612278699875 Engine time: 0.039520460180938244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.057805806864053,
    "estimated_duration": 3600.042230113074,
    "input_throughput": 6392.0030736076205,
    "output_throughput": 5631.542272036964,
    "total_throughput": 12023.545345644585,
    "itl": 152.33702918345253,
    "ttft": 1891051.958331661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7277725222334295,
    "arrivals": 461810,
    "finished_requests": 92807,
    "scheduler_time": 103.88971518815147
}
#Debug simulation 
Total elapsed time: 7.057943799998611. Arrivals time: 0.3957111043855548 Scheduler time: 6.556468745693564 Scheduler overhead time: 0.03884729743003845 Adapter cache time: 0.00973233999684453 Engine time: 0.039387515280395746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.110176759772003,
    "estimated_duration": 3600.0402497067585,
    "input_throughput": 6392.095200011841,
    "output_throughput": 5631.69397943577,
    "total_throughput": 12023.78917944761,
    "itl": 152.33386914874325,
    "ttft": 1891031.5975777002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6548210145835773,
    "arrivals": 461810,
    "finished_requests": 92809,
    "scheduler_time": 103.89122992699487
}
#Debug simulation 
Total elapsed time: 7.110378636978567. Arrivals time: 0.34508797572925687 Scheduler time: 6.658924832940102 Scheduler overhead time: 0.03897529188543558 Adapter cache time: 0.010113320779055357 Engine time: 0.039426855742931366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.973526363261044,
    "estimated_duration": 3600.060111905989,
    "input_throughput": 6392.059655864136,
    "output_throughput": 5631.515688571765,
    "total_throughput": 12023.575344435902,
    "itl": 152.33704578913625,
    "ttft": 1891053.1436029857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.737832825146618,
    "arrivals": 461810,
    "finished_requests": 92808,
    "scheduler_time": 103.88999707172255
}
#Debug simulation 
Total elapsed time: 6.973653980065137. Arrivals time: 0.3643304603174329 Scheduler time: 6.504390801303089 Scheduler overhead time: 0.03860970865935087 Adapter cache time: 0.00933779077604413 Engine time: 0.039205728098750114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8849616958759725,
    "estimated_duration": 3600.1626084941545,
    "input_throughput": 6391.751013053544,
    "output_throughput": 5631.892835107456,
    "total_throughput": 12023.643848161,
    "itl": 152.3702123388864,
    "ttft": 1892794.92737367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5111014532367693,
    "arrivals": 461464,
    "finished_requests": 92725,
    "scheduler_time": 103.90921724612926
}
#Debug simulation 
Total elapsed time: 6.8850745116360486. Arrivals time: 0.35411689803004265 Scheduler time: 6.4272979083471 Scheduler overhead time: 0.038526026997715235 Adapter cache time: 0.008269152604043484 Engine time: 0.03931387094780803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.1378018790856,
    "estimated_duration": 3600.0369446008403,
    "input_throughput": 6391.712739090047,
    "output_throughput": 5632.013035424022,
    "total_throughput": 12023.725774514069,
    "itl": 152.37201523201114,
    "ttft": 1892779.2183221346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5479612421430654,
    "arrivals": 461464,
    "finished_requests": 92721,
    "scheduler_time": 103.90455898491562
}
#Debug simulation 
Total elapsed time: 7.137978682760149. Arrivals time: 0.5861333408392966 Scheduler time: 6.44833678053692 Scheduler overhead time: 0.03842582926154137 Adapter cache time: 0.008419654797762632 Engine time: 0.03908909764140844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.974490228109062,
    "estimated_duration": 3600.007002620198,
    "input_throughput": 6391.765900247502,
    "output_throughput": 5632.059878006595,
    "total_throughput": 12023.825778254097,
    "itl": 152.370009052912,
    "ttft": 1892770.9720587004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5480628520995399,
    "arrivals": 461464,
    "finished_requests": 92721,
    "scheduler_time": 103.90515591625659
}
#Debug simulation 
Total elapsed time: 6.974613508209586. Arrivals time: 0.4016118822619319 Scheduler time: 6.468431685119867 Scheduler overhead time: 0.03861286723986268 Adapter cache time: 0.009061036631464958 Engine time: 0.03927360521629453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.877628596033901,
    "estimated_duration": 3600.006971277269,
    "input_throughput": 6391.765955896468,
    "output_throughput": 5632.059927041293,
    "total_throughput": 12023.825882937761,
    "itl": 152.37170001792356,
    "ttft": 1892767.4670456469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5238541183550847,
    "arrivals": 461464,
    "finished_requests": 92721,
    "scheduler_time": 103.90434240702076
}
#Debug simulation 
Total elapsed time: 6.87774691497907. Arrivals time: 0.31510596070438623 Scheduler time: 6.459033007267863 Scheduler overhead time: 0.03836019663140178 Adapter cache time: 0.008667130954563618 Engine time: 0.039131378289312124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.957126852124929,
    "estimated_duration": 3600.0602618863077,
    "input_throughput": 6391.773838792117,
    "output_throughput": 5631.9771128987595,
    "total_throughput": 12023.750951690878,
    "itl": 152.37002888455186,
    "ttft": 1892775.8119451203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5554823254980159,
    "arrivals": 461464,
    "finished_requests": 92722,
    "scheduler_time": 103.90677160365752
}
#Debug simulation 
Total elapsed time: 6.9573084488511086. Arrivals time: 0.32996717002242804 Scheduler time: 6.510121386498213 Scheduler overhead time: 0.03864852245897055 Adapter cache time: 0.008462957572191954 Engine time: 0.05235001305118203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.886756175197661,
    "estimated_duration": 3600.113337838035,
    "input_throughput": 6391.6798835612735,
    "output_throughput": 5631.951301893201,
    "total_throughput": 12023.631185454475,
    "itl": 152.3702146912347,
    "ttft": 1892779.8857415551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4963483489537618,
    "arrivals": 461464,
    "finished_requests": 92723,
    "scheduler_time": 103.90799864169887
}
#Debug simulation 
Total elapsed time: 6.886868885252625. Arrivals time: 0.3644601949490607 Scheduler time: 6.419263603631407 Scheduler overhead time: 0.0384096740745008 Adapter cache time: 0.008238059934228659 Engine time: 0.03896660776808858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.908090881071985,
    "estimated_duration": 3600.078821478618,
    "input_throughput": 6391.741164864012,
    "output_throughput": 5632.00529917076,
    "total_throughput": 12023.746464034772,
    "itl": 152.37038013293832,
    "ttft": 1892771.673051203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5629017988964917,
    "arrivals": 461464,
    "finished_requests": 92723,
    "scheduler_time": 103.90718768663938
}
#Debug simulation 
Total elapsed time: 6.9082080870866776. Arrivals time: 0.38766739424318075 Scheduler time: 6.4163170382380486 Scheduler overhead time: 0.0384941017255187 Adapter cache time: 0.00893437396734953 Engine time: 0.039223671425133944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.017552492208779,
    "estimated_duration": 3600.1692915730223,
    "input_throughput": 6390.302826550668,
    "output_throughput": 5628.112002240554,
    "total_throughput": 12018.414828791221,
    "itl": 152.42614291851177,
    "ttft": 1866728.5227163301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.661844844955507,
    "arrivals": 426676,
    "finished_requests": 92713,
    "scheduler_time": 103.75244583383817
}
#Debug simulation 
Total elapsed time: 8.017756314948201. Arrivals time: 0.3183856778778136 Scheduler time: 7.588204392697662 Scheduler overhead time: 0.03933590464293957 Adapter cache time: 0.014009061735123396 Engine time: 0.039809230249375105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.08684016065672,
    "estimated_duration": 3600.101251628542,
    "input_throughput": 6390.490264570425,
    "output_throughput": 5627.0764581513,
    "total_throughput": 12017.566722721725,
    "itl": 152.4217899271325,
    "ttft": 1866815.5628485691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7818725275551064,
    "arrivals": 426676,
    "finished_requests": 92704,
    "scheduler_time": 103.74759916454437
}
#Debug simulation 
Total elapsed time: 8.086945200804621. Arrivals time: 0.33970335638150573 Scheduler time: 7.635375012643635 Scheduler overhead time: 0.039503402542322874 Adapter cache time: 0.01455984078347683 Engine time: 0.03981823055073619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.966853624209762,
    "estimated_duration": 3600.1014896172433,
    "input_throughput": 6390.48984211998,
    "output_throughput": 5627.0760861671715,
    "total_throughput": 12017.565928287151,
    "itl": 152.42178021457542,
    "ttft": 1866815.854704037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.782117189988505,
    "arrivals": 426676,
    "finished_requests": 92704,
    "scheduler_time": 103.74760555723097
}
#Debug simulation 
Total elapsed time: 7.966964786872268. Arrivals time: 0.31172300269827247 Scheduler time: 7.5447458191774786 Scheduler overhead time: 0.03931798320263624 Adapter cache time: 0.013162138406187296 Engine time: 0.040153400506824255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.985554834362119,
    "estimated_duration": 3600.1626180730395,
    "input_throughput": 6390.648823611898,
    "output_throughput": 5627.33997022714,
    "total_throughput": 12017.988793839038,
    "itl": 152.41825844499368,
    "ttft": 1866827.0842834937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6981104872748194,
    "arrivals": 426676,
    "finished_requests": 92708,
    "scheduler_time": 103.7516153486809
}
#Debug simulation 
Total elapsed time: 7.985764638055116. Arrivals time: 0.33428316842764616 Scheduler time: 7.539339208044112 Scheduler overhead time: 0.039153816644102335 Adapter cache time: 0.015031678602099419 Engine time: 0.039971415884792805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.00489153387025,
    "estimated_duration": 3600.125789778153,
    "input_throughput": 6390.4467075351,
    "output_throughput": 5627.038104479217,
    "total_throughput": 12017.484812014316,
    "itl": 152.42257218811332,
    "ttft": 1866839.4891479171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8078967162035442,
    "arrivals": 426676,
    "finished_requests": 92704,
    "scheduler_time": 103.74762066152051
}
#Debug simulation 
Total elapsed time: 8.005006430670619. Arrivals time: 0.3269427684135735 Scheduler time: 7.5670678382739425 Scheduler overhead time: 0.03946955734863877 Adapter cache time: 0.013530764728784561 Engine time: 0.04005032544955611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.022003842983395,
    "estimated_duration": 3600.1431876965225,
    "input_throughput": 6390.785810583559,
    "output_throughput": 5627.707272655257,
    "total_throughput": 12018.493083238816,
    "itl": 152.41545279923253,
    "ttft": 1866787.8659833642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6206072598369585,
    "arrivals": 426676,
    "finished_requests": 92712,
    "scheduler_time": 103.75270664374442
}
#Debug simulation 
Total elapsed time: 8.022141955792904. Arrivals time: 0.32084773341193795 Scheduler time: 7.5906087616458535 Scheduler overhead time: 0.03932676697149873 Adapter cache time: 0.013680798001587391 Engine time: 0.039639058988541365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.064143794123083,
    "estimated_duration": 3600.151540839073,
    "input_throughput": 6390.400998130759,
    "output_throughput": 5626.9978555620855,
    "total_throughput": 12017.398853692845,
    "itl": 152.42353838907678,
    "ttft": 1866850.2544726324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8326702121272638,
    "arrivals": 426676,
    "finished_requests": 92704,
    "scheduler_time": 103.74767834478615
}
#Debug simulation 
Total elapsed time: 8.064339470118284. Arrivals time: 0.35786826256662607 Scheduler time: 7.5937593025155365 Scheduler overhead time: 0.03933232370764017 Adapter cache time: 0.015344299376010895 Engine time: 0.039986039977520704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.314141956157982,
    "estimated_duration": 3600.1455136218506,
    "input_throughput": 6391.562205731711,
    "output_throughput": 5630.688238378034,
    "total_throughput": 12022.250444109744,
    "itl": 152.58473676978707,
    "ttft": 1867378.623917017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.992377521300256,
    "arrivals": 420888,
    "finished_requests": 92677,
    "scheduler_time": 103.74214013037071
}
#Debug simulation 
Total elapsed time: 7.314254591241479. Arrivals time: 0.30893476214259863 Scheduler time: 6.89516962133348 Scheduler overhead time: 0.039010641630738974 Adapter cache time: 0.01403228472918272 Engine time: 0.03936017770320177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.3680185889825225,
    "estimated_duration": 3600.139528411345,
    "input_throughput": 6390.609257900755,
    "output_throughput": 5629.835410558064,
    "total_throughput": 12020.444668458818,
    "itl": 152.5912410315287,
    "ttft": 1867486.1282246835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1097579415887715,
    "arrivals": 420888,
    "finished_requests": 92670,
    "scheduler_time": 103.73878410696142
}
#Debug simulation 
Total elapsed time: 7.368123972788453. Arrivals time: 0.3101073419675231 Scheduler time: 6.946414470206946 Scheduler overhead time: 0.03941229870542884 Adapter cache time: 0.014734715688973665 Engine time: 0.039537491742521524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.643223040737212,
    "estimated_duration": 3600.1395102414035,
    "input_throughput": 6390.609290154226,
    "output_throughput": 5629.835438971902,
    "total_throughput": 12020.444729126128,
    "itl": 152.59121964627786,
    "ttft": 1867486.4617631328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.109730860590943,
    "arrivals": 420888,
    "finished_requests": 92670,
    "scheduler_time": 103.7387930179791
}
#Debug simulation 
Total elapsed time: 7.643403358757496. Arrivals time: 0.35710036335512996 Scheduler time: 7.175450357608497 Scheduler overhead time: 0.03914205823093653 Adapter cache time: 0.014567010570317507 Engine time: 0.03933971421793103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.4441800019703805,
    "estimated_duration": 3600.0147160953793,
    "input_throughput": 6390.830819978917,
    "output_throughput": 5630.030596647986,
    "total_throughput": 12020.861416626904,
    "itl": 152.58690431677493,
    "ttft": 1867447.936468679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.006383326023339,
    "arrivals": 420888,
    "finished_requests": 92670,
    "scheduler_time": 103.7379909048552
}
#Debug simulation 
Total elapsed time: 7.444286820944399. Arrivals time: 0.3465342503041029 Scheduler time: 6.984668668359518 Scheduler overhead time: 0.03924930468201637 Adapter cache time: 0.016378025989979506 Engine time: 0.039653907995671034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.41356733487919,
    "estimated_duration": 3600.0017130630217,
    "input_throughput": 6390.781958941041,
    "output_throughput": 5630.021765393862,
    "total_throughput": 12020.803724334903,
    "itl": 152.59294080785116,
    "ttft": 1867455.4234849834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.141546568553896,
    "arrivals": 420888,
    "finished_requests": 92668,
    "scheduler_time": 103.73388938092003
}
#Debug simulation 
Total elapsed time: 7.413686199113727. Arrivals time: 0.34424912882968783 Scheduler time: 6.956183802336454 Scheduler overhead time: 0.03928493894636631 Adapter cache time: 0.016449540853500366 Engine time: 0.03964970773085952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.320350809954107,
    "estimated_duration": 3600.1245866697473,
    "input_throughput": 6390.782720462161,
    "output_throughput": 5630.425145578292,
    "total_throughput": 12021.207866040453,
    "itl": 152.58683070608322,
    "ttft": 1867382.3789228767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525028425710882,
    "arrivals": 420888,
    "finished_requests": 92675,
    "scheduler_time": 103.7423918637518
}
#Debug simulation 
Total elapsed time: 7.3205303200520575. Arrivals time: 0.34979217406362295 Scheduler time: 6.859899905510247 Scheduler overhead time: 0.03889133129268885 Adapter cache time: 0.014672449324280024 Engine time: 0.039513124153018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.454818754922599,
    "estimated_duration": 3600.0305419671536,
    "input_throughput": 6390.730781808437,
    "output_throughput": 5629.976680399209,
    "total_throughput": 12020.707462207647,
    "itl": 152.59406278554445,
    "ttft": 1867467.732728739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.170092678070067,
    "arrivals": 420888,
    "finished_requests": 92668,
    "scheduler_time": 103.73393616566185
}
#Debug simulation 
Total elapsed time: 7.4549277178011835. Arrivals time: 0.3180351979099214 Scheduler time: 7.0260557807050645 Scheduler overhead time: 0.03901458205655217 Adapter cache time: 0.014617572538554668 Engine time: 0.039534168783575296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.146149612031877,
    "estimated_duration": 3600.1653942408657,
    "input_throughput": 6372.583614269657,
    "output_throughput": 5632.328457030707,
    "total_throughput": 12004.912071300363,
    "itl": 152.80238371791756,
    "ttft": 1864588.055199393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9158653277019344,
    "arrivals": 418034,
    "finished_requests": 92583,
    "scheduler_time": 103.73435114433593
}
#Debug simulation 
Total elapsed time: 7.146293285302818. Arrivals time: 0.3955687512643635 Scheduler time: 6.638028128538281 Scheduler overhead time: 0.039016344118863344 Adapter cache time: 0.01656494941562414 Engine time: 0.039252907037734985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.081601073034108,
    "estimated_duration": 3600.135419235195,
    "input_throughput": 6372.781389671707,
    "output_throughput": 5632.112862106578,
    "total_throughput": 12004.894251778285,
    "itl": 152.8067694515682,
    "ttft": 1864557.625367961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0629940936388564,
    "arrivals": 418034,
    "finished_requests": 92583,
    "scheduler_time": 103.72937469290673
}
#Debug simulation 
Total elapsed time: 7.081796527840197. Arrivals time: 0.32457687007263303 Scheduler time: 6.645306367427111 Scheduler overhead time: 0.039077043533325195 Adapter cache time: 0.015765906311571598 Engine time: 0.039286404848098755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.023225319106132,
    "estimated_duration": 3600.137642514242,
    "input_throughput": 6372.777454135697,
    "output_throughput": 5632.109383973307,
    "total_throughput": 12004.886838109003,
    "itl": 152.80683339579852,
    "ttft": 1864558.4106521253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0630746267736058,
    "arrivals": 418034,
    "finished_requests": 92583,
    "scheduler_time": 103.72944601950502
}
#Debug simulation 
Total elapsed time: 7.023335731122643. Arrivals time: 0.32008371222764254 Scheduler time: 6.592858647461981 Scheduler overhead time: 0.03873493755236268 Adapter cache time: 0.014674299862235785 Engine time: 0.03939836844801903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.077877329196781,
    "estimated_duration": 3600.04488497738,
    "input_throughput": 6372.710266956616,
    "output_throughput": 5632.404497125431,
    "total_throughput": 12005.114764082047,
    "itl": 152.80410151483304,
    "ttft": 1864534.0290804957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9665655984869126,
    "arrivals": 418034,
    "finished_requests": 92581,
    "scheduler_time": 103.72941146627595
}
#Debug simulation 
Total elapsed time: 7.0780245661735535. Arrivals time: 0.39588374318555 Scheduler time: 6.569731073919684 Scheduler overhead time: 0.03891355451196432 Adapter cache time: 0.016330840066075325 Engine time: 0.03933223383501172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.119888145942241,
    "estimated_duration": 3600.129075106833,
    "input_throughput": 6372.3631907056615,
    "output_throughput": 5631.705579722401,
    "total_throughput": 12004.068770428063,
    "itl": 152.80716812688198,
    "ttft": 1864683.8382862383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1029348332621183,
    "arrivals": 418034,
    "finished_requests": 92578,
    "scheduler_time": 103.72808092192018
}
#Debug simulation 
Total elapsed time: 7.120111593045294. Arrivals time: 0.31411920906975865 Scheduler time: 6.69492512056604 Scheduler overhead time: 0.03890546644106507 Adapter cache time: 0.01447995426133275 Engine time: 0.039820059202611446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.075222247745842,
    "estimated_duration": 3600.1171002869714,
    "input_throughput": 6372.669099616573,
    "output_throughput": 5632.404012187176,
    "total_throughput": 12005.07311180375,
    "itl": 152.8005966642044,
    "ttft": 1864568.3751969102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8717714846087323,
    "arrivals": 418034,
    "finished_requests": 92583,
    "scheduler_time": 103.73416020888234
}
#Debug simulation 
Total elapsed time: 7.075339368078858. Arrivals time: 0.31983476411551237 Scheduler time: 6.645414663944393 Scheduler overhead time: 0.03885866096243262 Adapter cache time: 0.014421407133340836 Engine time: 0.03919688193127513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.152191529981792,
    "estimated_duration": 3600.0035560361275,
    "input_throughput": 6372.304816626071,
    "output_throughput": 5631.736937038886,
    "total_throughput": 12004.041753664958,
    "itl": 152.80811705574249,
    "ttft": 1864620.5163741496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149516558572649,
    "arrivals": 418034,
    "finished_requests": 92575,
    "scheduler_time": 103.72310140399625
}
#Debug simulation 
Total elapsed time: 7.15234507760033. Arrivals time: 0.3922669258899987 Scheduler time: 6.647127882577479 Scheduler overhead time: 0.039201758336275816 Adapter cache time: 0.016289501450955868 Engine time: 0.039555300027132034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.918432121630758,
    "estimated_duration": 3600.0501299780803,
    "input_throughput": 6365.261086000356,
    "output_throughput": 5635.260695695791,
    "total_throughput": 12000.521781696147,
    "itl": 152.9028698820221,
    "ttft": 1863387.8038461956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7812038669688885,
    "arrivals": 416602,
    "finished_requests": 92557,
    "scheduler_time": 103.73016977082833
}
#Debug simulation 
Total elapsed time: 6.918616591021419. Arrivals time: 0.32270344253629446 Scheduler time: 6.486019020434469 Scheduler overhead time: 0.0384608437307179 Adapter cache time: 0.014541423879563808 Engine time: 0.03921391814947128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.903172109276056,
    "estimated_duration": 3600.070426457469,
    "input_throughput": 6365.048258944307,
    "output_throughput": 5635.03226240001,
    "total_throughput": 12000.080521344316,
    "itl": 152.9080288819698,
    "ttft": 1863409.568779185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9052817802829747,
    "arrivals": 416602,
    "finished_requests": 92554,
    "scheduler_time": 103.72747108736809
}
#Debug simulation 
Total elapsed time: 6.903315358329564. Arrivals time: 0.31963611859828234 Scheduler time: 6.474123830907047 Scheduler overhead time: 0.038536741863936186 Adapter cache time: 0.014296439476311207 Engine time: 0.03921126388013363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.974412338342518,
    "estimated_duration": 3600.0688193551596,
    "input_throughput": 6365.0511003576985,
    "output_throughput": 5635.034777927856,
    "total_throughput": 12000.085878285554,
    "itl": 152.90784217910172,
    "ttft": 1863407.7713475944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.907575957775128,
    "arrivals": 416602,
    "finished_requests": 92554,
    "scheduler_time": 103.72736114921057
}
#Debug simulation 
Total elapsed time: 6.974532959982753. Arrivals time: 0.33666293090209365 Scheduler time: 6.526444955263287 Scheduler overhead time: 0.03851572098210454 Adapter cache time: 0.015732537489384413 Engine time: 0.03954162774607539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.872140497900546,
    "estimated_duration": 3600.089117518778,
    "input_throughput": 6365.192152741334,
    "output_throughput": 5635.199668052157,
    "total_throughput": 12000.391820793491,
    "itl": 152.9039767919118,
    "ttft": 1863401.755266294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.819476763410484,
    "arrivals": 416602,
    "finished_requests": 92557,
    "scheduler_time": 103.73025622308306
}
#Debug simulation 
Total elapsed time: 6.872353148646653. Arrivals time: 0.31751046841964126 Scheduler time: 6.44500965392217 Scheduler overhead time: 0.038601445499807596 Adapter cache time: 0.014423166401684284 Engine time: 0.03916524909436703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.976003097835928,
    "estimated_duration": 3600.095835350708,
    "input_throughput": 6365.003335464747,
    "output_throughput": 5634.9924912551005,
    "total_throughput": 11999.995826719847,
    "itl": 152.90879228952417,
    "ttft": 1863419.2633853143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9339842529222397,
    "arrivals": 416602,
    "finished_requests": 92554,
    "scheduler_time": 103.72740788552295
}
#Debug simulation 
Total elapsed time: 6.976132196839899. Arrivals time: 0.32253062445670366 Scheduler time: 6.5442416672594845 Scheduler overhead time: 0.03886594343930483 Adapter cache time: 0.01368319895118475 Engine time: 0.03922574734315276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.294665118213743,
    "estimated_duration": 3600.161634189524,
    "input_throughput": 6365.064496655226,
    "output_throughput": 5635.144213342284,
    "total_throughput": 12000.20870999751,
    "itl": 152.9003372332268,
    "ttft": 1863459.5236161414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7402092716330413,
    "arrivals": 416602,
    "finished_requests": 92559,
    "scheduler_time": 103.73451468998611
}
#Debug simulation 
Total elapsed time: 7.294749235268682. Arrivals time: 0.3310934789478779 Scheduler time: 6.852651262655854 Scheduler overhead time: 0.03863636776804924 Adapter cache time: 0.015513969119638205 Engine time: 0.03923909133300185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.915159542113543,
    "estimated_duration": 3600.143558863337,
    "input_throughput": 6364.944237733341,
    "output_throughput": 5635.058621497072,
    "total_throughput": 12000.002859230413,
    "itl": 152.9097831054567,
    "ttft": 1863422.6097499386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9583804874867143,
    "arrivals": 416602,
    "finished_requests": 92555,
    "scheduler_time": 103.72811641919107
}
#Debug simulation 
Total elapsed time: 6.915372124873102. Arrivals time: 0.3314193431288004 Scheduler time: 6.472509780433029 Scheduler overhead time: 0.03850151505321264 Adapter cache time: 0.015724997501820326 Engine time: 0.03952287184074521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.893111469224095,
    "estimated_duration": 3600.1663197029384,
    "input_throughput": 6356.331615781635,
    "output_throughput": 5643.548157429705,
    "total_throughput": 11999.87977321134,
    "itl": 152.80552198432477,
    "ttft": 1858297.0494295317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.377219484769751,
    "arrivals": 415862,
    "finished_requests": 92728,
    "scheduler_time": 103.8789687296141
}
#Debug simulation 
Total elapsed time: 6.893231408204883. Arrivals time: 0.3682822030968964 Scheduler time: 6.417454752139747 Scheduler overhead time: 0.03813283331692219 Adapter cache time: 0.01285274513065815 Engine time: 0.03906656615436077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.844808432273567,
    "estimated_duration": 3600.0295287700023,
    "input_throughput": 6356.298418423871,
    "output_throughput": 5643.211211920569,
    "total_throughput": 11999.50963034444,
    "itl": 152.80911164675888,
    "ttft": 1858323.343374622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4717785861040542,
    "arrivals": 415862,
    "finished_requests": 92722,
    "scheduler_time": 103.8726842620679
}
#Debug simulation 
Total elapsed time: 6.844926088117063. Arrivals time: 0.37706127343699336 Scheduler time: 6.357819348573685 Scheduler overhead time: 0.037992559373378754 Adapter cache time: 0.01311024185270071 Engine time: 0.04152608383446932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8436032817699015,
    "estimated_duration": 3600.031373799155,
    "input_throughput": 6356.295160797848,
    "output_throughput": 5643.20831975433,
    "total_throughput": 11999.503480552177,
    "itl": 152.80915060156622,
    "ttft": 1858324.5470653756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.473792957756677,
    "arrivals": 415862,
    "finished_requests": 92722,
    "scheduler_time": 103.87268927356588
}
#Debug simulation 
Total elapsed time: 6.843782608862966. Arrivals time: 0.33031998947262764 Scheduler time: 6.404721116647124 Scheduler overhead time: 0.03802108112722635 Adapter cache time: 0.014304059091955423 Engine time: 0.03887029318138957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.83922112500295,
    "estimated_duration": 3600.0821687845155,
    "input_throughput": 6356.295753028876,
    "output_throughput": 5643.390913730021,
    "total_throughput": 11999.686666758897,
    "itl": 152.8070158804489,
    "ttft": 1858301.082340288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4038218801771256,
    "arrivals": 415862,
    "finished_requests": 92726,
    "scheduler_time": 103.87592066143124
}
#Debug simulation 
Total elapsed time: 6.839347716420889. Arrivals time: 0.36123717203736305 Scheduler time: 6.371445722877979 Scheduler overhead time: 0.03793998435139656 Adapter cache time: 0.012660846579819918 Engine time: 0.03861892316490412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.834828426130116,
    "estimated_duration": 3600.05150141654,
    "input_throughput": 6356.259623229308,
    "output_throughput": 5643.1767690007255,
    "total_throughput": 11999.436392230033,
    "itl": 152.8098967734783,
    "ttft": 1858332.821862726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.49366205601022,
    "arrivals": 415862,
    "finished_requests": 92722,
    "scheduler_time": 103.87272811587889
}
#Debug simulation 
Total elapsed time: 6.834947824943811. Arrivals time: 0.38514366280287504 Scheduler time: 6.341460441239178 Scheduler overhead time: 0.03808915987610817 Adapter cache time: 0.014129768125712872 Engine time: 0.03871446615085006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8135919170454144,
    "estimated_duration": 3600.139875720138,
    "input_throughput": 6356.37830472421,
    "output_throughput": 5643.589610788618,
    "total_throughput": 11999.967915512829,
    "itl": 152.80453664295325,
    "ttft": 1858285.325994311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3455226327059682,
    "arrivals": 415862,
    "finished_requests": 92728,
    "scheduler_time": 103.87899831952673
}
#Debug simulation 
Total elapsed time: 6.8137794067151845. Arrivals time: 0.33805833803489804 Scheduler time: 6.369160016067326 Scheduler overhead time: 0.03810310270637274 Adapter cache time: 0.012286070734262466 Engine time: 0.0386612843722105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.785354340448976,
    "estimated_duration": 3600.0938688411215,
    "input_throughput": 6356.20065300299,
    "output_throughput": 5643.1156353541655,
    "total_throughput": 11999.316288357157,
    "itl": 152.8112301604108,
    "ttft": 1858352.061865488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5091443576291195,
    "arrivals": 415862,
    "finished_requests": 92723,
    "scheduler_time": 103.87334117042654
}
#Debug simulation 
Total elapsed time: 6.785467658191919. Arrivals time: 0.3522162577137351 Scheduler time: 6.326067585032433 Scheduler overhead time: 0.038095771335065365 Adapter cache time: 0.013146508485078812 Engine time: 0.03853592975065112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.809615056961775,
    "estimated_duration": 3600.128805436624,
    "input_throughput": 6390.09803350909,
    "output_throughput": 5654.817119114428,
    "total_throughput": 12044.915152623518,
    "itl": 152.29529100536337,
    "ttft": 1855354.011751888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8293921786057752,
    "arrivals": 415494,
    "finished_requests": 93245,
    "scheduler_time": 104.08894654018424
}
#Debug simulation 
Total elapsed time: 6.809756697155535. Arrivals time: 0.3053908171132207 Scheduler time: 6.398537388071418 Scheduler overhead time: 0.03798662777990103 Adapter cache time: 0.011750924400985241 Engine time: 0.03865475347265601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.1301592737436295,
    "estimated_duration": 3600.0788830283714,
    "input_throughput": 6390.026926479073,
    "output_throughput": 5654.670817344857,
    "total_throughput": 12044.69774382393,
    "itl": 152.29691261974787,
    "ttft": 1855379.9906997473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8838507872377568,
    "arrivals": 415494,
    "finished_requests": 93242,
    "scheduler_time": 104.08607057077688
}
#Debug simulation 
Total elapsed time: 7.13036118587479. Arrivals time: 0.40520162088796496 Scheduler time: 6.617906543891877 Scheduler overhead time: 0.03783144196495414 Adapter cache time: 0.013311424758285284 Engine time: 0.038669927045702934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.825006358325481,
    "estimated_duration": 3600.0805384374657,
    "input_throughput": 6390.023988181284,
    "output_throughput": 5654.668217182611,
    "total_throughput": 12044.692205363895,
    "itl": 152.2969587942015,
    "ttft": 1855381.007219486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8854981570318385,
    "arrivals": 415494,
    "finished_requests": 93242,
    "scheduler_time": 104.08607861006458
}
#Debug simulation 
Total elapsed time: 6.82511684531346. Arrivals time: 0.34202990494668484 Scheduler time: 6.377402545884252 Scheduler overhead time: 0.03793479362502694 Adapter cache time: 0.011404354590922594 Engine time: 0.03887003334239125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.863436590880156,
    "estimated_duration": 3600.085656876902,
    "input_throughput": 6389.984070533629,
    "output_throughput": 5654.558513382634,
    "total_throughput": 12044.542583916264,
    "itl": 152.29807007873868,
    "ttft": 1855363.9939659666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8546916904416895,
    "arrivals": 415494,
    "finished_requests": 93241,
    "scheduler_time": 104.08505375331461
}
#Debug simulation 
Total elapsed time: 6.863561688922346. Arrivals time: 0.31448051845654845 Scheduler time: 6.443331617861986 Scheduler overhead time: 0.03784499270841479 Adapter cache time: 0.01187759405001998 Engine time: 0.0386605691164732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.884698370937258,
    "estimated_duration": 3600.097381384736,
    "input_throughput": 6389.994092646334,
    "output_throughput": 5654.641761987509,
    "total_throughput": 12044.635854633843,
    "itl": 152.2974695305738,
    "ttft": 1855385.3601631157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8964387364499314,
    "arrivals": 415494,
    "finished_requests": 93242,
    "scheduler_time": 104.08620068003923
}
#Debug simulation 
Total elapsed time: 6.884884338825941. Arrivals time: 0.32702838396653533 Scheduler time: 6.450693846680224 Scheduler overhead time: 0.037872124928981066 Adapter cache time: 0.013047464191913605 Engine time: 0.03876927401870489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.846975099761039,
    "estimated_duration": 3600.106461762921,
    "input_throughput": 6390.137692965528,
    "output_throughput": 5654.852215128923,
    "total_throughput": 12044.98990809445,
    "itl": 152.2947964239506,
    "ttft": 1855342.7403050028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8103036299184907,
    "arrivals": 415494,
    "finished_requests": 93245,
    "scheduler_time": 104.08881576549393
}
#Debug simulation 
Total elapsed time: 6.847094133961946. Arrivals time: 0.37737377639859915 Scheduler time: 6.361832197289914 Scheduler overhead time: 0.03801419772207737 Adapter cache time: 0.013037034776061773 Engine time: 0.03933736216276884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.794007431715727,
    "estimated_duration": 3600.1220699200308,
    "input_throughput": 6389.95054979094,
    "output_throughput": 5654.663537687265,
    "total_throughput": 12044.614087478205,
    "itl": 152.2981280354323,
    "ttft": 1855385.8422087617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9081338385865138,
    "arrivals": 415494,
    "finished_requests": 93243,
    "scheduler_time": 104.08661792342902
}
#Debug simulation 
Total elapsed time: 6.794139958918095. Arrivals time: 0.3401276315562427 Scheduler time: 6.348155282437801 Scheduler overhead time: 0.037720334716141224 Adapter cache time: 0.01195389311760664 Engine time: 0.03881144896149635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.852875558193773,
    "estimated_duration": 3600.0805981415338,
    "input_throughput": 6368.89991069544,
    "output_throughput": 5678.638697854031,
    "total_throughput": 12047.53860854947,
    "itl": 152.50621001398179,
    "ttft": 1828300.7537964329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.78432183603307,
    "arrivals": 386239,
    "finished_requests": 92893,
    "scheduler_time": 104.33650480289582
}
#Debug simulation 
Total elapsed time: 6.853054853156209. Arrivals time: 0.32010987726971507 Scheduler time: 6.411576443351805 Scheduler overhead time: 0.03816231992095709 Adapter cache time: 0.026626721490174532 Engine time: 0.03904280764982104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.869430811144412,
    "estimated_duration": 3600.1640643976675,
    "input_throughput": 6368.466711484699,
    "output_throughput": 5678.285109881573,
    "total_throughput": 12046.751821366272,
    "itl": 152.5235133369473,
    "ttft": 1828356.4870204038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.178561730405587,
    "arrivals": 386239,
    "finished_requests": 92888,
    "scheduler_time": 104.32749037288842
}
#Debug simulation 
Total elapsed time: 6.869573242031038. Arrivals time: 0.3162839859724045 Scheduler time: 6.430196062196046 Scheduler overhead time: 0.03851669980213046 Adapter cache time: 0.02781831007450819 Engine time: 0.039026190992444754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.815124252345413,
    "estimated_duration": 3600.0065491516575,
    "input_throughput": 6368.051192963048,
    "output_throughput": 5677.954670614933,
    "total_throughput": 12046.00586357798,
    "itl": 152.52343599641796,
    "ttft": 1828362.9229785777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.186954353228174,
    "arrivals": 386239,
    "finished_requests": 92880,
    "scheduler_time": 104.32260553974608
}
#Debug simulation 
Total elapsed time: 6.815257729031146. Arrivals time: 0.31751451827585697 Scheduler time: 6.375478776637465 Scheduler overhead time: 0.0383613589219749 Adapter cache time: 0.02736424934118986 Engine time: 0.03892624983564019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.88858522567898,
    "estimated_duration": 3600.0401757279114,
    "input_throughput": 6368.783369303396,
    "output_throughput": 5678.680237468857,
    "total_throughput": 12047.463606772253,
    "itl": 152.51258323800408,
    "ttft": 1828302.8930032142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.911470275211446,
    "arrivals": 386239,
    "finished_requests": 92890,
    "scheduler_time": 104.33172830641969
}
#Debug simulation 
Total elapsed time: 6.88876824779436. Arrivals time: 0.3204934918321669 Scheduler time: 6.445159981492907 Scheduler overhead time: 0.03852241253480315 Adapter cache time: 0.027984893415123224 Engine time: 0.038951951544731855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.871016448829323,
    "estimated_duration": 3600.090775617661,
    "input_throughput": 6367.902208262178,
    "output_throughput": 5677.821831171196,
    "total_throughput": 12045.724039433373,
    "itl": 152.52690936813866,
    "ttft": 1828395.616703011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.269951852261917,
    "arrivals": 386239,
    "finished_requests": 92880,
    "scheduler_time": 104.32271325632415
}
#Debug simulation 
Total elapsed time: 6.8711647861637175. Arrivals time: 0.3242357773706317 Scheduler time: 6.423637160100043 Scheduler overhead time: 0.03847226360812783 Adapter cache time: 0.028010223526507616 Engine time: 0.03918452514335513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.847645685076714,
    "estimated_duration": 3600.1267327852925,
    "input_throughput": 6369.519103639728,
    "output_throughput": 5679.10757524417,
    "total_throughput": 12048.626678883898,
    "itl": 152.50182418606715,
    "ttft": 1828250.857472382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.65418510765985,
    "arrivals": 386239,
    "finished_requests": 92901,
    "scheduler_time": 104.34144458730945
}
#Debug simulation 
Total elapsed time: 6.847751932218671. Arrivals time: 0.31796181481331587 Scheduler time: 6.408348579891026 Scheduler overhead time: 0.038102797232568264 Adapter cache time: 0.027093858923763037 Engine time: 0.03874263120815158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.856857292819768,
    "estimated_duration": 3600.168939797523,
    "input_throughput": 6367.76395312419,
    "output_throughput": 5677.69855854309,
    "total_throughput": 12045.46251166728,
    "itl": 152.5301023539527,
    "ttft": 1828426.5206333147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.350182767994536,
    "arrivals": 386239,
    "finished_requests": 92880,
    "scheduler_time": 104.32274237998843
}
#Debug simulation 
Total elapsed time: 6.857055515982211. Arrivals time: 0.30883240373805165 Scheduler time: 6.425953540019691 Scheduler overhead time: 0.03824381483718753 Adapter cache time: 0.027297974098473787 Engine time: 0.03902912978082895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.96359394909814,
    "estimated_duration": 3600.0086628713043,
    "input_throughput": 6648.663723189395,
    "output_throughput": 5858.634235390445,
    "total_throughput": 12507.297958579838,
    "itl": 146.61234112234976,
    "ttft": 1801671.1014538468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.116356015589661,
    "arrivals": 383390,
    "finished_requests": 96566,
    "scheduler_time": 107.76228986334746
}
#Debug simulation 
Total elapsed time: 6.96370013570413. Arrivals time: 0.3131861346773803 Scheduler time: 6.530203706584871 Scheduler overhead time: 0.03871396742761135 Adapter cache time: 0.023867500014603138 Engine time: 0.039803186897188425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.096994326915592,
    "estimated_duration": 3600.153112325925,
    "input_throughput": 6648.328349717462,
    "output_throughput": 5858.351948363083,
    "total_throughput": 12506.680298080544,
    "itl": 146.6228032942714,
    "ttft": 1801708.6288332907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.385935841505386,
    "arrivals": 383390,
    "finished_requests": 96564,
    "scheduler_time": 107.75872684585497
}
#Debug simulation 
Total elapsed time: 7.097119324840605. Arrivals time: 0.3552817068994045 Scheduler time: 6.619613386224955 Scheduler overhead time: 0.039232686161994934 Adapter cache time: 0.02480359235778451 Engine time: 0.0400987695902586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.021220539230853,
    "estimated_duration": 3600.1625422385173,
    "input_throughput": 6648.310935738374,
    "output_throughput": 5858.336603570686,
    "total_throughput": 12506.647539309059,
    "itl": 146.62315912247004,
    "ttft": 1801712.282916764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.395385941993383,
    "arrivals": 383390,
    "finished_requests": 96564,
    "scheduler_time": 107.75873442411348
}
#Debug simulation 
Total elapsed time: 7.021400628145784. Arrivals time: 0.3257582071237266 Scheduler time: 6.574317102320492 Scheduler overhead time: 0.03901173919439316 Adapter cache time: 0.02418899303302169 Engine time: 0.03996725752949715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.046365975867957,
    "estimated_duration": 3600.0899978819743,
    "input_throughput": 6648.5135132959795,
    "output_throughput": 5858.501874233271,
    "total_throughput": 12507.01538752925,
    "itl": 146.6153638843431,
    "ttft": 1801703.4700978328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1952706569805125,
    "arrivals": 383390,
    "finished_requests": 96566,
    "scheduler_time": 107.76235814506553
}
#Debug simulation 
Total elapsed time: 7.04648002423346. Arrivals time: 0.329336647875607 Scheduler time: 6.5940429624170065 Scheduler overhead time: 0.03922766866162419 Adapter cache time: 0.02546801883727312 Engine time: 0.040248164907097816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.033234968781471,
    "estimated_duration": 3600.054045745406,
    "input_throughput": 6647.887697209453,
    "output_throughput": 5858.040110515447,
    "total_throughput": 12505.9278077249,
    "itl": 146.6241707620533,
    "ttft": 1801693.7944302862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.452226653452937,
    "arrivals": 383390,
    "finished_requests": 96558,
    "scheduler_time": 107.75381040514608
}
#Debug simulation 
Total elapsed time: 7.033356013707817. Arrivals time: 0.3208453129045665 Scheduler time: 6.590514985844493 Scheduler overhead time: 0.03931528236716986 Adapter cache time: 0.024467971175909042 Engine time: 0.040006766095757484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.061645503155887,
    "estimated_duration": 3600.0115538853493,
    "input_throughput": 6648.7714391269665,
    "output_throughput": 5859.051751441058,
    "total_throughput": 12507.823190568024,
    "itl": 146.60819230892938,
    "ttft": 1801644.3925190785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.018627596348418,
    "arrivals": 383390,
    "finished_requests": 96569,
    "scheduler_time": 107.76576616412939
}
#Debug simulation 
Total elapsed time: 7.061812797095627. Arrivals time: 0.31040731770917773 Scheduler time: 6.6296449662186205 Scheduler overhead time: 0.039107540156692266 Adapter cache time: 0.024508824571967125 Engine time: 0.04001445323228836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.029982445761561,
    "estimated_duration": 3600.10326485017,
    "input_throughput": 6647.796810071791,
    "output_throughput": 5857.960021843345,
    "total_throughput": 12505.756831915136,
    "itl": 146.6266660661304,
    "ttft": 1801726.2410479025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5021654925495485,
    "arrivals": 383390,
    "finished_requests": 96558,
    "scheduler_time": 107.75420853267626
}
#Debug simulation 
Total elapsed time: 7.030101807788014. Arrivals time: 0.3305472698993981 Scheduler time: 6.576816926244646 Scheduler overhead time: 0.03918524319306016 Adapter cache time: 0.025308131705969572 Engine time: 0.040097061078995466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.321901062037796,
    "estimated_duration": 3600.0218083863683,
    "input_throughput": 6757.415453242485,
    "output_throughput": 5942.332335366806,
    "total_throughput": 12699.747788609291,
    "itl": 144.60681616909255,
    "ttft": 1789878.3170244473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6350799475261564,
    "arrivals": 381970,
    "finished_requests": 97942,
    "scheduler_time": 109.20725479120705
}
#Debug simulation 
Total elapsed time: 7.321982268709689. Arrivals time: 0.5780283086933196 Scheduler time: 6.624868504237384 Scheduler overhead time: 0.03932726522907615 Adapter cache time: 0.021351661533117294 Engine time: 0.040321115870028734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.076852680183947,
    "estimated_duration": 3600.0294226910187,
    "input_throughput": 6757.3939386905695,
    "output_throughput": 5942.290044954462,
    "total_throughput": 12699.683983645033,
    "itl": 144.611595214549,
    "ttft": 1789898.402410077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.796449391010687,
    "arrivals": 381970,
    "finished_requests": 97940,
    "scheduler_time": 109.20358300997005
}
#Debug simulation 
Total elapsed time: 7.077012470923364. Arrivals time: 0.31282352888956666 Scheduler time: 6.643638654612005 Scheduler overhead time: 0.03953249333426356 Adapter cache time: 0.02163571259006858 Engine time: 0.041004575323313475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.212892324198037,
    "estimated_duration": 3600.040359428568,
    "input_throughput": 6757.373410075153,
    "output_throughput": 5942.271992582773,
    "total_throughput": 12699.645402657925,
    "itl": 144.6119093963596,
    "ttft": 1789901.126500436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.802566793039424,
    "arrivals": 381970,
    "finished_requests": 97940,
    "scheduler_time": 109.2036033000083
}
#Debug simulation 
Total elapsed time: 7.213026002980769. Arrivals time: 0.342008164152503 Scheduler time: 6.748784728348255 Scheduler overhead time: 0.039911441039294004 Adapter cache time: 0.02286261785775423 Engine time: 0.040900209452956915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.4303339957259595,
    "estimated_duration": 3600.0637630044203,
    "input_throughput": 6757.3367033083105,
    "output_throughput": 5942.263084292414,
    "total_throughput": 12699.599787600724,
    "itl": 144.60722535000548,
    "ttft": 1789889.9105583453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.688710110008227,
    "arrivals": 381970,
    "finished_requests": 97942,
    "scheduler_time": 109.20808902966563
}
#Debug simulation 
Total elapsed time: 7.430425430648029. Arrivals time: 0.32582362927496433 Scheduler time: 6.982136810198426 Scheduler overhead time: 0.04018344357609749 Adapter cache time: 0.022690463345497847 Engine time: 0.041061969473958015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.0785503489896655,
    "estimated_duration": 3600.0779791634636,
    "input_throughput": 6757.30279755016,
    "output_throughput": 5942.209897623072,
    "total_throughput": 12699.512695173233,
    "itl": 144.61334051265354,
    "ttft": 1789918.435221277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8366460691578688,
    "arrivals": 381970,
    "finished_requests": 97940,
    "scheduler_time": 109.20364753745712
}
#Debug simulation 
Total elapsed time: 7.078735530842096. Arrivals time: 0.307691712398082 Scheduler time: 6.650760642718524 Scheduler overhead time: 0.03965696459636092 Adapter cache time: 0.021625112276524305 Engine time: 0.04064546152949333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.144364658277482,
    "estimated_duration": 3600.0956062340774,
    "input_throughput": 6757.379153451918,
    "output_throughput": 5942.349687312451,
    "total_throughput": 12699.72884076437,
    "itl": 144.6036002438567,
    "ttft": 1789870.4012491042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5714432536158167,
    "arrivals": 381970,
    "finished_requests": 97946,
    "scheduler_time": 109.21139864295375
}
#Debug simulation 
Total elapsed time: 7.144512294325978. Arrivals time: 0.3409996894188225 Scheduler time: 6.682131824549288 Scheduler overhead time: 0.03931695781648159 Adapter cache time: 0.022936327382922173 Engine time: 0.04080562340095639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.427035206928849,
    "estimated_duration": 3600.113299330025,
    "input_throughput": 6757.236502675397,
    "output_throughput": 5942.151599501353,
    "total_throughput": 12699.38810217675,
    "itl": 144.61461430578754,
    "ttft": 1789933.3602986897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8696938870102406,
    "arrivals": 381970,
    "finished_requests": 97940,
    "scheduler_time": 109.20376598780322
}
#Debug simulation 
Total elapsed time: 7.427126315888017. Arrivals time: 0.33199034351855516 Scheduler time: 6.973500468768179 Scheduler overhead time: 0.03976907720789313 Adapter cache time: 0.022743660490959883 Engine time: 0.0408296980895102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.408676839899272,
    "estimated_duration": 3600.0604373906704,
    "input_throughput": 6767.230001743508,
    "output_throughput": 5976.764938867345,
    "total_throughput": 12743.994940610854,
    "itl": 144.0603332485703,
    "ttft": 1791252.1100066723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.83629264635968,
    "arrivals": 381260,
    "finished_requests": 98230,
    "scheduler_time": 109.86340513377824
}
#Debug simulation 
Total elapsed time: 7.408854769077152. Arrivals time: 0.5990351322107017 Scheduler time: 6.690819699317217 Scheduler overhead time: 0.03967518359422684 Adapter cache time: 0.020245607942342758 Engine time: 0.04076787317171693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.47693172423169,
    "estimated_duration": 3600.029208432437,
    "input_throughput": 6767.288427253664,
    "output_throughput": 5976.73984133282,
    "total_throughput": 12744.028268586484,
    "itl": 144.06386772925822,
    "ttft": 1791247.6126994777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9492963979486426,
    "arrivals": 381260,
    "finished_requests": 98229,
    "scheduler_time": 109.85960735977994
}
#Debug simulation 
Total elapsed time: 7.477022372186184. Arrivals time: 0.6002348545007408 Scheduler time: 6.757846195716411 Scheduler overhead time: 0.0397271285764873 Adapter cache time: 0.02003225777298212 Engine time: 0.04089562362059951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.4590923096984625,
    "estimated_duration": 3600.0373559557074,
    "input_throughput": 6767.273111679272,
    "output_throughput": 5976.72631491014,
    "total_throughput": 12743.999426589413,
    "itl": 144.0640118534681,
    "ttft": 1791250.1580088586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.954265357181442,
    "arrivals": 381260,
    "finished_requests": 98229,
    "scheduler_time": 109.8596221540257
}
#Debug simulation 
Total elapsed time: 7.459177698940039. Arrivals time: 0.3271859143860638 Scheduler time: 7.012740426231176 Scheduler overhead time: 0.0398709368892014 Adapter cache time: 0.02033934323117137 Engine time: 0.040796220768243074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.451882816851139,
    "estimated_duration": 3600.111369153067,
    "input_throughput": 6767.13426388565,
    "output_throughput": 5976.680383935414,
    "total_throughput": 12743.814647821064,
    "itl": 144.0613557848139,
    "ttft": 1791267.004545872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8773836219031257,
    "arrivals": 381260,
    "finished_requests": 98230,
    "scheduler_time": 109.8643005115597
}
#Debug simulation 
Total elapsed time: 7.452026997227222. Arrivals time: 0.6030031908303499 Scheduler time: 6.730174157302827 Scheduler overhead time: 0.039804031141102314 Adapter cache time: 0.019812630023807287 Engine time: 0.04088137950748205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.445089415181428,
    "estimated_duration": 3600.0664965111123,
    "input_throughput": 6767.218334330787,
    "output_throughput": 5976.6779366025485,
    "total_throughput": 12743.896270933335,
    "itl": 144.06509094269552,
    "ttft": 1791277.0796108842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9763980235904497,
    "arrivals": 381260,
    "finished_requests": 98229,
    "scheduler_time": 109.8597105705208
}
#Debug simulation 
Total elapsed time: 7.445205147378147. Arrivals time: 0.33242170326411724 Scheduler time: 6.994122196454555 Scheduler overhead time: 0.03977190051227808 Adapter cache time: 0.02000999916344881 Engine time: 0.04065266344696283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.499482870101929,
    "estimated_duration": 3600.1462472152575,
    "input_throughput": 6767.2186980862125,
    "output_throughput": 5976.783586678958,
    "total_throughput": 12744.00228476517,
    "itl": 144.057265984887,
    "ttft": 1791261.5859215434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7850600260565723,
    "arrivals": 381260,
    "finished_requests": 98234,
    "scheduler_time": 109.86741607803954
}
#Debug simulation 
Total elapsed time: 7.499569167383015. Arrivals time: 0.3382117310538888 Scheduler time: 7.040886849630624 Scheduler overhead time: 0.03989920672029257 Adapter cache time: 0.021396698895841837 Engine time: 0.04085170803591609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.47659481363371,
    "estimated_duration": 3600.092297721702,
    "input_throughput": 6767.169834900519,
    "output_throughput": 5976.635102832379,
    "total_throughput": 12743.804937732899,
    "itl": 144.06602688659925,
    "ttft": 1791288.0247464064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0020517960190722,
    "arrivals": 381260,
    "finished_requests": 98229,
    "scheduler_time": 109.85974735363297
}
#Debug simulation 
Total elapsed time: 7.476721735671163. Arrivals time: 0.32539165019989014 Scheduler time: 7.031084796413779 Scheduler overhead time: 0.03993778582662344 Adapter cache time: 0.020497548393905163 Engine time: 0.04127680230885744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.2801614459604025,
    "estimated_duration": 3600.0811365000623,
    "input_throughput": 6865.051942697951,
    "output_throughput": 6046.9006599011755,
    "total_throughput": 12911.952602599127,
    "itl": 142.11851359009881,
    "ttft": 1784914.7356360296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2762233892199666,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17910776146994
}
#Debug simulation 
Total elapsed time: 7.280298902187496. Arrivals time: 0.31870862608775496 Scheduler time: 6.842188339680433 Scheduler overhead time: 0.04017858859151602 Adapter cache time: 0.019365993794053793 Engine time: 0.04121386678889394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.351351529825479,
    "estimated_duration": 3600.0662803688597,
    "input_throughput": 6865.080272207585,
    "output_throughput": 6046.925613205525,
    "total_throughput": 12912.00588541311,
    "itl": 142.12208288609142,
    "ttft": 1784891.4114446468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3583785487874447,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.1761783221567
}
#Debug simulation 
Total elapsed time: 7.351463502738625. Arrivals time: 0.34553851978853345 Scheduler time: 6.884179306682199 Scheduler overhead time: 0.040470490232110023 Adapter cache time: 0.020820097997784615 Engine time: 0.04160705907270312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.227972179185599,
    "estimated_duration": 3600.069935949655,
    "input_throughput": 6865.0733012720075,
    "output_throughput": 6046.919473040047,
    "total_throughput": 12911.992774312053,
    "itl": 142.1221462821278,
    "ttft": 1784892.796214393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3629270376078861,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17619713794514
}
#Debug simulation 
Total elapsed time: 7.22816425235942. Arrivals time: 0.314824472181499 Scheduler time: 6.793965450488031 Scheduler overhead time: 0.040205593686550856 Adapter cache time: 0.019180765375494957 Engine time: 0.041323655750602484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.2861208049580455,
    "estimated_duration": 3600.111485660438,
    "input_throughput": 6864.994069889504,
    "output_throughput": 6046.849684158165,
    "total_throughput": 12911.843754047668,
    "itl": 142.11947136350472,
    "ttft": 1784929.267654191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2949353374843462,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17926283017249
}
#Debug simulation 
Total elapsed time: 7.286235728766769. Arrivals time: 0.3819164112210274 Scheduler time: 6.784842929802835 Scheduler overhead time: 0.04026392148807645 Adapter cache time: 0.019457879941910505 Engine time: 0.04127659695222974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.319569554179907,
    "estimated_duration": 3600.079659175417,
    "input_throughput": 6865.054759832956,
    "output_throughput": 6046.903141300539,
    "total_throughput": 12911.957901133494,
    "itl": 142.12250079211685,
    "ttft": 1784895.7721820392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3786462609097414,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17615995220618
}
#Debug simulation 
Total elapsed time: 7.319701930973679. Arrivals time: 0.3260556207969785 Scheduler time: 6.87455783970654 Scheduler overhead time: 0.039984510745853186 Adapter cache time: 0.01905702380463481 Engine time: 0.04140032781288028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.318699026945978,
    "estimated_duration": 3600.0075117535844,
    "input_throughput": 6865.192341768561,
    "output_throughput": 6047.024326734261,
    "total_throughput": 12912.216668502822,
    "itl": 142.11639875479776,
    "ttft": 1784871.1380952396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2468509729742,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17820783701595
}
#Debug simulation 
Total elapsed time: 7.318877947051078. Arrivals time: 0.36041099997237325 Scheduler time: 6.837265432346612 Scheduler overhead time: 0.040506350342184305 Adapter cache time: 0.020406270399689674 Engine time: 0.04152978491038084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.2741539580747485,
    "estimated_duration": 3600.0937710443827,
    "input_throughput": 6865.027849769114,
    "output_throughput": 6046.879438277727,
    "total_throughput": 12911.907288046841,
    "itl": 142.12285960791792,
    "ttft": 1784900.6782820194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3944912379980108,
    "arrivals": 380865,
    "finished_requests": 99632,
    "scheduler_time": 111.17625670616152
}
#Debug simulation 
Total elapsed time: 7.274268146138638. Arrivals time: 0.3206712375395 Scheduler time: 6.833937371149659 Scheduler overhead time: 0.040224434807896614 Adapter cache time: 0.019638621248304844 Engine time: 0.041246827226132154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.422624289058149,
    "estimated_duration": 3600.115363055817,
    "input_throughput": 6875.46522925583,
    "output_throughput": 6102.542775560321,
    "total_throughput": 12978.008004816153,
    "itl": 141.60030826387117,
    "ttft": 1774981.581141486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.433867248692633,
    "arrivals": 377686,
    "finished_requests": 100012,
    "scheduler_time": 112.01982410003467
}
#Debug simulation 
Total elapsed time: 7.422738484106958. Arrivals time: 0.403172992169857 Scheduler time: 6.894929436035454 Scheduler overhead time: 0.04055290715768933 Adapter cache time: 0.02350190607830882 Engine time: 0.04173874668776989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.300498049706221,
    "estimated_duration": 3600.0338888283077,
    "input_throughput": 6875.210835322339,
    "output_throughput": 6102.182278942346,
    "total_throughput": 12977.393114264685,
    "itl": 141.6078110722281,
    "ttft": 1774980.7747063986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.664013203873773,
    "arrivals": 377686,
    "finished_requests": 100006,
    "scheduler_time": 112.01141380500525
}
#Debug simulation 
Total elapsed time: 7.300669077783823. Arrivals time: 0.31625046767294407 Scheduler time: 6.861582684330642 Scheduler overhead time: 0.040427916683256626 Adapter cache time: 0.021923483349382877 Engine time: 0.04169500060379505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.3444807031191885,
    "estimated_duration": 3600.0395601083223,
    "input_throughput": 6875.200004539745,
    "output_throughput": 6102.172665941203,
    "total_throughput": 12977.372670480949,
    "itl": 141.60799875613782,
    "ttft": 1774983.5122614023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.669441715292578,
    "arrivals": 377686,
    "finished_requests": 100006,
    "scheduler_time": 112.01142634823123
}
#Debug simulation 
Total elapsed time: 7.344630079809576. Arrivals time: 0.32626659888774157 Scheduler time: 6.89505985705182 Scheduler overhead time: 0.04039105912670493 Adapter cache time: 0.02240855060517788 Engine time: 0.041701540350914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.348916340153664,
    "estimated_duration": 3600.044103304023,
    "input_throughput": 6875.195216993091,
    "output_throughput": 6102.343296249543,
    "total_throughput": 12977.538513242635,
    "itl": 141.60348497709816,
    "ttft": 1774982.2682296128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.512554223798178,
    "arrivals": 377686,
    "finished_requests": 100007,
    "scheduler_time": 112.01513146151127
}
#Debug simulation 
Total elapsed time: 7.349033821839839. Arrivals time: 0.35523427557200193 Scheduler time: 6.870664876885712 Scheduler overhead time: 0.04054815508425236 Adapter cache time: 0.022240325808525085 Engine time: 0.041601323522627354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.306579797994345,
    "estimated_duration": 3600.0844375911483,
    "input_throughput": 6875.114300530443,
    "output_throughput": 6102.096598239525,
    "total_throughput": 12977.210898769968,
    "itl": 141.60943338438892,
    "ttft": 1774992.3385239926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7206089204736066,
    "arrivals": 377686,
    "finished_requests": 100006,
    "scheduler_time": 112.01200055666874
}
#Debug simulation 
Total elapsed time: 7.306783969979733. Arrivals time: 0.32267776457592845 Scheduler time: 6.861232949886471 Scheduler overhead time: 0.040517840534448624 Adapter cache time: 0.022020370699465275 Engine time: 0.04145482508465648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.309424750972539,
    "estimated_duration": 3600.03031411039,
    "input_throughput": 6875.6276587400425,
    "output_throughput": 6102.686945131742,
    "total_throughput": 12978.314603871784,
    "itl": 141.5975079850644,
    "ttft": 1774953.8133702525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.354836430880159,
    "arrivals": 377686,
    "finished_requests": 100012,
    "scheduler_time": 112.01938824786173
}
#Debug simulation 
Total elapsed time: 7.309541009366512. Arrivals time: 0.3619947782717645 Scheduler time: 6.824093452189118 Scheduler overhead time: 0.040571995079517365 Adapter cache time: 0.02249134238809347 Engine time: 0.04159262729808688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.3839511829428375,
    "estimated_duration": 3600.0232902919747,
    "input_throughput": 6874.920522526036,
    "output_throughput": 6101.808024197096,
    "total_throughput": 12976.72854672313,
    "itl": 141.61145402877779,
    "ttft": 1775045.6635273139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.772530648373124,
    "arrivals": 377686,
    "finished_requests": 100002,
    "scheduler_time": 112.00749789260509
}
#Debug simulation 
Total elapsed time: 7.38405965315178. Arrivals time: 0.3902694950811565 Scheduler time: 6.86982647748664 Scheduler overhead time: 0.04053900204598904 Adapter cache time: 0.023034931626170874 Engine time: 0.041647575329989195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.437757186591625,
    "estimated_duration": 3600.0950385582482,
    "input_throughput": 7026.958935542749,
    "output_throughput": 6223.305984992125,
    "total_throughput": 13250.264920534873,
    "itl": 138.726067014749,
    "ttft": 1756611.9081997084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3198497099010718,
    "arrivals": 376204,
    "finished_requests": 102306,
    "scheduler_time": 114.22030057724086
}
#Debug simulation 
Total elapsed time: 7.437963022850454. Arrivals time: 0.3449119161814451 Scheduler time: 6.968895434401929 Scheduler overhead time: 0.04120626486837864 Adapter cache time: 0.021627705544233322 Engine time: 0.04226741520687938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.508730927016586,
    "estimated_duration": 3600.000833264455,
    "input_throughput": 7026.570040280262,
    "output_throughput": 6223.0402262671605,
    "total_throughput": 13249.610266547423,
    "itl": 138.7324526639248,
    "ttft": 1756632.9430009616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.477423190916894,
    "arrivals": 376204,
    "finished_requests": 102299,
    "scheduler_time": 114.21236303524024
}
#Debug simulation 
Total elapsed time: 7.508847031276673. Arrivals time: 0.39263466326519847 Scheduler time: 6.991993434727192 Scheduler overhead time: 0.04164693783968687 Adapter cache time: 0.021103883627802134 Engine time: 0.04236257262527943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.451304337009788,
    "estimated_duration": 3600.006630947547,
    "input_throughput": 7026.55872423824,
    "output_throughput": 6223.0302042814255,
    "total_throughput": 13249.588928519666,
    "itl": 138.73259671196658,
    "ttft": 1756635.938872837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4816897809319127,
    "arrivals": 376204,
    "finished_requests": 102299,
    "scheduler_time": 114.21238543670641
}
#Debug simulation 
Total elapsed time: 7.451457777060568. Arrivals time: 0.37194214947521687 Scheduler time: 6.956951815634966 Scheduler overhead time: 0.0412729294039309 Adapter cache time: 0.019969733897596598 Engine time: 0.04223917191848159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.538467851933092,
    "estimated_duration": 3600.047905944796,
    "input_throughput": 7026.667605791549,
    "output_throughput": 6223.26885234053,
    "total_throughput": 13249.936458132079,
    "itl": 138.72937142930218,
    "ttft": 1756625.720599507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.37404857535146,
    "arrivals": 376204,
    "finished_requests": 102303,
    "scheduler_time": 114.21631138729352
}
#Debug simulation 
Total elapsed time: 7.5386445838958025. Arrivals time: 0.39689907897263765 Scheduler time: 7.018020758405328 Scheduler overhead time: 0.04141403455287218 Adapter cache time: 0.020687314681708813 Engine time: 0.04236143548041582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.445010663941503,
    "estimated_duration": 3600.0398231497725,
    "input_throughput": 7026.49393968874,
    "output_throughput": 6222.972828228064,
    "total_throughput": 13249.466767916805,
    "itl": 138.73370286206801,
    "ttft": 1756649.657541859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.513379735108469,
    "arrivals": 376204,
    "finished_requests": 102299,
    "scheduler_time": 114.21243493539608
}
#Debug simulation 
Total elapsed time: 7.445153572130948. Arrivals time: 0.3641994260251522 Scheduler time: 6.957248571328819 Scheduler overhead time: 0.041155957616865635 Adapter cache time: 0.02106537390500307 Engine time: 0.042478484101593494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.433983495924622,
    "estimated_duration": 3600.0461711383905,
    "input_throughput": 7027.054320250695,
    "output_throughput": 6223.39046082716,
    "total_throughput": 13250.444781077855,
    "itl": 138.7249595768801,
    "ttft": 1756592.2972599699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2664581235358057,
    "arrivals": 376204,
    "finished_requests": 102306,
    "scheduler_time": 114.22003223634474
}
#Debug simulation 
Total elapsed time: 7.434115083888173. Arrivals time: 0.38078185450285673 Scheduler time: 6.930418819654733 Scheduler overhead time: 0.041203578002750874 Adapter cache time: 0.02030986174941063 Engine time: 0.04238542029634118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.485046601854265,
    "estimated_duration": 3600.0746470108893,
    "input_throughput": 7026.425971751104,
    "output_throughput": 6222.912632825815,
    "total_throughput": 13249.338604576918,
    "itl": 138.73464308774209,
    "ttft": 1756661.8636024408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5456984582170987,
    "arrivals": 376204,
    "finished_requests": 102299,
    "scheduler_time": 114.21269045127613
}
#Debug simulation 
Total elapsed time: 7.485229914076626. Arrivals time: 0.389632532838732 Scheduler time: 6.971627837512642 Scheduler overhead time: 0.04154485324397683 Adapter cache time: 0.02047725487500429 Engine time: 0.04257524060085416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.845700650010258,
    "estimated_duration": 3600.098297039632,
    "input_throughput": 7095.82291711486,
    "output_throughput": 6282.187633209234,
    "total_throughput": 13378.010550324094,
    "itl": 137.3216570059593,
    "ttft": 1748397.089622883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5241228964785283,
    "arrivals": 375496,
    "finished_requests": 103106,
    "scheduler_time": 115.34347404564743
}
#Debug simulation 
Total elapsed time: 7.845832860097289. Arrivals time: 0.3731678044423461 Scheduler time: 7.349353366997093 Scheduler overhead time: 0.041789083275943995 Adapter cache time: 0.01943389605730772 Engine time: 0.04268288007006049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.502517139073461,
    "estimated_duration": 3600.1205779741867,
    "input_throughput": 7095.434013039092,
    "output_throughput": 6281.823764004538,
    "total_throughput": 13377.257777043631,
    "itl": 137.3258413119668,
    "ttft": 1748415.3584119722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.624698692583485,
    "arrivals": 375496,
    "finished_requests": 103102,
    "scheduler_time": 115.34101028178169
}
#Debug simulation 
Total elapsed time: 7.5026309713721275. Arrivals time: 0.3291052170097828 Scheduler time: 7.052900394424796 Scheduler overhead time: 0.041145727038383484 Adapter cache time: 0.01778329536318779 Engine time: 0.042533434461802244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.574245641939342,
    "estimated_duration": 3600.127954964829,
    "input_throughput": 7095.419473847438,
    "output_throughput": 6281.8108919745155,
    "total_throughput": 13377.230365821953,
    "itl": 137.3260311590025,
    "ttft": 1748418.6627120455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.627638554871092,
    "arrivals": 375496,
    "finished_requests": 103102,
    "scheduler_time": 115.34107446218863
}
#Debug simulation 
Total elapsed time: 7.574440797790885. Arrivals time: 0.3375229253433645 Scheduler time: 7.11391110252589 Scheduler overhead time: 0.042023133020848036 Adapter cache time: 0.018636969849467278 Engine time: 0.042901148088276386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.54362447373569,
    "estimated_duration": 3600.1323386148583,
    "input_throughput": 7095.755821528668,
    "output_throughput": 6282.128231069872,
    "total_throughput": 13377.88405259854,
    "itl": 137.32267320300207,
    "ttft": 1748409.997333617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.56136641822522,
    "arrivals": 375496,
    "finished_requests": 103106,
    "scheduler_time": 115.3436078015968
}
#Debug simulation 
Total elapsed time: 7.543740768916905. Arrivals time: 0.40139053110033274 Scheduler time: 7.018800915684551 Scheduler overhead time: 0.04167827544733882 Adapter cache time: 0.01968910824507475 Engine time: 0.04294819291681051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.5815091440454125,
    "estimated_duration": 3600.146453488206,
    "input_throughput": 7095.383015668665,
    "output_throughput": 6281.778614336054,
    "total_throughput": 13377.161630004719,
    "itl": 137.3266106393345,
    "ttft": 1748425.9006030723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6471303917653906,
    "arrivals": 375496,
    "finished_requests": 103102,
    "scheduler_time": 115.34117119097972
}
#Debug simulation 
Total elapsed time: 7.581636030226946. Arrivals time: 0.3627750016748905 Scheduler time: 7.097047177143395 Scheduler overhead time: 0.041703369934111834 Adapter cache time: 0.01793280430138111 Engine time: 0.04279198218137026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.897862772922963,
    "estimated_duration": 3600.0587785914786,
    "input_throughput": 7095.900809151435,
    "output_throughput": 6282.25659383503,
    "total_throughput": 13378.157402986464,
    "itl": 137.3205657532164,
    "ttft": 1748381.2341308475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890450468612675,
    "arrivals": 375496,
    "finished_requests": 103106,
    "scheduler_time": 115.34333370709132
}
#Debug simulation 
Total elapsed time: 7.898005856666714. Arrivals time: 0.6833296348340809 Scheduler time: 7.089500301517546 Scheduler overhead time: 0.04166640155017376 Adapter cache time: 0.018538714852184057 Engine time: 0.04565195320174098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.572304311674088,
    "estimated_duration": 3600.0168309995606,
    "input_throughput": 7095.637659257131,
    "output_throughput": 6281.888685981746,
    "total_throughput": 13377.526345238877,
    "itl": 137.32684010794623,
    "ttft": 1748388.077684165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6693888119608147,
    "arrivals": 375496,
    "finished_requests": 103099,
    "scheduler_time": 115.33639577134508
}
#Debug simulation 
Total elapsed time: 7.572414111811668. Arrivals time: 0.39377436414361 Scheduler time: 7.054713110905141 Scheduler overhead time: 0.04196617938578129 Adapter cache time: 0.019187739118933678 Engine time: 0.04348561353981495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.607953843194991,
    "estimated_duration": 3600.0235716570837,
    "input_throughput": 7171.174989867292,
    "output_throughput": 6319.267234555479,
    "total_throughput": 13490.442224422772,
    "itl": 136.08771314491608,
    "ttft": 1741463.4394121731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9885375412902782,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.06739067337259
}
#Debug simulation 
Total elapsed time: 7.608072255272418. Arrivals time: 0.3488904586993158 Scheduler time: 7.135452366434038 Scheduler overhead time: 0.04201217880472541 Adapter cache time: 0.019139299634844065 Engine time: 0.04314802959561348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.597888199146837,
    "estimated_duration": 3600.098149275884,
    "input_throughput": 7171.026435818882,
    "output_throughput": 6319.136328151439,
    "total_throughput": 13490.162763970322,
    "itl": 136.08921033232266,
    "ttft": 1741492.3007294799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0507740714890006,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.06838351826012
}
#Debug simulation 
Total elapsed time: 7.5980881922878325. Arrivals time: 0.3949231249280274 Scheduler time: 7.079384586773813 Scheduler overhead time: 0.04240213567391038 Adapter cache time: 0.018406064249575138 Engine time: 0.04335244558751583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.639731686096638,
    "estimated_duration": 3600.0990479698085,
    "input_throughput": 7171.024645713165,
    "output_throughput": 6319.134750703332,
    "total_throughput": 13490.159396416499,
    "itl": 136.08923733899,
    "ttft": 1741492.2911012906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0532040670141634,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.06840004528485
}
#Debug simulation 
Total elapsed time: 7.639865772798657. Arrivals time: 0.40577492536976933 Scheduler time: 7.111517550889403 Scheduler overhead time: 0.0422420734539628 Adapter cache time: 0.017744155135005713 Engine time: 0.043240346014499664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.603512373287231,
    "estimated_duration": 3600.054419711148,
    "input_throughput": 7171.113541686792,
    "output_throughput": 6319.213086180324,
    "total_throughput": 13490.326627867116,
    "itl": 136.0880454694,
    "ttft": 1741474.553249096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0082801583712022,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.068181715144
}
#Debug simulation 
Total elapsed time: 7.603636566083878. Arrivals time: 0.3383919829502702 Scheduler time: 7.1422139396891 Scheduler overhead time: 0.042055676225572824 Adapter cache time: 0.018467082642018795 Engine time: 0.04312286200001836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.583718920126557,
    "estimated_duration": 3600.112489786097,
    "input_throughput": 7170.997871106494,
    "output_throughput": 6319.111156816013,
    "total_throughput": 13490.109027922506,
    "itl": 136.089679204249,
    "ttft": 1741498.2533636007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.066282460801309,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.06844048576949
}
#Debug simulation 
Total elapsed time: 7.583903013728559. Arrivals time: 0.35911542270332575 Scheduler time: 7.102081231307238 Scheduler overhead time: 0.04212068626657128 Adapter cache time: 0.01735243760049343 Engine time: 0.04356788890436292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.533178053796291,
    "estimated_duration": 3600.1081525922755,
    "input_throughput": 7171.148450473747,
    "output_throughput": 6319.491258510703,
    "total_throughput": 13490.63970898445,
    "itl": 136.08752822859125,
    "ttft": 1741468.8817018848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9687762955483062,
    "arrivals": 375142,
    "finished_requests": 104081,
    "scheduler_time": 116.07061664521474
}
#Debug simulation 
Total elapsed time: 7.533311273902655. Arrivals time: 0.35607462795451283 Scheduler time: 7.055221957154572 Scheduler overhead time: 0.041889581829309464 Adapter cache time: 0.017771852668374777 Engine time: 0.04305010801181197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.589139713905752,
    "estimated_duration": 3600.1291124057575,
    "input_throughput": 7170.964760968919,
    "output_throughput": 6319.0819800342715,
    "total_throughput": 13490.04674100319,
    "itl": 136.09024267693536,
    "ttft": 1741504.865156577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0793608545884539,
    "arrivals": 375142,
    "finished_requests": 104078,
    "scheduler_time": 116.06851824588888
}
#Debug simulation 
Total elapsed time: 7.589257933665067. Arrivals time: 0.4000725573860109 Scheduler time: 7.067551611922681 Scheduler overhead time: 0.04179893946275115 Adapter cache time: 0.017472469713538885 Engine time: 0.043008603155612946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.573364165145904,
    "estimated_duration": 3600.075576567209,
    "input_throughput": 7280.080776801635,
    "output_throughput": 6441.602546053402,
    "total_throughput": 13721.683322855037,
    "itl": 133.72783141088908,
    "ttft": 1731484.2972032926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8301716708718143,
    "arrivals": 373254,
    "finished_requests": 105830,
    "scheduler_time": 118.21657203616712
}
#Debug simulation 
Total elapsed time: 7.573524747043848. Arrivals time: 0.28671531425789 Scheduler time: 7.1646016063168645 Scheduler overhead time: 0.042473938316106796 Adapter cache time: 0.016706028953194618 Engine time: 0.04349626135081053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.534741010982543,
    "estimated_duration": 3600.062950048317,
    "input_throughput": 7279.956312888433,
    "output_throughput": 6441.460419376492,
    "total_throughput": 13721.416732264925,
    "itl": 133.73174661822262,
    "ttft": 1731489.2341689658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9527139896829675,
    "arrivals": 373254,
    "finished_requests": 105827,
    "scheduler_time": 118.21302441686002
}
#Debug simulation 
Total elapsed time: 7.534823048394173. Arrivals time: 0.288248245138675 Scheduler time: 7.124965356197208 Scheduler overhead time: 0.04231152404099703 Adapter cache time: 0.016618066001683474 Engine time: 0.04342757165431976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.57098089531064,
    "estimated_duration": 3600.0882397664536,
    "input_throughput": 7279.905173018813,
    "output_throughput": 6441.415169730498,
    "total_throughput": 13721.320342749312,
    "itl": 133.73226363100233,
    "ttft": 1731493.4224943959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9559350118599954,
    "arrivals": 373254,
    "finished_requests": 105827,
    "scheduler_time": 118.21335496015197
}
#Debug simulation 
Total elapsed time: 7.571075066924095. Arrivals time: 0.3057286632247269 Scheduler time: 7.143655031919479 Scheduler overhead time: 0.042196950409561396 Adapter cache time: 0.016854818910360336 Engine time: 0.04332233406603336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.598112472798675,
    "estimated_duration": 3600.1228600887885,
    "input_throughput": 7280.023771009198,
    "output_throughput": 6441.558774865829,
    "total_throughput": 13721.582545875026,
    "itl": 133.72974031590286,
    "ttft": 1731491.2865658612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8709949259948804,
    "arrivals": 373254,
    "finished_requests": 105831,
    "scheduler_time": 118.21683164836936
}
#Debug simulation 
Total elapsed time: 7.598274328745902. Arrivals time: 0.2872349675744772 Scheduler time: 7.18883841810748 Scheduler overhead time: 0.042338631115853786 Adapter cache time: 0.01677235821262002 Engine time: 0.04363757045939565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.5504032908938825,
    "estimated_duration": 3600.1151412512954,
    "input_throughput": 7279.850774686822,
    "output_throughput": 6441.367036927588,
    "total_throughput": 13721.21781161441,
    "itl": 133.7328890547088,
    "ttft": 1731517.3233757443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9841292879916763,
    "arrivals": 373254,
    "finished_requests": 105827,
    "scheduler_time": 118.21374679375357
}
#Debug simulation 
Total elapsed time: 7.550504681188613. Arrivals time: 0.2817313061095774 Scheduler time: 7.14686662144959 Scheduler overhead time: 0.042356840800493956 Adapter cache time: 0.016714199911803007 Engine time: 0.043454273603856564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.5351368500851095,
    "estimated_duration": 3600.029403575514,
    "input_throughput": 7280.174149124903,
    "output_throughput": 6441.6851642843985,
    "total_throughput": 13721.8593134093,
    "itl": 133.7263635557389,
    "ttft": 1731465.7781376096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7880500763514744,
    "arrivals": 373254,
    "finished_requests": 105830,
    "scheduler_time": 118.21645211347014
}
#Debug simulation 
Total elapsed time: 7.535241111181676. Arrivals time: 0.28083762899041176 Scheduler time: 7.1327512296848 Scheduler overhead time: 0.04229752765968442 Adapter cache time: 0.016873743385076523 Engine time: 0.04318029247224331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.4790768241509795,
    "estimated_duration": 3600.0026394171978,
    "input_throughput": 7279.7077182817375,
    "output_throughput": 6441.251110791956,
    "total_throughput": 13720.958829073694,
    "itl": 133.7333367758544,
    "ttft": 1731502.1071483255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0096573066338848,
    "arrivals": 373254,
    "finished_requests": 105822,
    "scheduler_time": 118.20980553138747
}
#Debug simulation 
Total elapsed time: 7.479206981137395. Arrivals time: 0.26759353559464216 Scheduler time: 7.0914803659543395 Scheduler overhead time: 0.04196329088881612 Adapter cache time: 0.016014214605093002 Engine time: 0.04288715496659279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.599103438202292,
    "estimated_duration": 3600.071965633417,
    "input_throughput": 7374.783963611318,
    "output_throughput": 6523.121544285058,
    "total_throughput": 13897.905507896376,
    "itl": 132.12541760983885,
    "ttft": 1719984.545379053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2303160730609737,
    "arrivals": 372568,
    "finished_requests": 107031,
    "scheduler_time": 119.64085487739297
}
#Debug simulation 
Total elapsed time: 7.599186251871288. Arrivals time: 0.2703035087324679 Scheduler time: 7.208777655847371 Scheduler overhead time: 0.04246860183775425 Adapter cache time: 0.014786165673285723 Engine time: 0.04342609457671642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.606412843801081,
    "estimated_duration": 3600.035676832036,
    "input_throughput": 7374.225253056736,
    "output_throughput": 6522.938411728306,
    "total_throughput": 13897.163664785043,
    "itl": 132.12824535618637,
    "ttft": 1720033.8770705613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3068793323240302,
    "arrivals": 372568,
    "finished_requests": 107025,
    "scheduler_time": 119.63688288227512
}
#Debug simulation 
Total elapsed time: 7.606526388786733. Arrivals time: 0.27063693944364786 Scheduler time: 7.216045260895044 Scheduler overhead time: 0.042285147588700056 Adapter cache time: 0.014578783418983221 Engine time: 0.04347654851153493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.528543267864734,
    "estimated_duration": 3600.0395459942447,
    "input_throughput": 7374.217327567779,
    "output_throughput": 6522.931401164542,
    "total_throughput": 13897.148728732322,
    "itl": 132.12829853393654,
    "ttft": 1720036.27998442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.309484396912165,
    "arrivals": 372568,
    "finished_requests": 107025,
    "scheduler_time": 119.63692950036214
}
#Debug simulation 
Total elapsed time: 7.528681049123406. Arrivals time: 0.27598807075992227 Scheduler time: 7.132354880217463 Scheduler overhead time: 0.0424685413017869 Adapter cache time: 0.014645547606050968 Engine time: 0.04349150229245424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.60162440687418,
    "estimated_duration": 3600.0974431770906,
    "input_throughput": 7374.731772973847,
    "output_throughput": 6523.075380780693,
    "total_throughput": 13897.80715375454,
    "itl": 132.126112967358,
    "ttft": 1719996.2124041554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2559348005848,
    "arrivals": 372568,
    "finished_requests": 107031,
    "scheduler_time": 119.64089920980143
}
#Debug simulation 
Total elapsed time: 7.601707364898175. Arrivals time: 0.28570739924907684 Scheduler time: 7.19628188200295 Scheduler overhead time: 0.04245752515271306 Adapter cache time: 0.014427001122385263 Engine time: 0.04344536457210779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.8135034609586,
    "estimated_duration": 3600.0568157568036,
    "input_throughput": 7374.181952853206,
    "output_throughput": 6522.900110137136,
    "total_throughput": 13897.082062990341,
    "itl": 132.12880387899932,
    "ttft": 1720043.3049969373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.326083896718924,
    "arrivals": 372568,
    "finished_requests": 107025,
    "scheduler_time": 119.63695385847355
}
#Debug simulation 
Total elapsed time: 7.813573607709259. Arrivals time: 0.5225016982294619 Scheduler time: 7.1716000023297966 Scheduler overhead time: 0.04217995097860694 Adapter cache time: 0.014486649073660374 Engine time: 0.043413101229816675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.606243003159761,
    "estimated_duration": 3600.016001211996,
    "input_throughput": 7374.634165809812,
    "output_throughput": 6523.0582286562285,
    "total_throughput": 13897.69239446604,
    "itl": 132.1255514290857,
    "ttft": 1719985.6217378888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204990268845571,
    "arrivals": 372568,
    "finished_requests": 107028,
    "scheduler_time": 119.63881111787332
}
#Debug simulation 
Total elapsed time: 7.6063586310483515. Arrivals time: 0.2731323572807014 Scheduler time: 7.213286384008825 Scheduler overhead time: 0.04242281895130873 Adapter cache time: 0.014537542592734098 Engine time: 0.043398675974458456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.586107055190951,
    "estimated_duration": 3600.07466922035,
    "input_throughput": 7374.145382864865,
    "output_throughput": 6522.867761819382,
    "total_throughput": 13897.013144684248,
    "itl": 132.1293425778854,
    "ttft": 1720051.7868897056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3426833965256828,
    "arrivals": 372568,
    "finished_requests": 107025,
    "scheduler_time": 119.63703103933776
}
#Debug simulation 
Total elapsed time: 7.586187633220106. Arrivals time: 0.2704875534400344 Scheduler time: 7.1958936038427055 Scheduler overhead time: 0.04244076460599899 Adapter cache time: 0.01446652039885521 Engine time: 0.04344926727935672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.5804170980118215,
    "estimated_duration": 3600.024747111876,
    "input_throughput": 7375.9948515083925,
    "output_throughput": 6555.696601511882,
    "total_throughput": 13931.691453020276,
    "itl": 132.0067808976707,
    "ttft": 1714341.3758041398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8844809579965647,
    "arrivals": 372217,
    "finished_requests": 107297,
    "scheduler_time": 120.25056957359907
}
#Debug simulation 
Total elapsed time: 7.580501358024776. Arrivals time: 0.2715641027316451 Scheduler time: 7.1895638960413635 Scheduler overhead time: 0.04243117244914174 Adapter cache time: 0.013958700932562351 Engine time: 0.043496981263160706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.603212062269449,
    "estimated_duration": 3600.008221919615,
    "input_throughput": 7375.900654427147,
    "output_throughput": 6555.435583815441,
    "total_throughput": 13931.336238242588,
    "itl": 132.00993640117147,
    "ttft": 1714354.4232322143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9397146691381978,
    "arrivals": 372217,
    "finished_requests": 107295,
    "scheduler_time": 120.24797383926396
}
#Debug simulation 
Total elapsed time: 7.603334137238562. Arrivals time: 0.2717281864024699 Scheduler time: 7.2113520465791225 Scheduler overhead time: 0.04262892948463559 Adapter cache time: 0.014195184223353863 Engine time: 0.04359513381496072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.620595003012568,
    "estimated_duration": 3600.0151745792173,
    "input_throughput": 7375.88640945205,
    "output_throughput": 6555.422923393207,
    "total_throughput": 13931.309332845258,
    "itl": 132.01010806831408,
    "ttft": 1714357.9601290782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9419677337817896,
    "arrivals": 372217,
    "finished_requests": 107295,
    "scheduler_time": 120.2481028082944
}
#Debug simulation 
Total elapsed time: 7.6207077582366765. Arrivals time: 0.27296195505186915 Scheduler time: 7.227394075132906 Scheduler overhead time: 0.042733898386359215 Adapter cache time: 0.014094139914959669 Engine time: 0.04367739520967007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.571914786007255,
    "estimated_duration": 3600.0777311569764,
    "input_throughput": 7375.8862955068125,
    "output_throughput": 6555.60011822726,
    "total_throughput": 13931.486413734072,
    "itl": 132.0082658297484,
    "ttft": 1714347.8121090531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8992637326126011,
    "arrivals": 372217,
    "finished_requests": 107297,
    "scheduler_time": 120.25153511567352
}
#Debug simulation 
Total elapsed time: 7.572034167125821. Arrivals time: 0.2755026062950492 Scheduler time: 7.177427776157856 Scheduler overhead time: 0.0423705754801631 Adapter cache time: 0.014088751282542944 Engine time: 0.04320325795561075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.611699020955712,
    "estimated_duration": 3600.0297688253045,
    "input_throughput": 7375.8565081711495,
    "output_throughput": 6555.3963482086965,
    "total_throughput": 13931.252856379846,
    "itl": 132.01056695449358,
    "ttft": 1714365.36554863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9544173586368612,
    "arrivals": 372217,
    "finished_requests": 107295,
    "scheduler_time": 120.248174032337
}
#Debug simulation 
Total elapsed time: 7.61183159891516. Arrivals time: 0.27162691997364163 Scheduler time: 7.220607252325863 Scheduler overhead time: 0.04244700586423278 Adapter cache time: 0.014013085514307022 Engine time: 0.04356933897361159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.603825062979013,
    "estimated_duration": 3600.145656264732,
    "input_throughput": 7376.02850978853,
    "output_throughput": 6555.675867983409,
    "total_throughput": 13931.70437777194,
    "itl": 132.00586557599016,
    "ttft": 1714334.4259568793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8641245352267299,
    "arrivals": 372217,
    "finished_requests": 107300,
    "scheduler_time": 120.25535884785222
}
#Debug simulation 
Total elapsed time: 7.603910063393414. Arrivals time: 0.2710283622145653 Scheduler time: 7.213549240492284 Scheduler overhead time: 0.042412026319652796 Adapter cache time: 0.014090092852711678 Engine time: 0.0433838302269578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.5946009662002325,
    "estimated_duration": 3600.0395709175054,
    "input_throughput": 7375.836425384799,
    "output_throughput": 6555.3784993494955,
    "total_throughput": 13931.214924734295,
    "itl": 132.0107503631636,
    "ttft": 1714370.6295575998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9652321842685391,
    "arrivals": 372217,
    "finished_requests": 107295,
    "scheduler_time": 120.24824166880262
}
#Debug simulation 
Total elapsed time: 7.594680292997509. Arrivals time: 0.27305975183844566 Scheduler time: 7.202168567571789 Scheduler overhead time: 0.04246661951765418 Adapter cache time: 0.014008804690092802 Engine time: 0.04348477674648166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.735280211083591,
    "estimated_duration": 3600.0126439869905,
    "input_throughput": 7495.41700779024,
    "output_throughput": 6646.93887671981,
    "total_throughput": 14142.35588451005,
    "itl": 129.87703873539107,
    "ttft": 1701045.1823231082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.068110222632532,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.8632049931836
}
#Debug simulation 
Total elapsed time: 7.735406207852066. Arrivals time: 0.3061218988150358 Scheduler time: 7.309540892485529 Scheduler overhead time: 0.04309735679998994 Adapter cache time: 0.012816541828215122 Engine time: 0.04397074552252889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.757669095881283,
    "estimated_duration": 3600.1089168631433,
    "input_throughput": 7495.216567923012,
    "output_throughput": 6646.761126563342,
    "total_throughput": 14141.977694486353,
    "itl": 129.87996087453087,
    "ttft": 1701126.0123289835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1419990246649896,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.86384837453521
}
#Debug simulation 
Total elapsed time: 7.75778092071414. Arrivals time: 0.3056229962967336 Scheduler time: 7.33201251225546 Scheduler overhead time: 0.04340222757309675 Adapter cache time: 0.012855580542236567 Engine time: 0.04396599670872092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.928447710815817,
    "estimated_duration": 3600.1119808198737,
    "input_throughput": 7495.210188949421,
    "output_throughput": 6646.755469686946,
    "total_throughput": 14141.965658636367,
    "itl": 129.88002182897452,
    "ttft": 1701125.819907946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.143464724402881,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.8638844620666
}
#Debug simulation 
Total elapsed time: 7.92853908194229. Arrivals time: 0.5581507375463843 Scheduler time: 7.2510383375920355 Scheduler overhead time: 0.04283620696514845 Adapter cache time: 0.012684137560427189 Engine time: 0.04408713709563017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.775122142862529,
    "estimated_duration": 3600.0410098635557,
    "input_throughput": 7495.357948998114,
    "output_throughput": 6646.88650335873,
    "total_throughput": 14142.244452356843,
    "itl": 129.8777879786605,
    "ttft": 1701098.8175423571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0917418004968225,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.863465316158
}
#Debug simulation 
Total elapsed time: 7.775245721917599. Arrivals time: 0.3097219541668892 Scheduler time: 7.345627604518086 Scheduler overhead time: 0.043133589904755354 Adapter cache time: 0.012665459420531988 Engine time: 0.04405025765299797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.757494134828448,
    "estimated_duration": 3600.137040478431,
    "input_throughput": 7495.158016655411,
    "output_throughput": 6646.70920327522,
    "total_throughput": 14141.867219930631,
    "itl": 129.8806614059236,
    "ttft": 1701133.8245062644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1589324401319074,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.86414410702999
}
#Debug simulation 
Total elapsed time: 7.757589311804622. Arrivals time: 0.3154851677827537 Scheduler time: 7.321584170684218 Scheduler overhead time: 0.04332631453871727 Adapter cache time: 0.012858947273343801 Engine time: 0.04422919172793627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.747953277081251,
    "estimated_duration": 3600.138065701604,
    "input_throughput": 7495.414761195051,
    "output_throughput": 6646.93757941655,
    "total_throughput": 14142.352340611602,
    "itl": 129.87745210176033,
    "ttft": 1701056.4930391517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0435275529208592,
    "arrivals": 371082,
    "finished_requests": 109194,
    "scheduler_time": 121.86799845563523
}
#Debug simulation 
Total elapsed time: 7.748035282827914. Arrivals time: 0.2780095743946731 Scheduler time: 7.349852904677391 Scheduler overhead time: 0.04343145340681076 Adapter cache time: 0.012795692775398493 Engine time: 0.04402833245694637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.765703048091382,
    "estimated_duration": 3600.0097056572513,
    "input_throughput": 7495.423125553386,
    "output_throughput": 6646.944301954677,
    "total_throughput": 14142.367427508063,
    "itl": 129.88118925533493,
    "ttft": 1701071.7002057445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.17377138692886,
    "arrivals": 371082,
    "finished_requests": 109189,
    "scheduler_time": 121.85942139572077
}
#Debug simulation 
Total elapsed time: 7.765825488138944. Arrivals time: 0.30702335480600595 Scheduler time: 7.338101419154555 Scheduler overhead time: 0.04354143841192126 Adapter cache time: 0.012735297437757254 Engine time: 0.04448316618800163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.79458162933588,
    "estimated_duration": 3600.010466627473,
    "input_throughput": 7571.442709036037,
    "output_throughput": 6686.6980591173315,
    "total_throughput": 14258.140768153367,
    "itl": 128.79517485316367,
    "ttft": 1696413.8891543096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7069726688484652,
    "arrivals": 370740,
    "finished_requests": 110114,
    "scheduler_time": 122.65922028931602
}
#Debug simulation 
Total elapsed time: 7.794662141241133. Arrivals time: 0.2805473767220974 Scheduler time: 7.393323604483157 Scheduler overhead time: 0.04373496538028121 Adapter cache time: 0.011843024753034115 Engine time: 0.04502110742032528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.790851071942598,
    "estimated_duration": 3600.092091865915,
    "input_throughput": 7571.2710409784695,
    "output_throughput": 6686.546450961335,
    "total_throughput": 14257.817491939804,
    "itl": 128.79673540776187,
    "ttft": 1696438.916996544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7533465849095984,
    "arrivals": 370740,
    "finished_requests": 110114,
    "scheduler_time": 122.66097609639161
}
#Debug simulation 
Total elapsed time: 7.790960843209177. Arrivals time: 0.27915914356708527 Scheduler time: 7.3921564212068915 Scheduler overhead time: 0.043377830646932125 Adapter cache time: 0.011799764819443226 Engine time: 0.04457714036107063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.053696813993156,
    "estimated_duration": 3600.095656663231,
    "input_throughput": 7571.263543942485,
    "output_throughput": 6686.539829975362,
    "total_throughput": 14257.803373917848,
    "itl": 128.79683498250208,
    "ttft": 1696441.0335209912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7553345071151887,
    "arrivals": 370740,
    "finished_requests": 110114,
    "scheduler_time": 122.66108336333413
}
#Debug simulation 
Total elapsed time: 8.053812173195183. Arrivals time: 0.5394839025102556 Scheduler time: 7.393817480187863 Scheduler overhead time: 0.04355765273794532 Adapter cache time: 0.011928318534046412 Engine time: 0.04466140689328313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.752112030051649,
    "estimated_duration": 3600.0614720439958,
    "input_throughput": 7571.335437370802,
    "output_throughput": 6686.603322451772,
    "total_throughput": 14257.938759822575,
    "itl": 128.7963157380625,
    "ttft": 1696428.534922895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7218847453896902,
    "arrivals": 370740,
    "finished_requests": 110114,
    "scheduler_time": 122.6606808016612
}
#Debug simulation 
Total elapsed time: 7.752196911722422. Arrivals time: 0.27987799933180213 Scheduler time: 7.352235987782478 Scheduler overhead time: 0.043405527248978615 Adapter cache time: 0.01168849691748619 Engine time: 0.04498512437567115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.817364559974521,
    "estimated_duration": 3600.102539581666,
    "input_throughput": 7571.249068691058,
    "output_throughput": 6686.527046198301,
    "total_throughput": 14257.776114889359,
    "itl": 128.79687868751168,
    "ttft": 1696442.7007460536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7650175486691329,
    "arrivals": 370740,
    "finished_requests": 110114,
    "scheduler_time": 122.6610210370169
}
#Debug simulation 
Total elapsed time: 7.8174482099711895. Arrivals time: 0.2811253070831299 Scheduler time: 7.415963539388031 Scheduler overhead time: 0.043716443702578545 Adapter cache time: 0.011862108949571848 Engine time: 0.04476029286161065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.06496699899435,
    "estimated_duration": 3600.137637102683,
    "input_throughput": 7571.303307708109,
    "output_throughput": 6686.563244668916,
    "total_throughput": 14257.866552377025,
    "itl": 128.7949813158243,
    "ttft": 1696433.7003772012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6907016181224035,
    "arrivals": 370740,
    "finished_requests": 110116,
    "scheduler_time": 122.66428714522525
}
#Debug simulation 
Total elapsed time: 8.065073204692453. Arrivals time: 0.29228392615914345 Scheduler time: 7.652645627968013 Scheduler overhead time: 0.043695536442101 Adapter cache time: 0.011887942906469107 Engine time: 0.04450055444613099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.735831181053072,
    "estimated_duration": 3600.0061576452,
    "input_throughput": 7571.403160551576,
    "output_throughput": 6686.607451734367,
    "total_throughput": 14258.010612285943,
    "itl": 128.79759848496633,
    "ttft": 1696418.4954890492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7701880398020178,
    "arrivals": 370740,
    "finished_requests": 110113,
    "scheduler_time": 122.6572569210053
}
#Debug simulation 
Total elapsed time: 7.735938912257552. Arrivals time: 0.28158381674438715 Scheduler time: 7.334799328353256 Scheduler overhead time: 0.043296394404023886 Adapter cache time: 0.011703242547810078 Engine time: 0.044588073156774044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.914130894932896,
    "estimated_duration": 3600.1131209934233,
    "input_throughput": 7685.331007700451,
    "output_throughput": 6767.593178649041,
    "total_throughput": 14452.924186349492,
    "itl": 127.03185805698692,
    "ttft": 1683541.0982265982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5447668184200295,
    "arrivals": 369999,
    "finished_requests": 111950,
    "scheduler_time": 124.24260993565503
}
#Debug simulation 
Total elapsed time: 7.914240380283445. Arrivals time: 0.28402432426810265 Scheduler time: 7.509954249020666 Scheduler overhead time: 0.04444382479414344 Adapter cache time: 0.010386600159108639 Engine time: 0.045125934295356274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.9025520212017,
    "estimated_duration": 3600.0394860235974,
    "input_throughput": 7685.40792605591,
    "output_throughput": 6767.672436535131,
    "total_throughput": 14453.080362591041,
    "itl": 127.03275174730749,
    "ttft": 1683520.434302155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5804432000685492,
    "arrivals": 369999,
    "finished_requests": 111948,
    "scheduler_time": 124.23925294247171
}
#Debug simulation 
Total elapsed time: 7.902680243365467. Arrivals time: 0.28424910781905055 Scheduler time: 7.49791266489774 Scheduler overhead time: 0.04456454515457153 Adapter cache time: 0.010323407128453255 Engine time: 0.04526603780686855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.934140105266124,
    "estimated_duration": 3600.0405902913644,
    "input_throughput": 7685.405568652421,
    "output_throughput": 6767.670360635612,
    "total_throughput": 14453.075929288032,
    "itl": 127.03277578599429,
    "ttft": 1683521.073458024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5815415594354294,
    "arrivals": 369999,
    "finished_requests": 111948,
    "scheduler_time": 124.23925885086389
}
#Debug simulation 
Total elapsed time: 7.93423104705289. Arrivals time: 0.28569362917914987 Scheduler time: 7.528442096430808 Scheduler overhead time: 0.04416276514530182 Adapter cache time: 0.01043280865997076 Engine time: 0.045170380268245935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.9051055810414255,
    "estimated_duration": 3600.01146509739,
    "input_throughput": 7685.388023966062,
    "output_throughput": 6767.724557605233,
    "total_throughput": 14453.112581571295,
    "itl": 127.03270554985512,
    "ttft": 1683492.3361684086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5559274809621282,
    "arrivals": 369999,
    "finished_requests": 111947,
    "scheduler_time": 124.23900312559572
}
#Debug simulation 
Total elapsed time: 7.90520094987005. Arrivals time: 0.2944827023893595 Scheduler time: 7.489750583190471 Scheduler overhead time: 0.04428986506536603 Adapter cache time: 0.010348320938646793 Engine time: 0.04603849723935127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.904058115091175,
    "estimated_duration": 3600.046931722945,
    "input_throughput": 7685.392030919578,
    "output_throughput": 6767.658439480315,
    "total_throughput": 14453.050470399892,
    "itl": 127.0329116983151,
    "ttft": 1683523.9264774115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5890867866203202,
    "arrivals": 369999,
    "finished_requests": 111948,
    "scheduler_time": 124.23930406259859
}
#Debug simulation 
Total elapsed time: 7.904202483128756. Arrivals time: 0.2882178518921137 Scheduler time: 7.495933276135474 Scheduler overhead time: 0.04408244043588638 Adapter cache time: 0.010346807539463043 Engine time: 0.04533697431907058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.930542741902173,
    "estimated_duration": 3600.101448316307,
    "input_throughput": 7685.355925994746,
    "output_throughput": 6767.61512134459,
    "total_throughput": 14452.971047339337,
    "itl": 127.0317989009859,
    "ttft": 1683534.8910846105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.532228952492588,
    "arrivals": 369999,
    "finished_requests": 111950,
    "scheduler_time": 124.2426096835356
}
#Debug simulation 
Total elapsed time: 7.930665859021246. Arrivals time: 0.28641480999067426 Scheduler time: 7.52432607114315 Scheduler overhead time: 0.04405660880729556 Adapter cache time: 0.01037787226960063 Engine time: 0.04513721959665418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.8650734960101545,
    "estimated_duration": 3600.055908858536,
    "input_throughput": 7685.37286654878,
    "output_throughput": 6767.641563579222,
    "total_throughput": 14453.014430128002,
    "itl": 127.03313648281933,
    "ttft": 1683528.4786694595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5963805062323817,
    "arrivals": 369999,
    "finished_requests": 111948,
    "scheduler_time": 124.23938604177549
}
#Debug simulation 
Total elapsed time: 7.865178934298456. Arrivals time: 0.28285602014511824 Scheduler time: 7.463039777241647 Scheduler overhead time: 0.04392249137163162 Adapter cache time: 0.010366943199187517 Engine time: 0.04483599681407213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 43.80593903595582,
    "estimated_duration": 3600.0498776685063,
    "input_throughput": 6530.368966783736,
    "output_throughput": 5783.511258872953,
    "total_throughput": 12313.880225656689,
    "itl": 149.07179419619476,
    "ttft": 1751619.1805371633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6671863281773395,
    "arrivals": 322758,
    "finished_requests": 95157,
    "scheduler_time": 106.08717014434012
}
#Debug simulation 
Total elapsed time: 43.80613777600229. Arrivals time: 0.3515492342412472 Scheduler time: 43.311735175549984 Scheduler overhead time: 0.05515806982293725 Adapter cache time: 0.01062140753492713 Engine time: 0.0558125851675868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.24094958882779,
    "estimated_duration": 3600.1396794418665,
    "input_throughput": 6555.138994956618,
    "output_throughput": 5811.005922760007,
    "total_throughput": 12366.144917716625,
    "itl": 148.39679024468694,
    "ttft": 1761867.716536379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8698476094659459,
    "arrivals": 322758,
    "finished_requests": 95555,
    "scheduler_time": 106.60241048265269
}
#Debug simulation 
Total elapsed time: 38.241052167955786. Arrivals time: 0.35162186715751886 Scheduler time: 37.7505467236042 Scheduler overhead time: 0.053012801334261894 Adapter cache time: 0.01113179000094533 Engine time: 0.05399569543078542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.39336155168712,
    "estimated_duration": 3600.1431057328664,
    "input_throughput": 6555.132756367462,
    "output_throughput": 5811.000392369489,
    "total_throughput": 12366.133148736952,
    "itl": 148.39677788736577,
    "ttft": 1761867.915159331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8716378441639288,
    "arrivals": 322758,
    "finished_requests": 95555,
    "scheduler_time": 106.60246020592109
}
#Debug simulation 
Total elapsed time: 38.393499810714275. Arrivals time: 0.34690756956115365 Scheduler time: 37.90873596351594 Scheduler overhead time: 0.05287462705746293 Adapter cache time: 0.011256357189267874 Engine time: 0.0530174127779901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 43.921467137057334,
    "estimated_duration": 3600.0681815800667,
    "input_throughput": 6530.335764274785,
    "output_throughput": 5783.481853630259,
    "total_throughput": 12313.817617905044,
    "itl": 149.07143092799785,
    "ttft": 1751624.9191794144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6824756131717019,
    "arrivals": 322758,
    "finished_requests": 95157,
    "scheduler_time": 106.0873775671702
}
#Debug simulation 
Total elapsed time: 43.92167987301946. Arrivals time: 0.3612669021822512 Scheduler time: 43.41755018942058 Scheduler overhead time: 0.05530072841793299 Adapter cache time: 0.010858125519007444 Engine time: 0.0554480142891407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 43.68379377713427,
    "estimated_duration": 3600.1045606957564,
    "input_throughput": 6543.613831995824,
    "output_throughput": 5800.810961991629,
    "total_throughput": 12344.424793987453,
    "itl": 148.67953059265608,
    "ttft": 1755429.836972325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7506459292583197,
    "arrivals": 322758,
    "finished_requests": 95298,
    "scheduler_time": 106.39582331804253
}
#Debug simulation 
Total elapsed time: 43.68395872693509. Arrivals time: 0.35155451484024525 Scheduler time: 43.1891173934564 Scheduler overhead time: 0.05513198068365455 Adapter cache time: 0.011255037039518356 Engine time: 0.055658545810729265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 43.89493091776967,
    "estimated_duration": 3600.152913985401,
    "input_throughput": 6530.721489263759,
    "output_throughput": 5783.687942562885,
    "total_throughput": 12314.409431826643,
    "itl": 149.0699792533839,
    "ttft": 1751594.4461451375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6518309642886752,
    "arrivals": 322758,
    "finished_requests": 95162,
    "scheduler_time": 106.0912914939639
}
#Debug simulation 
Total elapsed time: 43.895079581066966. Arrivals time: 0.35510243475437164 Scheduler time: 43.3974969452247 Scheduler overhead time: 0.05464155087247491 Adapter cache time: 0.010888433549553156 Engine time: 0.05534556182101369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 43.46017160825431,
    "estimated_duration": 3600.1311870692793,
    "input_throughput": 6543.565435785512,
    "output_throughput": 5800.768059510751,
    "total_throughput": 12344.333495296263,
    "itl": 148.68018179013362,
    "ttft": 1755440.7346209264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7603289708122637,
    "arrivals": 322758,
    "finished_requests": 95298,
    "scheduler_time": 106.39610149581246
}
#Debug simulation 
Total elapsed time: 43.46037037810311. Arrivals time: 0.3492476432584226 Scheduler time: 42.96930494112894 Scheduler overhead time: 0.05499824462458491 Adapter cache time: 0.01074212696403265 Engine time: 0.05473695043474436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.16079775709659,
    "estimated_duration": 3600.0983121179706,
    "input_throughput": 6360.918790167083,
    "output_throughput": 5633.6186519495795,
    "total_throughput": 11994.537442116663,
    "itl": 152.77932324772624,
    "ttft": 1710176.0718504125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30604877439327505,
    "arrivals": 287932,
    "finished_requests": 92701,
    "scheduler_time": 103.03079587835501
}
#Debug simulation 
Total elapsed time: 23.160889190156013. Arrivals time: 0.31254131672903895 Scheduler time: 22.725776251405478 Scheduler overhead time: 0.04716171231120825 Adapter cache time: 0.008557155728340149 Engine time: 0.04784452822059393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.266943411901593,
    "estimated_duration": 3600.0187448750044,
    "input_throughput": 6361.045211945168,
    "output_throughput": 5633.719554619761,
    "total_throughput": 11994.76476656493,
    "itl": 152.78008631181515,
    "ttft": 1710191.3867475698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3255637251888402,
    "arrivals": 287932,
    "finished_requests": 92700,
    "scheduler_time": 103.02833633853218
}
#Debug simulation 
Total elapsed time: 23.267049791757017. Arrivals time: 0.3175297058187425 Scheduler time: 22.827571423724294 Scheduler overhead time: 0.04652424203231931 Adapter cache time: 0.00846112659201026 Engine time: 0.04760921746492386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.182596562895924,
    "estimated_duration": 3600.0153224512087,
    "input_throughput": 6361.065425801494,
    "output_throughput": 5633.7485214342105,
    "total_throughput": 11994.813947235705,
    "itl": 152.77995799338345,
    "ttft": 1710178.0521336899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3262729720212524,
    "arrivals": 287932,
    "finished_requests": 92701,
    "scheduler_time": 103.02821167402566
}
#Debug simulation 
Total elapsed time: 23.182780582923442. Arrivals time: 0.3149860966950655 Scheduler time: 22.744146118871868 Scheduler overhead time: 0.04741381108760834 Adapter cache time: 0.008401163388043642 Engine time: 0.04797510802745819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 23.252004539128393,
    "estimated_duration": 3600.1087485136363,
    "input_throughput": 6360.900350428195,
    "output_throughput": 5633.602320589227,
    "total_throughput": 11994.502671017422,
    "itl": 152.7793284029734,
    "ttft": 1710181.1411563456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31248867499874916,
    "arrivals": 287932,
    "finished_requests": 92701,
    "scheduler_time": 103.03095632272625
}
#Debug simulation 
Total elapsed time: 23.252135565970093. Arrivals time: 0.3237357400357723 Scheduler time: 22.806092732120305 Scheduler overhead time: 0.04779264843091369 Adapter cache time: 0.008278244640678167 Engine time: 0.047283278312534094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 23.572101769968867,
    "estimated_duration": 3600.009268679307,
    "input_throughput": 6361.061955932411,
    "output_throughput": 5633.734384089637,
    "total_throughput": 11994.796340022049,
    "itl": 152.77960314552425,
    "ttft": 1710191.699128923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32691632684320215,
    "arrivals": 287932,
    "finished_requests": 92700,
    "scheduler_time": 103.02800667124629
}
#Debug simulation 
Total elapsed time: 23.572197292931378. Arrivals time: 0.32053304789587855 Scheduler time: 23.12624919693917 Scheduler overhead time: 0.047773484606295824 Adapter cache time: 0.008914610370993614 Engine time: 0.049326354172080755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.161991870962083,
    "estimated_duration": 3600.0332888810076,
    "input_throughput": 6361.033680085205,
    "output_throughput": 5633.720405486609,
    "total_throughput": 11994.754085571814,
    "itl": 152.77827138968357,
    "ttft": 1710176.4356454746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2960149791953157,
    "arrivals": 287932,
    "finished_requests": 92701,
    "scheduler_time": 103.0288865760624
}
#Debug simulation 
Total elapsed time: 23.162177844904363. Arrivals time: 0.3154829954728484 Scheduler time: 22.723973932210356 Scheduler overhead time: 0.04648709390312433 Adapter cache time: 0.008232749998569489 Engine time: 0.04872880736365914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.166271205060184,
    "estimated_duration": 3600.0162345907406,
    "input_throughput": 6361.049647489525,
    "output_throughput": 5633.723483001363,
    "total_throughput": 11994.773130490888,
    "itl": 152.7795965312423,
    "ttft": 1710195.2322567857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33094044800847733,
    "arrivals": 287932,
    "finished_requests": 92700,
    "scheduler_time": 103.02812797703082
}
#Debug simulation 
Total elapsed time: 23.166362044867128. Arrivals time: 0.3120798822492361 Scheduler time: 22.729991603642702 Scheduler overhead time: 0.04839277919381857 Adapter cache time: 0.00850810157135129 Engine time: 0.04823801899328828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.102085639722645,
    "estimated_duration": 3600.1476617112826,
    "input_throughput": 6322.310954651438,
    "output_throughput": 5636.584358974379,
    "total_throughput": 11958.895313625817,
    "itl": 153.52204195021952,
    "ttft": 1712768.7728248094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2601414582342838,
    "arrivals": 282072,
    "finished_requests": 92019,
    "scheduler_time": 102.97386811275759
}
#Debug simulation 
Total elapsed time: 14.102173659019172. Arrivals time: 0.2828604020178318 Scheduler time: 13.712183326017112 Scheduler overhead time: 0.041221892926841974 Adapter cache time: 0.007040291093289852 Engine time: 0.040912109427154064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.083906148560345,
    "estimated_duration": 3600.040962423584,
    "input_throughput": 6322.336394938486,
    "output_throughput": 5636.366422436425,
    "total_throughput": 11958.702817374911,
    "itl": 153.52134124338366,
    "ttft": 1712773.1938604861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2766270175809041,
    "arrivals": 282072,
    "finished_requests": 92015,
    "scheduler_time": 102.9704912929415
}
#Debug simulation 
Total elapsed time: 14.084080528002232. Arrivals time: 0.2824981682933867 Scheduler time: 13.69479305902496 Scheduler overhead time: 0.04002388846129179 Adapter cache time: 0.006941469851881266 Engine time: 0.04169688047841191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.111668137833476,
    "estimated_duration": 3600.0436929494053,
    "input_throughput": 6322.331599634804,
    "output_throughput": 5636.362147420517,
    "total_throughput": 11958.69374705532,
    "itl": 153.52135470063584,
    "ttft": 1712774.8133828898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2772477143444121,
    "arrivals": 282072,
    "finished_requests": 92015,
    "scheduler_time": 102.97056726876633
}
#Debug simulation 
Total elapsed time: 14.111770289950073. Arrivals time: 0.27991421101614833 Scheduler time: 13.725482873618603 Scheduler overhead time: 0.040643167681992054 Adapter cache time: 0.006913003046065569 Engine time: 0.040860957466065884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 14.097057638689876,
    "estimated_duration": 3600.002897748349,
    "input_throughput": 6322.403244240677,
    "output_throughput": 5636.426018626614,
    "total_throughput": 11958.829262867292,
    "itl": 153.5217712104529,
    "ttft": 1712766.6360557738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2655949439830148,
    "arrivals": 282072,
    "finished_requests": 92015,
    "scheduler_time": 102.96960764148892
}
#Debug simulation 
Total elapsed time: 14.097141107078642. Arrivals time: 0.30127157690003514 Scheduler time: 13.688459075987339 Scheduler overhead time: 0.04069793503731489 Adapter cache time: 0.006934764329344034 Engine time: 0.041615731082856655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.316412485670298,
    "estimated_duration": 3600.110425411794,
    "input_throughput": 6322.319126474157,
    "output_throughput": 5636.505440712675,
    "total_throughput": 11958.824567186832,
    "itl": 153.52321823082696,
    "ttft": 1712766.2487897517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2806430665776132,
    "arrivals": 282072,
    "finished_requests": 92018,
    "scheduler_time": 102.97274306166251
}
#Debug simulation 
Total elapsed time: 14.316540984902531. Arrivals time: 0.2885807091370225 Scheduler time: 13.920235109515488 Scheduler overhead time: 0.04108905512839556 Adapter cache time: 0.0070136431604623795 Engine time: 0.04149494878947735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.11674568708986,
    "estimated_duration": 3600.140757171278,
    "input_throughput": 6322.323079913157,
    "output_throughput": 5636.595169113432,
    "total_throughput": 11958.91824902659,
    "itl": 153.52235781351393,
    "ttft": 1712750.9222174454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2541542750666852,
    "arrivals": 282072,
    "finished_requests": 92019,
    "scheduler_time": 102.97379850017991
}
#Debug simulation 
Total elapsed time: 14.116878331173211. Arrivals time: 0.30198320420458913 Scheduler time: 13.707430011592805 Scheduler overhead time: 0.04105397779494524 Adapter cache time: 0.006925093941390514 Engine time: 0.04155704891309142 
