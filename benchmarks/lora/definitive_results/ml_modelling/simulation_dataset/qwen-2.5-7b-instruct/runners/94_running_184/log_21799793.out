INFO 06-01 00:47:08 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:08 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123244485 . Total output tokens: 110517912
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.071105199982412,
    "estimated_duration": 3600.0080345863275,
    "input_throughput": 4514.295202640413,
    "output_throughput": 3995.777193217554,
    "total_throughput": 8510.072395857967,
    "itl": 126.71645889361902,
    "ttft": 1839810.6150464404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 183717,
    "finished_requests": 65544,
    "scheduler_time": 29.782749259090984
}
#Debug simulation 
Total elapsed time: 5.071232225978747. Arrivals time: 0.21624810015782714 Scheduler time: 4.656959768733941 Scheduler overhead time: 0.04278713837265968 Adapter cache time: 0.09064970479812473 Engine time: 0.0444797242525965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.4720090080518275,
    "estimated_duration": 3600.0554360111096,
    "input_throughput": 4848.3475630418425,
    "output_throughput": 4303.040960159313,
    "total_throughput": 9151.388523201156,
    "itl": 200.10390954546048,
    "ttft": 1737030.1961304003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 179046,
    "finished_requests": 70726,
    "scheduler_time": 45.3996129671611
}
#Debug simulation 
Total elapsed time: 5.472103022970259. Arrivals time: 0.44175856350921094 Scheduler time: 4.911705548409373 Scheduler overhead time: 0.02829524257685989 Adapter cache time: 0.04754659614991397 Engine time: 0.029524119687266648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.28043986891862,
    "estimated_duration": 3600.18480938686,
    "input_throughput": 4848.283608799704,
    "output_throughput": 4303.1993689897445,
    "total_throughput": 9151.482977789448,
    "itl": 200.1043969071839,
    "ttft": 1737057.15669116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574654,
    "arrivals": 179046,
    "finished_requests": 70729,
    "scheduler_time": 45.40085426912408
}
#Debug simulation 
Total elapsed time: 5.280562964966521. Arrivals time: 0.22966712794732302 Scheduler time: 4.930882411659695 Scheduler overhead time: 0.02832416573073715 Adapter cache time: 0.04881573538295925 Engine time: 0.029555988032370806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.2188420430757105,
    "estimated_duration": 3600.1208263821936,
    "input_throughput": 4653.762417423199,
    "output_throughput": 4141.159621851335,
    "total_throughput": 8794.922039274534,
    "itl": 122.99677490427212,
    "ttft": 1783564.272168343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 179046,
    "finished_requests": 67883,
    "scheduler_time": 31.1356696002654
}
#Debug simulation 
Total elapsed time: 5.21894442604389. Arrivals time: 0.2145921060582623 Scheduler time: 4.816814273828641 Scheduler overhead time: 0.043121854425407946 Adapter cache time: 0.07837925245985389 Engine time: 0.04550040222238749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.276005950989202,
    "estimated_duration": 3600.187590637837,
    "input_throughput": 4848.169869089421,
    "output_throughput": 4303.002165855304,
    "total_throughput": 9151.172034944726,
    "itl": 200.1098907146083,
    "ttft": 1737064.1414499853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 179046,
    "finished_requests": 70727,
    "scheduler_time": 45.40015196841713
}
#Debug simulation 
Total elapsed time: 5.276107616024092. Arrivals time: 0.21664192609023303 Scheduler time: 4.940314993844368 Scheduler overhead time: 0.028241925174370408 Adapter cache time: 0.04802262410521507 Engine time: 0.029656718368642032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.240300167002715,
    "estimated_duration": 3600.1068454677925,
    "input_throughput": 4658.211469782343,
    "output_throughput": 4145.257804997418,
    "total_throughput": 8803.469274779762,
    "itl": 122.95720452704136,
    "ttft": 1782012.2105084215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 179046,
    "finished_requests": 67950,
    "scheduler_time": 31.208028128877835
}
#Debug simulation 
Total elapsed time: 5.240400844952092. Arrivals time: 0.21414341544732451 Scheduler time: 4.8376295760972425 Scheduler overhead time: 0.04337810550350696 Adapter cache time: 0.07907118345610797 Engine time: 0.04553615557961166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.273275231011212,
    "estimated_duration": 3600.1508691982026,
    "input_throughput": 4848.329315678756,
    "output_throughput": 4303.239937122504,
    "total_throughput": 9151.569252801259,
    "itl": 200.10083394891015,
    "ttft": 1737036.6430618926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 179046,
    "finished_requests": 70729,
    "scheduler_time": 45.401023554043356
}
#Debug simulation 
Total elapsed time: 5.27338624605909. Arrivals time: 0.22051331121474504 Scheduler time: 4.933296141447499 Scheduler overhead time: 0.028207046445459127 Adapter cache time: 0.04836727736983448 Engine time: 0.02969071944244206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 120059615 . Total output tokens: 107649944
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.241041579982266,
    "estimated_duration": 3600.111159002165,
    "input_throughput": 4656.512051879651,
    "output_throughput": 4143.648165612385,
    "total_throughput": 8800.160217492037,
    "itl": 123.09174380784725,
    "ttft": 1782910.1197282863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 179046,
    "finished_requests": 67925,
    "scheduler_time": 31.2128786438779
}
#Debug simulation 
Total elapsed time: 5.241174557013437. Arrivals time: 0.22304122301284224 Scheduler time: 4.828163341036998 Scheduler overhead time: 0.04314927873201668 Adapter cache time: 0.0807004343951121 Engine time: 0.045609142747707665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.46760783996433,
    "estimated_duration": 3600.0761300944205,
    "input_throughput": 5067.559779498752,
    "output_throughput": 4478.742231369733,
    "total_throughput": 9546.302010868485,
    "itl": 191.7975891970011,
    "ttft": 1692185.730779556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 176720,
    "finished_requests": 73710,
    "scheduler_time": 47.277692949653336
}
#Debug simulation 
Total elapsed time: 5.467716282000765. Arrivals time: 0.23009624041151255 Scheduler time: 5.121821389184333 Scheduler overhead time: 0.02929518569726497 Adapter cache time: 0.04203611344564706 Engine time: 0.030746583128347993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.494794808095321,
    "estimated_duration": 3600.0495048071493,
    "input_throughput": 5067.448926921704,
    "output_throughput": 4478.64869037786,
    "total_throughput": 9546.097617299563,
    "itl": 191.7995891623966,
    "ttft": 1692210.5714853872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 176720,
    "finished_requests": 73708,
    "scheduler_time": 47.27692839628928
}
#Debug simulation 
Total elapsed time: 5.494895218056627. Arrivals time: 0.22723716730251908 Scheduler time: 5.151626130682416 Scheduler overhead time: 0.02949850191362202 Adapter cache time: 0.04185085603967309 Engine time: 0.030824476620182395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.376875409041531,
    "estimated_duration": 3600.1132259553146,
    "input_throughput": 4823.283021992245,
    "output_throughput": 4273.331707759726,
    "total_throughput": 9096.614729751971,
    "itl": 118.8381782966314,
    "ttft": 1748608.5618173233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 176720,
    "finished_requests": 70144,
    "scheduler_time": 32.174788164273544
}
#Debug simulation 
Total elapsed time: 5.376974413054995. Arrivals time: 0.22209981677588075 Scheduler time: 4.972124453284778 Scheduler overhead time: 0.044565295218490064 Adapter cache time: 0.0696084537776187 Engine time: 0.04734570859000087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.499258472002111,
    "estimated_duration": 3600.193416852363,
    "input_throughput": 5067.7952230554265,
    "output_throughput": 4478.787701938969,
    "total_throughput": 9546.582924994396,
    "itl": 191.80081608486392,
    "ttft": 1692149.8896612502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 176720,
    "finished_requests": 73714,
    "scheduler_time": 47.279556909358796
}
#Debug simulation 
Total elapsed time: 5.499393796082586. Arrivals time: 0.2275659419829026 Scheduler time: 5.1550877501722425 Scheduler overhead time: 0.029549767612479627 Adapter cache time: 0.042206889018416405 Engine time: 0.03112005698494613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.369683128083125,
    "estimated_duration": 3600.0113811262418,
    "input_throughput": 4823.57475063523,
    "output_throughput": 4273.584544942997,
    "total_throughput": 9097.159295578227,
    "itl": 118.83933618716114,
    "ttft": 1748542.9708277336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 176720,
    "finished_requests": 70144,
    "scheduler_time": 32.173644494023286
}
#Debug simulation 
Total elapsed time: 5.369792019017041. Arrivals time: 0.22347244818229228 Scheduler time: 4.964522358146496 Scheduler overhead time: 0.044435354648157954 Adapter cache time: 0.06943181774113327 Engine time: 0.046821024967357516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.504638466052711,
    "estimated_duration": 3600.0537698536964,
    "input_throughput": 5067.591254544347,
    "output_throughput": 4478.770049219365,
    "total_throughput": 9546.361303763711,
    "itl": 191.79808828955362,
    "ttft": 1692160.1641515226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 176720,
    "finished_requests": 73710,
    "scheduler_time": 47.277499132587316
}
#Debug simulation 
Total elapsed time: 5.504739842028357. Arrivals time: 0.23453287116717547 Scheduler time: 5.153817214653827 Scheduler overhead time: 0.029549238388426602 Adapter cache time: 0.042202414479106665 Engine time: 0.03080924041569233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118470383 . Total output tokens: 106229005
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.39580652397126,
    "estimated_duration": 3600.024486793749,
    "input_throughput": 4823.119138132344,
    "output_throughput": 4273.153434492553,
    "total_throughput": 9096.272572624897,
    "itl": 118.83820105809252,
    "ttft": 1748611.993648967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 176720,
    "finished_requests": 70141,
    "scheduler_time": 32.172524035168514
}
#Debug simulation 
Total elapsed time: 5.3959290569182485. Arrivals time: 0.2295884492341429 Scheduler time: 4.983976741787046 Scheduler overhead time: 0.0445977826602757 Adapter cache time: 0.06952368188649416 Engine time: 0.047081093420274556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.5779389219824225,
    "estimated_duration": 3600.098806158855,
    "input_throughput": 5184.0827168609885,
    "output_throughput": 4564.683328103878,
    "total_throughput": 9748.766044964867,
    "itl": 187.5447322309039,
    "ttft": 1671165.513157151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 175562,
    "finished_requests": 75341,
    "scheduler_time": 48.12811441080407
}
#Debug simulation 
Total elapsed time: 5.578045792994089. Arrivals time: 0.23272650770377368 Scheduler time: 5.235165216377936 Scheduler overhead time: 0.03002360137179494 Adapter cache time: 0.03447225783020258 Engine time: 0.03154628712218255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.583690160070546,
    "estimated_duration": 3600.0842700970593,
    "input_throughput": 5184.103370862715,
    "output_throughput": 4564.6506490129905,
    "total_throughput": 9748.754019875705,
    "itl": 187.54850787167595,
    "ttft": 1671182.3600474515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 175562,
    "finished_requests": 75340,
    "scheduler_time": 48.127277050894975
}
#Debug simulation 
Total elapsed time: 5.583789800060913. Arrivals time: 0.2324680145829916 Scheduler time: 5.241785683319904 Scheduler overhead time: 0.030061861034482718 Adapter cache time: 0.03396473661996424 Engine time: 0.03125734406057745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.394538477063179,
    "estimated_duration": 3600.042634020578,
    "input_throughput": 4875.522815794428,
    "output_throughput": 4318.475801670502,
    "total_throughput": 9193.99861746493,
    "itl": 117.26956939433123,
    "ttft": 1738148.0850927685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 175562,
    "finished_requests": 70910,
    "scheduler_time": 32.452605395084255
}
#Debug simulation 
Total elapsed time: 5.394638025085442. Arrivals time: 0.23424285557121038 Scheduler time: 4.984198674443178 Scheduler overhead time: 0.045092278509400785 Adapter cache time: 0.06219049985520542 Engine time: 0.047518663108348846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.5906871480401605,
    "estimated_duration": 3600.1343691174716,
    "input_throughput": 5184.059006268447,
    "output_throughput": 4564.815730483021,
    "total_throughput": 9748.874736751468,
    "itl": 187.54523392324316,
    "ttft": 1671134.9962142757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 175562,
    "finished_requests": 75343,
    "scheduler_time": 48.12840888563811
}
#Debug simulation 
Total elapsed time: 5.590794650022872. Arrivals time: 0.23218164849095047 Scheduler time: 5.24865430558566 Scheduler overhead time: 0.029967337963171303 Adapter cache time: 0.03436370170675218 Engine time: 0.031448726425878704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.433185733039863,
    "estimated_duration": 3600.0017246578464,
    "input_throughput": 4876.300997235896,
    "output_throughput": 4318.9723753473345,
    "total_throughput": 9195.27337258323,
    "itl": 117.4228036293821,
    "ttft": 1737987.2796670292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 175562,
    "finished_requests": 70921,
    "scheduler_time": 32.512751873387515
}
#Debug simulation 
Total elapsed time: 5.433316598064266. Arrivals time: 0.23178062064107507 Scheduler time: 5.024197257240303 Scheduler overhead time: 0.045239784638397396 Adapter cache time: 0.06266027712263167 Engine time: 0.047951960819773376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.764621083042584,
    "estimated_duration": 3600.066230496889,
    "input_throughput": 5184.129347927042,
    "output_throughput": 4564.673522056805,
    "total_throughput": 9748.802869983847,
    "itl": 187.54557324453697,
    "ttft": 1671157.8972301069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 175562,
    "finished_requests": 75340,
    "scheduler_time": 48.12769262114742
}
#Debug simulation 
Total elapsed time: 5.764699388993904. Arrivals time: 0.2373384399106726 Scheduler time: 5.418125173775479 Scheduler overhead time: 0.029814396635629237 Adapter cache time: 0.03395224455744028 Engine time: 0.031475940137170255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117664903 . Total output tokens: 105498308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.417405904037878,
    "estimated_duration": 3600.108907783284,
    "input_throughput": 4876.641637713713,
    "output_throughput": 4319.087671593299,
    "total_throughput": 9195.729309307013,
    "itl": 117.47646760918202,
    "ttft": 1737952.385880673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 175562,
    "finished_requests": 70928,
    "scheduler_time": 32.53490404404967
}
#Debug simulation 
Total elapsed time: 5.417509926948696. Arrivals time: 0.22685087425634265 Scheduler time: 5.014240884920582 Scheduler overhead time: 0.04498696234077215 Adapter cache time: 0.0622367300093174 Engine time: 0.047717860783450305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.681696007959545,
    "estimated_duration": 3600.137122216814,
    "input_throughput": 5283.1421010675995,
    "output_throughput": 4644.5883677074535,
    "total_throughput": 9927.730468775053,
    "itl": 184.3408056869389,
    "ttft": 1647544.5918982828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48049657579744176,
    "arrivals": 174997,
    "finished_requests": 76368,
    "scheduler_time": 49.059252672518724
}
#Debug simulation 
Total elapsed time: 5.681831615976989. Arrivals time: 0.23613654961809516 Scheduler time: 5.337365389452316 Scheduler overhead time: 0.03066305536776781 Adapter cache time: 0.031153387972153723 Engine time: 0.03214763617143035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.6626353829633445,
    "estimated_duration": 3600.021363029733,
    "input_throughput": 5283.202815216992,
    "output_throughput": 4644.692993134858,
    "total_throughput": 9927.89580835185,
    "itl": 184.34075864135775,
    "ttft": 1647547.2267003066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5123404047358782,
    "arrivals": 174997,
    "finished_requests": 76366,
    "scheduler_time": 49.05775583336194
}
#Debug simulation 
Total elapsed time: 5.662743740947917. Arrivals time: 0.23654861946124583 Scheduler time: 5.318125086836517 Scheduler overhead time: 0.030589018017053604 Adapter cache time: 0.030964883277192712 Engine time: 0.03213679767213762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.479513718048111,
    "estimated_duration": 3600.108457539862,
    "input_throughput": 4963.591572519213,
    "output_throughput": 4370.77832114889,
    "total_throughput": 9334.369893668103,
    "itl": 116.17936857958625,
    "ttft": 1718612.4779405775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5132434461824613,
    "arrivals": 174997,
    "finished_requests": 71741,
    "scheduler_time": 33.10310038798506
}
#Debug simulation 
Total elapsed time: 5.479613821953535. Arrivals time: 0.2384003580082208 Scheduler time: 5.070330411777832 Scheduler overhead time: 0.04555163881741464 Adapter cache time: 0.0557690808782354 Engine time: 0.04792638402432203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.6901873900787905,
    "estimated_duration": 3600.1995596387337,
    "input_throughput": 5283.050476765401,
    "output_throughput": 4644.507817693835,
    "total_throughput": 9927.558294459235,
    "itl": 184.34156651489104,
    "ttft": 1647605.7235867134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49150204349542065,
    "arrivals": 174997,
    "finished_requests": 76368,
    "scheduler_time": 49.060069407484185
}
#Debug simulation 
Total elapsed time: 5.690306253032759. Arrivals time: 0.24137639347463846 Scheduler time: 5.340886586578563 Scheduler overhead time: 0.030584489461034536 Adapter cache time: 0.030987071222625673 Engine time: 0.032109370455145836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.435440766974352,
    "estimated_duration": 3600.039407623769,
    "input_throughput": 4963.521222061975,
    "output_throughput": 4370.721322294036,
    "total_throughput": 9334.242544356011,
    "itl": 116.17943725337724,
    "ttft": 1718669.9378832285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5196568892896184,
    "arrivals": 174997,
    "finished_requests": 71737,
    "scheduler_time": 33.10350244874216
}
#Debug simulation 
Total elapsed time: 5.435543747036718. Arrivals time: 0.22885757021140307 Scheduler time: 5.035072434227914 Scheduler overhead time: 0.045381492003798485 Adapter cache time: 0.0567119917832315 Engine time: 0.04789361369330436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.664732557954267,
    "estimated_duration": 3600.073182549442,
    "input_throughput": 5283.232877652421,
    "output_throughput": 4644.6266928826135,
    "total_throughput": 9927.859570535034,
    "itl": 184.33946032627395,
    "ttft": 1647538.9093368403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46943789629964217,
    "arrivals": 174997,
    "finished_requests": 76367,
    "scheduler_time": 49.05873545231382
}
#Debug simulation 
Total elapsed time: 5.664830600027926. Arrivals time: 0.23838964034803212 Scheduler time: 5.318284076987766 Scheduler overhead time: 0.03049460845068097 Adapter cache time: 0.03099908703006804 Engine time: 0.032242024200968444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117286699 . Total output tokens: 105141760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.461542717996053,
    "estimated_duration": 3600.093534821543,
    "input_throughput": 4963.758532147643,
    "output_throughput": 4370.956989810552,
    "total_throughput": 9334.715521958195,
    "itl": 116.17770787026905,
    "ttft": 1718650.7518153472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5264475937560199,
    "arrivals": 174997,
    "finished_requests": 71743,
    "scheduler_time": 33.10376654595182
}
#Debug simulation 
Total elapsed time: 5.461639050976373. Arrivals time: 0.23735080496408045 Scheduler time: 5.053769084624946 Scheduler overhead time: 0.04551964660640806 Adapter cache time: 0.05547175358515233 Engine time: 0.04792381380684674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.530964717036113,
    "estimated_duration": 3600.102066528246,
    "input_throughput": 5081.701202333526,
    "output_throughput": 4500.831559930128,
    "total_throughput": 9582.532762263654,
    "itl": 191.07309006425453,
    "ttft": 1671026.3171014264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 169522,
    "finished_requests": 73777,
    "scheduler_time": 47.68459103343096
}
#Debug simulation 
Total elapsed time: 5.531061645015143. Arrivals time: 0.23044663085602224 Scheduler time: 5.171472294256091 Scheduler overhead time: 0.029735541786067188 Adapter cache time: 0.05424252653028816 Engine time: 0.03128938004374504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.519999623997137,
    "estimated_duration": 3600.070294590963,
    "input_throughput": 5081.6666073123415,
    "output_throughput": 4500.870725870374,
    "total_throughput": 9582.537333182716,
    "itl": 191.07718314987773,
    "ttft": 1671033.37078703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 169522,
    "finished_requests": 73776,
    "scheduler_time": 47.68333913046907
}
#Debug simulation 
Total elapsed time: 5.520097665023059. Arrivals time: 0.22703028563410044 Scheduler time: 5.163816322223283 Scheduler overhead time: 0.02950434817466885 Adapter cache time: 0.05432610306888819 Engine time: 0.03147964598610997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.5226916269166395,
    "estimated_duration": 3600.00897814875,
    "input_throughput": 4921.101893781995,
    "output_throughput": 4375.874364652512,
    "total_throughput": 9296.976258434508,
    "itl": 115.97522587498042,
    "ttft": 1711247.7442334588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 169522,
    "finished_requests": 71452,
    "scheduler_time": 33.24532182872183
}
#Debug simulation 
Total elapsed time: 5.522794203949161. Arrivals time: 0.23419133725110441 Scheduler time: 5.095622397377156 Scheduler overhead time: 0.04560563247650862 Adapter cache time: 0.0772816491080448 Engine time: 0.04841640265658498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.5201481690164655,
    "estimated_duration": 3600.1662844825355,
    "input_throughput": 5081.779994123144,
    "output_throughput": 4500.999875990203,
    "total_throughput": 9582.779870113347,
    "itl": 191.07328213265617,
    "ttft": 1671004.658292535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 169522,
    "finished_requests": 73780,
    "scheduler_time": 47.6852610372996
}
#Debug simulation 
Total elapsed time: 5.520280507043935. Arrivals time: 0.22992778720799834 Scheduler time: 5.161820392939262 Scheduler overhead time: 0.029512355802580714 Adapter cache time: 0.05396589753217995 Engine time: 0.031105811591260135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.513632579008117,
    "estimated_duration": 3600.0770256863843,
    "input_throughput": 4921.134151740048,
    "output_throughput": 4375.983871344084,
    "total_throughput": 9297.118023084133,
    "itl": 115.97607367596756,
    "ttft": 1711259.8243521426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 169522,
    "finished_requests": 71454,
    "scheduler_time": 33.24565241982398
}
#Debug simulation 
Total elapsed time: 5.513742108014412. Arrivals time: 0.2306625305209309 Scheduler time: 5.091219355352223 Scheduler overhead time: 0.04581396747380495 Adapter cache time: 0.0758945191046223 Engine time: 0.04842261236626655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.549493272090331,
    "estimated_duration": 3600.0921233930153,
    "input_throughput": 5081.635795130134,
    "output_throughput": 4500.843435286475,
    "total_throughput": 9582.47923041661,
    "itl": 191.07631161307805,
    "ttft": 1671037.2747094214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 169522,
    "finished_requests": 73776,
    "scheduler_time": 47.68381001989473
}
#Debug simulation 
Total elapsed time: 5.549597870092839. Arrivals time: 0.23309767816681415 Scheduler time: 5.187281910795718 Scheduler overhead time: 0.029683934058994055 Adapter cache time: 0.05445446993689984 Engine time: 0.031222111196257174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113701235 . Total output tokens: 101957884
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.528828184935264,
    "estimated_duration": 3600.111527749993,
    "input_throughput": 4921.0867117420885,
    "output_throughput": 4375.659164605177,
    "total_throughput": 9296.745876347266,
    "itl": 115.97234095412348,
    "ttft": 1711273.429342421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 169522,
    "finished_requests": 71453,
    "scheduler_time": 33.24655453725249
}
#Debug simulation 
Total elapsed time: 5.528942415956408. Arrivals time: 0.2342608334729448 Scheduler time: 5.101885094074532 Scheduler overhead time: 0.045883792103268206 Adapter cache time: 0.07642052683513612 Engine time: 0.04863765148911625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.741427376982756,
    "estimated_duration": 3600.0164801240044,
    "input_throughput": 5397.391402866772,
    "output_throughput": 4714.675083769439,
    "total_throughput": 10112.066486636211,
    "itl": 180.6509535135992,
    "ttft": 1600501.1665876394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 167239,
    "finished_requests": 77960,
    "scheduler_time": 49.95190489030508
}
#Debug simulation 
Total elapsed time: 5.741536634042859. Arrivals time: 0.23602570546790957 Scheduler time: 5.3803242925787345 Scheduler overhead time: 0.03103263082448393 Adapter cache time: 0.046832891064696014 Engine time: 0.032672762288711965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.005563725018874,
    "estimated_duration": 3600.0123269979836,
    "input_throughput": 5397.397629525085,
    "output_throughput": 4714.680522817417,
    "total_throughput": 10112.078152342501,
    "itl": 180.6545337769717,
    "ttft": 1600478.9094301488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 167239,
    "finished_requests": 77960,
    "scheduler_time": 49.951503915738634
}
#Debug simulation 
Total elapsed time: 6.005640120944008. Arrivals time: 0.24761535855941474 Scheduler time: 5.631697530741803 Scheduler overhead time: 0.03127344977110624 Adapter cache time: 0.047337708063423634 Engine time: 0.03311789676081389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.69192530203145,
    "estimated_duration": 3600.092270182198,
    "input_throughput": 5165.940093823978,
    "output_throughput": 4527.95005700646,
    "total_throughput": 9693.890150830439,
    "itl": 111.80869495200862,
    "ttft": 1651377.8448325628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 167239,
    "finished_requests": 74657,
    "scheduler_time": 34.61773227122036
}
#Debug simulation 
Total elapsed time: 5.692025847965851. Arrivals time: 0.24130569386761636 Scheduler time: 5.2640556511469185 Scheduler overhead time: 0.0472840458387509 Adapter cache time: 0.06693985569290817 Engine time: 0.050026216194964945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.770383188966662,
    "estimated_duration": 3600.1221264006263,
    "input_throughput": 5397.271347410316,
    "output_throughput": 4714.538675100277,
    "total_throughput": 10111.810022510594,
    "itl": 180.65380407687903,
    "ttft": 1600507.0888281318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 167239,
    "finished_requests": 77961,
    "scheduler_time": 49.95321455914165
}
#Debug simulation 
Total elapsed time: 5.770511779934168. Arrivals time: 0.24052924499846995 Scheduler time: 5.403840555227362 Scheduler overhead time: 0.03104235022328794 Adapter cache time: 0.04757625749334693 Engine time: 0.03278627374675125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.656899844063446,
    "estimated_duration": 3600.04627417986,
    "input_throughput": 5166.056373605055,
    "output_throughput": 4528.108462637381,
    "total_throughput": 9694.164836242437,
    "itl": 111.81080674917979,
    "ttft": 1651314.6225954734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 167239,
    "finished_requests": 74658,
    "scheduler_time": 34.61838238251784
}
#Debug simulation 
Total elapsed time: 5.657034025993198. Arrivals time: 0.23654951236676425 Scheduler time: 5.234127613133751 Scheduler overhead time: 0.047419233713299036 Adapter cache time: 0.066353325615637 Engine time: 0.05004253005608916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.774710914003663,
    "estimated_duration": 3600.0102044524892,
    "input_throughput": 5397.400811799958,
    "output_throughput": 4714.683302566177,
    "total_throughput": 10112.084114366135,
    "itl": 180.65210391733186,
    "ttft": 1600485.0919988477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 167239,
    "finished_requests": 77960,
    "scheduler_time": 49.951742606308315
}
#Debug simulation 
Total elapsed time: 5.774811328970827. Arrivals time: 0.2379630736541003 Scheduler time: 5.41052912408486 Scheduler overhead time: 0.031122867832891643 Adapter cache time: 0.04776058974675834 Engine time: 0.03279199043754488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 112121278 . Total output tokens: 100538812
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.655607093940489,
    "estimated_duration": 3600.1173614348722,
    "input_throughput": 5166.126582214328,
    "output_throughput": 4528.005440773434,
    "total_throughput": 9694.132022987762,
    "itl": 111.8081493544433,
    "ttft": 1651309.132319186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 167239,
    "finished_requests": 74658,
    "scheduler_time": 34.61729323686341
}
#Debug simulation 
Total elapsed time: 5.655705554992892. Arrivals time: 0.2342926519922912 Scheduler time: 5.235799485701136 Scheduler overhead time: 0.047079649404622614 Adapter cache time: 0.06643971242010593 Engine time: 0.04979798337444663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.9273368830326945,
    "estimated_duration": 3600.1386166097773,
    "input_throughput": 5466.363686443882,
    "output_throughput": 4848.963570308042,
    "total_throughput": 10315.327256751923,
    "itl": 177.35152119980208,
    "ttft": 1569331.128928419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 166072,
    "finished_requests": 79762,
    "scheduler_time": 51.70380320543618
}
#Debug simulation 
Total elapsed time: 5.927474354044534. Arrivals time: 0.26225252531003207 Scheduler time: 5.543363458942622 Scheduler overhead time: 0.031705902656540275 Adapter cache time: 0.0420524732908234 Engine time: 0.033206865191459656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.9327901270007715,
    "estimated_duration": 3600.0983042715525,
    "input_throughput": 5466.42461864163,
    "output_throughput": 4848.919258479022,
    "total_throughput": 10315.343877120651,
    "itl": 177.35418315509037,
    "ttft": 1569354.5646647424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 166072,
    "finished_requests": 79761,
    "scheduler_time": 51.7025449162119
}
#Debug simulation 
Total elapsed time: 5.932897594058886. Arrivals time: 0.2521449467167258 Scheduler time: 5.5587409066502005 Scheduler overhead time: 0.03179896995425224 Adapter cache time: 0.04157548665534705 Engine time: 0.03358905133791268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.751510826055892,
    "estimated_duration": 3600.045335346495,
    "input_throughput": 5197.7089889061135,
    "output_throughput": 4617.508517680946,
    "total_throughput": 9815.21750658706,
    "itl": 110.12136358359278,
    "ttft": 1630582.5680173077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 166072,
    "finished_requests": 75762,
    "scheduler_time": 35.586779059246034
}
#Debug simulation 
Total elapsed time: 5.751618613023311. Arrivals time: 0.24023584509268403 Scheduler time: 5.329217528924346 Scheduler overhead time: 0.047928400337696075 Adapter cache time: 0.06095897709019482 Engine time: 0.05051729211118072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.916126076946966,
    "estimated_duration": 3600.2008615044597,
    "input_throughput": 5466.269454692652,
    "output_throughput": 4848.951953393219,
    "total_throughput": 10315.221408085872,
    "itl": 177.35387631840578,
    "ttft": 1569322.1867512057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 166072,
    "finished_requests": 79763,
    "scheduler_time": 51.70432767235282
}
#Debug simulation 
Total elapsed time: 5.91624139691703. Arrivals time: 0.24883710104040802 Scheduler time: 5.545479797408916 Scheduler overhead time: 0.03172108193393797 Adapter cache time: 0.04184021323453635 Engine time: 0.03346688696183264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.782273018034175,
    "estimated_duration": 3600.095433411508,
    "input_throughput": 5197.587493470524,
    "output_throughput": 4617.32732019494,
    "total_throughput": 9814.914813665464,
    "itl": 110.11112274771561,
    "ttft": 1630620.382211725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 166072,
    "finished_requests": 75760,
    "scheduler_time": 35.58436010723767
}
#Debug simulation 
Total elapsed time: 5.7823835760355. Arrivals time: 0.2508016793290153 Scheduler time: 5.350556282675825 Scheduler overhead time: 0.0480656479485333 Adapter cache time: 0.05971837812103331 Engine time: 0.05039631447289139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.899147121002898,
    "estimated_duration": 3600.115404360752,
    "input_throughput": 5466.398931590467,
    "output_throughput": 4848.994834680781,
    "total_throughput": 10315.393766271249,
    "itl": 177.3521228170266,
    "ttft": 1569320.4545333213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 166072,
    "finished_requests": 79762,
    "scheduler_time": 51.703729111196104
}
#Debug simulation 
Total elapsed time: 5.899250548915006. Arrivals time: 0.2381226207362488 Scheduler time: 5.54032374417875 Scheduler overhead time: 0.031539877876639366 Adapter cache time: 0.04139739880338311 Engine time: 0.03305723599623889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111319766 . Total output tokens: 99798210
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.997520618024282,
    "estimated_duration": 3600.083911957264,
    "input_throughput": 5197.653292983057,
    "output_throughput": 4617.459038881795,
    "total_throughput": 9815.112331864853,
    "itl": 110.11876853493125,
    "ttft": 1630551.8664133365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 166072,
    "finished_requests": 75762,
    "scheduler_time": 35.58754474205052
}
#Debug simulation 
Total elapsed time: 5.997600040980615. Arrivals time: 0.24538088054396212 Scheduler time: 5.569802243844606 Scheduler overhead time: 0.04799117869697511 Adapter cache time: 0.06070408981759101 Engine time: 0.05068231001496315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.952374582993798,
    "estimated_duration": 3600.003205108459,
    "input_throughput": 5580.4953094186885,
    "output_throughput": 4901.043414340082,
    "total_throughput": 10481.538723758771,
    "itl": 174.50430616541837,
    "ttft": 1565031.7261607826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 165445,
    "finished_requests": 80567,
    "scheduler_time": 52.0657765271294
}
#Debug simulation 
Total elapsed time: 5.95250605000183. Arrivals time: 0.24679972231388092 Scheduler time: 5.584955104044639 Scheduler overhead time: 0.03191873128525913 Adapter cache time: 0.03985134675167501 Engine time: 0.03392363456077874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.9921945800306275,
    "estimated_duration": 3600.012777193733,
    "input_throughput": 5580.4801936454005,
    "output_throughput": 4901.029827386778,
    "total_throughput": 10481.51002103218,
    "itl": 174.50856420355862,
    "ttft": 1565018.449350437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 165445,
    "finished_requests": 80566,
    "scheduler_time": 52.065217919382924
}
#Debug simulation 
Total elapsed time: 5.99229672702495. Arrivals time: 0.2467431533150375 Scheduler time: 5.625527299940586 Scheduler overhead time: 0.032073249691165984 Adapter cache time: 0.03880219138227403 Engine time: 0.03406198404263705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.79348095995374,
    "estimated_duration": 3600.0386575314947,
    "input_throughput": 5258.3582569027985,
    "output_throughput": 4645.907889074849,
    "total_throughput": 9904.266145977648,
    "itl": 108.96273367864363,
    "ttft": 1632789.2306206205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 165445,
    "finished_requests": 76007,
    "scheduler_time": 35.594644167674964
}
#Debug simulation 
Total elapsed time: 5.793579458957538. Arrivals time: 0.24275990354362875 Scheduler time: 5.3716559710446745 Scheduler overhead time: 0.04833096743095666 Adapter cache time: 0.05666381341870874 Engine time: 0.05116369703318924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.988008221029304,
    "estimated_duration": 3600.1160619783504,
    "input_throughput": 5580.5864739148565,
    "output_throughput": 4900.988383775641,
    "total_throughput": 10481.574857690497,
    "itl": 174.50756446772547,
    "ttft": 1565044.2078777002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 165445,
    "finished_requests": 80569,
    "scheduler_time": 52.06636356267389
}
#Debug simulation 
Total elapsed time: 5.988178513012826. Arrivals time: 0.25237026542890817 Scheduler time: 5.614827289478853 Scheduler overhead time: 0.03214378049597144 Adapter cache time: 0.03939809906296432 Engine time: 0.03417714324314147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.756693001021631,
    "estimated_duration": 3600.0264041425503,
    "input_throughput": 5258.63115287595,
    "output_throughput": 4646.147034019835,
    "total_throughput": 9904.778186895785,
    "itl": 108.96382722173084,
    "ttft": 1632681.9460474956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 165445,
    "finished_requests": 76010,
    "scheduler_time": 35.59605050827996
}
#Debug simulation 
Total elapsed time: 5.756794685032219. Arrivals time: 0.23725900787394494 Scheduler time: 5.340800281846896 Scheduler overhead time: 0.04831950843799859 Adapter cache time: 0.05605656548868865 Engine time: 0.05139740160666406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.961814771988429,
    "estimated_duration": 3600.1812818457975,
    "input_throughput": 5580.485377586196,
    "output_throughput": 4900.89959885407,
    "total_throughput": 10481.384976440266,
    "itl": 174.50487061468914,
    "ttft": 1565091.1517385691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 165445,
    "finished_requests": 80569,
    "scheduler_time": 52.06844421826367
}
#Debug simulation 
Total elapsed time: 5.961918683024123. Arrivals time: 0.24227793351747096 Scheduler time: 5.599302217364311 Scheduler overhead time: 0.03224297205451876 Adapter cache time: 0.03892052860464901 Engine time: 0.03409372386522591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110918909 . Total output tokens: 99458983
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.790754472021945,
    "estimated_duration": 3600.000921893511,
    "input_throughput": 5258.413097861969,
    "output_throughput": 4645.927976930318,
    "total_throughput": 9904.341074792286,
    "itl": 108.96200362593179,
    "ttft": 1632723.784701561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 165445,
    "finished_requests": 76006,
    "scheduler_time": 35.59439925487395
}
#Debug simulation 
Total elapsed time: 5.790858102962375. Arrivals time: 0.23789757466875017 Scheduler time: 5.372608297271654 Scheduler overhead time: 0.048178901546634734 Adapter cache time: 0.05794194177724421 Engine time: 0.05128003703430295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.094195875921287,
    "estimated_duration": 3600.013577306938,
    "input_throughput": 5678.006641100289,
    "output_throughput": 5010.938045821141,
    "total_throughput": 10688.94468692143,
    "itl": 171.44101055481127,
    "ttft": 1529384.6626333604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 162486,
    "finished_requests": 82283,
    "scheduler_time": 53.3746550064657
}
#Debug simulation 
Total elapsed time: 6.094298848998733. Arrivals time: 0.24611007841303945 Scheduler time: 5.720630855299532 Scheduler overhead time: 0.032781149726361036 Adapter cache time: 0.044885040377266705 Engine time: 0.034514613333158195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.112235629931092,
    "estimated_duration": 3600.1357599161915,
    "input_throughput": 5678.428638056666,
    "output_throughput": 5010.9171439745805,
    "total_throughput": 10689.345782031247,
    "itl": 171.43997226526648,
    "ttft": 1529357.6908980669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 162486,
    "finished_requests": 82288,
    "scheduler_time": 53.37624309071179
}
#Debug simulation 
Total elapsed time: 6.112362091895193. Arrivals time: 0.24719286512117833 Scheduler time: 5.737951954943128 Scheduler overhead time: 0.03262632165569812 Adapter cache time: 0.044416324933990836 Engine time: 0.03473007050342858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.908207689994015,
    "estimated_duration": 3600.0449438771957,
    "input_throughput": 5382.88863114289,
    "output_throughput": 4762.984148062601,
    "total_throughput": 10145.87277920549,
    "itl": 106.36724864962605,
    "ttft": 1592967.0649369212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 162486,
    "finished_requests": 77975,
    "scheduler_time": 36.654621820504246
}
#Debug simulation 
Total elapsed time: 5.908306194934994. Arrivals time: 0.23994407756254077 Scheduler time: 5.4857074548490345 Scheduler overhead time: 0.04931956960354 Adapter cache time: 0.05770620913244784 Engine time: 0.05208434723317623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.115819582948461,
    "estimated_duration": 3600.088231313281,
    "input_throughput": 5678.503605047071,
    "output_throughput": 5010.983298434097,
    "total_throughput": 10689.486903481167,
    "itl": 171.44050330845786,
    "ttft": 1529354.8453980652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 162486,
    "finished_requests": 82288,
    "scheduler_time": 53.37580431990588
}
#Debug simulation 
Total elapsed time: 6.115919888019562. Arrivals time: 0.24736377829685807 Scheduler time: 5.740767097915523 Scheduler overhead time: 0.03278797387611121 Adapter cache time: 0.04483558866195381 Engine time: 0.0347965843975544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.917453150963411,
    "estimated_duration": 3600.105991875665,
    "input_throughput": 5383.18900713891,
    "output_throughput": 4763.248092888994,
    "total_throughput": 10146.437100027902,
    "itl": 106.36457441965446,
    "ttft": 1593036.773095175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 162486,
    "finished_requests": 77981,
    "scheduler_time": 36.654352365954374
}
#Debug simulation 
Total elapsed time: 5.917588570970111. Arrivals time: 0.24025104113388807 Scheduler time: 5.494883659644984 Scheduler overhead time: 0.04951488855294883 Adapter cache time: 0.05676363466773182 Engine time: 0.05255426233634353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.109759364044294,
    "estimated_duration": 3600.1333026128996,
    "input_throughput": 5678.432513919089,
    "output_throughput": 5010.920564221044,
    "total_throughput": 10689.353078140133,
    "itl": 171.43842362530935,
    "ttft": 1529344.3701350407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 162486,
    "finished_requests": 82288,
    "scheduler_time": 53.37661429996688
}
#Debug simulation 
Total elapsed time: 6.10986198997125. Arrivals time: 0.2445637711789459 Scheduler time: 5.73740984138567 Scheduler overhead time: 0.0326902320375666 Adapter cache time: 0.04393022146541625 Engine time: 0.03590639878530055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108923580 . Total output tokens: 97705388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.9371144929900765,
    "estimated_duration": 3600.0151870651357,
    "input_throughput": 5383.080068558991,
    "output_throughput": 4763.098517364602,
    "total_throughput": 10146.178585923593,
    "itl": 106.36538028318195,
    "ttft": 1592895.1299353454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 162486,
    "finished_requests": 77976,
    "scheduler_time": 36.65350304744577
}
#Debug simulation 
Total elapsed time: 5.937213397002779. Arrivals time: 0.23885307647287846 Scheduler time: 5.5164259823504835 Scheduler overhead time: 0.04945302684791386 Adapter cache time: 0.05675082735251635 Engine time: 0.05223572195973247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.310607816907577,
    "estimated_duration": 3600.170723216466,
    "input_throughput": 5914.421464151141,
    "output_throughput": 5169.654283331315,
    "total_throughput": 11084.075747482455,
    "itl": 164.6393570999418,
    "ttft": 1480801.2325295194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 161281,
    "finished_requests": 85438,
    "scheduler_time": 55.1629564668471
}
#Debug simulation 
Total elapsed time: 6.310707075987011. Arrivals time: 0.25434199708979577 Scheduler time: 5.930424178484827 Scheduler overhead time: 0.03410572709981352 Adapter cache time: 0.039726221235468984 Engine time: 0.03607088327407837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.291483185021207,
    "estimated_duration": 3600.1139119329196,
    "input_throughput": 5914.306747190708,
    "output_throughput": 5169.5055921182675,
    "total_throughput": 11083.812339308975,
    "itl": 164.64128669906992,
    "ttft": 1480843.6069429496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 161281,
    "finished_requests": 85434,
    "scheduler_time": 55.16162773012507
}
#Debug simulation 
Total elapsed time: 6.2916151490062475. Arrivals time: 0.2551091528730467 Scheduler time: 5.9105928329518065 Scheduler overhead time: 0.03394379117526114 Adapter cache time: 0.040255641215480864 Engine time: 0.035714325262233615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.048264057957567,
    "estimated_duration": 3600.083195734689,
    "input_throughput": 5560.3701113676225,
    "output_throughput": 4869.833291844853,
    "total_throughput": 10430.203403212476,
    "itl": 103.56085290938016,
    "ttft": 1557841.0954613816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 161281,
    "finished_requests": 80313,
    "scheduler_time": 37.67947850748226
}
#Debug simulation 
Total elapsed time: 6.048367743962444. Arrivals time: 0.2540407886262983 Scheduler time: 5.617596960044466 Scheduler overhead time: 0.05051894439384341 Adapter cache time: 0.04853954154532403 Engine time: 0.053627803921699524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.273836835986003,
    "estimated_duration": 3600.0495215208075,
    "input_throughput": 5914.193088934413,
    "output_throughput": 5169.283891444503,
    "total_throughput": 11083.476980378915,
    "itl": 164.6413399868973,
    "ttft": 1480811.302862851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 161281,
    "finished_requests": 85428,
    "scheduler_time": 55.16076135120035
}
#Debug simulation 
Total elapsed time: 6.273937092977576. Arrivals time: 0.2566295665455982 Scheduler time: 5.89196322998032 Scheduler overhead time: 0.034057432785630226 Adapter cache time: 0.03961117775179446 Engine time: 0.03573527233675122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.0537120319204405,
    "estimated_duration": 3600.054674822691,
    "input_throughput": 5560.416940330472,
    "output_throughput": 4869.91381620155,
    "total_throughput": 10430.330756532021,
    "itl": 103.55611740716975,
    "ttft": 1557856.9087329064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978164,
    "arrivals": 161281,
    "finished_requests": 80312,
    "scheduler_time": 37.67730807521112
}
#Debug simulation 
Total elapsed time: 6.05384513491299. Arrivals time: 0.2542130999499932 Scheduler time: 5.623750230530277 Scheduler overhead time: 0.05061017943080515 Adapter cache time: 0.04780635458882898 Engine time: 0.053439210867509246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.284594566910528,
    "estimated_duration": 3600.0977189795494,
    "input_throughput": 5914.433624328227,
    "output_throughput": 5169.557176707769,
    "total_throughput": 11083.990801035996,
    "itl": 164.63742043522845,
    "ttft": 1480819.3674877828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 161281,
    "finished_requests": 85436,
    "scheduler_time": 55.16247089989367
}
#Debug simulation 
Total elapsed time: 6.284704167977907. Arrivals time: 0.25527517672162503 Scheduler time: 5.904204036458395 Scheduler overhead time: 0.03387440147344023 Adapter cache time: 0.03953534935135394 Engine time: 0.03582951310090721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 108100252 . Total output tokens: 96978099
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.026517307967879,
    "estimated_duration": 3600.048085574925,
    "input_throughput": 5560.4243399441075,
    "output_throughput": 4869.880785828499,
    "total_throughput": 10430.305125772606,
    "itl": 103.5592451192641,
    "ttft": 1557824.4556756327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 161281,
    "finished_requests": 80313,
    "scheduler_time": 37.67819094721987
}
#Debug simulation 
Total elapsed time: 6.026621307944879. Arrivals time: 0.24700804450549185 Scheduler time: 5.603357169311494 Scheduler overhead time: 0.05041674105450511 Adapter cache time: 0.04860109474975616 Engine time: 0.05330734606832266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.364274801919237,
    "estimated_duration": 3600.0612137367802,
    "input_throughput": 5896.718899944831,
    "output_throughput": 5241.391709674312,
    "total_throughput": 11138.110609619143,
    "itl": 164.56178816503936,
    "ttft": 1457984.0098532345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 160680,
    "finished_requests": 85972,
    "scheduler_time": 56.33959359294593
}
#Debug simulation 
Total elapsed time: 6.364380388986319. Arrivals time: 0.2529329580720514 Scheduler time: 5.9898217098088935 Scheduler overhead time: 0.034135345253162086 Adapter cache time: 0.035570570384152234 Engine time: 0.035893493331968784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.574112201924436,
    "estimated_duration": 3600.143051423281,
    "input_throughput": 5896.694852613522,
    "output_throughput": 5241.330894487683,
    "total_throughput": 11138.025747101205,
    "itl": 164.56219218820854,
    "ttft": 1458006.461787745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 160680,
    "finished_requests": 85973,
    "scheduler_time": 56.3407889885734
}
#Debug simulation 
Total elapsed time: 6.574189885985106. Arrivals time: 0.27417555544525385 Scheduler time: 6.178029737784527 Scheduler overhead time: 0.03410820208955556 Adapter cache time: 0.03605858434457332 Engine time: 0.03576587210409343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.079302689991891,
    "estimated_duration": 3600.0294093214243,
    "input_throughput": 5530.201489035241,
    "output_throughput": 4924.765879438142,
    "total_throughput": 10454.967368473383,
    "itl": 103.61047231229753,
    "ttft": 1542163.292267667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 160680,
    "finished_requests": 80595,
    "scheduler_time": 38.63541101088038
}
#Debug simulation 
Total elapsed time: 6.079404709045775. Arrivals time: 0.2455829819664359 Scheduler time: 5.661805029492825 Scheduler overhead time: 0.05062678502872586 Adapter cache time: 0.044084473978728056 Engine time: 0.05331088602542877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.340846895007417,
    "estimated_duration": 3600.084433144238,
    "input_throughput": 5896.680867970485,
    "output_throughput": 5241.357904353349,
    "total_throughput": 11138.038772323835,
    "itl": 164.56164904102206,
    "ttft": 1457986.1000018176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 160680,
    "finished_requests": 85972,
    "scheduler_time": 56.33985697955076
}
#Debug simulation 
Total elapsed time: 6.340959722991101. Arrivals time: 0.2522455675061792 Scheduler time: 5.96731791307684 Scheduler overhead time: 0.03391546697821468 Adapter cache time: 0.0353372604586184 Engine time: 0.03611844277475029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.074227651930414,
    "estimated_duration": 3600.0541948603104,
    "input_throughput": 5530.125082123243,
    "output_throughput": 4924.748084434861,
    "total_throughput": 10454.873166558104,
    "itl": 103.60809235124113,
    "ttft": 1542146.2109706218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 160680,
    "finished_requests": 80596,
    "scheduler_time": 38.63408183426487
}
#Debug simulation 
Total elapsed time: 6.074394755996764. Arrivals time: 0.24724933702964336 Scheduler time: 5.654976116493344 Scheduler overhead time: 0.0504633974051103 Adapter cache time: 0.044214617111720145 Engine time: 0.05326140986289829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.360820232075639,
    "estimated_duration": 3600.0460074161642,
    "input_throughput": 5896.743807237124,
    "output_throughput": 5241.413848914379,
    "total_throughput": 11138.157656151503,
    "itl": 164.56226102876133,
    "ttft": 1457975.8521420301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 160680,
    "finished_requests": 85972,
    "scheduler_time": 56.33964807206536
}
#Debug simulation 
Total elapsed time: 6.360922166029923. Arrivals time: 0.2525833082618192 Scheduler time: 5.986605020239949 Scheduler overhead time: 0.03403346089180559 Adapter cache time: 0.03552179865073413 Engine time: 0.036020142142660916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107713687 . Total output tokens: 96635109
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.092871443950571,
    "estimated_duration": 3600.0671722167085,
    "input_throughput": 5530.050981726958,
    "output_throughput": 4924.6756107285155,
    "total_throughput": 10454.726592455474,
    "itl": 103.60736747782016,
    "ttft": 1542194.429264027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 160680,
    "finished_requests": 80596,
    "scheduler_time": 38.63474292327867
}
#Debug simulation 
Total elapsed time: 6.092970106983557. Arrivals time: 0.24624447035603225 Scheduler time: 5.674782332382165 Scheduler overhead time: 0.05056120583321899 Adapter cache time: 0.043887289240956306 Engine time: 0.05341303476598114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.57340323808603,
    "estimated_duration": 3600.029920010989,
    "input_throughput": 6088.539953004916,
    "output_throughput": 5414.456388723708,
    "total_throughput": 11502.996341728625,
    "itl": 159.16863561393038,
    "ttft": 1419729.2196282293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 158932,
    "finished_requests": 88694,
    "scheduler_time": 58.321808519100436
}
#Debug simulation 
Total elapsed time: 6.573519623023458. Arrivals time: 0.27983151108492166 Scheduler time: 6.172484414302744 Scheduler overhead time: 0.034982694196514785 Adapter cache time: 0.03220539819449186 Engine time: 0.037408860749565065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.562635077978484,
    "estimated_duration": 3600.157539754878,
    "input_throughput": 6088.6041118890735,
    "output_throughput": 5414.378338934352,
    "total_throughput": 11502.982450823425,
    "itl": 159.16960972901813,
    "ttft": 1419782.7017146118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 158932,
    "finished_requests": 88697,
    "scheduler_time": 58.32346320504949
}
#Debug simulation 
Total elapsed time: 6.562764934962615. Arrivals time: 0.26316615333780646 Scheduler time: 6.178941782563925 Scheduler overhead time: 0.03507136832922697 Adapter cache time: 0.032038673060014844 Engine time: 0.03695149801205844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.214745589997619,
    "estimated_duration": 3600.0122511858,
    "input_throughput": 5652.565208159274,
    "output_throughput": 5038.3103540899265,
    "total_throughput": 10690.8755622492,
    "itl": 100.76371053486596,
    "ttft": 1513758.9592622388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 158932,
    "finished_requests": 82284,
    "scheduler_time": 39.41426870471607
}
#Debug simulation 
Total elapsed time: 6.214848469942808. Arrivals time: 0.25142155890353024 Scheduler time: 5.7938583713257685 Scheduler overhead time: 0.052093369886279106 Adapter cache time: 0.037588634295389056 Engine time: 0.05500266724266112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.539758083061315,
    "estimated_duration": 3600.060187781205,
    "input_throughput": 6088.570706232912,
    "output_throughput": 5414.427810445442,
    "total_throughput": 11502.998516678354,
    "itl": 159.16909651163138,
    "ttft": 1419753.0519261172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 158932,
    "finished_requests": 88695,
    "scheduler_time": 58.32279267755692
}
#Debug simulation 
Total elapsed time: 6.539863272104412. Arrivals time: 0.2580584733514115 Scheduler time: 6.1613342149648815 Scheduler overhead time: 0.03484267380554229 Adapter cache time: 0.03208899183664471 Engine time: 0.0370044904993847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.428887036978267,
    "estimated_duration": 3600.1028064350185,
    "input_throughput": 5652.75996108344,
    "output_throughput": 5038.462781556515,
    "total_throughput": 10691.222742639955,
    "itl": 100.76614513268652,
    "ttft": 1513754.9490396273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 158932,
    "finished_requests": 82288,
    "scheduler_time": 39.415192998637394
}
#Debug simulation 
Total elapsed time: 6.429007499013096. Arrivals time: 0.25613401364535093 Scheduler time: 6.0039033711655065 Scheduler overhead time: 0.05185993143822998 Adapter cache time: 0.03738309384789318 Engine time: 0.05486572638619691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.558875725022517,
    "estimated_duration": 3600.1692229221585,
    "input_throughput": 6088.621851560656,
    "output_throughput": 5414.361323876431,
    "total_throughput": 11502.983175437086,
    "itl": 159.16727188368353,
    "ttft": 1419777.9451443625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 158932,
    "finished_requests": 88698,
    "scheduler_time": 58.323735430623266
}
#Debug simulation 
Total elapsed time: 6.558985278010368. Arrivals time: 0.2775096584809944 Scheduler time: 6.160168342874385 Scheduler overhead time: 0.035017152898944914 Adapter cache time: 0.032405443489551544 Engine time: 0.037223384832032025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 135, 66, 66, 66, 8640, 66, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 66, 8640, 135, 8640, 8640, 8640, 135, 8640, 66, 135, 135, 135, 8640, 66, 66, 8640, 66, 8640, 66, 66, 135, 66, 135, 8640, 66, 66, 135, 66, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 66, 8640, 8640, 8640, 135, 135, 66, 66, 66, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 66, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 135, 66, 66, 135, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 8640, 135, 8640, 66, 66, 66, 135, 135, 135, 8640, 8640, 135, 8640, 66, 135, 135, 66, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 477213 . Total input tokens: 106497215 . Total output tokens: 95530772
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.21377278806176,
    "estimated_duration": 3600.0597502954524,
    "input_throughput": 5652.818400675117,
    "output_throughput": 5038.479708152447,
    "total_throughput": 10691.298108827563,
    "itl": 100.76578585051999,
    "ttft": 1513716.0821021665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 158932,
    "finished_requests": 82286,
    "scheduler_time": 39.4155175492895
}
#Debug simulation 
Total elapsed time: 6.213876978028566. Arrivals time: 0.2551734265871346 Scheduler time: 5.789628975559026 Scheduler overhead time: 0.052108524134382606 Adapter cache time: 0.03732105914968997 Engine time: 0.05487178370822221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.653122923919,
    "estimated_duration": 3600.0728045384426,
    "input_throughput": 6201.225978501349,
    "output_throughput": 5501.275411717445,
    "total_throughput": 11702.501390218795,
    "itl": 156.49774439222264,
    "ttft": 1395078.038197078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 158306,
    "finished_requests": 90133,
    "scheduler_time": 59.398303171293286
}
#Debug simulation 
Total elapsed time: 6.6532248120056465. Arrivals time: 0.2661960704717785 Scheduler time: 6.2690020223381 Scheduler overhead time: 0.03545320965349674 Adapter cache time: 0.02836186357308179 Engine time: 0.03743969090282917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.642965434934013,
    "estimated_duration": 3600.142474409741,
    "input_throughput": 6201.1059725241175,
    "output_throughput": 5501.168951166887,
    "total_throughput": 11702.274923691004,
    "itl": 156.49831222613963,
    "ttft": 1395127.615419941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 158306,
    "finished_requests": 90133,
    "scheduler_time": 59.39924019676547
}
#Debug simulation 
Total elapsed time: 6.643130654934794. Arrivals time: 0.2671408196911216 Scheduler time: 6.257446789648384 Scheduler overhead time: 0.03545212571043521 Adapter cache time: 0.028509427676908672 Engine time: 0.03772089630365372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.267375339986756,
    "estimated_duration": 3600.0812515811367,
    "input_throughput": 5714.272418425266,
    "output_throughput": 5088.805979574461,
    "total_throughput": 10803.078397999727,
    "itl": 99.79797251355079,
    "ttft": 1498773.1229021824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 158306,
    "finished_requests": 83093,
    "scheduler_time": 40.03188266596048
}
#Debug simulation 
Total elapsed time: 6.267476263921708. Arrivals time: 0.2515425835736096 Scheduler time: 5.849638502229936 Scheduler overhead time: 0.0523448969470337 Adapter cache time: 0.03376165556255728 Engine time: 0.055345190688967705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.647956055006944,
    "estimated_duration": 3600.0966212080702,
    "input_throughput": 6201.184953893969,
    "output_throughput": 5501.239017677842,
    "total_throughput": 11702.42397157181,
    "itl": 156.49823933325405,
    "ttft": 1395093.1326066703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 158306,
    "finished_requests": 90133,
    "scheduler_time": 59.39919384258048
}
#Debug simulation 
Total elapsed time: 6.648091029957868. Arrivals time: 0.26424045604653656 Scheduler time: 6.265509056393057 Scheduler overhead time: 0.03553274378646165 Adapter cache time: 0.028590688831172884 Engine time: 0.03742347995284945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.2663446959340945,
    "estimated_duration": 3600.048122331025,
    "input_throughput": 5714.325003711275,
    "output_throughput": 5088.78392107101,
    "total_throughput": 10803.108924782284,
    "itl": 99.79666408185709,
    "ttft": 1498780.954503457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 158306,
    "finished_requests": 83093,
    "scheduler_time": 40.029931628333784
}
#Debug simulation 
Total elapsed time: 6.266445184941404. Arrivals time: 0.25553405890241265 Scheduler time: 5.844648286001757 Scheduler overhead time: 0.0522168583702296 Adapter cache time: 0.03398893459234387 Engine time: 0.05517424107529223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.628730042022653,
    "estimated_duration": 3600.134627609208,
    "input_throughput": 6201.354479575712,
    "output_throughput": 5501.358434796257,
    "total_throughput": 11702.712914371969,
    "itl": 156.49444280280792,
    "ttft": 1395089.0148544556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 158306,
    "finished_requests": 90135,
    "scheduler_time": 59.399837262450795
}
#Debug simulation 
Total elapsed time: 6.628836326068267. Arrivals time: 0.27035373065155 Scheduler time: 6.240426771109924 Scheduler overhead time: 0.035437000915408134 Adapter cache time: 0.028490612749010324 Engine time: 0.03737263847142458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 135, 33, 33, 33, 8640, 33, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 8640, 8640, 135, 135, 135, 8640, 8640, 33, 8640, 135, 8640, 8640, 8640, 135, 8640, 33, 135, 135, 135, 8640, 33, 33, 8640, 33, 8640, 33, 33, 135, 33, 135, 8640, 33, 33, 135, 33, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 33, 8640, 8640, 8640, 135, 135, 33, 33, 33, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 33, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 135, 33, 33, 135, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 8640, 135, 8640, 33, 33, 33, 135, 135, 135, 8640, 8640, 135, 8640, 33, 135, 135, 33, 8640, 8640, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 135, 8640, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 475464 . Total input tokens: 106102088 . Total output tokens: 95186808
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.294629355077632,
    "estimated_duration": 3600.065572752279,
    "input_throughput": 5714.2261951281225,
    "output_throughput": 5088.758698912897,
    "total_throughput": 10802.98489404102,
    "itl": 99.79753123823888,
    "ttft": 1498767.0208029414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 158306,
    "finished_requests": 83092,
    "scheduler_time": 40.02908798414754
}
#Debug simulation 
Total elapsed time: 6.294740758021362. Arrivals time: 0.26023387163877487 Scheduler time: 5.867805259185843 Scheduler overhead time: 0.052434061421081424 Adapter cache time: 0.03378442139364779 Engine time: 0.05555190332233906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.821566439932212,
    "estimated_duration": 3600.006420189718,
    "input_throughput": 6451.092661878117,
    "output_throughput": 5687.654023383922,
    "total_throughput": 12138.74668526204,
    "itl": 150.55552024845625,
    "ttft": 1339659.245474015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 157137,
    "finished_requests": 93583,
    "scheduler_time": 61.576651692745195
}
#Debug simulation 
Total elapsed time: 6.821704908972606. Arrivals time: 0.2690490933600813 Scheduler time: 6.437361073214561 Scheduler overhead time: 0.036603639367967844 Adapter cache time: 0.02263725211378187 Engine time: 0.038750019506551325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.820130133070052,
    "estimated_duration": 3600.1024797055497,
    "input_throughput": 6451.171634952889,
    "output_throughput": 5687.568649899851,
    "total_throughput": 12138.74028485274,
    "itl": 150.55731176002115,
    "ttft": 1339644.8581695058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 157137,
    "finished_requests": 93585,
    "scheduler_time": 61.577515314569524
}
#Debug simulation 
Total elapsed time: 6.820231962017715. Arrivals time: 0.2661621362203732 Scheduler time: 6.4393422530265525 Scheduler overhead time: 0.03655565483495593 Adapter cache time: 0.02216842770576477 Engine time: 0.03872412326745689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.389093112084083,
    "estimated_duration": 3600.006768125956,
    "input_throughput": 5888.011708109758,
    "output_throughput": 5205.246880620411,
    "total_throughput": 11093.258588730168,
    "itl": 97.37897546038076,
    "ttft": 1457383.412542622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 157137,
    "finished_requests": 85399,
    "scheduler_time": 41.26362326980423
}
#Debug simulation 
Total elapsed time: 6.389192060101777. Arrivals time: 0.26323346327990294 Scheduler time: 5.965665855794214 Scheduler overhead time: 0.053312223753891885 Adapter cache time: 0.025325773283839226 Engine time: 0.056426602066494524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.845940612955019,
    "estimated_duration": 3600.02671697259,
    "input_throughput": 6451.056290918305,
    "output_throughput": 5687.621956655578,
    "total_throughput": 12138.678247573884,
    "itl": 150.55603997360322,
    "ttft": 1339668.7578515639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 157137,
    "finished_requests": 93583,
    "scheduler_time": 61.57669891917228
}
#Debug simulation 
Total elapsed time: 6.846072981948964. Arrivals time: 0.2842436827486381 Scheduler time: 6.447351696551777 Scheduler overhead time: 0.036687579355202615 Adapter cache time: 0.021873725345358253 Engine time: 0.0386159080080688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.414094647043385,
    "estimated_duration": 3600.0474631038524,
    "input_throughput": 5887.945149957742,
    "output_throughput": 5205.1880404498515,
    "total_throughput": 11093.133190407594,
    "itl": 97.38099613420596,
    "ttft": 1457316.2894425695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 157137,
    "finished_requests": 85399,
    "scheduler_time": 41.26468406347394
}
#Debug simulation 
Total elapsed time: 6.41420521796681. Arrivals time: 0.2657103387173265 Scheduler time: 5.987582836300135 Scheduler overhead time: 0.053411953267641366 Adapter cache time: 0.025454232119955122 Engine time: 0.05640782217960805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.817185699008405,
    "estimated_duration": 3600.097403460649,
    "input_throughput": 6451.180731297639,
    "output_throughput": 5687.576669541578,
    "total_throughput": 12138.757400839217,
    "itl": 150.5552866521734,
    "ttft": 1339651.4041232057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 157137,
    "finished_requests": 93585,
    "scheduler_time": 61.57775522542109
}
#Debug simulation 
Total elapsed time: 6.817302803043276. Arrivals time: 0.2826629370683804 Scheduler time: 6.420078563503921 Scheduler overhead time: 0.036725317826494575 Adapter cache time: 0.021908654714934528 Engine time: 0.03867339878343046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 66, 33, 33, 33, 8640, 33, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 8640, 8640, 66, 66, 66, 8640, 8640, 33, 8640, 66, 8640, 8640, 8640, 66, 8640, 33, 66, 66, 66, 8640, 33, 33, 8640, 33, 8640, 33, 33, 66, 33, 66, 8640, 33, 33, 66, 33, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 33, 8640, 8640, 8640, 66, 66, 33, 33, 33, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 33, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 66, 33, 33, 66, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 8640, 66, 8640, 33, 33, 33, 66, 66, 66, 8640, 8640, 66, 8640, 33, 66, 66, 33, 8640, 8640, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 66, 8640, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 471807 . Total input tokens: 105279297 . Total output tokens: 94459900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.38776394398883,
    "estimated_duration": 3600.0128870666363,
    "input_throughput": 5888.199477328047,
    "output_throughput": 5205.256366531763,
    "total_throughput": 11093.455843859809,
    "itl": 97.37890043947606,
    "ttft": 1457365.5013492801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 157137,
    "finished_requests": 85400,
    "scheduler_time": 41.262696792083474
}
#Debug simulation 
Total elapsed time: 6.387859320966527. Arrivals time: 0.26483884092886 Scheduler time: 5.962735033128411 Scheduler overhead time: 0.053422923549078405 Adapter cache time: 0.025173538830131292 Engine time: 0.05636260693427175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.7473823060281575,
    "estimated_duration": 3600.2066771369373,
    "input_throughput": 4372.904783488681,
    "output_throughput": 3817.764709811188,
    "total_throughput": 8190.669493299868,
    "itl": 221.56482150845702,
    "ttft": 1549522.939616938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 106283,
    "finished_requests": 63111,
    "scheduler_time": 42.96635250264021
}
#Debug simulation 
Total elapsed time: 4.747485602041706. Arrivals time: 0.2060517253121361 Scheduler time: 4.4381895256228745 Scheduler overhead time: 0.02555317897349596 Adapter cache time: 0.03869576542638242 Engine time: 0.02692407020367682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.755895336973481,
    "estimated_duration": 3600.121956696354,
    "input_throughput": 4372.734643258021,
    "output_throughput": 3817.539840403573,
    "total_throughput": 8190.274483661594,
    "itl": 221.57858294413262,
    "ttft": 1549660.2680697222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 106283,
    "finished_requests": 63104,
    "scheduler_time": 42.96339499351926
}
#Debug simulation 
Total elapsed time: 4.7559970850124955. Arrivals time: 0.2011246430920437 Scheduler time: 4.451682755956426 Scheduler overhead time: 0.025624621659517288 Adapter cache time: 0.03849895822349936 Engine time: 0.02701836242340505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.67947005899623,
    "estimated_duration": 3600.0847416283814,
    "input_throughput": 4136.040140339849,
    "output_throughput": 3632.030337731903,
    "total_throughput": 7768.0704780717515,
    "itl": 138.21148620551836,
    "ttft": 1624086.4149898873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 106283,
    "finished_requests": 59735,
    "scheduler_time": 31.025082374816762
}
#Debug simulation 
Total elapsed time: 4.679568059043959. Arrivals time: 0.2008664180757478 Scheduler time: 4.293375390581787 Scheduler overhead time: 0.03875438775867224 Adapter cache time: 0.08699736918788403 Engine time: 0.04103331465739757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.755936169065535,
    "estimated_duration": 3600.0586788359415,
    "input_throughput": 4373.077886911143,
    "output_throughput": 3817.8397148915888,
    "total_throughput": 8190.917601802732,
    "itl": 221.56752204778903,
    "ttft": 1549563.636229178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 106283,
    "finished_requests": 63109,
    "scheduler_time": 42.96431690213357
}
#Debug simulation 
Total elapsed time: 4.756040211999789. Arrivals time: 0.21021277189720422 Scheduler time: 4.441399238654412 Scheduler overhead time: 0.02565214259084314 Adapter cache time: 0.0395117977168411 Engine time: 0.026981785078532994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.664434972917661,
    "estimated_duration": 3600.134708100275,
    "input_throughput": 4133.468107878789,
    "output_throughput": 3629.623627860105,
    "total_throughput": 7763.0917357388935,
    "itl": 138.28856515690356,
    "ttft": 1624733.6637619487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978164,
    "arrivals": 106283,
    "finished_requests": 59703,
    "scheduler_time": 30.99536167756396
}
#Debug simulation 
Total elapsed time: 4.664537486969493. Arrivals time: 0.19827157817780972 Scheduler time: 4.281776785268448 Scheduler overhead time: 0.03878273046575487 Adapter cache time: 0.08631633454933763 Engine time: 0.04095981561113149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.741221104981378,
    "estimated_duration": 3600.147187139824,
    "input_throughput": 4372.970654154689,
    "output_throughput": 3817.7902973238024,
    "total_throughput": 8190.760951478492,
    "itl": 221.56498989657524,
    "ttft": 1549542.9350873604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 106283,
    "finished_requests": 63110,
    "scheduler_time": 42.965857356195656
}
#Debug simulation 
Total elapsed time: 4.741322054993361. Arrivals time: 0.20136596157681197 Scheduler time: 4.436435550218448 Scheduler overhead time: 0.025651874719187617 Adapter cache time: 0.038685752428136766 Engine time: 0.027112815296277404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.652822618954815,
    "estimated_duration": 3600.1409213124753,
    "input_throughput": 4136.293641130919,
    "output_throughput": 3632.14782026724,
    "total_throughput": 7768.441461398159,
    "itl": 138.21179839645708,
    "ttft": 1624014.8115459324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 106283,
    "finished_requests": 59738,
    "scheduler_time": 31.027270762549676
}
#Debug simulation 
Total elapsed time: 4.652925294009037. Arrivals time: 0.19885768927633762 Scheduler time: 4.268948596669361 Scheduler overhead time: 0.0386553427670151 Adapter cache time: 0.0871070158900693 Engine time: 0.04099537874571979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.935864979983307,
    "estimated_duration": 3600.1771359951426,
    "input_throughput": 4552.498496846771,
    "output_throughput": 4003.6327257035964,
    "total_throughput": 8556.131222550368,
    "itl": 212.418428775725,
    "ttft": 1458768.0424843351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 101554,
    "finished_requests": 65893,
    "scheduler_time": 46.029099018644466
}
#Debug simulation 
Total elapsed time: 4.935961922979914. Arrivals time: 0.2054376007290557 Scheduler time: 4.6222418387187645 Scheduler overhead time: 0.026547088869847357 Adapter cache time: 0.04079581517726183 Engine time: 0.028266225708648562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.9535326599143445,
    "estimated_duration": 3600.14089326115,
    "input_throughput": 4552.381000054141,
    "output_throughput": 4003.595533435825,
    "total_throughput": 8555.976533489966,
    "itl": 212.41896124882584,
    "ttft": 1458803.9792652647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 101554,
    "finished_requests": 65891,
    "scheduler_time": 46.028414813964595
}
#Debug simulation 
Total elapsed time: 4.953630857984535. Arrivals time: 0.20627491432242095 Scheduler time: 4.639161073137075 Scheduler overhead time: 0.02648690587375313 Adapter cache time: 0.041341901291161776 Engine time: 0.027880036737769842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.834428069065325,
    "estimated_duration": 3600.07919660524,
    "input_throughput": 4317.108361020376,
    "output_throughput": 3808.185945722493,
    "total_throughput": 8125.294306742869,
    "itl": 132.74234724457406,
    "ttft": 1536403.0364823919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 101554,
    "finished_requests": 62508,
    "scheduler_time": 33.92764075939603
}
#Debug simulation 
Total elapsed time: 4.8345230660634115. Arrivals time: 0.2046794118359685 Scheduler time: 4.451486388687044 Scheduler overhead time: 0.04006123193539679 Adapter cache time: 0.07668159354943782 Engine time: 0.04253622703254223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.952722863992676,
    "estimated_duration": 3600.1975110470744,
    "input_throughput": 4552.472732317739,
    "output_throughput": 4003.6100674398617,
    "total_throughput": 8556.082799757602,
    "itl": 212.41689639494783,
    "ttft": 1458773.2993791222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 101554,
    "finished_requests": 65893,
    "scheduler_time": 46.02919087844188
}
#Debug simulation 
Total elapsed time: 4.952830675989389. Arrivals time: 0.20491446915548295 Scheduler time: 4.63959642755799 Scheduler overhead time: 0.02659569529350847 Adapter cache time: 0.04107260669115931 Engine time: 0.02806101052556187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.849340694025159,
    "estimated_duration": 3600.0754160027923,
    "input_throughput": 4317.113172383593,
    "output_throughput": 3808.2216108745447,
    "total_throughput": 8125.3347832581385,
    "itl": 132.74822845897899,
    "ttft": 1536391.0497298553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 101554,
    "finished_requests": 62509,
    "scheduler_time": 33.92686463024987
}
#Debug simulation 
Total elapsed time: 4.849435413023457. Arrivals time: 0.20545500423759222 Scheduler time: 4.466209520585835 Scheduler overhead time: 0.04002838092856109 Adapter cache time: 0.07589088613167405 Engine time: 0.04282971960492432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.952129400917329,
    "estimated_duration": 3600.084772123291,
    "input_throughput": 4552.451966383508,
    "output_throughput": 4003.6579448375237,
    "total_throughput": 8556.109911221032,
    "itl": 212.41696337124665,
    "ttft": 1458787.9672717834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 101554,
    "finished_requests": 65891,
    "scheduler_time": 46.027426903361075
}
#Debug simulation 
Total elapsed time: 4.952254702919163. Arrivals time: 0.20547294698189944 Scheduler time: 4.6379803327145055 Scheduler overhead time: 0.026676457026042044 Adapter cache time: 0.041424450813792646 Engine time: 0.02812882058788091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.817324936040677,
    "estimated_duration": 3600.0944341665972,
    "input_throughput": 4317.117310173531,
    "output_throughput": 3808.241214420754,
    "total_throughput": 8125.358524594285,
    "itl": 132.7485508943255,
    "ttft": 1536412.741296667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 101554,
    "finished_requests": 62509,
    "scheduler_time": 33.926328256973086
}
#Debug simulation 
Total elapsed time: 4.817418714985251. Arrivals time: 0.20525993790943176 Scheduler time: 4.434913465753198 Scheduler overhead time: 0.040054508368484676 Adapter cache time: 0.07555518334265798 Engine time: 0.04261598305311054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.172714549000375,
    "estimated_duration": 3600.0168939604473,
    "input_throughput": 4763.805977902842,
    "output_throughput": 4197.618634888003,
    "total_throughput": 8961.424612790845,
    "itl": 202.93443007590326,
    "ttft": 1372897.7847677432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 99226,
    "finished_requests": 69070,
    "scheduler_time": 49.31775852958298
}
#Debug simulation 
Total elapsed time: 5.172820340958424. Arrivals time: 0.2143640264403075 Scheduler time: 4.8514810057822615 Scheduler overhead time: 0.027771627414040267 Adapter cache time: 0.03691722475923598 Engine time: 0.029209979344159365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.174642562982626,
    "estimated_duration": 3600.0235632324548,
    "input_throughput": 4763.796597098171,
    "output_throughput": 4197.508359204112,
    "total_throughput": 8961.304956302283,
    "itl": 202.93654999903202,
    "ttft": 1372971.7224629351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 99226,
    "finished_requests": 69068,
    "scheduler_time": 49.317037523409745
}
#Debug simulation 
Total elapsed time: 5.174751900951378. Arrivals time: 0.21414426725823432 Scheduler time: 4.853281882591546 Scheduler overhead time: 0.02780523814726621 Adapter cache time: 0.03694241843186319 Engine time: 0.029503261437639594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.013682101969607,
    "estimated_duration": 3600.129347358208,
    "input_throughput": 4471.7815519082715,
    "output_throughput": 3949.2322714552047,
    "total_throughput": 8421.013823363475,
    "itl": 126.33376272287053,
    "ttft": 1471940.3155676909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 99226,
    "finished_requests": 64776,
    "scheduler_time": 35.969717453122215
}
#Debug simulation 
Total elapsed time: 5.01378273696173. Arrivals time: 0.20868060074280947 Scheduler time: 4.627756655681878 Scheduler overhead time: 0.04200445953756571 Adapter cache time: 0.0708300321130082 Engine time: 0.044540327857248485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.143038620008156,
    "estimated_duration": 3600.2056882043457,
    "input_throughput": 4763.135355344918,
    "output_throughput": 4196.781325440316,
    "total_throughput": 8959.916680785234,
    "itl": 202.99306154977353,
    "ttft": 1373145.035836678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 99226,
    "finished_requests": 69056,
    "scheduler_time": 49.302196542818415
}
#Debug simulation 
Total elapsed time: 5.143141882028431. Arrivals time: 0.21293308632448316 Scheduler time: 4.8219426478026435 Scheduler overhead time: 0.027709429268725216 Adapter cache time: 0.03785960527602583 Engine time: 0.02962403220590204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.014533048961312,
    "estimated_duration": 3600.128808605996,
    "input_throughput": 4469.106761274454,
    "output_throughput": 3947.434037923421,
    "total_throughput": 8416.540799197875,
    "itl": 126.80317984759989,
    "ttft": 1472596.325895802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 99226,
    "finished_requests": 64747,
    "scheduler_time": 36.01962572965695
}
#Debug simulation 
Total elapsed time: 5.014631532947533. Arrivals time: 0.21071463800035417 Scheduler time: 4.628719998174347 Scheduler overhead time: 0.041980445152148604 Adapter cache time: 0.06889766617678106 Engine time: 0.04445616586599499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.1601950380718336,
    "estimated_duration": 3600.2189135608614,
    "input_throughput": 4763.82837038003,
    "output_throughput": 4197.532250907812,
    "total_throughput": 8961.360621287842,
    "itl": 202.93461240074328,
    "ttft": 1372886.7841110372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 99226,
    "finished_requests": 69073,
    "scheduler_time": 49.319755180379794
}
#Debug simulation 
Total elapsed time: 5.160311651066877. Arrivals time: 0.21927642775699496 Scheduler time: 4.83300966816023 Scheduler overhead time: 0.02774660289287567 Adapter cache time: 0.03782253211829811 Engine time: 0.029395439894869924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.023442051024176,
    "estimated_duration": 3600.0485197945695,
    "input_throughput": 4472.136670235409,
    "output_throughput": 3949.322605466248,
    "total_throughput": 8421.459275701658,
    "itl": 127.1669151035793,
    "ttft": 1471824.1097879284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 99226,
    "finished_requests": 64779,
    "scheduler_time": 36.125405949455235
}
#Debug simulation 
Total elapsed time: 5.023574589053169. Arrivals time: 0.21282843651715666 Scheduler time: 4.636637921095826 Scheduler overhead time: 0.04173105920199305 Adapter cache time: 0.06797514436766505 Engine time: 0.04440059862099588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.302541920915246,
    "estimated_duration": 3600.1027030924793,
    "input_throughput": 4946.106672096957,
    "output_throughput": 4357.887064311617,
    "total_throughput": 9303.993736408573,
    "itl": 195.35144515868538,
    "ttft": 1289730.2983658079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 98086,
    "finished_requests": 71679,
    "scheduler_time": 52.70092345434145
}
#Debug simulation 
Total elapsed time: 5.302641151938587. Arrivals time: 0.21204753790516406 Scheduler time: 4.989352840697393 Scheduler overhead time: 0.028869890375062823 Adapter cache time: 0.02821068500634283 Engine time: 0.030583908432163298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.323097064043395,
    "estimated_duration": 3600.1880610268036,
    "input_throughput": 4946.586316638367,
    "output_throughput": 4358.134279109034,
    "total_throughput": 9304.720595747402,
    "itl": 195.34146485201046,
    "ttft": 1289657.774617441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 98086,
    "finished_requests": 71685,
    "scheduler_time": 52.70677541033327
}
#Debug simulation 
Total elapsed time: 5.323191980016418. Arrivals time: 0.21613712166436017 Scheduler time: 5.005321479169652 Scheduler overhead time: 0.028927872539497912 Adapter cache time: 0.028348210733383894 Engine time: 0.030643816222436726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.11212957999669,
    "estimated_duration": 3600.1314077483567,
    "input_throughput": 4599.9134821462985,
    "output_throughput": 4064.5549683287613,
    "total_throughput": 8664.46845047506,
    "itl": 124.36700274528417,
    "ttft": 1406025.0746558718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 98086,
    "finished_requests": 66633,
    "scheduler_time": 38.7449733761641
}
#Debug simulation 
Total elapsed time: 5.1122360590379685. Arrivals time: 0.2279211028944701 Scheduler time: 4.719951883540489 Scheduler overhead time: 0.04253778723068535 Adapter cache time: 0.05611804220825434 Engine time: 0.0454369243234396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3290883409790695,
    "estimated_duration": 3600.05991156348,
    "input_throughput": 4946.5987893146175,
    "output_throughput": 4358.261636036481,
    "total_throughput": 9304.860425351098,
    "itl": 195.33959129437144,
    "ttft": 1289526.2594755655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 98086,
    "finished_requests": 71683,
    "scheduler_time": 52.706210279040576
}
#Debug simulation 
Total elapsed time: 5.32921172992792. Arrivals time: 0.212469978723675 Scheduler time: 5.015489514102228 Scheduler overhead time: 0.02873067033942789 Adapter cache time: 0.028521297150291502 Engine time: 0.03040183545090258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.115488582989201,
    "estimated_duration": 3600.0700857877164,
    "input_throughput": 4599.36323611239,
    "output_throughput": 4064.5111487595714,
    "total_throughput": 8663.87438487196,
    "itl": 124.3694143516594,
    "ttft": 1406139.103788817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 98086,
    "finished_requests": 66628,
    "scheduler_time": 38.746712817088
}
#Debug simulation 
Total elapsed time: 5.115589331020601. Arrivals time: 0.21320865722373128 Scheduler time: 4.737417647847906 Scheduler overhead time: 0.04292762069962919 Adapter cache time: 0.05630925495643169 Engine time: 0.04535008070524782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.333478579064831,
    "estimated_duration": 3600.017217771418,
    "input_throughput": 4946.1438440071925,
    "output_throughput": 4357.783602410568,
    "total_throughput": 9303.92744641776,
    "itl": 195.34948422385114,
    "ttft": 1289775.117132217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 98086,
    "finished_requests": 71677,
    "scheduler_time": 52.699211558165224
}
#Debug simulation 
Total elapsed time: 5.333578477031551. Arrivals time: 0.21473667526151985 Scheduler time: 5.0179432524601 Scheduler overhead time: 0.028667113510891795 Adapter cache time: 0.02814121136907488 Engine time: 0.030533044366165996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.1138789899414405,
    "estimated_duration": 3600.016862783248,
    "input_throughput": 4599.833176113937,
    "output_throughput": 4064.5759610934924,
    "total_throughput": 8664.409137207429,
    "itl": 124.36581756793318,
    "ttft": 1406124.5000419568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 98086,
    "finished_requests": 66631,
    "scheduler_time": 38.74566373653728
}
#Debug simulation 
Total elapsed time: 5.113972648978233. Arrivals time: 0.21314084122423083 Scheduler time: 4.737386808847077 Scheduler overhead time: 0.042593113030306995 Adapter cache time: 0.05523130402434617 Engine time: 0.045334889204241335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.45397686411161,
    "estimated_duration": 3600.1390244548347,
    "input_throughput": 5094.667699055715,
    "output_throughput": 4452.915537734706,
    "total_throughput": 9547.58323679042,
    "itl": 190.20736966930676,
    "ttft": 1186775.0339590472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 97521,
    "finished_requests": 73689,
    "scheduler_time": 54.395766041534046
}
#Debug simulation 
Total elapsed time: 5.454110214021057. Arrivals time: 0.21846027963329107 Scheduler time: 5.136811999953352 Scheduler overhead time: 0.029489330714568496 Adapter cache time: 0.024065493722446263 Engine time: 0.031360352761112154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.414708888973109,
    "estimated_duration": 3600.1109343720163,
    "input_throughput": 5094.707450507881,
    "output_throughput": 4452.950281876905,
    "total_throughput": 9547.657732384787,
    "itl": 190.20899637142483,
    "ttft": 1186724.7546448486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 97521,
    "finished_requests": 73689,
    "scheduler_time": 54.39562837792952
}
#Debug simulation 
Total elapsed time: 5.414812715025619. Arrivals time: 0.22601660899817944 Scheduler time: 5.0903418806847185 Scheduler overhead time: 0.029360500746406615 Adapter cache time: 0.0239330162294209 Engine time: 0.03116662206593901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.1776292390422896,
    "estimated_duration": 3600.102975164757,
    "input_throughput": 4691.238033052953,
    "output_throughput": 4120.870181309482,
    "total_throughput": 8812.108214362435,
    "itl": 122.76366970558577,
    "ttft": 1377819.9117257025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 97521,
    "finished_requests": 67925,
    "scheduler_time": 39.892414387493645
}
#Debug simulation 
Total elapsed time: 5.177732510957867. Arrivals time: 0.2252246313728392 Scheduler time: 4.7935230556176975 Scheduler overhead time: 0.04304898309055716 Adapter cache time: 0.04975574044510722 Engine time: 0.04567266919184476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.442283107084222,
    "estimated_duration": 3600.1786892644905,
    "input_throughput": 5094.781282577744,
    "output_throughput": 4452.9725837789465,
    "total_throughput": 9547.75386635669,
    "itl": 190.20611558145077,
    "ttft": 1186715.0095342784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 97521,
    "finished_requests": 73691,
    "scheduler_time": 54.396561850145446
}
#Debug simulation 
Total elapsed time: 5.442381483037025. Arrivals time: 0.21261007036082447 Scheduler time: 5.131275134743191 Scheduler overhead time: 0.02948561357334256 Adapter cache time: 0.023949563736096025 Engine time: 0.031204713857732713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.1893165779765695,
    "estimated_duration": 3600.090625097921,
    "input_throughput": 4691.144129056651,
    "output_throughput": 4120.812930812397,
    "total_throughput": 8811.957059869048,
    "itl": 122.76276583375957,
    "ttft": 1377813.784021838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 97521,
    "finished_requests": 67926,
    "scheduler_time": 39.89285993709095
}
#Debug simulation 
Total elapsed time: 5.1894132620655. Arrivals time: 0.2268160377861932 Scheduler time: 4.803226931719109 Scheduler overhead time: 0.04318472521845251 Adapter cache time: 0.04965173522941768 Engine time: 0.04593085637316108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.416859712917358,
    "estimated_duration": 3600.092089609924,
    "input_throughput": 5094.734118867313,
    "output_throughput": 4452.973590944169,
    "total_throughput": 9547.707709811482,
    "itl": 190.20744877621274,
    "ttft": 1186711.6875419943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 97521,
    "finished_requests": 73689,
    "scheduler_time": 54.395839056227175
}
#Debug simulation 
Total elapsed time: 5.416955314925872. Arrivals time: 0.21292271791025996 Scheduler time: 5.105321861221455 Scheduler overhead time: 0.029577462235465646 Adapter cache time: 0.02396179537754506 Engine time: 0.03124153765384108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.173154597985558,
    "estimated_duration": 3600.03937845428,
    "input_throughput": 4691.3659059061565,
    "output_throughput": 4120.988533844842,
    "total_throughput": 8812.354439751,
    "itl": 122.7610067070374,
    "ttft": 1377835.9345523517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 97521,
    "finished_requests": 67927,
    "scheduler_time": 39.892824289176346
}
#Debug simulation 
Total elapsed time: 5.173254812019877. Arrivals time: 0.21470011386554688 Scheduler time: 4.799665459431708 Scheduler overhead time: 0.043178327614441514 Adapter cache time: 0.04930090717971325 Engine time: 0.045879864832386374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.072712091961876,
    "estimated_duration": 3600.0751847617867,
    "input_throughput": 4659.904901711116,
    "output_throughput": 4087.6474086675867,
    "total_throughput": 8747.552310378702,
    "itl": 206.90643714209924,
    "ttft": 1295638.3715697285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 92215,
    "finished_requests": 67349,
    "scheduler_time": 49.70342573131364
}
#Debug simulation 
Total elapsed time: 5.072809788049199. Arrivals time: 0.20605075813364238 Scheduler time: 4.74122820107732 Scheduler overhead time: 0.02763081935700029 Adapter cache time: 0.05574681668076664 Engine time: 0.02922505885362625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.067246068967506,
    "estimated_duration": 3600.069473655119,
    "input_throughput": 4659.9122941278865,
    "output_throughput": 4087.653893261993,
    "total_throughput": 8747.566187389879,
    "itl": 206.90757389703177,
    "ttft": 1295640.813079653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 92215,
    "finished_requests": 67349,
    "scheduler_time": 49.70340782834391
}
#Debug simulation 
Total elapsed time: 5.067348673939705. Arrivals time: 0.2015438840026036 Scheduler time: 4.740685141063295 Scheduler overhead time: 0.027431680355221033 Adapter cache time: 0.05572277354076505 Engine time: 0.02906231884844601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.066192061058246,
    "estimated_duration": 3600.1347351544314,
    "input_throughput": 4511.895302524899,
    "output_throughput": 3972.1402258536796,
    "total_throughput": 8484.03552837858,
    "itl": 126.68056165014424,
    "ttft": 1388708.1107601386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 92215,
    "finished_requests": 65212,
    "scheduler_time": 39.5669654685823
}
#Debug simulation 
Total elapsed time: 5.066285741981119. Arrivals time: 0.20789051207248122 Scheduler time: 4.656565586104989 Scheduler overhead time: 0.04225880280137062 Adapter cache time: 0.0940389446914196 Engine time: 0.045405855402350426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.070473219966516,
    "estimated_duration": 3600.221027877556,
    "input_throughput": 4659.733630268257,
    "output_throughput": 4087.5668149395906,
    "total_throughput": 8747.300445207848,
    "itl": 206.91170618522176,
    "ttft": 1295686.795068683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 92215,
    "finished_requests": 67350,
    "scheduler_time": 49.70390490306413
}
#Debug simulation 
Total elapsed time: 5.070565784000792. Arrivals time: 0.20358321676030755 Scheduler time: 4.741320246481337 Scheduler overhead time: 0.02757699543144554 Adapter cache time: 0.05587431928142905 Engine time: 0.029325358453206718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.050090507953428,
    "estimated_duration": 3600.1214408479455,
    "input_throughput": 4511.778079401193,
    "output_throughput": 3972.154338391382,
    "total_throughput": 8483.932417792576,
    "itl": 126.67564084609894,
    "ttft": 1388793.8910573612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 92215,
    "finished_requests": 65211,
    "scheduler_time": 39.566501181303884
}
#Debug simulation 
Total elapsed time: 5.050185469910502. Arrivals time: 0.20671109145041555 Scheduler time: 4.64230735169258 Scheduler overhead time: 0.04213789652567357 Adapter cache time: 0.09415307734161615 Engine time: 0.04491542454343289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.062894850037992,
    "estimated_duration": 3600.022441541545,
    "input_throughput": 4659.973173060677,
    "output_throughput": 4087.707295985248,
    "total_throughput": 8747.680469045925,
    "itl": 206.90637878178677,
    "ttft": 1295598.0032006395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 92215,
    "finished_requests": 67349,
    "scheduler_time": 49.70345604707225
}
#Debug simulation 
Total elapsed time: 5.062988825025968. Arrivals time: 0.20199845742899925 Scheduler time: 4.735750647028908 Scheduler overhead time: 0.027601997600868344 Adapter cache time: 0.05553955247160047 Engine time: 0.0291729555465281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.069261018070392,
    "estimated_duration": 3600.13150503769,
    "input_throughput": 4511.765188930217,
    "output_throughput": 3972.082680865929,
    "total_throughput": 8483.847869796145,
    "itl": 126.67388229119364,
    "ttft": 1388809.46712034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 92215,
    "finished_requests": 65210,
    "scheduler_time": 39.56723041708276
}
#Debug simulation 
Total elapsed time: 5.0693550310097635. Arrivals time: 0.21158197708427906 Scheduler time: 4.65605524298735 Scheduler overhead time: 0.042740516597405076 Adapter cache time: 0.09356667706742883 Engine time: 0.04523335746489465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.261370802065358,
    "estimated_duration": 3600.0997051589543,
    "input_throughput": 4842.7514313052125,
    "output_throughput": 4286.7634965456045,
    "total_throughput": 9129.514927850818,
    "itl": 198.82883653890934,
    "ttft": 1063828.479788997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 89808,
    "finished_requests": 70349,
    "scheduler_time": 53.77875773722297
}
#Debug simulation 
Total elapsed time: 5.261468359036371. Arrivals time: 0.19515738741029054 Scheduler time: 4.94555524433963 Scheduler overhead time: 0.028580454061739147 Adapter cache time: 0.04834764765109867 Engine time: 0.030331602902151644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.28058910893742,
    "estimated_duration": 3600.105203651471,
    "input_throughput": 4842.744034901219,
    "output_throughput": 4286.75694930999,
    "total_throughput": 9129.500984211209,
    "itl": 198.8309498659545,
    "ttft": 1063837.4570824876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 89808,
    "finished_requests": 70349,
    "scheduler_time": 53.77850256024841
}
#Debug simulation 
Total elapsed time: 5.280681821983308. Arrivals time: 0.19659125513862818 Scheduler time: 4.963070901343599 Scheduler overhead time: 0.028527133050374687 Adapter cache time: 0.048685542307794094 Engine time: 0.03042057587299496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.223006875021383,
    "estimated_duration": 3600.1029980635444,
    "input_throughput": 4640.268072603943,
    "output_throughput": 4121.821238998363,
    "total_throughput": 8762.089311602305,
    "itl": 122.70703255763516,
    "ttft": 1225755.8429263295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 89808,
    "finished_requests": 67395,
    "scheduler_time": 43.39044455564496
}
#Debug simulation 
Total elapsed time: 5.2231023729546. Arrivals time: 0.2048210265347734 Scheduler time: 4.828189880819991 Scheduler overhead time: 0.04369614040479064 Adapter cache time: 0.07930796488653868 Engine time: 0.04637100745458156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.276398516027257,
    "estimated_duration": 3600.179183110782,
    "input_throughput": 4842.717018583326,
    "output_throughput": 4286.686638375885,
    "total_throughput": 9129.403656959212,
    "itl": 198.83081446597998,
    "ttft": 1063808.3932515155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 89808,
    "finished_requests": 70350,
    "scheduler_time": 53.779293589210404
}
#Debug simulation 
Total elapsed time: 5.276497946935706. Arrivals time: 0.203209153492935 Scheduler time: 4.952661429881118 Scheduler overhead time: 0.028512947726994753 Adapter cache time: 0.04814560245722532 Engine time: 0.03043867158703506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.221255925949663,
    "estimated_duration": 3600.108003305262,
    "input_throughput": 4640.261621224341,
    "output_throughput": 4121.8155084170585,
    "total_throughput": 8762.077129641399,
    "itl": 122.70762340297753,
    "ttft": 1225863.9987192734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 89808,
    "finished_requests": 67395,
    "scheduler_time": 43.38750067187099
}
#Debug simulation 
Total elapsed time: 5.221396986977197. Arrivals time: 0.2082571075297892 Scheduler time: 4.82302360702306 Scheduler overhead time: 0.04361975542269647 Adapter cache time: 0.07901576021686196 Engine time: 0.046738854609429836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.267809415003285,
    "estimated_duration": 3600.0050011090348,
    "input_throughput": 4842.744105807972,
    "output_throughput": 4286.713767132514,
    "total_throughput": 9129.457872940486,
    "itl": 198.82654939184593,
    "ttft": 1063846.2015092787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 89808,
    "finished_requests": 70348,
    "scheduler_time": 53.77694765067878
}
#Debug simulation 
Total elapsed time: 5.267908002017066. Arrivals time: 0.19894177687820047 Scheduler time: 4.948972231824882 Scheduler overhead time: 0.028543252614326775 Adapter cache time: 0.047960472758859396 Engine time: 0.030104794073849916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.219298665993847,
    "estimated_duration": 3600.0420577474906,
    "input_throughput": 4640.3466215204235,
    "output_throughput": 4121.891011819067,
    "total_throughput": 8762.23763333949,
    "itl": 122.70820673491993,
    "ttft": 1225854.2394356632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642182,
    "arrivals": 89808,
    "finished_requests": 67395,
    "scheduler_time": 43.3883647780398
}
#Debug simulation 
Total elapsed time: 5.219400600064546. Arrivals time: 0.2082189448410645 Scheduler time: 4.8208570692222565 Scheduler overhead time: 0.043543919804506004 Adapter cache time: 0.07954013673588634 Engine time: 0.04648314940277487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.4447562880814075,
    "estimated_duration": 3600.0398321072207,
    "input_throughput": 5037.7937039058415,
    "output_throughput": 4446.861075598012,
    "total_throughput": 9484.654779503853,
    "itl": 190.50629264066905,
    "ttft": 866924.9059083816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 88684,
    "finished_requests": 73106,
    "scheduler_time": 57.162825115580205
}
#Debug simulation 
Total elapsed time: 5.444857906084508. Arrivals time: 0.1989710315829143 Scheduler time: 5.127181602176279 Scheduler overhead time: 0.030571106588467956 Adapter cache time: 0.04151780402753502 Engine time: 0.03246656060218811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.450318617979065,
    "estimated_duration": 3600.1955047508914,
    "input_throughput": 5037.688641093654,
    "output_throughput": 4446.731011933675,
    "total_throughput": 9484.41965302733,
    "itl": 190.50628259974243,
    "ttft": 866931.6200950071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 88684,
    "finished_requests": 73107,
    "scheduler_time": 57.16524434951546
}
#Debug simulation 
Total elapsed time: 5.450455320999026. Arrivals time: 0.19427768781315535 Scheduler time: 5.138872764073312 Scheduler overhead time: 0.029694627737626433 Adapter cache time: 0.042078484199009836 Engine time: 0.031532261171378195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.341053485055454,
    "estimated_duration": 3600.0387633845116,
    "input_throughput": 4785.014310180667,
    "output_throughput": 4234.667736096185,
    "total_throughput": 9019.682046276852,
    "itl": 119.17824322697375,
    "ttft": 1073927.9242266219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 88684,
    "finished_requests": 69475,
    "scheduler_time": 46.388796608273054
}
#Debug simulation 
Total elapsed time: 5.341152516077273. Arrivals time: 0.2018895805813372 Scheduler time: 4.955760007724166 Scheduler overhead time: 0.04473748698364943 Adapter cache time: 0.06994118844158947 Engine time: 0.04765177343506366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.433400726062246,
    "estimated_duration": 3600.0524025941904,
    "input_throughput": 5037.776113184089,
    "output_throughput": 4446.845548265918,
    "total_throughput": 9484.621661450006,
    "itl": 190.50435716534562,
    "ttft": 866910.3549599692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 88684,
    "finished_requests": 73106,
    "scheduler_time": 57.16395580047478
}
#Debug simulation 
Total elapsed time: 5.433561819023453. Arrivals time: 0.19392447266727686 Scheduler time: 5.122917905449867 Scheduler overhead time: 0.0298001104965806 Adapter cache time: 0.04152626090217382 Engine time: 0.03136379213538021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.295036837924272,
    "estimated_duration": 3600.0264094102754,
    "input_throughput": 4785.031008375811,
    "output_throughput": 4234.791156017481,
    "total_throughput": 9019.822164393292,
    "itl": 119.17820415231428,
    "ttft": 1073918.7461961142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 88684,
    "finished_requests": 69476,
    "scheduler_time": 46.38938742543443
}
#Debug simulation 
Total elapsed time: 5.295131854945794. Arrivals time: 0.2072735398542136 Scheduler time: 4.903685477445833 Scheduler overhead time: 0.045204056543298066 Adapter cache time: 0.07000726379919797 Engine time: 0.04766127676703036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.444683220004663,
    "estimated_duration": 3600.119415808131,
    "input_throughput": 5037.682339192322,
    "output_throughput": 4446.762773952717,
    "total_throughput": 9484.445113145039,
    "itl": 190.50360563012924,
    "ttft": 866913.365303539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 88684,
    "finished_requests": 73106,
    "scheduler_time": 57.16446825560141
}
#Debug simulation 
Total elapsed time: 5.444790180074051. Arrivals time: 0.1981156577821821 Scheduler time: 5.128705334034748 Scheduler overhead time: 0.02981207857374102 Adapter cache time: 0.04267955245450139 Engine time: 0.031474325340241194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.331046906998381,
    "estimated_duration": 3600.0382030689802,
    "input_throughput": 4784.783112944633,
    "output_throughput": 4234.359231800606,
    "total_throughput": 9019.14234474524,
    "itl": 118.992545172427,
    "ttft": 1074436.1851309573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 88684,
    "finished_requests": 69471,
    "scheduler_time": 46.33912237373668
}
#Debug simulation 
Total elapsed time: 5.3311455809744075. Arrivals time: 0.20294920029118657 Scheduler time: 4.943732577259652 Scheduler overhead time: 0.044962415588088334 Adapter cache time: 0.06958825618494302 Engine time: 0.04870475851930678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.567254384979606,
    "estimated_duration": 3600.130584591326,
    "input_throughput": 5171.414081390445,
    "output_throughput": 4571.66111430603,
    "total_throughput": 9743.075195696474,
    "itl": 185.5502095940752,
    "ttft": 719745.3871558639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 88054,
    "finished_requests": 75249,
    "scheduler_time": 59.79325289250191
}
#Debug simulation 
Total elapsed time: 5.56735321204178. Arrivals time: 0.19466748519334942 Scheduler time: 5.261128453887068 Scheduler overhead time: 0.030467537231743336 Adapter cache time: 0.03460767539218068 Engine time: 0.03219556447584182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.570913114002906,
    "estimated_duration": 3600.102524433818,
    "input_throughput": 5171.454388768549,
    "output_throughput": 4571.696747049839,
    "total_throughput": 9743.151135818389,
    "itl": 185.5503494943923,
    "ttft": 719749.5117077687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 88054,
    "finished_requests": 75249,
    "scheduler_time": 59.79276683066047
}
#Debug simulation 
Total elapsed time: 5.571010375977494. Arrivals time: 0.19344429508782923 Scheduler time: 5.265662607969716 Scheduler overhead time: 0.030536819831468165 Adapter cache time: 0.03493721422273666 Engine time: 0.03218367847148329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.415060146944597,
    "estimated_duration": 3600.0243362679225,
    "input_throughput": 4863.008236813511,
    "output_throughput": 4320.546070564793,
    "total_throughput": 9183.554307378305,
    "itl": 117.20973277535526,
    "ttft": 973352.3019892944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 88054,
    "finished_requests": 70798,
    "scheduler_time": 48.54306499103679
}
#Debug simulation 
Total elapsed time: 5.415159118012525. Arrivals time: 0.21038336004130542 Scheduler time: 5.027095274883322 Scheduler overhead time: 0.045495291939005256 Adapter cache time: 0.06242407520767301 Engine time: 0.04827068152371794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.597574471961707,
    "estimated_duration": 3600.0127457989665,
    "input_throughput": 5171.412523948777,
    "output_throughput": 4571.61936973849,
    "total_throughput": 9743.031893687266,
    "itl": 185.5511712132373,
    "ttft": 719758.95034008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 88054,
    "finished_requests": 75247,
    "scheduler_time": 59.79069672608331
}
#Debug simulation 
Total elapsed time: 5.597673011943698. Arrivals time: 0.20832440711092204 Scheduler time: 5.277747904532589 Scheduler overhead time: 0.030547260772436857 Adapter cache time: 0.03453585016541183 Engine time: 0.03222507541067898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.428992628003471,
    "estimated_duration": 3600.0658773732025,
    "input_throughput": 4863.074898166673,
    "output_throughput": 4320.639268787338,
    "total_throughput": 9183.71416695401,
    "itl": 117.21052171203132,
    "ttft": 973291.3044874984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 88054,
    "finished_requests": 70799,
    "scheduler_time": 48.54587007483411
}
#Debug simulation 
Total elapsed time: 5.42910055606626. Arrivals time: 0.21209334814921021 Scheduler time: 5.039876818424091 Scheduler overhead time: 0.04555502883158624 Adapter cache time: 0.06161781831178814 Engine time: 0.04839649167843163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.579024164937437,
    "estimated_duration": 3600.034825288506,
    "input_throughput": 5171.3808069920615,
    "output_throughput": 4571.591331392487,
    "total_throughput": 9742.972138384548,
    "itl": 185.54820607763688,
    "ttft": 719790.0788445602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 88054,
    "finished_requests": 75247,
    "scheduler_time": 59.7910454517446
}
#Debug simulation 
Total elapsed time: 5.579130865982734. Arrivals time: 0.19698285532649606 Scheduler time: 5.270530928159133 Scheduler overhead time: 0.030388818704523146 Adapter cache time: 0.034546498442068696 Engine time: 0.03237006242852658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.406655088067055,
    "estimated_duration": 3599.9830753963083,
    "input_throughput": 4863.063973730689,
    "output_throughput": 4320.595590102243,
    "total_throughput": 9183.659563832933,
    "itl": 117.2073016358845,
    "ttft": 973287.3146861716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 88054,
    "finished_requests": 70798,
    "scheduler_time": 48.54313372979992
}
#Debug simulation 
Total elapsed time: 5.406782714999281. Arrivals time: 0.20692469051573426 Scheduler time: 5.0230678614461794 Scheduler overhead time: 0.045559139805845916 Adapter cache time: 0.06115032674279064 Engine time: 0.04842328222002834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.471954751992598,
    "estimated_duration": 3600.123990500864,
    "input_throughput": 5032.394175257129,
    "output_throughput": 4464.992050944236,
    "total_throughput": 9497.386226201366,
    "itl": 189.89231022460072,
    "ttft": 685489.2984691323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 85140,
    "finished_requests": 73290,
    "scheduler_time": 58.770330403796294
}
#Debug simulation 
Total elapsed time: 5.472110269009136. Arrivals time: 0.19083018647506833 Scheduler time: 5.1498536196304485 Scheduler overhead time: 0.030168203404173255 Adapter cache time: 0.055056227021850646 Engine time: 0.03209297056309879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.462579476996325,
    "estimated_duration": 3600.1466019861377,
    "input_throughput": 5032.362568236815,
    "output_throughput": 4464.964007613458,
    "total_throughput": 9497.326575850273,
    "itl": 189.89476950639974,
    "ttft": 685501.295838622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 85140,
    "finished_requests": 73290,
    "scheduler_time": 58.77033058515728
}
#Debug simulation 
Total elapsed time: 5.4626804270083085. Arrivals time: 0.18765907117631286 Scheduler time: 5.144690267276019 Scheduler overhead time: 0.02997112472075969 Adapter cache time: 0.054553447174839675 Engine time: 0.03171821229625493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.4349043789552525,
    "estimated_duration": 3600.0634228961894,
    "input_throughput": 4866.5389861119675,
    "output_throughput": 4337.782468131342,
    "total_throughput": 9204.321454243309,
    "itl": 116.75405719474203,
    "ttft": 833262.3313855366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 85140,
    "finished_requests": 70927,
    "scheduler_time": 50.55181044014547
}
#Debug simulation 
Total elapsed time: 5.435005342937075. Arrivals time: 0.1960100617725402 Scheduler time: 5.0446200425503775 Scheduler overhead time: 0.045941377291455865 Adapter cache time: 0.07759443030226976 Engine time: 0.04907501465640962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.482546955929138,
    "estimated_duration": 3600.1467841703034,
    "input_throughput": 5032.440088182515,
    "output_throughput": 4465.022112620503,
    "total_throughput": 9497.462200803018,
    "itl": 189.8890250879638,
    "ttft": 685436.1827239464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 85140,
    "finished_requests": 73291,
    "scheduler_time": 58.77144534263809
}
#Debug simulation 
Total elapsed time: 5.482670155004598. Arrivals time: 0.18580305890645832 Scheduler time: 5.153352847672068 Scheduler overhead time: 0.029801620286889374 Adapter cache time: 0.0548783567501232 Engine time: 0.044778017210774124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.437504171044566,
    "estimated_duration": 3600.00422811016,
    "input_throughput": 4866.2953957686095,
    "output_throughput": 4337.778794275947,
    "total_throughput": 9204.074190044557,
    "itl": 116.75598978143181,
    "ttft": 833328.9051213143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 85140,
    "finished_requests": 70924,
    "scheduler_time": 50.553078751702635
}
#Debug simulation 
Total elapsed time: 5.437602074001916. Arrivals time: 0.19420927367173135 Scheduler time: 5.050190912792459 Scheduler overhead time: 0.045748236356303096 Adapter cache time: 0.07686952746007591 Engine time: 0.048889554920606315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.4513712379848585,
    "estimated_duration": 3600.1839026236935,
    "input_throughput": 5032.38820294612,
    "output_throughput": 4464.9760775512805,
    "total_throughput": 9497.3642804974,
    "itl": 189.88810823437294,
    "ttft": 685438.9161211343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 85140,
    "finished_requests": 73291,
    "scheduler_time": 58.77195983791904
}
#Debug simulation 
Total elapsed time: 5.451475103967823. Arrivals time: 0.18603603565134108 Scheduler time: 5.134921859251335 Scheduler overhead time: 0.02990008343476802 Adapter cache time: 0.054891463136300445 Engine time: 0.031666811904869974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.43835615797434,
    "estimated_duration": 3600.1268172322216,
    "input_throughput": 4866.075249390303,
    "output_throughput": 4337.467204003982,
    "total_throughput": 9203.542453394286,
    "itl": 116.7548494227407,
    "ttft": 833417.2479373082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 85140,
    "finished_requests": 70923,
    "scheduler_time": 50.549616619525345
}
#Debug simulation 
Total elapsed time: 5.438452792004682. Arrivals time: 0.19405276596080512 Scheduler time: 5.05062541202642 Scheduler overhead time: 0.04585477360524237 Adapter cache time: 0.0774256985168904 Engine time: 0.048826997401192784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.685778020997532,
    "estimated_duration": 3600.1822507660795,
    "input_throughput": 5303.40095864235,
    "output_throughput": 4693.421283437656,
    "total_throughput": 9996.822242080005,
    "itl": 178.61909352983938,
    "ttft": 401359.2646901819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 83948,
    "finished_requests": 77082,
    "scheduler_time": 63.395815843648926
}
#Debug simulation 
Total elapsed time: 5.685915017966181. Arrivals time: 0.18646371341310441 Scheduler time: 5.372369296266697 Scheduler overhead time: 0.03166571061592549 Adapter cache time: 0.0474168099462986 Engine time: 0.03318641905207187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.699177326983772,
    "estimated_duration": 3600.0040341430636,
    "input_throughput": 5303.462945853263,
    "output_throughput": 4693.189463056189,
    "total_throughput": 9996.652408909451,
    "itl": 178.61915962727684,
    "ttft": 401490.2492914106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 83948,
    "finished_requests": 77077,
    "scheduler_time": 63.39277441173537
}
#Debug simulation 
Total elapsed time: 5.699338353006169. Arrivals time: 0.18452160409651697 Scheduler time: 5.387867948622443 Scheduler overhead time: 0.03155745298136026 Adapter cache time: 0.04724395601078868 Engine time: 0.03327609784901142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.626134471967816,
    "estimated_duration": 3600.112464280215,
    "input_throughput": 5064.68900094361,
    "output_throughput": 4504.768437350043,
    "total_throughput": 9569.457438293653,
    "itl": 112.22385101630309,
    "ttft": 615240.3245081585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 83948,
    "finished_requests": 73704,
    "scheduler_time": 54.757110168343445
}
#Debug simulation 
Total elapsed time: 5.626231104019098. Arrivals time: 0.19143362424802035 Scheduler time: 5.247719018603675 Scheduler overhead time: 0.04753346415236592 Adapter cache time: 0.06617962184827775 Engine time: 0.05081158934626728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.703856069012545,
    "estimated_duration": 3600.001088967647,
    "input_throughput": 5303.467284637697,
    "output_throughput": 4693.193302573426,
    "total_throughput": 9996.660587211123,
    "itl": 178.61620883506973,
    "ttft": 401485.79422856297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 83948,
    "finished_requests": 77077,
    "scheduler_time": 63.392765165927806
}
#Debug simulation 
Total elapsed time: 5.703955817967653. Arrivals time: 0.1826226944103837 Scheduler time: 5.393100205576047 Scheduler overhead time: 0.03167530405335128 Adapter cache time: 0.04792268818709999 Engine time: 0.03376800776459277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.611138247069903,
    "estimated_duration": 3600.1062359886996,
    "input_throughput": 5064.832481253821,
    "output_throughput": 4504.957614270499,
    "total_throughput": 9569.79009552432,
    "itl": 112.22344757409486,
    "ttft": 615169.6570748219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 83948,
    "finished_requests": 73706,
    "scheduler_time": 54.75824494514539
}
#Debug simulation 
Total elapsed time: 5.611263698083349. Arrivals time: 0.19253199035301805 Scheduler time: 5.231587964342907 Scheduler overhead time: 0.04760897043161094 Adapter cache time: 0.06609972834121436 Engine time: 0.05074953497387469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.690431050956249,
    "estimated_duration": 3600.0526478365787,
    "input_throughput": 5303.421329539037,
    "output_throughput": 4693.346918177346,
    "total_throughput": 9996.768247716383,
    "itl": 178.61504272516922,
    "ttft": 401405.14337992953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 83948,
    "finished_requests": 77079,
    "scheduler_time": 63.3935587385122
}
#Debug simulation 
Total elapsed time: 5.690535616013221. Arrivals time: 0.182257647276856 Scheduler time: 5.381021202658303 Scheduler overhead time: 0.03169108089059591 Adapter cache time: 0.047409953782334924 Engine time: 0.03333622217178345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.586366320028901,
    "estimated_duration": 3600.1158674459584,
    "input_throughput": 5064.5358847672405,
    "output_throughput": 4504.837787764188,
    "total_throughput": 9569.373672531428,
    "itl": 112.21343822762877,
    "ttft": 615281.6974587496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 83948,
    "finished_requests": 73704,
    "scheduler_time": 54.754718316469855
}
#Debug simulation 
Total elapsed time: 5.586462707957253. Arrivals time: 0.19256966386456043 Scheduler time: 5.207186573068611 Scheduler overhead time: 0.047517799539491534 Adapter cache time: 0.06603135808836669 Engine time: 0.050642333924770355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.805853590019979,
    "estimated_duration": 3600.1662216920595,
    "input_throughput": 5470.966835176516,
    "output_throughput": 4798.947030806788,
    "total_throughput": 10269.913865983302,
    "itl": 174.3950515460448,
    "ttft": 279242.0864288226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 83337,
    "finished_requests": 78584,
    "scheduler_time": 65.55658962116156
}
#Debug simulation 
Total elapsed time: 5.805952387047. Arrivals time: 0.17923991952557117 Scheduler time: 5.503972501959652 Scheduler overhead time: 0.03229172853752971 Adapter cache time: 0.041231883340515196 Engine time: 0.03407020773738623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.8209089720621705,
    "estimated_duration": 3600.192458929709,
    "input_throughput": 5470.926964236652,
    "output_throughput": 4798.912057367131,
    "total_throughput": 10269.839021603782,
    "itl": 174.39699372351845,
    "ttft": 279292.2771958722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 83337,
    "finished_requests": 78584,
    "scheduler_time": 65.55673428896502
}
#Debug simulation 
Total elapsed time: 5.821038695052266. Arrivals time: 0.17876967985648662 Scheduler time: 5.519366440363228 Scheduler overhead time: 0.03226239257492125 Adapter cache time: 0.0415008538402617 Engine time: 0.033987470204010606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.684799156966619,
    "estimated_duration": 3600.0661200334002,
    "input_throughput": 5186.540296050664,
    "output_throughput": 4565.5389240038485,
    "total_throughput": 9752.079220054513,
    "itl": 109.07870371702555,
    "ttft": 542213.5774478792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 83337,
    "finished_requests": 74480,
    "scheduler_time": 56.06571251451924
}
#Debug simulation 
Total elapsed time: 5.68489574897103. Arrivals time: 0.18926133902277797 Scheduler time: 5.312504463130608 Scheduler overhead time: 0.04866947664413601 Adapter cache time: 0.059502232237719 Engine time: 0.05175834882538766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.819121469045058,
    "estimated_duration": 3600.0876102520306,
    "input_throughput": 5470.971024124923,
    "output_throughput": 4799.008488238013,
    "total_throughput": 10269.979512362937,
    "itl": 174.3976912936558,
    "ttft": 279291.7198144369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 83337,
    "finished_requests": 78583,
    "scheduler_time": 65.55489998319995
}
#Debug simulation 
Total elapsed time: 5.819218861986883. Arrivals time: 0.18693869200069457 Scheduler time: 5.509582805098034 Scheduler overhead time: 0.03235724871046841 Adapter cache time: 0.041208226000890136 Engine time: 0.033990059164352715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.679130875039846,
    "estimated_duration": 3600.078558464847,
    "input_throughput": 5186.644318106851,
    "output_throughput": 4565.696479414894,
    "total_throughput": 9752.340797521745,
    "itl": 109.07524162347559,
    "ttft": 542129.1326319283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 83337,
    "finished_requests": 74482,
    "scheduler_time": 56.066936847318026
}
#Debug simulation 
Total elapsed time: 5.679242703015916. Arrivals time: 0.19361728033982217 Scheduler time: 5.303057412849739 Scheduler overhead time: 0.04868801333941519 Adapter cache time: 0.05898110650014132 Engine time: 0.0519123172853142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.831301762023941,
    "estimated_duration": 3600.168741604843,
    "input_throughput": 5470.963005811767,
    "output_throughput": 4798.943671817574,
    "total_throughput": 10269.906677629342,
    "itl": 174.3981836422881,
    "ttft": 279261.7299364171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 83337,
    "finished_requests": 78584,
    "scheduler_time": 65.55586879642189
}
#Debug simulation 
Total elapsed time: 5.83148811198771. Arrivals time: 0.18562829121947289 Scheduler time: 5.522902205935679 Scheduler overhead time: 0.032309810048900545 Adapter cache time: 0.04137337824795395 Engine time: 0.0340269390726462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.684089230955578,
    "estimated_duration": 3600.121114730885,
    "input_throughput": 5186.3719038784975,
    "output_throughput": 4565.313075926501,
    "total_throughput": 9751.684979804999,
    "itl": 109.07874414633872,
    "ttft": 542297.8097291571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 83337,
    "finished_requests": 74479,
    "scheduler_time": 56.06599145933169
}
#Debug simulation 
Total elapsed time: 5.684191867010668. Arrivals time: 0.19451428460888565 Scheduler time: 5.305705529288389 Scheduler overhead time: 0.048613584134727716 Adapter cache time: 0.06074571085628122 Engine time: 0.05171295371837914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.877928547095507,
    "estimated_duration": 3600.0650863713627,
    "input_throughput": 5597.466578114335,
    "output_throughput": 4878.950124122322,
    "total_throughput": 10476.416702236658,
    "itl": 148.16385369157004,
    "ttft": 53619.20568170703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 81595,
    "finished_requests": 80426,
    "scheduler_time": 67.25716043010142
}
#Debug simulation 
Total elapsed time: 5.87802518508397. Arrivals time: 0.17384531477000564 Scheduler time: 5.563782109413296 Scheduler overhead time: 0.03730668965727091 Adapter cache time: 0.04688426642678678 Engine time: 0.038744379533454776 
